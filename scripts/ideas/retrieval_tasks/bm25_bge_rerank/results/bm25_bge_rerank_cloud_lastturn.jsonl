{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00550-7-2005", "score": 0.7193405628204346, "text": "\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"}, {"document_id": "ibmcld_00513-7-2197", "score": 0.7076270580291748, "text": "\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databases"}, {"document_id": "ibmcld_00512-7-2158", "score": 0.6889686584472656, "text": "\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00612-7-2163", "score": 0.6750555634498596, "text": "\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https://www.ibm.com/cloud/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"}, {"document_id": "ibmcld_00576-7385-9302", "score": 0.6695342063903809, "text": "\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https://blog.cloudant.com/2018/05/24/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https://blog.cloudant.com/2019/05/10/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https://blog.cloudant.com/2019/04/08/Time-series-data-storage.html)", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-basics"}, {"document_id": "ibmcld_00512-1696-3972", "score": 0.6470240354537964, "text": "\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00580-7-1957", "score": 0.6438422799110413, "text": "\nLearning Center \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Learning Center offers a video series to help you learn to use IBM Cloudant. The videos start with the basics of using IBM Cloudant. Then the videos walk you through document structure, the API, indexing and querying, and include an Under the Hood topic that highlights the architecture that powers the service.\n\nYou can use the [playlist](https://www.youtube.com/embed/playlist?list=PLzpeuWUENMK3F93hGaS4ezGmlX4Bipt4S) to go through the courses, or navigate directly to the topic of your choosing.\n\n\n\n Introduction to IBM Cloudant video \n\nLearn about the IBM Cloudant 17-part video series that provides an overview of the IBM Cloudant database-as-a-service.\n\n\n\n* Introduction to IBM Cloudant video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 1 - What is IBM Cloudant?\n\nIBM Cloudant is a database, run as a service in the IBM Cloud\u00ae. Its job is to store your application's data securely and make it possible for you to retrieve it quickly and efficiently. IBM Cloudant's key features are shown in the following list:\n\nDatabase\n: Stores and retrieves data. More specifically, it is a JSON document store. JSON comes from JavaScript and represents simple objects in a universal file format.\n\nDocument\n: The unit of storage in IBM Cloudant. Documents are added, updated, and deleted in their entirety.\n\nHTTP API\n: Any IBM Cloudant operation can be achieved by using HTTPS. HTTP is the protocol that powers the World Wide Web and IBM Cloudant is a database that is built for the web. Most databases are hidden in a private network, inaccessible but to a handful of machines. The IBM Cloudant service sits (mainly) on the public internet where it can be accessed by anyone with an internet connection (and permission to do so).\n\nIBM Cloudant wasn't written entirely by IBM.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00460-10355-12276", "score": 0.64096999168396, "text": "\n: Introduce the Mango query operator, $keyMapMatch that offers the ability to make queries on the keys of a map.\n\nImprovements\n: Internal bug fixes.\n\nDatabase reporting\n: Report the database that was used for authentication for a GET /_session request, provided it is configured.\n\n\n\n\n\n\n\n September 2020 \n\n\n\n 1 September 2020 \n\nThe following changes were made in build 8162:\n\nImprovements\n: Internal bug fixes.\n\nDrilldown parameters\n: Drilldown parameters for text index searches can now be specified as a list of lists, which gives you the ability to avoid having to define it redundantly in a single query. Some languages don't have this facility.\n\ncouch_index server\n: The couch_index server doesn't crash and log errors in the following cases: If a design document is deleted while that index is building, or when a design document is added immediately after database creation.\n\nInvalid parameters\n: IBM Cloudant now checks for and reports invalid parameters on database creation.\n\n\n\n\n\n\n\n July 2020 \n\n\n\n 1 July 2020 \n\nThe following changes were made in build 8158:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n May 2020 \n\n\n\n 15 May 2020 \n\nThe following changes were made in build 8153:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n April 2020 \n\n\n\n 1 April 2020 \n\nThe following changes were made in build 8152:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n March 2020 \n\n\n\n 15 March 2020 \n\nThe following changes were made in build 8142:\n\nNew! Endpoints\n: New endpoints were added, so you can post multiple queries: POST /{db}/_all_docs/queries and POST /{db}/_design_docs/queries.\n\nMultiple queries\n: The ability to submit multiple queries against a view by using the POST to /{db}/_design/{ddoc}/_view/{view} with the ?queries option was replaced by the new queries endpoint. The same is true of the _all_docs and _design_docs endpoints. Specify a keys object when you POST to these endpoints.\n\ndisk_size and data_size fields", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_00580-20968-23077", "score": 0.6323119401931763, "text": "\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_06501-4100-5934", "score": 0.6290208101272583, "text": "\nAfter you connect to your deployment, you see a basic overview. Included is a simple summary of the cluster and the default databases. The cluster contains three nodes, the two data nodes and the third arbiter node, so it shows the three hosts and their replica set. Also shown is the current MongoDB version. Databases for MongoDB Standard uses the Community version while Databases for MongoDB EE uses the Enterprise version of the MongoDB database.\n\nNext, you see the default databases for your deployment, which all hold information related to the database instance. local holds replication data. config holds data for cluster operations. admin holds user authentication data. MongoDB Compass might not have access to all the data in these databases for permissions and security reasons.\n\nNow you can use MongoDB Compass to view any data you and your applications have stored in your deployment. You can also use MongoDB Compass to create new databases, collections, and documents. Specific information can be found in the [MongoDB Compass documentation](https://docs.mongodb.com/compass/current/).\n\n\n\n\n\n Next Steps \n\n\n\n* For guidance on best practices, check out [Best Practices for MongoDB on the IBM Cloud](https://www.ibm.com/cloud/blog/best-practices-for-mongodb-on-the-ibm-cloud). If you are using MongoDB for the first time, see the [official MongoDB documentation](https://docs.mongodb.com/).\n* Connect to and manage your MongoDB database through the [MongoDB Shell](https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-connecting-cli-client) and explore the [OpsManager](https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-ops-manager) functions offered in Databases for MongoDB Enterprise Edition deployments.\n* Looking for more tools on managing your databases and data?", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-getting-started"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00580-4796-6846", "score": 0.6764156818389893, "text": "\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_03893-40670-42257", "score": 0.6648945808410645, "text": "\nYou don't need to include the entire set of available parameters in the JSON, only the advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if you want to deploy a peer and override the chaincode startup timeout and specify a different port for the statsd address, you would paste in the following JSON:\n\n{\n\"peer\": {\n\"chaincode\": {\n\"startuptimeout\": \"600s\"\n}\n},\n\"metrics\": {\n\"statsd\": {\n\"address\": \"127.0.0.1:9443\"\n}\n}\n}\n\n\n\n\n\n Modifying peer settings after deployment \n\nAfter a peer is deployed, a subset of the fields can be updated as well. Click the peer tile in the console and then the Settings icon to open a side panel. Click Edit configuration JSON (Advanced) to open the panel where you can override the peer settings. The JSON in the Current configuration box contains the current settings for the peer. Not all of these values can be overridden after the peer is deployed. A subset of these parameters can be overridden by pasting a JSON with the overrides into the Configuration JSON box. Again, you don't need to include the entire set of parameters from the Current configurationJSON, only paste the parameters you want to override into the Configuration JSON box.\n\nThe following subset of parameters can be overridden after a peer is deployed:\n\n{\n\"peer\": {\n\"id\": \"jdoe\",\n\"networkId\": \"dev\",\n\"keepalive\": {\n\"minInterval\": \"60s\",\n\"client\": {\n\"interval\": \"60s\",\n\"timeout\": \"20s\"\n},\n\"deliveryClient\": {\n\"interval\": \"60s\",\n\"timeout\": \"20s\"\n}\n},\n\"gossip\": {\n\"useLeaderElection\": true,\n\"orgLeader\": false,", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}, {"document_id": "ibmcld_00472-21040-23007", "score": 0.6540673971176147, "text": "\nhighlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes \n limit Limit the number of the returned documents to the specified number. For a grouped search, this parameter limits the number of documents per group. Yes Numeric The limit value can be any positive integer number up to and including 200. Yes \n q Abbreviation for query. Runs a Lucene query. No String or Number Yes \n query Runs a Lucene query. No String or Number Yes \n ranges This field defines ranges for faceted, numeric search fields. The value is a JSON object where the fields names are faceted numeric search fields, and the values of the fields are JSON objects. The field names of the JSON objects are names for ranges. The values are strings that describe the range, for example \"[0 TO 10]\". Yes JSON The value must be an object with fields that have objects as their values. These objects must have strings with ranges as their field values. No \n sort Specifies the sort order of the results. In a grouped search (when group_field is used), this parameter specifies the sort order within a group. The default sort order is relevance. Yes JSON A JSON string of the form \"fieldname<type>\" or -fieldname<type> for descending order. The fieldname is the name of a String or Number field, and type is either a number, a string, or a JSON array of strings. The type part is optional, and defaults to number. Some examples are \"foo\", \"-foo\", \"bar<string>\", \"-foo<number>\", and [\"-foo<number>\",\"bar<string>\"]. String fields that are used for sorting must not be analyzed fields.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}, {"document_id": "ibmcld_07046-11817-13746", "score": 0.6524196267127991, "text": "\nHowever, a different document ID was assigned to it and stored in the parent_document_id field. The assigned document ID is what was returned when you called the List documents method and is what had to be used as the document_id in the endpoint URL for a Delete document method request. When you used the Update document method to assign a new document_id, the original ID continued to be returned in query results. However, the assigned ID had to be used to delete the document. If you have an application that relies on the previous behavior, you can specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\nNotes about enhancing data:\n\n\n\n* You cannot apply prebuilt or user-trained Smart Document Understanding models to JSON files.\n* When you apply an enrichment to a field from the JSON file, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n* Only the first 50,000 characters of a custom field from a JSON file are enriched.\n* In project types where the Part of Speech (POS) enrichment is applied automatically, the enrichment is applied to the field that contains the bulk of the file content in the first JSON file that is added to the collection. This field is determined by the following rules:\n\n\n\n* If a field is named text, the POS enrichment is applied to it.\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_04826-8541-10194", "score": 0.64866042137146, "text": "\n* Optional: Specifies CACHING_DIRECTIVES for the request and reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentation information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) are applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-modified-since TIMESTAMP\n\n\n\n* Optional: Copies the object if its entity tag (ETag) is different than the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-none-match ETAG\n\n\n\n* Optional: Copies the object if it hasn't been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-unmodified-since TIMESTAMP\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",\n\"Date_to\": \"2019-11-09T16:00:00.000Z\",\n\"Sha256sum\": \"9e39dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx8ce6b68ede3a47\",", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage-cli-plugin?topic=cloud-object-storage-cli-plugin-ic-cos-cli"}, {"document_id": "ibmcld_04457-8541-10194", "score": 0.64866042137146, "text": "\n* Optional: Specifies CACHING_DIRECTIVES for the request and reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentation information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) are applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-modified-since TIMESTAMP\n\n\n\n* Optional: Copies the object if its entity tag (ETag) is different than the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-none-match ETAG\n\n\n\n* Optional: Copies the object if it hasn't been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-unmodified-since TIMESTAMP\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",\n\"Date_to\": \"2019-11-09T16:00:00.000Z\",\n\"Sha256sum\": \"9e39dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx8ce6b68ede3a47\",", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ic-cos-cli"}, {"document_id": "ibmcld_04981-8541-10194", "score": 0.64866042137146, "text": "\n* Optional: Specifies CACHING_DIRECTIVES for the request and reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentation information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) are applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: Copies the object if its entity tag (Etag) matches the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-match ETAG\n\n\n\n* Optional: Copies the object if it has been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-modified-since TIMESTAMP\n\n\n\n* Optional: Copies the object if its entity tag (ETag) is different than the specified tag (ETAG).\n\n\n\n* Flag: --copy-source-if-none-match ETAG\n\n\n\n* Optional: Copies the object if it hasn't been modified since the specified time (TIMESTAMP).\n\n\n\n* Flag: --copy-source-if-unmodified-since TIMESTAMP\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",\n\"Date_to\": \"2019-11-09T16:00:00.000Z\",\n\"Sha256sum\": \"9e39dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx8ce6b68ede3a47\",", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli"}, {"document_id": "ibmcld_03893-54294-56100", "score": 0.646124541759491, "text": "\n\"BroadcastTraceDir\": null,\n\"DeliverTraceDir\": null\n},\n\"Metrics\": {\n\"Provider\": \"disabled\",\n\"Statsd\": {\n\"Network\": \"udp\",\n\"Address\": \"127.0.0.1:8125\",\n\"WriteInterval\": \"30s\",\n\"Prefix\": null\n}\n}\n}\nShow more\n\n\n\n\n\n Providing your own customizations when you create an ordering service \n\nAfter you click Add ordering service on the nodes tab and step through the ordering service configuration panels, you can click Edit configuration JSON on the Summary panel to view and edit the JSON. Note that if you do not select any advanced options in the console, then the generated JSON is empty, but you can insert your own customizations.\n\nAlternatively, if you do check any of the advanced options when you configure the ordering service, those settings are included in the JSON on the Summary panel. Any edits that you make to theJSON override what was specified in the console. You can insert additional fields or modify the generated JSON. The overrides that are visible in the JSON on the Summary page are what is used to override the default settings when the ordering node is deployed. If you are deploying multiple ordering nodes, then the overrides are applied to each ordering node.\n\nYou don't need to include the entire set of available parameters in the JSON, only any advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if did not select any advanced options in the console and you want to deploy the ordering nodes with your own value for the ServerTimeout and the statsd address port, you would paste the following JSON into the Configuration JSON box:\n\n{\n\"General\": {\n\"Keepalive\": {\n\"ServerTimeout\": \"60s\"\n}\n},\n\"metrics\": {\n\"statsd\": {\n\"address\": \"127.0.0.1:9446\"\n}\n}\n}\n\n\n\n\n\n Modifying ordering node settings after deployment", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}, {"document_id": "ibmcld_03893-39361-41102", "score": 0.6445332765579224, "text": "\n\"format\": \"%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}\"\n}\n},\n\"metrics\": {\n\"provider\": \"disabled\",\n\"statsd\": {\n\"network\": \"udp\",\n\"address\": \"127.0.0.1:8125\",\n\"writeInterval\": \"10s\",\n\"prefix\": null\n}\n}\n}\nShow more\n\n\n\n\n\n Providing your own customizations when you create a peer \n\nAfter you click Create a peer on the nodes tab and step through the peer configuration panels, you can click Edit configuration on the Summary panel to view and edit the JSON. Note that if you do not select any advanced options in the console, then the generated JSON is empty, but you can still insert your own customizations.\n\nAlternatively, if you do check any of the advanced options when you configure the peer, those settings are included in the JSON on the Summary panel and can be additionally customized with other fields as needed. Any edits that you make will override what was specified in the console. For example, if you selected to use a LevelDB as the state database, but then overrode the setting to use CouchDB as the state database in the JSON, then the CouchDB database settings would be used when the peer is deployed. The override settings that are visible in the JSON on the Summary page are what is used when the peer is deployed.\n\nYou don't need to include the entire set of available parameters in the JSON, only the advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if you want to deploy a peer and override the chaincode startup timeout and specify a different port for the statsd address, you would paste in the following JSON:\n\n{\n\"peer\": {\n\"chaincode\": {\n\"startuptimeout\": \"600s\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}, {"document_id": "ibmcld_00472-19526-21520", "score": 0.643688440322876, "text": "\nIt differs from using \"fieldname:value\" in the q parameter only in that the values aren't analyzed. [Faceting](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. No JSON A JSON array that includes two elements: the field name and the value. Yes \n group_field Field by which to group search matches. Yes String A string that includes the name of a string field. Fields that include other data such as numbers, objects, or arrays can't be used. No \n group_limit Maximum group count. This field can be used only if group_field is specified. Yes Numeric No \n group_sort This field defines the order of the groups in a search that uses group_field. The default sort order is relevance. Yes JSON This field can have the same values as the sort field, so single fields and arrays of fields are supported. No \n highlight_fields Specifies which fields to highlight. If specified, the result object includes a highlights field with an entry for each specified field. Yes Array of strings Yes \n highlight_pre_tag A string that is inserted before the highlighted word in the highlights output. Yes, defaults to <em> String Yes \n highlight_post_tag A string that is inserted after the highlighted word in the highlights output. Yes, defaults to </em> String Yes \n highlight_number Number of fragments that are returned in highlights. If the search term exceeds the fragment size, then the entire search term is returned. Yes, defaults to 1 Numeric Yes \n highlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06968-15099-17180", "score": 0.6461834907531738, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/icons/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_07111-1693-3780", "score": 0.6442331075668335, "text": "\n* You can use any of the fields that are indexed by default. To see your choices, check the Fields to index list. Fields that have a Type value are stored in the index.\n* The number of segments per document is limited to 1,000. After segment number 999 is created, any remaining document content is stored within segment 1,000.\n* Metadata from PDF and Microsoft Word documents and any custom metadata is extracted and included in the index with each segment.\n\n\n\nBe careful with documents that contain repeating sections, such as a catalog that has a description and specifications section for each product entry. If you split the document at too granular a level, the subsections, such as a section with specification details, can be disassociated from the product to which it belongs.\n\nTo split the documents in a collection, complete the following steps:\n\n\n\n1. Click Manage collections from the navigation panel, and then click to open a collection.\n2. Open the Manage fields page.\n\nA list of the identified fields is displayed.\n3. From the Improve query results by splitting your documents section, click Split document.\n4. Choose the field that you want to use as your page break marker from the Select field dropdown.\n\nThe list that you can choose from includes a subset of all the identified fields.\n5. Click Apply changes and reprocess.\n\n\n\nYou can check the status of the splitting process from the Activity page.\n\nThe metadata field includes the parent document ID. Each resulting segment of the original document can contain different information. For example, if you split the document based on the subtitle field, the first segment might contain only a title field. The next segment might contain a subtitle and a text field. The third might contain a subtitle field, a text field, and a footer field.\n\n\n\n Updating documents that were split \n\nIf a document that was split changes and you want to upload the document again, work with a developer to replace the document by using the API. A developer can use the Update a document method to replace the original parent document.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-split-documents"}, {"document_id": "ibmcld_16358-7447-9162", "score": 0.6287714242935181, "text": "\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_16358-3407-5152", "score": 0.6217566728591919, "text": "\nSplitting the PDF creates two smaller files that can be enriched faster in Discovery.\n\n\n\n\n\n\n\n Step 2: Create a Document Retrieval project \n\nNow that you have the latest copy of the product documentation, add it to a Discovery project as your data source.\n\nIn Discovery, you will create a Document Retrieval project type. Documents that you add to a project of this type are automatically enriched in the following ways:\n\n\n\n* Entities, such as proper nouns, are identified and tagged.\n* Parts of speech are identified and tagged.\n\n\n\nThis tagged information is used later when a natural language phrase is submitted as a search query to return an accurate response.\n\n\n\n1. Open a new web browser page.\n2. From the Discovery Plus plan service page in IBM Cloud, click Launch Discovery.\n3. From the My Projects page, click New Project.\n4. Name your project Discovery documentation, and then click the Document Retrieval tile.\n\nZoom\n\n![Shows the project type options](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-new-project.png)\n\nFigure 1. Project type options\n5. Click Next.\n\n\n\nYou'll configure the data source for the project in the next step.\n\n\n\n\n\n Step 3: Upload data to the project \n\nAdd the documentation PDFs to your Discovery project.\n\n\n\n1. From the Select data source page, click the Upload data tile, and then click Next.\n\nZoom\n\n![Shows that the Upload data option is chosen from the data sources page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-data-source.png)\n\nFigure 2. Creating a collection from uploaded data\n2. Name the collection Discovery docs part 1, and then click Next.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_07224-1506-3498", "score": 0.6171159148216248, "text": "\nPNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text, if any, is extracted.\n\n\n\n\n\n Using the Smart Document Understanding editor \n\nThe SDU editor is only available for collections that contain supported document types and do not have the Element Classification enrichment applied. If you do not want to use the SDU editor, you can set up your configuration using the API, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\nThe SDU editor functions are only available in the Discovery tooling, they are not available in the API.\n\nNavigating the Smart Document Understanding editor:\n\nIf you did not yet create a Discovery instance and environment, see [Getting started](https://cloud.ibm.com/docs/discovery?topic=discovery-getting-started) for instructions.\n\n\n\n1. On the Manage Data screen, click Upload your own data, and create a new private collection in Discovery.\n2. Drag and drop documents into your collection, or click select documents to upload documents. After the upload is complete, this information displays:\n\n\n\n* The fields identified from your documents.\n* Enrichments applied to your documents. The Entity Extraction, Sentiment Analysis, Category Classification, and Concept Tagging enrichments are automatically applied to the text field by Discovery (unless you are importing documents using a connector). You can add (or remove) additional enrichments to the text (and other) fields.\n* Pre-built queries you can run immediately.\n\n\n\n3. Click Configure data on the upper right. On the Configure data screen, there are three tabs: Identify fields, Manage fields, and Enrich fields.\n\n\n\n* Identify fields contains the SDU editor.\n* Manage fields lists all indexed fields (all fields are indexed by default). Switch off any fields you do not want to index. For example, your PDFs might contain a running header or footer that does not contain useful information, so you can exclude those fields from the index.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sdu"}, {"document_id": "ibmcld_03054-7324-9318", "score": 0.6167803406715393, "text": "\nSelect the language of the files that you are adding to this collection.\n\nFor information about the languages supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n\nIf you are uploading a PDF document and want to extract party, nature, and category information from it, then expand the Advanced section and click Use the Default Contract Configuration with this collection.\n\n\n\n2. Click Next.\n3. Click Select documents to upload documents.\n\nSupported file types include PDF, HTML, JSON, Word, Excel, PowerPoint, PNG, TIFF, JPG, GIF, TXT, CSV, ZIP, GZIP, and TAR\n\nNo ongoing synchronization of uploaded documents is available. If you want to pick up changes that are made to a document, upload a later version of the document.\n\n\n\n\n\n2. Wait for the collection to be fully ingested.\n\nYour collection is added to a project that is created for you automatically. The project is a conversational search project with a name like Untitled Project 3; its sole purpose is to store your data collection.\n3. Find the project name in the page breadcrumb after your collection is created. Make a note of the project name in case you want to return to the collection from the Discovery application later.\n4. 1.5.0 only: If you want to add another collection to the project, click Manage collections, and then click New collection to add another collection.\n5. When the project contains all of the data collections that you want to use, click Back to Watson Assistant to finish creating the search skill.\n6. Select the project you just created from the list of projects, and then click Configure.\n\n\n\n\n\n Data collection creation example \n\nFor example, you might have a JSON file like this one:\n\n{\n\"Title\": \"About\",\n\"Shortdesc\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"Topics\": \"overview\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_16487-3110-5017", "score": 0.6058567762374878, "text": "\n* A .zip file that contains files in UIMA CAS XMI format\n\n\n\n\n\n CSV files \n\nYou can upload a two-column CSV file that contains sample text from your local machine. Upload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv![External link icon](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/icons/launch-glyph.svg)](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the .zip file that you downloaded.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"}, {"document_id": "ibmcld_07120-2825-4141", "score": 0.5991907715797424, "text": "\nGet a copy of the PDF so that you can upload it to your project. You can download the file from the [US Securities and Exchange Commission](https://www.sec.gov/tm/reports-and-publications/special-studies/algo_trading_report_2020) website.\n2. From the Select data source page, click Upload data, and then click Next.\n\nZoom\n\n![Shows the data source options.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-upload-data.png)\n\nFigure 2. Data source options\n3. In the Collection name field, add Algorithmic Trading PDF, and then click Next.\n\nZoom\n\n![Shows the collection name field](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-add-pdf.png)\n\nFigure 3. Uploaded data collection name field\n4. Drag the file that you downloaded to the page and drop it into the tile with the Drag and drop files here or upload link.\n\nZoom\n\n![Shows the tile where you drag the file that you want to upload.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-drag-file.png)\n\nFigure 4. File upload dialog\n5. Click Finish.\n\nYou add only one file. In a real scenario, you might upload multiple files with information about the same topic.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-sdu"}, {"document_id": "ibmcld_07132-3199-5135", "score": 0.5941956043243408, "text": "\n* The following file types can be ingested by Discovery, all other document types are ignored:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* JSON and HTML documents are supported by IBM Watson\u2122 Discovery, but can not be edited using the SDU editor. To change the configuration of HTML and JSON docs, you need to use the API. For more information, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\n** Individual image files (PNG, TIFF, JPG) are scanned and the text (if any) is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text (if any) extracted.\n\n\n\n* You cannot specify the data type (For example: text or date) of fields. During document ingestion, if a field is detected that does not yet exist in the index, Discovery automatically detects the data type of that field based on the value of the field for the first document indexed.\n* A document can fail to be ingested because of a type mismatch between data in the current document and similar data in a previously ingested document. For example, a field might be typed as a date in one document and a string in a subsequent document, preventing the subsequent document from being indexed correctly.\n* If you plan to use custom tokenization (currently only available for Japanese collections when using the Discovery API), the tokenization dictionary for your collection must be added before uploading documents.\n\n\n\n\n\n\n\n Uploading documents with the Discovery tooling \n\n\n\n1. Create a collection. See [Preparing the service for your documents](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicepreparing-the-service-for-your-documents).\n2. Click on the collection to open it.\n3. Click the Upload documents button and start uploading your documents via drag and drop or browse.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-addcontent"}, {"document_id": "ibmcld_16423-3286-5408", "score": 0.5906462073326111, "text": "\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15298-4-1840", "score": 0.6872776746749878, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Expanding file share capacity \n\nFor File Storage for VPC file shares, you can increase the file share size from its original capacity in GB increments up to 32,000 GB capacity, depending on your file share profile. This process doesn't require you to perform manual steps. For example, you don't need to migrate your data to a larger file share. The expansion operation causes no outage or lack of access to your storage.\n\nBilling for the file share is automatically updated to add the pro-rated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nIBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access.\n\n\n\n Expandable file share concepts \n\nYou can increase the capacity of the file share. The file share size cannot be less than the current file share size.\n\nCapacity can be increased for file shares that are in a stable state. Your user authorization is verified before the file share is expanded. You can use the [UI](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-ui), [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-cli), or [API](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-api) to increase file share capacity. You can expand a file share multiple times up to its [maximum capacity limit](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexp-share-capacity-IOPS-limitations). After you expanded the file share, you can't reduce the capacity.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacity"}, {"document_id": "ibmcld_07578-1268470-1270517", "score": 0.6866916418075562, "text": "\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1271119-1273166", "score": 0.6866916418075562, "text": "\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_06968-16615-18789", "score": 0.6858965158462524, "text": "\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_15298-2224-3803", "score": 0.683506429195404, "text": "\nFile shares that are created from an [IOPS tier profile](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profilesfs-tiers) can be expanded to the maximum size for its IOPS tier:\n\n\n\n* A general-purpose, 3 IOPS/GB profile can be expanded up to 32,000 GB.\n* A 5 IOPS/GB profile can be expanded up to 9,600 GB.\n* A 10 IOPS/GB profile can be expanded up to 4,800 GB.\n\n\n\nIOPS is automatically adjusted for tiered file share profiles, based on the size of the file share. For example, if you expand a share with a 5 IOPS/GB profile from 250 GB to 1,000 GB, it has a maximum IOPS of 5,000 IOPS (1,000 GB capacity x 5 IOPS). Because a 5 IOPS/GB file share can potentially expand to 9,600 GB, the max IOPS is adjusted to 48,000 IOPS. The capacity and the IOPS are immediately changed and you don't to restart the instance.\n\nYou can monitor the progress of your file share expansion from the UI or CLI. You can also use the [Activity Tracker](https://cloud.ibm.com/docs/vpc?topic=vpc-at-events) to verify that the file share was expanded. After a file share is expanded, you can't reduce capacity.\n\n\n\n\n\n Requirements \n\nThe file share must be in a stable state before you can request that the capacity is increased.\n\n\n\n\n\n Limitations \n\nThe following limitations apply to this release.\n\n\n\n* File shares can expand, with the following restrictions:\n\n\n\n* If the file share was created with a [Tiered IOPS profile](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profilesfs-tiers) that limits capacity to less than 32,000 GB, it can expand only to the allowed capacity for that tier.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacity"}, {"document_id": "ibmcld_15298-1247-2694", "score": 0.6825389862060547, "text": "\nYou can use the [UI](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-ui), [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-cli), or [API](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexpand-vpc-share-api) to increase file share capacity. You can expand a file share multiple times up to its [maximum capacity limit](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacityexp-share-capacity-IOPS-limitations). After you expanded the file share, you can't reduce the capacity.\n\nExpanded capacity is determined by the maximum that is allowed by the file share profile. File shares that are created from a [Custom](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profilescustom) profile or a [dp2](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profilesdp2-profile) profile can be expanded within the allowable IOPS range for that file share size.\n\nFile shares that are created from an [IOPS tier profile](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-profilesfs-tiers) can be expanded to the maximum size for its IOPS tier:\n\n\n\n* A general-purpose, 3 IOPS/GB profile can be expanded up to 32,000 GB.\n* A 5 IOPS/GB profile can be expanded up to 9,600 GB.\n* A 10 IOPS/GB profile can be expanded up to 4,800 GB.\n\n\n\nIOPS is automatically adjusted for tiered file share profiles, based on the size of the file share.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-expand-capacity"}, {"document_id": "ibmcld_10835-31243-32889", "score": 0.6795499324798584, "text": "\nSometimes, the resulting compressed file is larger than the maximum codeSize as described in the [Action Limits](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-limitslimits_actions) allowed by Cloud Functions. To reduce the size of the compressed file, select only the dependencies that you need, rather than selecting the entire virtualenv folder. The packages that you need can be found in the site-packages directory within the virtualenv folder. Note that you must also include the activate_this.py file from the bin directory of your virtualenv folder in your compressed file.\n\nzip -r pyjoke.zip virtualenv __main__.py\n8. Create an action called pyjoke by using the pyjoke.zip file. Make sure to use the --kind corresponding to the runtime image used to create the compressed action file. Otherwise, the action fails to execute during invoke.\n\nibmcloud fn action create pyjoke <file_path>/pyjoke.zip --kind python:3.11\n9. Invoke the action to test that the pyjoke module is working.\n\nibmcloud fn action invoke pyjoke --result\n\nExample output\n\n{\n\"joke\": \"A QA engineer walks into a bar. Runs into a bar. Crawls into a bar. Dances into a bar. Tiptoes into a bar. Rams a bar. Jumps into a bar.\"\n}\n\n\n\n\n\n\n\n Packaging large Python dependencies in a custom Docker image \n\nCloud Functions has a size limit for the app code, see maximum codeSize described in the [Action Limits](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-limitslimits_actions). However, you can install large packages and dependencies into a custom Docker image and deploy it with your app code when you create an action. You can then import the packages at run time.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-prep"}, {"document_id": "ibmcld_16420-7310-8898", "score": 0.6771848201751709, "text": "\n<br><br> * JSON file that you downloaded from a Knowledge Studio workspace.<br> * ZIP file that you downloaded from the Human Annotation Tool (HAT)<br><br><br> JSON To avoid visual overload for human annotation, define no more than 50 entity types and 50 relation types. File size limitation for uploading a type system: 20 MB \n Dictionary management Upload a CSV dictionary file in read-only mode or a ZIP of dictionaries that you downloaded from another workspace. Create a new dictionary, and then upload a CSV file of term entries or add term entries to it. Dictionary file:<br><br><br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries downloaded from another workspace<br><br><br><br>Term entries file:<br><br><br><br> * CSV file in UTF-8 format<br><br><br> <br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries to use in another workspace<br><br><br> File size limitations:<br><br><br><br> * 1 MB per CSV term entries file<br> * 16 MB per CSV read-only dictionary file<br> * 15,000 entries per dictionary, except a read-only dictionary<br> * 64 dictionaries per workspace<br><br><br> \n\n\n\n\n\n\n\n Machine learning model \n\nTable 2: Machine learning model\n\n\n\n Task Typical usage Supported input formats Supported output formats Limits and requirements \n\n Document management Upload a small, representative subset of documents Upload documents that contain annotations previously added by a human annotator, a machine learning model, or a UIMA analysis engine You cannot ingest the entire corpus from IBM Watson Explorer for calculating high value documents for annotation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-creating-a-workspace"}, {"document_id": "ibmcld_16483-7521-9109", "score": 0.6771848201751709, "text": "\n<br><br> * JSON file that you downloaded from a Knowledge Studio workspace.<br> * ZIP file that you downloaded from the Human Annotation Tool (HAT)<br><br><br> JSON To avoid visual overload for human annotation, define no more than 50 entity types and 50 relation types. File size limitation for uploading a type system: 20 MB \n Dictionary management Upload a CSV dictionary file in read-only mode or a ZIP of dictionaries that you downloaded from another workspace. Create a new dictionary, and then upload a CSV file of term entries or add term entries to it. Dictionary file:<br><br><br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries downloaded from another workspace<br><br><br><br>Term entries file:<br><br><br><br> * CSV file in UTF-8 format<br><br><br> <br><br> * CSV file in UTF-8 format<br> * ZIP of dictionaries to use in another workspace<br><br><br> File size limitations:<br><br><br><br> * 1 MB per CSV term entries file<br> * 16 MB per CSV read-only dictionary file<br> * 15,000 entries per dictionary, except a read-only dictionary<br> * 64 dictionaries per workspace<br><br><br> \n\n\n\n\n\n\n\n Machine learning model \n\nTable 2: Machine learning model\n\n\n\n Task Typical usage Supported input formats Supported output formats Limits and requirements \n\n Document management Upload a small, representative subset of documents Upload documents that contain annotations previously added by a human annotator, a machine learning model, or a UIMA analysis engine You cannot ingest the entire corpus from IBM Watson Explorer for calculating high value documents for annotation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-create-project"}, {"document_id": "ibmcld_01225-4-2021", "score": 0.6737706661224365, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Expanding File Share Capacity \n\nWith this feature, current users of IBM Cloud\u00ae File Storage for Classic are able to expand the size of their File Storage for Classic in GB increments up to 12 TB immediately. They don't need to create a duplicate or manually migrate data to a larger volume.\n\nBilling for the volume is automatically updated to add the pro-rated difference of the new price to the current billing cycle. Then, the full new amount is billed in the next billing cycle.\n\nThe upgrade process is not instantaneous. You can expect to see the updated size in the UI or through the API in a short while after you put in the modification request. Resizing does not cause any outage or loss of access to the storage, so you can continue your operations as normal while you wait.\n\n\n\n Advantages of Expandable Storage \n\n\n\n* Cost management \u2013 You might know of a potential for growth of your data, but you need a smaller amount of storage to start. The ability to expand, allows customers to save on costs of storage at the start and then grow to accommodate their needs.\n* Growing Storage needs - Customers who experience rapid growth beyond need a way to quickly and easily increase the size of their storage to manage that growth.\n\n\n\n\n\n\n\n Effects of expanding storage capacity on Replication \n\nExpand action on the primary storage results in automatic resizing of the replica.\n\n\n\n\n\n Limitations \n\nThis feature is available for storage that is provisioned in [data centers](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-selectDC) with enhanced capabilities. Encrypted storage that is provisioned in these data centers can be increased up to 12 TB.\n\nExisting size limitations for File Storage for Classic that was provisioned with Endurance still apply (up to 4 TB for 10 IOPS tier and up to 12 TB for all other tiers).\n\n\n\n\n\n Resizing storage in the UI \n\n\n\n1. Go to the [IBM Cloud\u00ae console](https://cloud.ibm.com/login). From the menu, select Classic Infrastructure!", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacity"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16276-5813-8052", "score": 0.5827193260192871, "text": "\nIf you expect customers to typically make a request about a specific type of claim, such as auto, home, or medical, you might not want to ask another question about what type. They might say I need to file an auto claim or I want to make a home claim.\n\nAlthough you still need a step that collects the answer about the type of claim, you might not want or need to ask that explicit question, especially if your assistant is used with the phone integration. Instead, you can create a step with the claim options, but set it to never ask.\n\nThis table shows how you might set up the steps. The last step is a catch-all in case the customer doesn't mention the claim type initially.\n\n\n\nExample using the never ask response setting\n\n Step Conditions Assistant says Customer response Customer response setting And then \n\n 1 None What kind of claim? Options: Automobile, Homeowner, Medical Never ask Continue to the next step \n 2 Step 1 is Automobile None Click here to file an automobile claim Skip (default) End the action \n 3 Step 1 is Homeowner None Click here to file a homeowner claim Skip (default) End the action \n 4 Step 1 is Medical None Click here to file a medical claim Skip (default) End the action \n 5 Step 1 is not defined (no claim type) None Click here to file an insurance claim Skip (default) End the action \n\n\n\n\n\n\n\n\n\n\n\n Customer response types \n\nThe configuration information that you must provide varies by response type.\n\n\n\n Options \n\nAn options response presents customers with a list of choices to select from. How these options are presented depends upon how your customers connect to the assistant. In the web chat integration, the options are shown as clickable buttons (for 4 or fewer options) or as a drop-down list (for more than 4 options).\n\nThere are two ways to create the list:\n\n\n\n* Enter a list of options and synonyms\n* Generate a dynamic list from a variable\n\n\n\n\n\n Entering a list of options and synonyms \n\nEnter each choice in the Option fields. You can click Add synonyms to enter variations of an option value that customers might type. You can enter multiple synonyms in a comma-separated list.\n\nFor example, you might define the following options and synonyms:\n\n\n\nOptions example\n\n Option value Synonyms", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-collect-info"}, {"document_id": "ibmcld_03249-37219-39347", "score": 0.5790783166885376, "text": "\nYou probably want either the Found response for all of them or none of them to be returned.\n\nTo prevent Found responses from being displayed, you can do one of the following things to each Found response:\n\n- Add a condition to the response that prevents it from being displayed if particular slots are filled. For example, you can add a condition, like !($size && $time), that prevents the response from being displayed if the $size and $time context variables are both provided.\n- Add the !all_slots_filled condition to the response. This setting prevents the response from being displayed if all of the slots are filled. Do not use this approach if you are including a confirmation slot. The confirmation slot is also a slot, and you typically want to prevent the Found responses from being displayed before the confirmation slot itself is filled.\n\n Handling requests to exit a process {: dialog-slots-node-level-handler}\n\nAdd at least one slot handler that can recognize it when a user wants to exit the node.\n\nFor example, in a node that collects information to schedule a pet grooming appointment, you can add a handler that conditions on the cancel intent, which recognizes utterances such as, <q>Forget it. I changed my mind.</q>\n\n1. In the JSON editor for the handler, fill all of the slot context variables with dummy values to prevent the node from continuing to ask for any that are missing. And in the handler response, add a message such as, Ok, we'll stop there. No appointment will be scheduled.\n1. Choose what action you want your assistant to take next from the following options:\n\n- Prompt again (Default): Displays the prompt for the slot that the user was working with just before asking the off-topic question.\n- Skip current slot: Displays the prompt associated with the slot that comes after the slot that the user was working with just before asking the off-topic question. And your assistant makes no further attempts to fill the skipped slot.\n- Skip to response: Skips the prompts for all remaining empty slots including the slot the user was working with just before asking the off-topic question.\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots"}, {"document_id": "ibmcld_16359-5458-7439", "score": 0.5690101385116577, "text": "\n[Download icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/download-icon.png).\n\nYour example phrases are downloaded to a CSV file.\n\n\n\n\n\n\n\n\n\n Asking clarifying questions \n\nWhen your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to take, your assistant shows a list of the possible actions to the customer, and asks the customer to pick the right one.\n\nZoom\n\n![Shows a sample conversation between a user and the assistant, where the assistant asks for clarification from the user.](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/disambig-demo.png)\n\nSample conversation\n\nAny Created by you action that might match the customer's input can be included in the choices that are listed by a clarifying question. The Set by assistant actions are never included.\n\nIn the assistant output, the possible actions are listed by name. The default name for an action is the text of the first example message that you add to it (such as I want to open an account), but you can change this name to something more descriptive.\n\nThe order in which the actions are listed might change. In fact, the actions themselves that are included in the list might change. This behavior is intended. As part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-understand-questions"}, {"document_id": "ibmcld_16276-4355-6349", "score": 0.5652622580528259, "text": "\nIf your action asks for the same type of data in more than one step, use the Always ask for this information setting to prevent the assistant from making incorrect assumptions. For example, you might have an action in which one step asks for a hotel check-in date and another step asks for the check-out date. If you skip asking, the assistant can mistake the check-in date for the check-out date.\n\nTo require that a step is always used in the conversation with a customer:\n\n\n\n1. In the customer response, click the Settings icon to open Customer response settings.\n\nZoom\n\n![Customer response settings](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/collect-info-customer-response-settings.png)\n\nCustomer response settings\n2. Choose Always ask for this information, regardless of previous messages.\n3. Click Apply.\n\n\n\n\n\n\n\n Never ask \n\nThere might be some situations where you need a step to never ask a question because you anticipate redundant questions in the conversation.\n\nTo set that a step is never asked in the conversation with a customer:\n\n\n\n1. In the customer response, click the Settings icon to open Customer response settings.\n2. Choose Never ask. Collect information from previous messages.\n3. Click Apply.\n\n\n\n\n\n Example \n\nThis example explains when you might set a step to never ask for a response.\n\nYou might have an action that responds to requests to file an insurance claim. If you expect customers to typically make a request about a specific type of claim, such as auto, home, or medical, you might not want to ask another question about what type. They might say I need to file an auto claim or I want to make a home claim.\n\nAlthough you still need a step that collects the answer about the type of claim, you might not want or need to ask that explicit question, especially if your assistant is used with the phone integration. Instead, you can create a step with the claim options, but set it to never ask.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-collect-info"}, {"document_id": "ibmcld_02934-18620-20749", "score": 0.5631695985794067, "text": "\n* [Preventing a Found response from displaying when it is not needed](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-stifle-found-responses)\n* [Handling requests to exit a process](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-node-level-handler)\n\n\n\n\n\n Asking for everything at once \n\nInclude an initial prompt for the whole node that clearly tells users which units of information you want them to provide. Displaying this prompt first gives users the opportunity to provide all the details at once and not have to wait to be prompted for each piece of information one at a time.\n\nFor example, when the node is triggered because a customer wants to order a pizza, you can respond with the preliminary prompt, I can take your pizza order. Tell me what size pizza you want and the time that you want it delivered.\n\nIf the user provides even one piece of this information in their initial request, then the prompt is not displayed. For example, the initial input might be, I want to order a large pizza. When your assistant analyzes the input, it recognizes large as the pizza size and fills the Size slot with the value provided. Because one of the slots is filled, it skips displaying the initial prompt to avoid asking for the pizza size information again. Instead, it displays the prompts for any remaining slots with missing information.\n\nFrom the Customize pane where you enabled the Slots feature, select the Prompt for everything checkbox to enable the intial prompt. This setting adds the If no slots are pre-filled, ask this first field to the node, where you can specify the text that prompts the user for everything.\n\n\n\n\n\n Capturing multiple values \n\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza. To do so define an entity (@toppings), and the accepted values for it (pepperoni, cheese, mushroom, and so on). Add a slot that asks the user about toppings. Use the values property of the entity type to capture multiple values, if provided.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_03249-17439-19450", "score": 0.5626411437988281, "text": "\n* [Moving on after multiple failed attempts](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-stop-trying-after-3)\n* [Preventing a Found response from displaying when it is not needed](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-stifle-found-responses)\n* [Handling requests to exit a process](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-node-level-handler)\n\n\n\n\n\n Asking for everything at once \n\nInclude an initial prompt for the whole node that clearly tells users which units of information you want them to provide. Displaying this prompt first gives users the opportunity to provide all the details at once and not have to wait to be prompted for each piece of information one at a time.\n\nFor example, when the node is triggered because a customer wants to order a pizza, you can respond with the preliminary prompt, I can take your pizza order. Tell me what size pizza you want and the time that you want it delivered.\n\nIf the user provides even one piece of this information in their initial request, then the prompt is not displayed. For example, the initial input might be, I want to order a large pizza. When your assistant analyzes the input, it recognizes large as the pizza size and fills the Size slot with the value provided. Because one of the slots is filled, it skips displaying the initial prompt to avoid asking for the pizza size information again. Instead, it displays the prompts for any remaining slots with missing information.\n\nFrom the Customize pane where you enabled the Slots feature, select the Prompt for everything checkbox to enable the intial prompt. This setting adds the If no slots are pre-filled, ask this first field to the node, where you can specify the text that prompts the user for everything.\n\n\n\n\n\n Capturing multiple values \n\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots"}, {"document_id": "ibmcld_02900-18168-20276", "score": 0.5591644048690796, "text": "\nYou might have a root node that conditions on #forecast which could answer the user. However, because the user's input includes the word tomorrow and the reservation node with slots is being processed, your assistant assumes the user is providing or updating the reservation date instead. The current node always gets priority. If you define a clear confirmation statement, such as, Ok, setting the reservation date to tomorrow, the user is more likely to realize there was a miscommunication and correct it.\n\nConversely, while filling slots, if the user provides a value that is not expected by any of the slots, there is a chance it will match against a completely unrelated root node that the user never intended to digress to.\n\nBe sure to do lots of testing as you configure the digression behavior.\n* When to use digressions instead of slot handlers: For general questions that users might ask at any time, use a root node that allows digressions into it, processes the input, and then goes back to the flow that was in progress. For nodes with slots, try to anticipate the types of related questions users might want to ask while filling in the slots, and address them by adding handlers to the node.\n\nFor example, if the node with slots collects the information required to fill out an insurance claim, then you might want to add handlers that address common questions about insurance. However, for questions about how to get help, or your stores locations, or the history of your company, use a root level node.\n\n\n\n\n\n\n\n\n\n Disambiguation \n\nWhen you enable disambiguation, you instruct your assistant to ask users for help when it finds that more than one dialog node can respond to their input. Instead of guessing which node to process, your assistant shares a list of the best node options with the user, and asks the user to pick the correct one.\n\n![Shows a sample conversation between a user and the assistant, where the assistant asks for clarification from the user.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/disambig-demo.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime"}, {"document_id": "ibmcld_02934-20364-22061", "score": 0.5590277314186096, "text": "\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza. To do so define an entity (@toppings), and the accepted values for it (pepperoni, cheese, mushroom, and so on). Add a slot that asks the user about toppings. Use the values property of the entity type to capture multiple values, if provided.\n\n\n\nMultiple value slot\n\n Check for Save as Prompt Follow-up if found Follow-up if not found \n\n @toppings.values $toppings Any toppings on that? Great addition. What toppings would you like? We offer ... \n\n\n\nTo reference the user-specified toppings later, use the <? $entity-name.join(',') ?> syntax to list each item in the toppings array and separate the values with a comma. For example, I am ordering you a $size pizza with <? $toppings.join(',') ?> for delivery by $time.\n\n\n\n\n\n Reformatting values \n\nBecause you are asking for information from the user and need to reference their input in responses, consider reformatting the values so you can display them in a friendlier format.\n\nFor example, time values are saved in the hh:mm:ss format. You can use the JSON editor for the slot to reformat the time value as you save it so it uses the hour:minutes AM/PM format instead:\n\n{\n\"context\":{\n\"time\": \"<? @sys-time.reformatDateTime('h:mm a') ?>\"\n}\n}\n\nSee [Expression language methods](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-methods) for other reformatting ideas.\n\n\n\n\n\n Dealing with zeros \n\nUsing @sys-number in a slot condition is helpful for capturing any numbers that users specify in their input. However, it does not behave as expected when users specify the number zero (0).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_03069-14150-15392", "score": 0.5505136251449585, "text": "\n[Close](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close.png) to close the edit view.\n\nNow, add child nodes that either ask for the order number or get confirmation from the user that she wants to cancel an order with the detected order number.\n8. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the cancel_order node, and then select Add child node.\n\n![Shows the menu on the #cancel_order node with the Add child node menu option selected.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ass-add-child-to-cancel.png)\n9. Add a label to the node to distinguish it from other child nodes you will be adding. In the name field, add Ask for order number. Type true into the If assistant recognizes field of this node.\n10. Add the following message in the response text field:\n\nWhat is the order number?\n\n![Shows the Ask for order number node details.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ass-ask-for-order-number.png)\n11. Click !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}, {"document_id": "ibmcld_03403-14203-15425", "score": 0.547598123550415, "text": "\n[Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n\nNow, add child nodes that either ask for the order number or get confirmation from the user that she wants to cancel an order with the detected order number.\n8. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the cancel_order node, and then select Add child node.\n\n![Shows the menu on the #cancel_order node with the Add child node menu option selected.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-add-child-to-cancel.png)\n9. Add a label to the node to distinguish it from other child nodes you will be adding. In the name field, add Ask for order number. Type true into the If assistant recognizes field of this node.\n10. Add the following message in the response text field:\n\nWhat is the order number?\n\n![Shows the Ask for order number node details.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-ask-for-order-number.png)\n11. Click !", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00495-1384-3135", "score": 0.7899012565612793, "text": "\nRetrieving data](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudretrieving-data).\n\n\n\n\n\n\n\n Installing Python \n\nNormally, you don't run commands individually in Python. You usually create a script, which is a list of the commands you want to run, stored in a Python file, with a py extension.\n\n\n\n1. Set up service credential requirements.\n\na. Create a service instance and credentials by following the [Getting started](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial.\n\nb. [Locate your service credentials](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-locating-your-service-credentialslocating-your-service-credentials) by following this tutorial.\n2. Install the required version of Python.\n\nYou must have a current version of the [Python programming language](https://www.python.org/) that is installed on your system. [: note]\n\na. Check that Python is installed by running the following command at a prompt:\n\npython3 --version\n\nb. Verify that you get a result similar to the following example:\n\nPython 3.8.1\n3. Verify that your Python Client Library meets the requirement.\n\nThe following examples use the deprecated python-cloudant client library.\n\na. Check that the client library installed successfully by running the following command at a prompt:\n\npip freeze\n\nYou get a list of all the Python modules installed on your system.\n\nb. Inspect the list, looking for an IBM Cloudant entry similar to the following example:\n\ncloudant==2.14.0\n\n\n\n\n\n\n\n Step 1: Connecting to a service instance \n\nYou must connect to your service instance before you create a database.\n\nThe following components are identified as normal import statements.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"}, {"document_id": "ibmcld_12896-1393-3153", "score": 0.785685658454895, "text": "\nRetrieving data](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudretrieving-data).\n\n\n\n\n\n\n\n Installing Python \n\nNormally, you don't run commands individually in Python. You usually create a script, which is a list of the commands you want to run, stored in a Python file, with a py extension.\n\n\n\n1. Set up service credential requirements.\n\na. Create a service instance and credentials by following the [Getting started](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial.\n\nb. [Locate your service credentials](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-locating-your-service-credentialslocating-your-service-credentials) by following this tutorial.\n2. Install the required version of Python.\n\nYou must have a current version of the [Python programming language](https://www.python.org/) that is installed on your system. [: note]\n\na. Check that Python is installed by running the following command at a prompt:\n\npython3 --version\n\nb. Verify that you get a result similar to the following example:\n\nPython 3.8.1\n3. Verify that your Python Client Library meets the requirement.\n\nThe following examples use the deprecated python-cloudant client library.\n\na. Check that the client library installed successfully by running the following command at a prompt:\n\npip freeze\n\nYou get a list of all the Python modules installed on your system.\n\nb. Inspect the list, looking for an IBM Cloudant entry similar to the following example:\n\ncloudant==2.14.0\n\n\n\n\n\n\n\n Step 1: Connecting to a service instance \n\nYou must connect to your service instance before you create a database.\n\nThe following components are identified as normal import statements.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"}, {"document_id": "ibmcld_04658-5342-6512", "score": 0.7498840093612671, "text": "\n\"credentials\": {\n\"url\":\"CLOUDANT_DATABASE_URL\"\n},\n\"label\": \"cloudantNoSQLDB\"\n}\n]\n}\n}\n3. Find your app in the IBM Cloud [Resource List](https://cloud.ibm.com/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n4. Copy and paste just the url value from the credentials to the url field of the vcap-local.json file, replacing CLOUDANT_DATABASE_URL.\n5. From the get-started-aspnet-core/src/GetStartedDotnet directory, restart your app by running the following command.\n\ndotnet run\n6. Refresh your browser view at http://localhost:5000/. Any names you enter into the app will now get added to the database.\n\n\n\nYour local app and the IBM Cloud app share the database. View your IBM Cloud app at the URL listed in the output of the ibmcloud cf push command. Names you add from either app should appear in both when you refresh the browsers.\n\nRemember, if you don't need your app live, stop it so you don't incur any unexpected charges.\n\n\n\n\n\n Next Steps \n\n\n\n* [Samples](https://ibm-cloud.github.io)\n* [Architecture Center](https://www.ibm.com/cloud/architecture/architectures)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-getting_started-dotnet"}, {"document_id": "ibmcld_05374-4649-6424", "score": 0.7461933493614197, "text": "\nAnd now what I'll do is ibmcloud ce project create \u2014name amazing product production app. So this create our nice, little\u2026 Target first. I\u2019ll get my default resource group and then I'll go ahead and create the project. There we go. Should only take a moment - perfect. Now you can change your name to whatever you like. This is just a catch-all for your project, which is useful. Then I will take the next command, which is ibmcloud ce app create \u2014name pythonbackend \u2014 build-source . \u2014strategy build packs\n\nNow because I already have a requirements.txt, this will be, this application is smart enough to figure out, \u201chey it's a python application! So let's go ahead and build it!\", which is nice. So as you can see, it's taking step one here. It's running the build, which is good. It creates a nice, private image for us too, which is useful. It takes a couple moments. There we go and now we see that if we wanted to do this with no wait, which is the -nw, we can actually put this into the background and wait for it to come up and then we can check it via this build run get the actual name. Being that we're going to be looking at this live, we'll go ahead and do this here.\n\nPerfect! So now I go ahead and open up the this URL here and it came over here and as you can see\n\n\u201chello moving from Heroku to Code Engine\u201d\n\nAnd that's it. I took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-heroku-migrate"}, {"document_id": "ibmcld_00576-7-1946", "score": 0.7456735372543335, "text": "\nUsing IBM Cloudant \n\nIf you never use IBM Cloudant or NoSQL databases in general, scan this introduction and some best practices before you read further. It describes the most important things you need to know about IBM Cloudant and how to use it best. The rest of the documentation assumes that you know these basics.\n\nYou can find more information about IBM Cloudant in the following sections:\n\n\n\n* [Client Libraries](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-client-librariesclient-libraries)\n* [API and SDK reference](https://cloud.ibm.com/apidocs/cloudantintroduction)\n\n\n\n\n\n Connecting to IBM Cloudant \n\nTo access IBM Cloudant, you must have an [IBM Cloud\u00ae account](https://cloud.ibm.com/login).\n\n\n\n\n\n HTTP API \n\nAll requests to IBM Cloudant go over the web. This statement means that any system that can speak to the web can speak to IBM Cloudant. All language-specific libraries for IBM Cloudant are just wrappers that provide some convenience and linguistic niceties to help you work with a simple API. Many users choose to use raw HTTP libraries for working with IBM Cloudant.\n\nFor more information about how IBM Cloudant uses HTTP, see [HTTP](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-http-works-with-cloudant) in the API reference.\n\nIBM Cloudant supports the following HTTP request methods:\n\nGET\n: Request the specified item. As with normal HTTP requests, the format of the URL defines what is returned. With IBM Cloudant, this definition can include static items, database documents, and configuration and statistical information. In most cases, the information is returned in the form of a JSON document.\n\nHEAD\n: The HEAD method retrieves the HTTP header of a GET request without the body of the response.\n\nPOST\n: Upload data. In IBM Cloudant's API, the POST method sets values, uploads documents, sets document values, and starts some administration commands.\n\nPUT\n: Used to \"store\" a specific resource.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-basics"}, {"document_id": "ibmcld_06004-26793-28571", "score": 0.7419301271438599, "text": "\n: Use a cloud service such as [IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) or [IBM Cloud Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n\n\n How can I scale my app? \n\nIf you want to dynamically add and remove apps in response to workload usage, see [Scaling apps](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_scaling) for steps to enable horizontal pod autoscaling.\n\n\n\n\n\n\n\n Versioning and updating apps \n\nYou put in a lot of effort preparing for the next version of your app. You can use IBM Cloud and Kubernetes update tools to roll out different versions of your app.\n\n\n\n How can I organize my deployments to make them easier to update and manage? \n\nNow that you have a good idea of what to include in your deployment, you might wonder how are you going to manage all these different YAML files? Not to mention the objects that they create in your Kubernetes environment!\n\nThe following tips can help you organize your deployment YAML files.\n\n\n\n* Use a version-control system, such as Git.\n* Group closely related Kubernetes objects within a single YAML file. For example, if you are creating a deployment, you might also add the service file to the YAML. Separate objects with --- such as in the following example.\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n...\n---\napiVersion: v1\nkind: Service\nmetadata:\n...\n* You can use the kubectl apply -f command to apply to an entire directory, not just a single file.\n* Try out the [kustomize project](https://cloud.ibm.com/docs/containers?topic=containers-appkustomize) that you can use to help write, customize, and reuse your Kubernetes resource YAML configurations.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_04650-5479-6774", "score": 0.7371936440467834, "text": "\nThis file will get used ONLY when the app is running locally. When running in IBM Cloud, the credentials will be read from the VCAP_SERVICES environment variable.\n\n\n\n1. Create a file called .env in the get-started-go directory with the following content:\n\nCLOUDANT_URL=\n2. Find your app in the IBM Cloud [resource list](https://cloud.ibm.com/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the CLOUDANT_URL field of the .env file and save the changes. The result will be something like:\n\nCLOUDANT_URL=https://123456789 ... bluemix.cloudant.com\n4. Run your app locally.\n\ngo run main.go\n5. View your app at: http://localhost:8080. Any names that you enter into the app are added to the database.\n\n\n\nYour local app and the IBM Cloud app share the database. View your IBM Cloud app at the URL listed in the output of the push command. Names you add from either app show in both apps when you refresh the browsers.\n\nIf you don't need your app live, stop it so you don't incur any unexpected charges.\n\n\n\n\n\n Next steps \n\n\n\n* [Samples](https://ibm-cloud.github.io)\n* [Architecture Center](https://www.ibm.com/cloud/architecture/architectures)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-getting-started-go"}, {"document_id": "ibmcld_04652-5588-7168", "score": 0.7366779446601868, "text": "\nIn the get-started-node directory, create a file called vcap-local.json with the following content:\n\n{\n\"services\": {\n\"cloudantNoSQLDB\": [\n{\n\"credentials\": {\n\"url\":\"CLOUDANT_DATABASE_URL\"\n},\n\"label\": \"cloudantNoSQLDB\"\n}\n]\n}\n}\n2. Find your app in the IBM Cloud [resource list](https://cloud.ibm.com/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the url field of the vcap-local.json file, replacing CLOUDANT_DATABASE_URL.\n4. Run your app locally.\n\nnpm start\n\nView your local app at http://localhost:3000. Any names you enter into the app will now get added to the database.\n\n\n\nAvoid trouble: IBM Cloud defines the PORT environment variable when your app runs on the cloud. When you run your app locally, the PORT variable is not defined, so 3000 is used as the port number. See [Run your app locally](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-hints) for more information.\n\nYour local app and the IBM Cloud app are sharing the database. Names you add from either app will appear in both when you refresh the browsers.\n\nRemember, if you don't need your app live on IBM Cloud, stop the app so you don't incur any unexpected charges.\n\n\n\n\n\n Next steps \n\n[Manage your Node.js app](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-nodejs_runtime). Some example tasks include configuring caching and integrating third-party services.\n\nCheck out the following resources:", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-getting-started-node"}, {"document_id": "ibmcld_00491-1283-3050", "score": 0.7362688779830933, "text": "\n(Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}, {"document_id": "ibmcld_04655-3982-5887", "score": 0.7346324324607849, "text": "\nSearch for IBM Cloudant, and select the service.\n3. For Available authentication methods, select Use both legacy credentials and IAM. You can leave the default settings for the other fields. Click Create to create the service.\n4. In the navigation, go to Connections, then click Create connection. Select your app, and click Connect.\n5. Using the default values, click Connect & restage app to connect the database to your app. Click Restage when prompted.\n\nIBM Cloud will restart your app and provide the database credentials to your app using the VCAP_SERVICES environment variable. This environment variable is available to the app only when it is running on IBM Cloud.\n\n\n\nEnvironment variables enable you to separate deployment settings from your source code. For example, instead of specifying a database password in your source code, you can store it in an environment variable that you reference in your source code.\n\n\n\n\n\n Step 6: Use the database \n\nWe're now going to update your local code to point to this database. We'll create a .env file that will store the credentials for the services the app will use. This file will get used ONLY when the app is running locally. When running in IBM Cloud, the credentials will be read from the VCAP_SERVICES environment variable.\n\n\n\n1. Create a file called .env in the get-started-ruby directory with the following content:\n\nCLOUDANT_URL=\n2. Find your app in the IBM Cloud [resource list](https://cloud.ibm.com/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the CLOUDANT_URL field of the .env file and save the changes. The result will be something like:\n\nCLOUDANT_URL=https://123456789 ... bluemix.cloudant.com\n4. Run your app locally.\n\nrails server\n\nView your app at: http://localhost:3000.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-getting-started-ruby"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00558-1499-3456", "score": 0.7206534743309021, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_01183-7-2154", "score": 0.7175540328025818, "text": "\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https://cloud.ibm.com/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose"}, {"document_id": "ibmcld_12904-1535-3460", "score": 0.7066519260406494, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_07578-1323355-1325090", "score": 0.701846718788147, "text": "\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https://www.w3.org/TR/xml/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1326020-1327755", "score": 0.701846718788147, "text": "\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https://www.w3.org/TR/xml/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-47319-49349", "score": 0.6929935216903687, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-47304-49334", "score": 0.6929935216903687, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16729-112397-114109", "score": 0.6918129920959473, "text": "\n[Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_05013-2864-3381", "score": 0.6892207860946655, "text": "\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-faq-provision"}, {"document_id": "ibmcld_13336-1484-3613", "score": 0.6868727207183838, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07103-31052-33321", "score": 0.6555442810058594, "text": "\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_07103-29564-31587", "score": 0.6492873430252075, "text": "\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes"}, {"document_id": "ibmcld_07578-47319-49349", "score": 0.6281747817993164, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-47304-49334", "score": 0.6281747817993164, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13336-3083-5168", "score": 0.603560209274292, "text": "\nAnd, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan? \n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n\n\n\n\n What does \"pricing per minute\" mean? \n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Do you round up to the nearest minute for every call to the API? \n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_01025-7-2061", "score": 0.5958154201507568, "text": "\nFAQs - Lite plan \n\nThis is a collection of frequently asked questions (FAQ) about the IBM\u00ae Db2\u00ae on Cloud Lite plan.\n\n\n\n Will my free plan expire? \n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n\n\n\n\n\n Will my data be deleted? \n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n\n\n\n\n\n How can I download a backup of my data on the Lite plan? \n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n\n\n\n\n Can I change the email I use for reactivation? \n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"}, {"document_id": "ibmcld_07578-494591-496583", "score": 0.5956963300704956, "text": "\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-494573-496565", "score": 0.5956963300704956, "text": "\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01183-7-2154", "score": 0.5941759347915649, "text": "\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https://cloud.ibm.com/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-plan_choose"}, {"document_id": "ibmcld_01705-11723-13541", "score": 0.5798979997634888, "text": "\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https://cloud.ibm.com/billing/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/Lite.svg) in the catalog.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12343-7-1769", "score": 0.7485815286636353, "text": "\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https://www.python.org/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https://github.com/pallets/flask), [Django](https://www.djangoproject.com/), [Jupyter](https://jupyter.org/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https://www.python.org/downloads/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https://jupyter.org/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https://pypi.org/).\n\nYour SDK should follow the [semantic versioning best practices](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https://www.python.org/dev/peps/pep-0008/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_12341-2467-4426", "score": 0.6904758214950562, "text": "\nUse a well-defined, well-documented request library that includes browser support, like [axios](https://github.com/axios/axios), [superagent](https://github.com/visionmedia/superagent), or [node-fetch](https://github.com/node-fetch/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture \n\nAll network calls from your SDK should be asynchronous. All asynchronous calls should be handled using Promises, not callbacks.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using node-sdk-core \n\n[IBM node-sdk-core](https://github.com/IBM/node-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* NPM metadata\n* [Contributor guidelines](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-node"}, {"document_id": "ibmcld_00462-1307-2903", "score": 0.6863212585449219, "text": "\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https://pypi.org/project/ibmcloudant/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https://www.python.org/about/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https://github.com/IBM/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https://pkg.go.dev/mod/github.com/IBM/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com/IBM/cloudant-go-sdk/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https://github.com/ibm/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant/couchbackup\n\nFor more information, see [couchbackup](https://github.com/cloudant/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https://curl.haxx.se/).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-client-libraries"}, {"document_id": "ibmcld_12343-2679-4417", "score": 0.6829360723495483, "text": "\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https://github.com/IBM/python-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* [Contributor guidelines](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples \n\nFor your Python SDK, you will want some simple code samples and explanations of what each does. Linking out to the API reference documentation for more advanced use is strongly encouraged.\n\nAt minimum, the samples should be included in the README.md file. They should communicate how to install the library, and complete the basic operations provided by your API.\n\nThe samples should include simple installation and initialization instructions for the popular frameworks and data science tools. Additional examples should be available in an /examples directory for more advanced operations which can be copied and pasted in to user applications.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_10841-22000-23598", "score": 0.6824020147323608, "text": "\n[CHANGELOG.md](https://github.com/ibm-functions/runtime-python/blob/master/python3.7/CHANGELOG.md). \n 3.6 Python 3.6 reached end of support on 2021/12/23. <br>See [end of life Python Releases](https://endoflife.date/python). \n 2.7 Python 2.7 reached end of support on 2020/01/01. <br>See [the Active Python Releases](https://www.python.org/downloads/). \n\n\n\n\n\n Migrating from Python 3.7 to Python 3.9, Python 3.11 \n\n\n\nTable 2. Migrating details from Python 3.7 to Python 3.9\n\n Package Details \n\n ibmcloudant The cloudant sdk has moved to the new ibmcloudant sdk. It includes a number of breaking changes. See [migration guide](https://github.com/cloudant/python-cloudant/blob/master/MIGRATION.md) for more information. \n ibm-watson The watson-developer-cloud sdk has renamed to the new ibm-watson sdk and includes breaking changes. See [pypi ibm-watson](https://pypi.org/project/ibm-watson/) and [github ibm-watson](https://github.com/watson-developer-cloud/python-sdk) for more information. \n\n\n\nFor more information about migrating to python:3.9, see [(Details on GitHub)](https://github.com/ibm-functions/runtime-python/blob/master/python3.9/CHANGELOG.md).\n\n\n\n\n\n Python packages \n\nEnsure that your action uses only the packages that are mentioned in the following table. \\n While other Python packages might be part of the runtime, they are included only as indirect dependencies of the other listed packages. These unlisted packages are candidates to be removed as soon as they are not required by the referring package.\n\nPython 3.11 packages\n\nPython 3.9 packages\n\nPython 3.7 packages\n\n\n\nTable 1.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-runtimes"}, {"document_id": "ibmcld_12343-1428-3200", "score": 0.6769278049468994, "text": "\nYou should follow the [PEP8 style guide for Python](https://www.python.org/dev/peps/pep-0008/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.\n\n\n\n Docstrings \n\nAll non-trivial methods should have docstrings. Docstrings should follow the [PEP257 guidelines](https://www.python.org/dev/peps/pep-0257/). For more examples, see the [Google style guide regarding docstrings](https://google.github.io/styleguide/pyguide.html381-docstrings).\n\n\n\n\n\n\n\n Dependencies \n\nYour Python SDK should use synchronous network calls, using a library like [requests](https://pypi.org/project/requests/).\n\n[PyJWT](https://pyjwt.readthedocs.io/en/latest/) is recommended for encoding and decoding JSON web tokens.\n\nYour SDK should use [logging](https://docs.python.org/3/library/logging.html) to assist users with low-level debugging.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https://github.com/IBM/python-sdk-core) provides configuration and authentication support.", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-python"}, {"document_id": "ibmcld_12341-1239-2954", "score": 0.6720489263534546, "text": "\nThe releases of these SDKs should be published on [NPM](https://www.npmjs.com/). Your NPM package should be [scoped](https://docs.npmjs.com/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https://www.npmjs.com/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https://github.com/airbnb/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https://github.com/axios/axios), [superagent](https://github.com/visionmedia/superagent), or [node-fetch](https://github.com/node-fetch/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-node"}, {"document_id": "ibmcld_02602-1716-3243", "score": 0.6660894155502319, "text": "\n2. To view summary usage help for all the toolkit commands, enter the following command:\n\napic\n3. To view usage help for any command, use the --help option. For example:\n\napic validate --help\n\n\n\n\n\n\n\n\n\n Installing LoopBack connectors \n\nBefore you can use a LoopBack data source to access data in a backend system such as a database, you must install the data source connector. The In-memory and email connectors are built in to LoopBack, so you don't need to install them.\n\n\n\n Prerequisites \n\nThe Oracle, DB2, and SQLLite connectors require C compiler tools to build and install binary extensions. The exact requirements depend on your operating system as described in the following list.\n\nLinux\n\n\n\n* Python v2.7 (v3.x is not supported)\n* make\n* A C/C++ compiler toolchain, for example GCC version 4.2 or later.\n* On Debian and Debian-derived distributions (Ubuntu, Mint etc), use the command: apt-get install build-essential\n\n\n\nMac OS X\n\n\n\n* [Python Releases for Mac OS X](https://www.python.org/downloads/mac-osx/)\n* [Xcode](https://developer.apple.com/xcode/?cm_mc_uid=46449280653414622613810&cm_mc_sid_50200000=1459433716)\n\n\n\nWindows\n\n\n\n* [Microsoft .NET Framework 4](https://www.microsoft.com/en-us/download/details.aspx?id=17851)\n* [Visual Studio](https://visualstudio.microsoft.com/downloads/)\n* [Python v2.7.10](https://www.python.org/downloads/release/python-2710/)\n* [Microsoft Windows SDK for Windows 10](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk)\n* npm version 3: See the following note.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-creating_apis"}, {"document_id": "ibmcld_05374-4649-6424", "score": 0.6605692505836487, "text": "\nAnd now what I'll do is ibmcloud ce project create \u2014name amazing product production app. So this create our nice, little\u2026 Target first. I\u2019ll get my default resource group and then I'll go ahead and create the project. There we go. Should only take a moment - perfect. Now you can change your name to whatever you like. This is just a catch-all for your project, which is useful. Then I will take the next command, which is ibmcloud ce app create \u2014name pythonbackend \u2014 build-source . \u2014strategy build packs\n\nNow because I already have a requirements.txt, this will be, this application is smart enough to figure out, \u201chey it's a python application! So let's go ahead and build it!\", which is nice. So as you can see, it's taking step one here. It's running the build, which is good. It creates a nice, private image for us too, which is useful. It takes a couple moments. There we go and now we see that if we wanted to do this with no wait, which is the -nw, we can actually put this into the background and wait for it to come up and then we can check it via this build run get the actual name. Being that we're going to be looking at this live, we'll go ahead and do this here.\n\nPerfect! So now I go ahead and open up the this URL here and it came over here and as you can see\n\n\u201chello moving from Heroku to Code Engine\u201d\n\nAnd that's it. I took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-heroku-migrate"}, {"document_id": "ibmcld_07214-89252-90583", "score": 0.6601835489273071, "text": "\n: The Java, Python, and Node.js SDKs for Discovery do not provide all of the functionality provided by the default REST (cURL) API. Not all cURL methods have an equivalent method in the non-cURL SDKs, and not all non-cURL methods provide all of the same features that their cURL equivalents have. In other words, the Java, Python, and Node.js SDKs currently provide only a subset of the cURL API's capabilities. : If you use the Word converter, matching on headings by using the style key is much more accurate and efficient than it by using the level key.\n\nData Crawler : The Data Crawler retries uploads if it encounters an upload failure. : The Data Crawler is unable to retry documents that uploaded successfully but failed to be converted or indexed. : The Data Crawler does not have a function to check downstream status and attempt to re-upload URLs that failed downstream. : There is no easy way to determine which documents are ingested by the Data Crawler. For example, if you run the Data Crawler against a set of 500 documents, the Data Crawler might report failures submitting 65 documents with a total collection of 212 documents. The status of the remaining 223 documents is undetermined. : A workaround is available, but it is complicated and involves invoking the API directly. Contact IBM\u00ae support for assistance.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02855-7-2041", "score": 0.7133057117462158, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16384-7-2422", "score": 0.7054768204689026, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16295-7-1721", "score": 0.68269282579422, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16280-4696-6712", "score": 0.6760047674179077, "text": "\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-assistant"}, {"document_id": "ibmcld_16384-1889-3334", "score": 0.6758383512496948, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_03080-7-1901", "score": 0.6654963493347168, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_03166-4-2012", "score": 0.664196252822876, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https://medium.com/ibm-watson/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16334-28517-30318", "score": 0.6620814800262451, "text": "\nFor more information, see [Create a web chat instance to add to your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant. For more information about the home screen feature, see [Configuring the home screen](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* Home screen enabled by default: The home screen feature is now enabled by default for all new web chat deployments.\n* Home screen context support: You can now access context variables from the home screen. Note that initial context must be set using a conversation_start node. For more information, see [Starting the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-welcome).\n\n\n\n\n\n\n\n 4.0.0 \n\nRelease date: 16 March 2021\n\n\n\n* Session history now generally available: Session history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. It is enabled by default. For more information about this feature, see [Session history](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-session-history).\n\nSession history persists within only one browser tab, not across multiple tabs. The dialog provides an option for links to open in a new tab or the same tab.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_16368-7-2072", "score": 0.658322811126709, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16365-7-1700", "score": 0.6546785831451416, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02855-7-2041", "score": 0.778716504573822, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16295-7-1721", "score": 0.7682482600212097, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16384-7-2422", "score": 0.7326273918151855, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16384-1889-3334", "score": 0.7305968999862671, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_03421-1518-3290", "score": 0.7285632491111755, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03166-4-2012", "score": 0.7233786582946777, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https://medium.com/ibm-watson/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16368-7-2072", "score": 0.7210323810577393, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03166-8640-10452", "score": 0.7153282165527344, "text": "\nFor more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_03080-1529-3357", "score": 0.7052921056747437, "text": "\nFor a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16389-0-2061", "score": 0.7050412893295288, "text": "\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16384-1889-3334", "score": 0.7294123768806458, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16368-7-2072", "score": 0.7084847092628479, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16368-9848-11461", "score": 0.6989517211914062, "text": "\nTo change the size of the web chat window, you can use the [updateCSSVariables()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdatecssvariables) instance method to modify the CSS styling.\n\nIf you need to change the position of the web chat window, or you need to change the size beyond the limits allowed in the CSS, you can use a custom DOM element to contain the web chat window. To do this, use the [element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationoptionselement) configuration option.\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial that shows how render the web chat in a custom element, see [Tutorial: Customizing the size and position of the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-size-position).\n\nAdding the web chat to your mobile application\n: You can use a WebView with a JavaScript bridge to add the web chat to your mobile application. For more information, see [Adding the web chat to your mobile application](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-mobile).\n\n\n\n\n\n Customizing the conversation \n\nIntercepting and modifying messages\n: By [subscribing to events](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventssummary), your code can intercept messages that are sent and received between the customer and the assistant, and even modify their content.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03418-4897-6906", "score": 0.695250391960144, "text": "\nYou can edit all or a subset of the phrases in a JSON file, and then configure the web chat to use your version by specifying the instance.updateLanguagePack() method.\n\nFor more information, see [Languages](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslanguages).\n\n\n\n\n\n\n\n Versioning \n\nWeb chat follows semantic versioning practices. Starting with web chat version 2.0.0, you can set the version of web chat that you want to use as a configuration option.\n\nIf you don't specify a version, the latest version is used automatically (clientVersion=\"latest\"). When you apply the latest version, you benefit from the continuous improvements, feature additions, and bug fixes that are made to the web chat regularly.\n\nHowever, if you apply extensive customizations to your deployment, such as overriding the theme with your own custom theme, for example, you might want to lock your deployment to a specific version. Locking on a version enables you to test new versions before you apply them to your live web chat.\n\nTo use a specific version (clientVersion=\"major.minor.patch\"), specify it as follows:\n\nThe following examples show what to specify when the current version is 2.3.1.\n\n\n\n* If you want to stay on a major version, but get the latest minor and patch releases, specify clientVersion=\"2\".\n* If you want to stay on a minor version, but get the latest patch releases, specify clientVersion=\"2.3\".\n* If you want to lock on to a specific minor version and patch release, specify clientVersion=\"2.3.1\".\n\n\n\nTo test the updates in a version release of web chat before you apply the version to your live web chat, follow these steps:\n\n\n\n1. Lock the web chat that is running in your production environment to a specific version.\n2. Embed your web chat deployment into a new page in a test environment, and then override the version lock setting. For example, specify clientVersion=\"latest\".\n3. Test the web chat, and make adjustments to the configuration if necessary.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_03421-1518-3290", "score": 0.6932065486907959, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_02855-13982-15842", "score": 0.68617844581604, "text": "\nFor more information about rich response types, see [Rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_03166-8640-10452", "score": 0.6854254603385925, "text": "\nFor more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_02855-5574-7284", "score": 0.6796865463256836, "text": "\nFor more information, see the [Using a custom launcher tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16384-7-2422", "score": 0.6727451682090759, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16383-0-2125", "score": 0.6719449758529663, "text": "\n\n\n\n\n\n\n  Controlling the web chat version \n\nThe web chat JavaScript code follows semantic versioning practices. Starting with web chat version 2.0.0, you can set the version of the web chat that you want to use as a configuration option.\n\nIf you don't specify a version, the latest version is used automatically (clientVersion: \"latest\"). When you apply the latest version, you benefit from the continuous improvements, feature additions, and bug fixes that are made to the web chat regularly.\n\nHowever, if you apply extensive customizations to your deployment, such as overriding the theme with your own custom theme, you might want to lock your deployment to a specific version. Locking on a version enables you to test new versions before you apply them to your live web chat.\n\nTo use a specific version (clientVersion: \"major.minor.patch\"), specify it as follows:\n\nThe following examples show what to specify when the current version is 2.3.1.\n\n\n\n*  If you want to stay on a major version, but get the latest minor and patch releases, specify clientVersion: \"2\".\n*  If you want to stay on a minor version, but get the latest patch releases, specify clientVersion: \"2.3\".\n*  If you want to lock on to a specific minor version and patch release, specify clientVersion: \"2.3.1\".\n\n\n\nTo test the updates in a version release of the web chat before you apply the version to your live web chat, follow these steps:\n\n\n\n1.  Lock the web chat that is running in your production environment to a specific version.\n2.  Embed your web chat deployment into a new page in a test environment, and then override the version lock setting. For example, specify clientVersion: \"latest\".\n3.  Test the web chat, and make adjustments to the configuration if necessary.\n4.  Update your production deployment to use the latest version and apply any other configuration changes that you determined to be necessary after testing.\n\n\n\nFor more information about features that were introduced in previous web chat versions, see the [Web chat release notes](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-versions"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16387-7-1890", "score": 0.6887495517730713, "text": "\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https://www.npmjs.com/package/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable"}, {"document_id": "ibmcld_16385-7-2272", "score": 0.6827706098556519, "text": "\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https://tools.ietf.org/html/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security"}, {"document_id": "ibmcld_03188-4819-6738", "score": 0.6772816181182861, "text": "\nFor more information about how to pass data, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored. The information is stored in the context.integrations.chat.browser_info object.\n\nYou can design your dialog to take advantage of details about the web browser in use. The following properties are taken from the window object that represents the window in which the web chat is running:\n\n\n\n* browser_name: The browser name, such as chrome, edge, or firefox.\n* browser_version: The browser version, such as 80.0.0.\n* browser_OS: The operating system of the customer's computer, such as Mac OS.\n* language: The default locale code of the browser, such as en-US.\n* page_url: Full URL of the web page in which the web chat is embedded. For example: https://www.example.com/products\n* screen_resolution: Specifies the height and width of the browser window in which the web page is displayed. For example: width: 1440, height: 900\n* user_agent: Content from the User-Agent request header.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations"}, {"document_id": "ibmcld_03422-4-2013", "score": 0.6715018153190613, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Securing the web chat \n\nUnderstand what you need to do to secure your web chat integration.\n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 (RS256) to encrypt communication. RS256 signatures use a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nThe following diagram illustrates the requests that are sent back and forth to authenticate a request.\n\n![Shows the order in which requests are sent among your website, web chat, and the service](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-security.png)\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\n\n\n Before you begin \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security"}, {"document_id": "ibmcld_16368-14455-16070", "score": 0.6648876667022705, "text": "\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.\n\nFor more information about how user identity information is specified and how it is used, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\n\n\n\n\n Security and administration \n\nSecuring the web chat\n: To secure the web chat, you can use JSON Web Token (JWT) to authenticate users and encrypt private data. For more information, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\nControlling the web chat version\n: The web chat code hosted by IBM Cloud is regularly updated with improvements and new features. By default, the embed script automatically uses the latest version of the web chat. To avoid unexpected changes that might affect your website, you might want to control which version of the web chat your website uses, giving you an opportunity to test each new version before you deploy in in production., in order to avoid unexpected changes when a new version is released.\n\nFor more information about web chat versioning, see [Controlling the web chat version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-versions).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16298-6367-7794", "score": 0.660753607749939, "text": "\nFor more information see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n// Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, // Required\niss: 'www.ibm.com', // Required\nacr: 'loa1' // Required", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-zendesk"}, {"document_id": "ibmcld_03421-9438-11232", "score": 0.6561956405639648, "text": "\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* User-based service plans use the user_id associated with user input for billing purposes. See [User-based plans](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. See [Labeling and deleting data](https://cloud.ibm.com/docs/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\n\n\nTo support these user-based capabilities, add the [updateUserID() method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16388-7-1918", "score": 0.6561723947525024, "text": "\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"}, {"document_id": "ibmcld_03180-5630-7213", "score": 0.6559584140777588, "text": "\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https://support.zendesk.com/hc/en-us/articles/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n// Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n/\n* Returns a signed JWT.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-zendesk"}, {"document_id": "ibmcld_02855-22154-24172", "score": 0.6552912592887878, "text": "\nWhen you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\nFor more information about security, see [Security](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=key-conceptssecurity).\n\n\n\n Enable security \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nAfter you enable security, users cannot submit messages through the web chat unless you take steps to prove their origin. Do not enable it until you have support for authentication in place.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03421-1518-3290", "score": 0.6690530776977539, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03421-4250-6078", "score": 0.6584917306900024, "text": "\nYou can make simple changes to the color of things like the text font and web chat header from the Style tab of the web chat configuration page. To make more extensive style changes, you can set the CSS style color theme to a different theme or specify your own theme.\n\n\n\n* You can choose to use a different base Carbon Design theme. The supported base themes are color themes that are defined by [IBM Carbon Design](https://www.carbondesignsystem.com/guidelines/color/usage/). For more information, see [Theming](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodstheming).\n* Alternatively, you can set individual variables within the theme to customize specific UI elements. For example, the text that is displayed in the chat window uses the fonts IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n* Apply style settings to user-defined response types. If you enable the web chat to return custom response types, be sure to apply existing or custom CSS classes to them. For more information, see [Custom content](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-render).\n* Change the style of the home screen that can be displayed when the web chat is opened. For more information about the home screen, see [Adding a home screen](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen). For more information about how to customize it, see [HTML content](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-renderhtml)\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03166-1557-3458", "score": 0.6491274833679199, "text": "\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https://cloud.ibm.com/docs/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16380-7-2028", "score": 0.6331070065498352, "text": "\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"></div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"}, {"document_id": "ibmcld_16366-7-1826", "score": 0.6297173500061035, "text": "\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_16368-4005-5684", "score": 0.627253532409668, "text": "\n* [Intercepting and modifying messages](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developmodify-messages)\n* [Rendering custom response types](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developcustom-response-types)\n* [Implementing a contact center integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developcontact-center)\n\n\n\nManaging data\n: \n\n* [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developuser-id)\n\n\n\nSecurity and administration\n: \n\n* [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developsecure-web-chat)\n* [Controlling the web chat version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-developweb-chat-version)\n\n\n\n\n\n Web chat style and content \n\nCustomizing the look of the web chat\n: If you want to customize the style and appearance of the web chat beyond the options that are available on the Style tab in the web chat settings, you can do so by choosing a different Carbon Design theme.\n\nThe supported themes are color themes that are defined by [IBM Carbon Design](https://v10.carbondesignsystem.com/guidelines/color/usage/). To set the Carbon theme, use the [carbonTheme](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationoptionscarbonTheme) configuration option.\n\nYou can also set individual variables within the theme to customize specific UI elements. For example, the text that is displayed in the chat window uses the fonts IBMPlexSans, Arial, Helvetica, sans-serif.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03421-2813-4727", "score": 0.6249942779541016, "text": "\nIf you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).\n* Render your own custom response types inside the web chat widget, including responses that incorporate code from your website at run time. For a tutorial that shows you how, see [Creating a custom response](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-user-defined-response).\n* Use React portals to render your custom response type as part of your application. For a tutorial that shows you how, see [Custom responses with React](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-react-portals).\n\n\n\n\n\n\n\n Change the look of the web chat \n\nYou can make simple changes to the color of things like the text font and web chat header from the Style tab of the web chat configuration page. To make more extensive style changes, you can set the CSS style color theme to a different theme or specify your own theme.\n\n\n\n* You can choose to use a different base Carbon Design theme. The supported base themes are color themes that are defined by [IBM Carbon Design](https://www.carbondesignsystem.com/guidelines/color/usage/).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16365-1312-3051", "score": 0.6237409114837646, "text": "\nFor more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03080-7-1901", "score": 0.623704195022583, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16368-7668-9098", "score": 0.621755838394165, "text": "\nTo change to a different language, use the [updateLanguagePack()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace the current language pack with one of the available translated language packs. For more information, see [Supporting global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Opening, closing, and rendering the web chat window \n\nReplacing the default launcher\n: To better integrate with your website, you might want to replace the built-in launcher icon with a different mechanism for opening the web chat. To hide the default launcher, set the [showLauncher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationoptionsshowLauncher) configuration option to false. To open the web chat based on some other interaction, use the [openWindow](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsopenwindow) instance method.\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial that shows you how to implement a custom launcher, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n\nKeeping the web chat always open", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03418-1763-3833", "score": 0.6340854167938232, "text": "\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_03422-14609-15163", "score": 0.6244306564331055, "text": "\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security"}, {"document_id": "ibmcld_16384-7-2422", "score": 0.6238424777984619, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16364-110490-112399", "score": 0.6102972626686096, "text": "\nFor more information, see [Configure the search](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\n\n\n\n\n 25 August 2020 \n\nGive the web chat integration a try!\n: You can now use the web chat integration with a Lite plan. Previously, the web chat was available to Plus or higher plans only. For more information, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\n\n\n\n\n 12 August 2020 \n\nv2 Logs API is available\n: If you have a Premium plan, you can use the v2 API logs method to list log events for an assistant. For more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2listlogs) documentation.\n\n\n\n\n\n 5 August 2020 \n\nEnable your skill to improve itself\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https://cloud.ibm.com/docs/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03369-43606-45325", "score": 0.6082085967063904, "text": "\n* If you created your web chat integration before May 2020, check the code snippet that you embedded in your web page to see if it refers to watsonplatform.net. If so, you must edit the code snippet to use the new URL syntax. For example, change the following URL:\n\n<script src=\"https://assistant-web.watsonplatform.net/loadWatsonAssistantChat.js\"></script>\n\nThe correct syntax to use for the source service URL looks like this:\n\nsrc=\"https://web-chat.global.assistant.watson.appdomain.cloud/loadWatsonAssistantChat.js\"\n\n\n\n* If your web chat integration connects to a Salesforce service desk, then you must edit the API call that is included in the code snippet that you added to the Visualforce Page that you created in Salesforce. From Salesforce, search for Visualforce Pages, and find your page. In the <iframe> snippet that you pasted into the page, make the following change:\n\nReplace: src=\u201chttps://assistant-integrations-{location}.watsonplatform.net/public/salesforceweb\u201d with a url with this syntax:\n\nsrc=\"https://integrations.{location}.assistant.watson.appdomain.cloud/public/salesforceweb/{integration-id}/agent_application?version=2020-09-24\"\n\nFrom the Web chat integration Salesforce live agent setup page, find the Visualforce page markup field. Look for the src parameter in the <iframe> element. It contains the full URL to use, including the appropriate {location} and {integration-id} values for your instance.\n* For a Slack integration that is over 7 months old, make sure the Request URL is using the proper endpoint.\n\n\n\n* Go to the [Slack API](https://api.slack.com/) web page. Click Your Apps to find your assistant app. Click Event Subscriptions from the navigation pane.\n* Edit the Request URL.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16295-7-1721", "score": 0.6026017665863037, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16365-7-1700", "score": 0.6009132266044617, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16334-35243-37326", "score": 0.594709038734436, "text": "\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.\n* Starter kit update: The starter kit now allow you to customize the timeout that occurs when the web chat integration checks whether any service desk agents are online.\n\n\n\n\n\n\n\n 3.1.1 \n\nRelease date: 22 October 2020\n\n\n\n* Accessibility improvement: Changed how the announcement text is generated to prevent announcements from being duplicated. Announcement text is hidden text that is provided for use by screen readers to indicate when dynamic web page changes occur.\n\n\n\n\n\n\n\n 3.1.0 \n\nRelease date: 8 October 2020\n\n\n\n* Suggestions now allow for trial and error: If customers select a suggestion and find that the response is not helpful, they can open the suggestions list again and try a different suggestion.\n\n\n\n\n\n\n\n 3.0.0 \n\nRelease date: 22 September 2020\n\n\n\n* Choose when a link to support is included in suggestions: The Suggestions beta feature has moved to its own tab. Now you can enable suggestions even if your web chat is not set up to connect to a service desk solution. That's because now you can control if and when the option to connect to customer support is available from the suggestions list. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n* Search result format change: To support the ability to show more than 3 search results in a response, the search skill response type format changed. If you are using pre:receive or receive handlers to process search results, you might need to update your code. The results property was replaced by the primary_results and additional_results properties.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_03418-4-2127", "score": 0.5929490327835083, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Global audience support", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basics"}, {"document_id": "ibmcld_16334-17373-19365", "score": 0.5927227735519409, "text": "\n* Home screen: The web chat home screen has been updated to have a more modern look. For more information about the home screen, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configweb-chat-configure-home-screen).\n* Agent events: New events are now fired by the web chat when interacting with a human agent using a service desk integration. If you are using a custom service desk integration based on the [starter kit](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter), you can use these events to create a pre-chat form before the agent escalation occurs, to create a post-chat form after the agent conversation ends, or to specify what happens if an agent isn\u2019t available (like create a ticket submission form). For more information, see [Agent events summary](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventssummary).\n* Markdown support: The web chat now fully supports common Markdown formatting in messages received from an assistant. You might need to review existing assistant output that contains strings that might be recognized as Markdown. (For example, a line of text that begins with a greater-than (>) character is interpreted as a block quote.)\n* Time zone: The time zone set in the context by the web chat no longer overrides any time zone set by the assistant.\n* Locale: Any locale configured for the web chat is now sent to the assistant as part of the context.\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02774-5358-7120", "score": 0.7256108522415161, "text": "\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https://cloud.ibm.com/docs/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https://cloud.ibm.com/docs/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-preregister"}, {"document_id": "ibmcld_03966-9450-11507", "score": 0.7212661504745483, "text": "\nBe sure that you have [set the identity](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-identities"}, {"document_id": "ibmcld_11472-2693-4203", "score": 0.7106408476829529, "text": "\nStep 3: Integrate the App ID instance as the ID provider for the administrator's account \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Identity Providers](https://cloud.ibm.com/iam/identity-providers). For Type, choose IBM Cloud App ID, then click Create.\n2. Specify a name and select the App ID instance from the drop-down list.\n3. Select the checkbox to enable the ID provider.\n\nZoom\n\n![Create identity provider](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-idp-reference.png)\n\nFigure 3. Create identity provider page\n4. The default IdP URL is shown. Share this URL with users when they need to log in.\n\n\n\n\n\n\n\n Step 4: Add Users \n\nWhen you use App ID as ID provider with the Cloud directory, you can create users in the IBM Cloud user interface.\n\n\n\n1. Open the App ID instance page from the [resource list](https://cloud.ibm.com/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 5: Create or modify users' project assignments \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Users](https://cloud.ibm.com/iam/users) and click the user.\n\nZoom\n\n![Change User Access](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-manage-user.png)\n\nFigure 11. Change User Access\n\nIf you don't see the user that you want to manage, verify that they logged in to IBM Cloud at least once.", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-appid-cloud-org"}, {"document_id": "ibmcld_02774-6807-8305", "score": 0.7051376104354858, "text": "\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.\n\nibmcloud iam oauth-tokens\n3. Make a POST request to the /users endpoint that contains a description of the user and the attributes that you want to set as a JSON object.\n\nHeader:\n\nPOST <managementUrl>/management/v4/<tenantID>/users\nHost: <managementServerURL>\nAuthorization: 'Bearer <IAMToken>'\nContent-Type: application/json\n\nBody:\n\n{\n\"idp\": \"<identityProvider>\",\n\"idp-identity\": \"<userUniqueIdentifier>\",\n\"profile\": {\n\"attributes\": {\n\"mealPreference\":\"vegeterian\"\n}\n}\n}\n\n\n\nTable 2. The components of the POST request\n\n Components Description \n\n idp The identity provider that the user authenticates with. Options include: saml, cloud_directory, facebook, google, appid_custom, ibmid. \n idp-identity The unique identifier provided by the identity provider. \n profile The user's profile that contains the custom attribute JSON mapping. \n\n\n\nExample request:\n\n$ curl --request POST --url 'https://<managementURI>/users --header 'Authorization: Bearer <IAMToken>' --header 'Content-Type: application/json' --data '{\"idp\": \"saml\", \"idp-identity\": \"user@ibm.com\", \"profile\": { \"attributes\": { \"role\": \"admin\",\n\"frequent_flyer_points\": 1000 }}}'\n4. Verify that registration was successful.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-preregister"}, {"document_id": "ibmcld_11474-2650-4160", "score": 0.6888075470924377, "text": "\nStep 3: Integrate the App ID instance as the ID provider for the administrator's account \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Identity Providers](https://cloud.ibm.com/iam/identity-providers). For Type, choose IBM Cloud App ID, then click Create.\n2. Specify a name and select the App ID instance from the drop-down list.\n3. Select the checkbox to enable the ID provider.\n\nZoom\n\n![Create identity provider](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-idp-reference.png)\n\nFigure 3. Create identity provider page\n4. The default IdP URL is shown. Share this URL with users when they need to log in.\n\n\n\n\n\n\n\n Step 4: Add a dynamic rule to the access group \n\nThe access group needs a dynamic rule to test whether it should be applied to an IDP user when they log in.\n\nBecause the dynamic rules are evaluated during login, any changes are picked up the next time the user logs in.\n\n\n\n1. Navigate to [Manage \u2192 IAM \u2192 Access groups](https://cloud.ibm.com/iam/groups) and click your access group to open its details page.\n2. Click the Dynamic rules tab, then click Add.\n\n\n\n* Provide a name.\n* For the Authentication method, choose Users federated by IBM Cloud AppID, then select the IDP from the Identity provider drop-down list.\n\n\n\nZoom\n\n![Create Dynamic Rule](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-create-dynamic-rule1.png)\n\nFigure 9. Create Dynamic Rule\n3.", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-appid-org"}, {"document_id": "ibmcld_01608-9180-10583", "score": 0.6863193511962891, "text": "\nSelect All bare metal servers or All virtual servers, depending on the resource that you want the user to be able to tag.\n\n\n\n\n\n\n\n Granting users access to tag service IDs \n\nComplete the following steps to assign the administrator role on the IAM Identity Service for a user:\n\n\n\n1. Click Manage > Access (IAM), and select Users.\n2. Click the user's name from the table.\n3. Select the IAM Identity service and click Next.\n4. Select All resources and click Next.\n5. Select the Administrator role.\n6. Click Review > Add.\n7. Click Assign.\n\n\n\n\n\n\n\n Granting users access to tag service IDs by using the API \n\nTo assign the administrator role on the IAM Identity Service for a user, call the [IAM Policy Management API](https://cloud.ibm.com/apidocs/iam-policy-management) as shown in the following example request. Replace values with your target user's IAM ID and account ID.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X POST 'https://iam.cloud.ibm.com/v1/policies' -H 'Authorization: Bearer $TOKEN' -H 'Content-Type: application/json' -d '{\n\"type\": \"access\",\n\"description\": \"Administrator role for the IAM Identity Service so that user can tag service IDs\",\n\"subjects\": [\n{\n\"attributes\":\n{\n\"name\": \"iam_id\",\n\"value\": \"IBMid-123453user\"\n}\n]\n}'\n],\n\"roles\":[\n{\n\"role_id\": \"crn:v1:bluemix:public:iam::::role:Administrator\"\n}\n],\n\"resources\":[\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"$ACCOUNT_ID\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-access&interface=api"}, {"document_id": "ibmcld_01603-9169-10572", "score": 0.6863193511962891, "text": "\nSelect All bare metal servers or All virtual servers, depending on the resource that you want the user to be able to tag.\n\n\n\n\n\n\n\n Granting users access to tag service IDs \n\nComplete the following steps to assign the administrator role on the IAM Identity Service for a user:\n\n\n\n1. Click Manage > Access (IAM), and select Users.\n2. Click the user's name from the table.\n3. Select the IAM Identity service and click Next.\n4. Select All resources and click Next.\n5. Select the Administrator role.\n6. Click Review > Add.\n7. Click Assign.\n\n\n\n\n\n\n\n Granting users access to tag service IDs by using the API \n\nTo assign the administrator role on the IAM Identity Service for a user, call the [IAM Policy Management API](https://cloud.ibm.com/apidocs/iam-policy-management) as shown in the following example request. Replace values with your target user's IAM ID and account ID.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X POST 'https://iam.cloud.ibm.com/v1/policies' -H 'Authorization: Bearer $TOKEN' -H 'Content-Type: application/json' -d '{\n\"type\": \"access\",\n\"description\": \"Administrator role for the IAM Identity Service so that user can tag service IDs\",\n\"subjects\": [\n{\n\"attributes\":\n{\n\"name\": \"iam_id\",\n\"value\": \"IBMid-123453user\"\n}\n]\n}'\n],\n\"roles\":[\n{\n\"role_id\": \"crn:v1:bluemix:public:iam::::role:Administrator\"\n}\n],\n\"resources\":[\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"$ACCOUNT_ID\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-access"}, {"document_id": "ibmcld_02734-1732-3794", "score": 0.6775528192520142, "text": "\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https://cloud.ibm.com/docs-content/v1/content/27ecaa7a29890634603881a8e64789974a29916b/appid/images/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-anonymous"}, {"document_id": "ibmcld_16234-1331-2901", "score": 0.674716055393219, "text": "\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM). If you want to add users, and you don't want them to have full Manager access, use IAM to add them. From IAM, you can also manage access roles of those users that are already added to your assistants.\n\n\n\n Opening Identity and Access Management \n\n\n\n1. Open the Manage menu. ![Manage menu](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/user--avatar.svg)\n2. Click Manage users.\n3. In Access and permissions, click Identity and Access Management in step 2.\n\nZoom\n\n![Access and permissions](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/access-control-manage-users-modal.png)\n\nAccess and permissions\n\n\n\n\n\n\n\n Adding users in Identity and Access Management \n\n\n\n1. In IAM, click Invite users.\n2. Enter the email address of the person who needs access.\n3. In How do you want to assign access?, choose Access policy.\n\nZoom\n\n![Access policy](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/access-policy.png)\n\nAccess policy\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-access-control"}, {"document_id": "ibmcld_06966-6860-8310", "score": 0.6670323610305786, "text": "\nFor more information, see [Giving users access to a Watson Discovery instance](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-discovery/discovery-admin-add-users.html).\n3. Enable document-level security for the data source when you connect to it.\n\n\n\n\n\n Creating users for document-level security \n\nYou must create users that match the users available on the source system that Discovery is connecting to so that they can query with document-level security enabled.\n\n\n\n1. Log in to Discovery as an administrator.\n2. Create users who match the users available on your source or who are connected to the identity provider that your source system uses. If you create users for document-level security, keep the following points in mind:\n\n\n\n* Optional: For each user that you want to have access to query results, you must add users. The username must match the username that the source uses. This option is only for development and testing purposes. To create users individually, see [Managing users](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/admin/users.html).\n* To connect to an identity provider that the source is using, see [Connecting to your identity provider](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/admin/ldap.html).\n\n\n\n\n\nDiscovery does not synchronize changes that are made to the users in the identity provider with the user list for the service. Discovery administrators must ensure that the user list is current and remove any noncurrent users.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collection-types"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16365-7-1700", "score": 0.7217410802841187, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16384-7-2422", "score": 0.7144834399223328, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_03151-2261-3876", "score": 0.6818233132362366, "text": "\n* [NICE inContact](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter/tree/main/src/incontact/webChat)\n* [Twilio Flex](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter/tree/main/src/flex/webChat)\n* [Bring your own (starter kit)](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter)\n\n\n\n6. Follow the instructions that are provided on the screen to complete the integration process.\n\n\n\nAfter you integrate the assistant, test it from the target channel to ensure that the assistant works as expected.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) For environments where private endpoints are in use, keep in mind that these integrations send traffic over the internet. For more information, see [Private network endpoints](https://cloud.ibm.com/docs/assistant?topic=assistant-securitysecurity-private-endpoints).\n\n\n\n\n\n How service desk platform integrations work \n\nWatch a 4-minute video about integrating your assistant with a live agent integration, such as Zendesk:\n\nTo learn about how service desk integrations with your assistant can benefit your business, [read this blog post](https://medium.com/ibm-watson/contact-center-post-394dff427c8).\n\n\n\n\n\n Integration limits \n\nThe number of integrations you can create in a single service instance depends on your Watson Assistant plan.\n\n\n\nService plan details\n\n Service plan Integrations per assistant \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 100 \n Trial 100 \n Lite 100", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add"}, {"document_id": "ibmcld_16384-1889-3334", "score": 0.6710188388824463, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16376-7-1787", "score": 0.6646280288696289, "text": "\nTutorial: Interacting with the host web page \n\nYou can use custom responses and events to enable the web chat to interact with the web page where it appears.\n\nFor example, your customers might use your assistant to find information they need to complete a form. Rather than expecting the customer to then copy this information manually to the form, you can have the web chat automatically fill in the information.\n\nFor a complete, working version of the example described in this tutorial, see [Page interactions for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/page-interaction).\n\nThis example uses a custom response to render a button in the web chat that populates a form field with the customer's account number:\n\n\n\n1. Create a handler for the [customResponse](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventscustomresponse) event. This handler renders a custom button and creates a click handler for it. The click handler uses the Document.querySelector() method to interact with the DOM and fill in a form field with the customer's account number.\n\nThis example uses the hardcoded account number 1234567. In a typical production assistant, your assistant would retrieve this value from a session variable or query it from an external system.\n\nfunction customResponseHandler(event) {\nconst { element } = event.data;\n\nconst button = document.createElement('button');\nbutton.type = 'button';\nbutton.innerHTML = 'Fill in account number';\nbutton.addEventListener('click', () => {\n// Look for the account number element in the document and fill in the account number.\ndocument.querySelector('account-number').value = '1234567';\n});\n\nelement.appendChild(button);\n}\n2.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-page-interaction"}, {"document_id": "ibmcld_16368-7-2072", "score": 0.6603643894195557, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16383-0-2125", "score": 0.6594942212104797, "text": "\n\n\n\n\n\n\n  Controlling the web chat version \n\nThe web chat JavaScript code follows semantic versioning practices. Starting with web chat version 2.0.0, you can set the version of the web chat that you want to use as a configuration option.\n\nIf you don't specify a version, the latest version is used automatically (clientVersion: \"latest\"). When you apply the latest version, you benefit from the continuous improvements, feature additions, and bug fixes that are made to the web chat regularly.\n\nHowever, if you apply extensive customizations to your deployment, such as overriding the theme with your own custom theme, you might want to lock your deployment to a specific version. Locking on a version enables you to test new versions before you apply them to your live web chat.\n\nTo use a specific version (clientVersion: \"major.minor.patch\"), specify it as follows:\n\nThe following examples show what to specify when the current version is 2.3.1.\n\n\n\n*  If you want to stay on a major version, but get the latest minor and patch releases, specify clientVersion: \"2\".\n*  If you want to stay on a minor version, but get the latest patch releases, specify clientVersion: \"2.3\".\n*  If you want to lock on to a specific minor version and patch release, specify clientVersion: \"2.3.1\".\n\n\n\nTo test the updates in a version release of the web chat before you apply the version to your live web chat, follow these steps:\n\n\n\n1.  Lock the web chat that is running in your production environment to a specific version.\n2.  Embed your web chat deployment into a new page in a test environment, and then override the version lock setting. For example, specify clientVersion: \"latest\".\n3.  Test the web chat, and make adjustments to the configuration if necessary.\n4.  Update your production deployment to use the latest version and apply any other configuration changes that you determined to be necessary after testing.\n\n\n\nFor more information about features that were introduced in previous web chat versions, see the [Web chat release notes](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-versions"}, {"document_id": "ibmcld_16295-7-1721", "score": 0.658955454826355, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16366-2985-3766", "score": 0.6515116691589355, "text": "\nFor more information, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture-security).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_03166-4-2012", "score": 0.6509895920753479, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https://medium.com/ibm-watson/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06160-11142-12906", "score": 0.7471899390220642, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-11475-13230", "score": 0.7414923906326294, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10534-545406-546780", "score": 0.7161048650741577, "text": "\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/openshift?topic=openshift-bm_machine_idbm_machine_id)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10596-9883-11854", "score": 0.7067339420318604, "text": "\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10684-1332-2528", "score": 0.7051823139190674, "text": "\nYour Flow Logs for VPC gathers information from the VPC, VPC subnet, or VPC load balancer level. However, you can use the flow logs to gather information that is specific to your worker nodes. Separate flow log files are created for ingress and egress traffic.\n\n\n\n1. In the CLI, find the ibm-cloud.kubernetes.io/instance-id label value for the worker node.\n\noc describe node <worker_node_ip> | grep instance-id\n\nExample output.\n\nibm-cloud.kubernetes.io/instance-id=1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n2. In the IBM Cloud UI, click your IBM Cloud Object Storage instance in the Resource list.\n3. Click the bucket where your flow logs are collected.\n4. Download and decompress the flow log object.\n5. Open the file and navigate through the file directory until you reach directories that begin with instance-id=.\n6. Find the file directory that contains the instance ID found in the first step. The ID is included at the end of the file directory name. Example.\n\ninstance-id=crn%3AV1%...%3Ainstance%3A1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n7. In the instance=id= directory, locate the record-type=ingress and record-type=egress files. Your ingress and egress traffic logs are located here.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-flow-log"}, {"document_id": "ibmcld_06277-1333-2534", "score": 0.6993156671524048, "text": "\nYour Flow Logs for VPC gathers information from the VPC, VPC subnet, or VPC load balancer level. However, you can use the flow logs to gather information that is specific to your worker nodes. Separate flow log files are created for ingress and egress traffic.\n\n\n\n1. In the CLI, find the ibm-cloud.kubernetes.io/instance-id label value for the worker node.\n\nkubectl describe node <worker_node_ip> | grep instance-id\n\nExample output.\n\nibm-cloud.kubernetes.io/instance-id=1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n2. In the IBM Cloud UI, click your IBM Cloud Object Storage instance in the Resource list.\n3. Click the bucket where your flow logs are collected.\n4. Download and decompress the flow log object.\n5. Open the file and navigate through the file directory until you reach directories that begin with instance-id=.\n6. Find the file directory that contains the instance ID found in the first step. The ID is included at the end of the file directory name. Example.\n\ninstance-id=crn%3AV1%...%3Ainstance%3A1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n7. In the instance=id= directory, locate the record-type=ingress and record-type=egress files. Your ingress and egress traffic logs are located here.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-flow-log"}, {"document_id": "ibmcld_06160-10037-11653", "score": 0.6987738609313965, "text": "\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_06160-8533-10577", "score": 0.6980615854263306, "text": "\n* Check any Calico or Kubernetes network policies that are applied to the cluster and make sure that they do not block traffic from the worker node to the cluster apiservice, container registry, or other critical services.\n\n\n\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see if the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. Check the status of your worker nodes. If they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n6. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_05713-581893-583377", "score": 0.6960435509681702, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_05762-7-1980", "score": 0.6944195032119751, "text": "\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https://cloud.ibm.com/gen1/infrastructure/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https://cloud.ibm.com/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https://cloud.ibm.com/docs/containers?topic=containers-cli-update).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06209-6757-8643", "score": 0.7995585203170776, "text": "\n* [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_05598-24740-26499", "score": 0.7847387790679932, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1562\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N/A N/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N/A N/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1562, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1562. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1561\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https://www.ibm.com/support/pages/node/6501867) and the [change logs](https://github.com/containerd/containerd/releases/tag/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https://nvd.nist.gov/vuln/detail/CVE-2021-3778) and [CVE-2021-3796](https://nvd.nist.gov/vuln/detail/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1561, released 27 September 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1561. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.14_1559\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_119"}, {"document_id": "ibmcld_06209-19911-21816", "score": 0.7806484699249268, "text": "\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10394-7-1848", "score": 0.7780443429946899, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_10068-170960-171999", "score": 0.7748953104019165, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1533_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.29 4.3.31 See the [Red Hat OpenShift release notes](https://docs.openshift.com/container-platform/4.3/release_notes/ocp-4-3-release-notes.htmlocp-4-3-31). The update resolves CVE-2020-8558 (see the [IBM security bulletin](https://www.ibm.com/support/pages/node/6319989)). \n RHEL 7 packages N/A N/A Updated worker node images with package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.29_1533_openshift, released 3 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.29_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1532_openshift\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}, {"document_id": "ibmcld_05598-74065-74574", "score": 0.7732505202293396, "text": "\nMetadata updates N/A N/A Updated the worker node version fix pack metadata for internal documentation purposes. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.7_1533, released 1 February 2021 \n\nThe following table shows the changes that are in the worker node fix pack 1.19.7_1533. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.7_1532\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_119"}, {"document_id": "ibmcld_05598-33950-34862", "score": 0.7721840143203735, "text": "\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.13_1556. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.13_1555\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages 4.15.0-151 4.15.0-153 N/A \n HA proxy 68e6b3 9c98dc Updated image with fixes for [CVE-2021-27218](https://nvd.nist.gov/vuln/detail/CVE-2021-27218). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.13_1555, released 02 August 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.13_1555. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.12_1553\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_119"}, {"document_id": "ibmcld_05600-68077-68984", "score": 0.7711111307144165, "text": "\nThe following table shows the changes that are in the worker node fix pack patch update 1.21.3_1527. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.21.3_1526\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages 4.15.0-151 4.15.0-153 N/A \n HA proxy 68e6b3 9c98dc Updated image with fixes for [CVE-2021-27218](https://nvd.nist.gov/vuln/detail/CVE-2021-27218). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.21.3_1526, released 02 August 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.21.3_1526. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.21.2_1524\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_121"}, {"document_id": "ibmcld_10405-18875-19733", "score": 0.7686028480529785, "text": "\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.57_1580_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N/A N/A N/A \n RHEL 8 Packages N/A N/A N/A \n Red Hat OpenShift on IBM Cloud. N/A N/A N/A \n Haproxy af5031 8398d1 [CVE-2023-23916](https://nvd.nist.gov/vuln/detail/CVE-2023-23916). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.9.57_1580_openshift, released 13 March 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.9.57_1580_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.56_1576_openshift\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_changelog_49"}, {"document_id": "ibmcld_06209-8154-10055", "score": 0.767753541469574, "text": "\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": []}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16471-73103-74976", "score": 0.659162700176239, "text": "\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_16471-71623-73502", "score": 0.6271417140960693, "text": "\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_04826-38948-40745", "score": 0.626275360584259, "text": "\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage-cli-plugin?topic=cloud-object-storage-cli-plugin-ic-cos-cli"}, {"document_id": "ibmcld_04457-38780-40577", "score": 0.626275360584259, "text": "\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ic-cos-cli"}, {"document_id": "ibmcld_04981-38915-40712", "score": 0.626275360584259, "text": "\n* Optional: Max number of PARTS which will be uploaded to S3 that calculates the part size of the object to be uploaded. Limit is 10,000 parts.\n\n\n\n* Flag: --max-upload-parts PARTS\n\n\n\n* Optional: The buffer SIZE (in bytes) to use when buffering data into chunks and ending them as parts to S3. The minimum allowed part size is 5MB.\n\n\n\n* Flag: --part-size SIZE\n\n\n\n* Optional: Setting this value to true will cause the SDK to avoid calling AbortMultipartUpload on a failure, leaving all successfully uploaded parts on S3 for manual recovery.\n\n\n\n* Flag: --leave-parts-on-errors\n\n\n\n* Optional: Specifies CACHING_DIRECTIVES for the request/reply chain.\n\n\n\n* Flag: --cache-control CACHING_DIRECTIVES\n\n\n\n* Optional: Specifies presentational information (DIRECTIVES).\n\n\n\n* Flag: --content-disposition DIRECTIVES\n\n\n\n* Optional: Specifies what content encodings (CONTENT_ENCODING) have been applied to the object and thus what decoding mechanisms must be applied to obtain the media-type referenced by the Content-Type header field.\n\n\n\n* Flag: --content-encoding CONTENT_ENCODING\n\n\n\n* Optional: The LANGUAGE the content is in.\n\n\n\n* Flag: --content-language LANGUAGE\n\n\n\n* Optional: SIZE of the body in bytes. This parameter is useful when the size of the body cannot be determined automatically.\n\n\n\n* Flag: --content-length SIZE\n\n\n\n* Optional: The base64-encoded 128-bit MD5 digest of the data.\n\n\n\n* Flag: --content-md5 MD5\n\n\n\n* Optional: A standard MIME type describing the format of the object data.\n\n\n\n* Flag: --content-type MIME\n\n\n\n* Optional: A MAP of metadata to store.\n\n\n\n* Flag: --metadata MAP JSON Syntax: The --metadata flag takes the file:// prefix that is used to load the JSON structure from the specified file.\n\n\n\n\n\n{\n\"file_name\": \"file_20xxxxxxxxxxxx45.zip\",\n\"label\": \"texas\",\n\"state\": \"Texas\",", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli"}, {"document_id": "ibmcld_13727-6963-8467", "score": 0.5860288143157959, "text": "\n\"words\": [\n{\n\"word\": \"\uff2e\uff39\",\n\"translation\": \"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\",\n\"part_of_speech\": \"Mesi\"\n},\n{\n\"word\": \"\uff2e\uff39\uff23\",\n\"translation\": \"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u30b7\u30c6\u30a3\",\n\"part_of_speech\": \"Mesi\"\n},\n{\n\"word\": \"\uff39\uff23\",\n\"translation\": \"\u30e8\u30b3\u30cf\u30de\u30c1\u30e5\u30fc\u30ab\u30ac\u30a4\",\n\"part_of_speech\": \"Mesi\"\n}\n]\n}\nShow more\n\nWith these entries, assume that the service receives the following input text: \u4e00\u9031\u9593\uff2e\uff39\uff23\u3092\u8a2a\u554f\u3057\u305f. In this case, the service matches the word \uff2e\uff39\uff23 because \uff2e\uff39\uff23 is longer than \uff2e\uff39 and because \uff2e\uff39\uff23 matches before \uff39\uff23.\n\n\n\n\n\n Japanese parts of speech \n\nThe following table lists the parts of speech that are supported for Japanese custom entries. For more information about specifying the part of speech for a Japanese custom entry, see [Adding words to a Japanese custom model](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customWordscuJapaneseAdd).\n\n\n\nTable 1. Japanese parts of speech\n\n part_of_speech argument Japanese meaning English meaning \n\n Dosi Doushi Verb \n Fuku Fukishi Adverb \n Gobi Gobi Inflection \n Hoka Hoka Other (Words that have a special grammatical meaning of their own that does not fit into any other part of speech. For example, \u3042\u308a\u304c\u3068\u3046 for \"thank you.\") \n Jodo Jodoushi Auxiliary verb \n Josi Joshi Postpositional particle (For example, \u304c \u306e \u3092 for \"of.\") \n Kato Kantoushi Interjection \n Kedo Keiyodoushi Adjective verb \n Keyo Keiyoshi Adjective (For example, \u7f8e\u3057 for \"beautiful\" or \u660e\u308b for \"bright.\") \n Kigo Kigou Symbol \n Koyu Koyuumeishi Proper noun \n Mesi Meishi Noun \n Reta Rentaishi Determiner \n Stbi Setsubiji Suffix \n Stto Settoji Prefix", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-rules"}, {"document_id": "ibmcld_05048-4950-5968", "score": 0.5808079242706299, "text": "\n{endpoint}/{object-name}?uploadId={uploadId}= virtual host style\n\n<CompleteMultipartUpload>\n<Part>\n<PartNumber>{sequential part number}</PartNumber>\n<ETag>{ETag value from part upload response header}</ETag>\n</Part>\n</CompleteMultipartUpload>\n\nExample request\n\nPOST /some-bucket/multipart-object-123?uploadId=0000015a-df89-51d0-2790-dee1ac994053 HTTP/1.1\nAuthorization: Bearer {token}\nContent-Type: text/plain; charset=utf-8\nHost: s3.us.cloud-object-storage.appdomain.cloud\nContent-Length: 257\n\n<CompleteMultipartUpload>\n<Part>\n<PartNumber>1</PartNumber>\n<ETag>\"7417ca8d45a71b692168f0419c17fe2f\"</ETag>\n</Part>\n<Part>\n<PartNumber>2</PartNumber>\n<ETag>\"7417ca8d45a71b692168f0419c17fe2f\"</ETag>\n</Part>\n</CompleteMultipartUpload>\n\nExample response\n\nHTTP/1.1 200 OK\nDate: Fri, 03 Mar 2017 19:18:44 GMT\nX-Clv-Request-Id: c8be10e7-94c4-4c03-9960-6f242b42424d\nAccept-Ranges: bytes\nServer: Cleversafe/3.9.1.114\nX-Clv-S3-Version: 2.5\nETag: \"765ba3df36cf24e49f67fc6f689dfc6e-2\"\nContent-Type: application/xml\nContent-Length: 364", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-large-objects"}, {"document_id": "ibmcld_05137-32578-33461", "score": 0.578566312789917, "text": "\nFile Contents: This is a test file from Node.js code sample!!!\nDONE!\n\nStarting multi-part upload for js_large_file_c697db513f8211e9b1228597cf8e3a32.bin to bucket: js.bucket.c697b4403f8211e9b1228597cf8e3a32\nUploading to js_large_file_c697db513f8211e9b1228597cf8e3a32.bin (part 1 of 4)\nUploading to js_large_file_c697db513f8211e9b1228597cf8e3a32.bin (part 2 of 4)\nUploading to js_large_file_c697db513f8211e9b1228597cf8e3a32.bin (part 3 of 4)\nUploading to js_large_file_c697db513f8211e9b1228597cf8e3a32.bin (part 4 of 4)\nDONE!\n\nRetrieving bucket contents from: js.bucket.c697b4403f8211e9b1228597cf8e3a32\nItem: js_file_c697db503f8211e9b1228597cf8e3a32.txt (47 bytes).\nItem: js_large_file_c697db513f8211e9b1228597cf8e3a32.bin (20971520 bytes).\nDONE!\n\nDeleting item: js_large_file_c697db513f8211e9b1228597cf8e3a32.bin\nItem: js_large_file_c697db513f8211e9b1228597cf8e3a32.bin deleted!\nDONE!", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sdk-gs"}, {"document_id": "ibmcld_05088-15637-16709", "score": 0.5684762001037598, "text": "\nupload_id = mp[\"UploadId\"]\n\n min 20MB part size\npart_size = 1024 * 1024 * 20\nfile_size = os.stat(file_path).st_size\npart_count = int(math.ceil(file_size / float(part_size)))\ndata_packs = []\nposition = 0\npart_num = 0\n\n begin uploading the parts\nwith open(file_path, \"rb\") as file:\nfor i in range(part_count):\npart_num = i + 1\npart_size = min(part_size, (file_size - position))\n\nprint(\"Uploading to {0} (part {1} of {2})\".format(item_name, part_num, part_count))\n\nfile_data = file.read(part_size)\n\nmp_part = cos_cli.upload_part(\nBucket=bucket_name,\nKey=item_name,\nPartNumber=part_num,\nBody=file_data,\nContentLength=part_size,\nUploadId=upload_id\n)\n\ndata_packs.append({\n\"ETag\":mp_part[\"ETag\"],\n\"PartNumber\":part_num\n})\n\nposition += part_size\n\n complete upload\ncos_cli.complete_multipart_upload(\nBucket=bucket_name,\nKey=item_name,\nUploadId=upload_id,\nMultipartUpload={\n\"Parts\": data_packs\n}\n)\nprint(\"Upload for {0} Complete!n\".format(item_name))\nexcept ClientError as be:\n abort the upload\ncos_cli.abort_multipart_upload(\nBucket=bucket_name,\nKey=item_name,\nUploadId=upload_id\n)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-python"}, {"document_id": "ibmcld_13727-5292-7131", "score": 0.560061514377594, "text": "\nThey appear in the pronunciation for a word only if you include them in the word's translation.\n\n\n\nFor more information about working with SPR, see [Understanding phonetic symbols](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-symbols).\n\n\n\n\n\n Working with Japanese entries \n\nExtra rules and a part_of_speech field apply to the creation of entries for words in a Japanese custom model:\n\n\n\n* A sounds-like translation can contain only Katakana characters. Kanji and Hiragana characters are not allowed.\n* When you create a translation (sounds-like or phonetic) for a word, you can also specify an optional part_of_speech field to identify the word's part of speech. The service uses the part of speech to produce the correct intonation for the word. For a complete list, see [Japanese parts of speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-rulespartsOfSpeech).\n* You can create only a single entry for any word, and you can specify only a single part of speech for any word. You cannot create multiple entries with different parts of speech (for instance, noun and verb) for the same word. Adding a translation for a word that exists in a model overwrites the word's existing translation, including its part of speech.\n\nFor improved naturalness of synthesized speech, do not create custom entries for long phrases. Create translations for single words or short phrases only. Note that other languages limit translation to single words only.\n* The service applies the longest matching word from the word/translation pairs that are defined for a custom model. For example, consider the following three entries for a custom model.\n\n{\n\"words\": [\n{\n\"word\": \"\uff2e\uff39\",\n\"translation\": \"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\",\n\"part_of_speech\": \"Mesi\"\n},\n{\n\"word\": \"\uff2e\uff39\uff23\",\n\"translation\": \"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u30b7\u30c6\u30a3\",\n\"part_of_speech\": \"Mesi\"\n},\n{\n\"word\": \"\uff39\uff23\",", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-rules"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02961-7-1871", "score": 0.640035092830658, "text": "\nDialog building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nYou currently know what the node does, but months from now you might not. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips"}, {"document_id": "ibmcld_02882-4561-6101", "score": 0.6321898698806763, "text": "\nSee [Configuring the Jump to action](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to-config) for more details.\n\n\n\n7. Optional: If you want this node to be considered when users are shown a set of node choices at run time, and asked to pick the one that best matches their goal, then add a short description of the user goal handled by this node to the external node name field. For example, Open an account.\n\nSee [Disambiguation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-disambiguation) for more details.\n8. Optional: Name the node.\n\nThe dialog node name can contain letters (in Unicode), numbers, spaces, underscores, hyphens, and periods.\n\nNaming the node makes it easier for you to remember its purpose and to locate the node when it is minimized. If you don't provide a name, the node condition is used as the name.\n9. To add more nodes, select a node in the tree, and then click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon.\n\n\n\n* To create a peer node that is checked next if the condition for the existing node is not met, select Add node below.\n* To create a peer node that is checked before the condition for the existing node is checked, select Add node above.\n* To create a child node to the selected node, select Add child node. A child node is processed after its parent node.\n* To copy the current node, select Duplicate.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_07104-11530-13162", "score": 0.6303088665008545, "text": "\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in Google Protocol Buffers](https://www.ibm.com/support/pages/node/6570937)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in Node.js](https://www.ibm.com/support/pages/node/6570939)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in Java](https://www.ibm.com/support/pages/node/6570941)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in PostgreSQL](https://www.ibm.com/support/pages/node/6570943)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in Kotlin](https://www.ibm.com/support/pages/node/6570945)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data affected by vulnerability in Apache POI](https://www.ibm.com/support/pages/node/6570947)\n* [Security Bulletin: IBM Watson Discovery for IBM Cloud Pak for Data is affected by a remote code execution in Spring Framework (CVE-2022-22965)](https://www.ibm.com/support/pages/node/6570949)\n\n\n\n\n\n\n\n IBM Watson\u00ae Discovery for IBM Cloud Private (ICP) for Data 2.2.x End Of Support \n\nEffective 30 April 2022, IBM will withdraw support for the following programs:\n\n\n\n* IBM Watson Discovery for ICP for Data 2.2.x\n* IBM Watson Discovery for ICP for Data Add-on 2.2.x\n\n\n\nFor more information, see announcement [ENUS921-134.PDF](https://www.ibm.com/common/ssi/ShowDoc.wss?docURL=/common/ssi/rep_ca/4/897/ENUS921-134/index.html&request_locale=en).\n\n\n\n\n\n 4.0.7 release, 30 March 2022", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes-data"}, {"document_id": "ibmcld_06160-11142-12906", "score": 0.6209887266159058, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_02934-13221-15194", "score": 0.618498682975769, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/sauce.png)\n\nAfter responding to the off-topic question, the prompt associated with the current empty slot is displayed.\n\nThis condition is triggered if the user provides input that matches the slot handler conditions at any time during the dialog node flow up until the node-level response is displayed. See [Handling requests to exit a process](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-node-level-handler) for more ways to use the slot handler.\n7. Add a node-level response. The node-level response is not executed until after all of the required slots are filled. You can add a response that summarizes the information you collected. For example, A $size pizza is scheduled for delivery at $time. Enjoy!\n\nYou can alternatively show an image or list of options as a response instead of a text response. See [Response type options](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-response-types).\n\nIf you want to define different responses based on certain conditions, click Customize, and then click the Multiple responses toggle to turn it On. For information about conditional responses, see [Conditional responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multiple).\n8. Add logic that resets the slot context variables. As you collect answers from the user per slot, they are saved in context variables. You can use the context variables to pass the information to another node or to an application or external service for use. However, after passing the information, you must set the context variables to null to reset the node so it can start collecting information again. You cannot null the context variables within the current node because your assistant will not exit the node until the required slots are filled.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_02882-5559-7278", "score": 0.6183309555053711, "text": "\n[More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon.\n\n\n\n* To create a peer node that is checked next if the condition for the existing node is not met, select Add node below.\n* To create a peer node that is checked before the condition for the existing node is checked, select Add node above.\n* To create a child node to the selected node, select Add child node. A child node is processed after its parent node.\n* To copy the current node, select Duplicate.\n\n\n\nFor more information about the order in which dialog nodes are processed, see [Dialog overview](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n10. Test the dialog as you build it.\n\nSee [Testing your dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-build-test) for more information.\n\n\n\n\n\n\n\n Conditions \n\nA node condition determines whether that node is used in the conversation. Response conditions determine which response to return to a user.\n\n\n\n* [Condition artifacts](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-condition-artifacts)\n* [Special conditions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-special-conditions)\n* [Condition syntax details](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-condition-syntax)\n\n\n\nFor tips on performing more advanced actions in conditions, see [Condition usage tips](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tipsdialog-tips-condition-usage).\n\n\n\n Condition artifacts", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_03071-3000-4820", "score": 0.6173979043960571, "text": "\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots"}, {"document_id": "ibmcld_10596-11475-13230", "score": 0.6142985820770264, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_02882-3069-5022", "score": 0.6113572716712952, "text": "\nFor more information about how to test for values in conditions, see [Conditions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-conditions).\n4. Optional: If you want to collect multiple pieces of information from the user in this node, then click Customize and enable Slots. See [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots) for more details.\n5. Enter a response.\n\n\n\n* Add the text or multimedia elements that you want your assistant to display to the user as a response.\n* If you want to define different responses based on certain conditions, then click Customize and enable Multiple responses.\n* For information about conditional responses, rich responses, or how to add variety to responses, see [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses).\n\n\n\n6. Specify what to do after the current node is processed. You can choose from the following options:\n\n\n\n* Wait for user input: Your assistant pauses until new input is provided by the user.\n* Skip user input: Your assistant jumps directly to the first child node. This option is only available if the current node has at least one child node.\n* Jump to: Your assistant continues the dialog by processing the node you specify. You can choose whether your assistant should evaluate the target node's condition or skip directly to the target node's response. See [Configuring the Jump to action](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to-config) for more details.\n\n\n\n7. Optional: If you want this node to be considered when users are shown a set of node choices at run time, and asked to pick the one that best matches their goal, then add a short description of the user goal handled by this node to the external node name field. For example, Open an account.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_03827-6397-8588", "score": 0.604960560798645, "text": "\nFor this example, we assume one backup every 24 hours and retain seven backups.\n\nFor the peer pods:\n\n\n\n* CouchDB snapshot daily at 3:00 a.m.\n* Peer snapshot daily at 3:05 a.m.\n\n\n\nFor the ordering node pods:\n\n\n\n* Ordering node snapshots daily at 5:00 a.m. The two-hour gap allows sufficient time for all of the peers to be snapshotted from every organization before ordering nodes are snapshotted.\n\n\n\nIf you are using private data collections in your applications, your nodes must be running Hyperledger Fabric 2.2.1 or higher in order to back up peer and ordering nodes while they are running. When restoring from a backup, the peers must be restored from a lower block height than the ordering nodes. While peers can catch up to the block height of the ordering service, the ordering service does not have the actual private data (in a private data transaction, only hashes of the data are committed to the public ledger), rendering the data for these blocks unavailable. Fabric v2.2.1 and higher has a configurable option to lower the priority for the reconciliation of missing private data. Earlier versions constantly attempt to reconcile the missing private data, potentially blocking out reconciliation of other private data. On earlier versions of Hyperledger Fabric, you must back up ordering nodes and peers at exactly the same block heights to avoid this issue. This can be accomplished by scaling the both the peer and ordering node pods to 0 before taking the backup.\n\n\n\n\n\n\n\n Taking snapshots \n\nThe overall steps for the backup and restore process apply in all cases and are independent of where your components are deployed. However, the specific commands that are used in this example for creating, listing, and restoring snapshots apply only if you are running on IBM Cloud. For other cloud providers or when running in your own datacenter, follow the specific instructions for underlying snapshot creation and management found in the documentation of those providers.\n\nWhen a snapshot is being taken the node continues to function as normal.\n\n\n\n Node snapshots \n\nBecause the process for taking a snapshot is the same for all nodes, only one set of instructions is shown here.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-backup-restore"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06320-2897-4555", "score": 0.7287715673446655, "text": "\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https://docs.datastax.com/en/opscenter/6.5/opsc/online_help/services/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https://github.com/nosqlbench/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_06320-4083-5561", "score": 0.6479203104972839, "text": "\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https://github.com/nosqlbench/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https://docs.datastax.com/en/dsbulk/doc/dsbulk/reference/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https://docs.datastax.com/en/dse/6.0/cql/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https://docs.datastax.com/en/astra/docs/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https://cloud.ibm.com/docs/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https://cloud.ibm.com/apidocs/cloud-databases-api).", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_06320-1330-3318", "score": 0.5726518630981445, "text": "\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https://docs.datastax.com/en/devapp/doc/devapp/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10596-7-2100", "score": 0.7259654402732849, "text": "\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud oc worker commands, and as NotReady in the Red Hat OpenShift dashboards and when you run oc get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-7-2098", "score": 0.7178707718849182, "text": "\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud ks worker commands, and as NotReady in the Kubernetes dashboards and when you run kubectl get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_05558-7-2091", "score": 0.7162549495697021, "text": "\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https://cloud.ibm.com/docs/containers?topic=containers-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-add_workers"}, {"document_id": "ibmcld_10290-114867-116840", "score": 0.7157963514328003, "text": "\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n* Node-level customizations are not preserved: Any custom labels or taints that you applied at the individual worker node level are not applied to the replacement worker node. Instead, apply [labels](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersworker_pool_labels) or [taints](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cliworker_pool_taint) at the worker pool level so that the replacement worker node gets these attributes.\n* Automatic rebalancing: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-off).\n\n\n\nBefore you begin, make sure that your cluster has enough other worker nodes so that your pods can be rescheduled and continue to run.\n\n\n\n1. List all worker nodes in your cluster and note the name of the worker node that you want to replace.\n\noc get nodes\n\nThe name that is returned in this command is the private IP address that is assigned to your worker node. You can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Replace the worker node. As part of the replace process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_10035-7-2089", "score": 0.7142611742019653, "text": "\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-add_workers"}, {"document_id": "ibmcld_06128-11467-13651", "score": 0.71412193775177, "text": "\nHow many worker nodes do I need to handle my workload? \n\nNow that you have a good idea of what your workload looks like, let's map the estimated usage onto your available cluster configurations.\n\n\n\n1. Estimate the max worker node capacity, which depends on what type of cluster you have. You don't want to max out worker node capacity in case a surge or other temporary event happens.\n\n\n\n* Single zone clusters: Plan to have at least three worker nodes in your cluster. Further, you want one extra node's worth of CPU and memory capacity available within the cluster.\n* Multizone clusters: Plan to have at least two worker nodes per zone, so six nodes across three zones in total. Additionally, plan for the total capacity of your cluster to be at least 150% of your total workload's required capacity, so that if one zone goes down, you have resources available to maintain the workload.\n\n\n\n2. Align the app size and worker node capacity with one of the [available worker node flavors](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesplanning_worker_nodes). To see available flavors in a zone, run ibmcloud ks flavors --zone <zone>.\n\n\n\n* Don't overload worker nodes: To avoid your pods competing for CPU or running inefficiently, you must know what resources your apps require so that you can plan the number of worker nodes that you need. For example, if your apps require less resources than the resources that are available on the worker node, you can limit the number of pods that you deploy to one worker node. Keep your worker node at around 75% capacity to leave space for other pods that might need to be scheduled. If your apps require more resources than you have available on your worker node, use a different worker node flavor that can fulfill these requirements. You know that your worker nodes are overloaded when they frequently report back a status of NotReady or evict pods due to the lack of memory or other resources.\n* Larger versus smaller worker node flavors: Larger nodes can be more cost efficient than smaller nodes, particularly for workloads that are designed to gain efficiency when they process on a high-performance machine.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-strategy"}, {"document_id": "ibmcld_10710-7-1992", "score": 0.713737964630127, "text": "\nWorker node states \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\n\n\n Critical state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA worker node can go into a Critical state for many reasons. See [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready) for more information and troubleshooting steps.\n\n\n\n\n\n Deleting state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleting state means that you requested to delete the worker node, possibly as part of resizing a worker pool or autoscaling the cluster. Other operations can't be issued against the worker node while the worker node deletes. You can't reverse the deletion process. When the deletion process completes, you are no longer billed for the worker nodes.\n\n\n\n\n\n Deleted state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleted state means that your worker node is deleted, and no longer is listed in the cluster or billed. This state can't be undone. Any data that was stored only on the worker node, such as container images, are also deleted.\n\n\n\n\n\n Deployed state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nUpdates are successfully deployed to your worker node. After updates are deployed, Red Hat OpenShift on IBM Cloud starts a health check on the worker node. After the health check is successful, the worker node goes into a Normal state.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-worker-node-state-reference"}, {"document_id": "ibmcld_05575-0-1906", "score": 0.7076906561851501, "text": "\n\n\n\n\n\n\n  Why doesn't replacing a worker node create a worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you [replace a worker node](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clicli_worker_replace) or [update a VPC worker node](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node), a worker node is not automatically added back to your cluster.\n\n  Why it\u2019s happening \n\nBy default, your worker pools are set to automatically rebalance when you replace a worker node. However, you might have disabled automatic rebalancing by manually removing a worker node, such as in the following scenario.\n\n\n\n1.  You have a worker pool that automatically rebalances by default.\n2.  You have a troublesome worker node in the worker pool that you removed individually, such as with the ibmcloud ks worker rm command.\n3.  Now, automatic rebalancing is disabled for your worker pool, and is not reset unless you try to rebalance or resize the worker pool.\n4.  You try to replace a worker node with the ibmcloud ks worker replace command or update a VPC worker node with the ibmcloud ks worker replace --update command. The worker node is removed, but another worker node is not added back to your worker pool.\n\n\n\nYou might also have issued the remove command shortly after the replace command. If the remove command is processed before the replace command, the worker pool automatic rebalancing is still disabled, so your worker node is not replaced.\n\n  How to fix it \n\nTo enable automatic rebalancing, [rebalance](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_rebalance) or [resize](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) your worker pool. Now, when you replace a worker node, another worker node is created for you.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-off"}, {"document_id": "ibmcld_04489-112645-114324", "score": 0.7073017358779907, "text": "\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud ks worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}, {"document_id": "ibmcld_10044-0-1900", "score": 0.7061585187911987, "text": "\n\n\n\n\n\n\n  Why doesn't replacing a worker node create a worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you [replace a worker node](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clicli_worker_replace) or [update a VPC worker node](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node), a worker node is not automatically added back to your cluster.\n\n  Why it\u2019s happening \n\nBy default, your worker pools are set to automatically rebalance when you replace a worker node. However, you might have disabled automatic rebalancing by manually removing a worker node, such as in the following scenario.\n\n\n\n1.  You have a worker pool that automatically rebalances by default.\n2.  You have a troublesome worker node in the worker pool that you removed individually, such as with the ibmcloud oc worker rm command.\n3.  Now, automatic rebalancing is disabled for your worker pool, and is not reset unless you try to rebalance or resize the worker pool.\n4.  You try to replace a worker node with the ibmcloud oc worker replace command or update a VPC worker node with the ibmcloud oc worker replace --update command. The worker node is removed, but another worker node is not added back to your worker pool.\n\n\n\nYou might also have issued the remove command shortly after the replace command. If the remove command is processed before the replace command, the worker pool automatic rebalancing is still disabled, so your worker node is not replaced.\n\n  How to fix it \n\nTo enable automatic rebalancing, [rebalance](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_rebalance) or [resize](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) your worker pool. Now, when you replace a worker node, another worker node is created for you.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-off"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08259-0-511", "score": 0.816713809967041, "text": "\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-release-notes"}, {"document_id": "ibmcld_14491-1340-3282", "score": 0.8070582151412964, "text": "\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https://cloud.redhat.com/openshift/install/vsphere/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"}, {"document_id": "ibmcld_14492-7-1792", "score": 0.7887811660766602, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_08265-7-2115", "score": 0.7878215909004211, "text": "\nSetting up a Red Hat OpenShift for HPC cluster \n\nWhile IBM values the use of inclusive language, terms that are outside of IBM's direct influence are sometimes required for the sake of maintaining user understanding. As other industry leaders join IBM in embracing the use of inclusive language, IBM will continue to update the documentation to reflect those changes.\n\n\n\n Objective \n\n\n\n* Deploy a Red Hat\u00ae OpenShift\u00ae for HPC cluster with your choice of configuration properties\n\n\n\n\n\n\n\n Architecture overview and NFS file system setup \n\nThe Red Hat OpenShift for HPC cluster consists of a login (bastion) node, a storage node where the block storage volume is attached, one or more instances of your Red Hat OpenShift master, and a number of worker nodes.\n\n\n\n* The login node serves as a jump host and it is the only node that has a public IP address. The NFS node has only a private IP address and the only way to reach it is through the login node.\n* By default, every cluster in Red Hat OpenShift on IBM Cloud\u00ae is set up with multiple Red Hat OpenShift master instances to ensure the availability and accessibility of your cluster resources, even if one or more of these masters become unavailable. Worker nodes are created across multiple availability zones in a region.\n* Every cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all of the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). Since [Red Hat OpenShift on IBM Cloud](https://www.ibm.com/cloud/openshift) is a managed service, you cannot SSH directly into the master and worker nodes.\n* The storage node is configured as an NFS server and the block storage is mounted to /data, which is exported to share with Red Hat OpenShift cluster worker nodes. If you want to use the NFS storage inside the pods, then you need to create persistent volumes and persistent volume claims and attach them into the pods.", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-setting-up-red-hat-openshift-hpc-cluster"}, {"document_id": "ibmcld_07968-7-1612", "score": 0.7878077030181885, "text": "\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"}, {"document_id": "ibmcld_10702-7-1940", "score": 0.7861317992210388, "text": "\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https://docs.openshift.com/container-platform/4.11/welcome/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial"}, {"document_id": "ibmcld_10228-4-1670", "score": 0.7835730910301208, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https://docs.openshift.com/container-platform/4.11/welcome/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https://cloud.ibm.com/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/kubernetes/catalog/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started"}, {"document_id": "ibmcld_10229-4-1670", "score": 0.7835730314254761, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https://docs.openshift.com/container-platform/4.11/welcome/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https://cloud.ibm.com/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/kubernetes/catalog/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started&interface=ui"}, {"document_id": "ibmcld_07578-396975-399135", "score": 0.7808732986450195, "text": "\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-396949-399109", "score": 0.7808732986450195, "text": "\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14913-0-1238", "score": 0.7472542524337769, "text": "\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf"}, {"document_id": "ibmcld_16030-7-2126", "score": 0.6564295291900635, "text": "\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-behind-the-curtain"}, {"document_id": "ibmcld_04709-1717-3966", "score": 0.6525723934173584, "text": "\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"}, {"document_id": "ibmcld_16026-0-358", "score": 0.6449591517448425, "text": "\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vnf-limitations"}, {"document_id": "ibmcld_16030-4758-6868", "score": 0.6361034512519836, "text": "\nInter-subnet, inter-zone data flows - For these flows, the implicit router function removes the VNI and forwards the packet in the VPC's MPLS VPN for transit across the cloud backbone. At the destination zone, the implicit router function tags the data packet with the appropriate VNI. Then, the packet is forwarded to the destination hypervisor, where the VNI is stripped off again so that the data packet can be forwarded to the destination virtual server instance.\n\nExtra-vpc service data flows - Packets that are destined for IaaS or IBM Cloud Service Endpoint (CSE) services use the VPC's implicit router function. They also use a network address translation (NAT) function. The translation function replaces the virtual server instance address with an IPv4 address that identifies the VPC to the IaaS or CSE service that is requested.\n\nExtra-vpc internet data flows - Packets that are destined for the internet are the most complex. In addition to using the VPC's implicit router function, each of these flows also rely on one of the implicit router's two network address translation (NAT) functions.\n\n\n\n* An explicit one-to-many NAT through a public gateway function that serves all subnets that are connected to it.\n* One-to-one NAT assigned to individual virtual server instances.\n\n\n\nAfter NAT translation, the implicit router forwards these internet-destined packets to the internet, by using the cloud backbone.\n\n\n\n\n\n Life cycle of external IP addresses that are associated with public gateway functions \n\nAs both external IP addresses and PGWs are bound to an availability zone. A public gateway function can have only a single external IP. This external IP has the following lifecycle:\n\n\n\n* The external IP is allocated when the public gateway is created.\n* The external IP is released when the public gateway is deleted.\n\n\n\n\n\n\n\n Classic access \n\nThe [classic access](https://cloud.ibm.com/docs/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) feature for VPC is accomplished by reusing the VRF identifier from the IBM Cloud\u00ae classic infrastructure account as the VRF identifier for VPC.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-behind-the-curtain"}, {"document_id": "ibmcld_14301-1394-3227", "score": 0.6231585144996643, "text": "\nFor more information about resource requirements and capacity checking for some services, see [Resource requirements for services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-resource-requirements).\n\nThe following components are ordered and included in the Zerto service.\n\nZerto Virtual Replication Appliance (VRA) components are deployed only into the default cluster.\n\n\n\n Virtual Service Instances \n\n\n\n* One Virtual Service Instance (VSI) - Zerto Virtual Manager\n* 2 x 2.0 GHz cores\n* 4 GB RAM\n* Windows\u00ae Server 2019 Standard Edition (64-bit)\n\n\n\n\n\n\n\n Storage \n\n100 GB (SAN) disk\n\n\n\n\n\n Zerto Networking \n\n\n\n* VSI\n\n\n\n* One primary private IP address\n* 1 Gbps private network uplink\n\n\n\n* Virtual replication appliances (VRAs)\n\n\n\n* One private portable subnet for VRA deployment\n\n\n\n\n\nThe Zerto service is not configured with an IBM Cloud Infrastructure portable IP address or with a NAT connection to the public network, even if you have public interfaces in your instance. This implementation helps to avoid the possibility of asymmetric routing when it uses a network gateway appliance.\n\nWhen you deploy Zerto, you must configure your own proxy or NAT connection to the public network. If you do not complete the configuration, Zerto blocks management activities in 15 days. For more information about the Call Home feature for Zerto, see [Considerations for ordering Zerto](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-zerto_orderingzerto_ordering-private-only).\n\n\n\n\n\n Licenses and fees \n\nZerto Replication version 9.7u3 license.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Ordering Zerto](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-zerto_ordering)\n* [Managing Zerto](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-managingzertodr)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-addingzertodr"}, {"document_id": "ibmcld_14887-7-2470", "score": 0.6209197044372559, "text": "\nUnderstanding cloud maintenance operations \n\n\n\n Types of maintenance operations that affect your virtual server instances \n\n\n\n Host and dedicated host maintenance \n\nIBM Cloud\u00ae performs periodic maintenance on the server hosts and dedicated hosts that run virtual servers. This maintenance upgrades the software on the underlying hypervisor, update the firmware on the systems, or other security and performance updates. In general, users don't experience any issues during these upgrades. Modifications that require host maintenance are applied with no or little impact to running services in most cases. Scenarios can occur where the user is involved during maintenance operations, which are discussed in the [Possible impacts to virtual server instances during maintenance operations](https://cloud.ibm.com/docs/vpc?topic=vpc-about-cloud-maintenancemaintenance-impacts) section.\n\nMost updates are done transparently to the host and the virtual servers that run on those hosts do not see any disruption. Nondisruptive changes can occur multiple times per week or even daily if necessary, all without impacting the user experience.\n\n\n\n\n\n Data center maintenance \n\nIBM Cloud\u00ae also performs periodic data center maintenance upgrades. Users don't generally experience any issues during data center maintenance. Examples of this maintenance can be updates to the network, power infrastructure, or server hardware in a data center. Most maintenance is performed without impact to the user\u2019s workloads. Some infrequent scenarios can occur where the user might need to be involved during those operations, which are discussed in the following section.\n\n\n\n\n\n\n\n Possible impacts to virtual server instances during maintenance operations \n\nSome changes can require a secure live migration of a virtual server to update the hypervisor or host. These changes can be a firmware update, an event where the hypervisor kernel cannot be live patched, or load balancing. The regular live migration process is nondisruptive and use of dedicated hosts and virtual servers is not interrupted.\n\nWhen nondisruptive live migration occurs, the virtual server experiences a brief pause of around 10 seconds, and in some cases up to 30 seconds. You are not notified in advance of nondisruptive migration. The virtual server instance is not restarted as part of this process.\n\nIn cases where a disruptive migration is required, you are notified 30 days in advance of the scheduled migration.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-cloud-maintenance"}, {"document_id": "ibmcld_07953-7-2429", "score": 0.6062309741973877, "text": "\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https://cloud.ibm.com/docs/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"}, {"document_id": "ibmcld_04268-7-2143", "score": 0.6043046712875366, "text": "\nAbout Citrix Netscaler VPX \n\nThe Citrix Netscaler VPX is a dedicated virtual software appliance that provides load balancing on both the public and private IBM\u00a9 Cloud network.\n\nDeploying a Citrix Netscaler VPX in your IBM Cloud solution accelerates web application delivery, boosts performance, and ensures your cloud applications and services stay optimized, available, and secure. If you have challenging workloads, such as gaming, big data and analytics, or private clouds, the Citrix Netscaler VPX can help you deliver your solution when, where, and how your users need it most.\n\n\n\n Features \n\n\n\n* The only product that can load balance traffic on both the public and private network\n* Management using GUI (Graphical User Interface) or CLI (Command Line Interface)\n* Many different types of traffic distribution, including:\n\n\n\n* Least Connections\n* Round Robin\n* Least response time\n* Least bandwidth\n* Least packets\n* URL hashing\n* Domain name hashing\n* Source IP address hashing\n* Destination IP address hashing\n* Source IP - Destination IP hashing\n* Token\n* LRTM\n\n\n\n* SSL acceleration / SSL offload\n* GSLB (Global Server Load Balancing)\n\n\n\n* Uses the DNS infrastructure to connect the client to the best data center\n* Monitors the load and availability of the data centers to select the best connection choices\n\n\n\n* Content switching\n* Cache redirection\n* Application firewall capabilities\n* Application security features\n* Virtual appliance running on dedicated hardware\n* Deployed like any other IBM Cloud server, with flexibility and availability in mind\n* Offered in bandwidth tiers: 10Mbps, 200Mbps, and 1000Mbps\n\n\n\nThe Citrix Netscaler VPX can be deployed on demand, in as little as 15 minutes, in any IBM Cloud data center around the world. Several licensing models include the speed and features that you need, and offer the flexibility demanded by today's cloud solutions. This flexibility ensures a good fit for every use case, from small-to-medium implementations, all the way to larger enterprises.\n\nIBM Cloud offers the NetScaler VPX virtual appliance with full, unrestricted root access.\n\n\n\n\n\n Application security", "title": "", "source": "https://cloud.ibm.com/docs/citrix-netscaler-vpx?topic=citrix-netscaler-vpx-about-citrix-netscaler-vpx"}, {"document_id": "ibmcld_01234-3326-5025", "score": 0.6016589403152466, "text": "\nStorage traffic is to be isolated from other traffic types, and not be directed through firewalls and routers. Keeping the storage traffic in a dedicated VLAN also helps preventing MTU mismatch when Jumbo frames are enabled. For more information, see [Enabling Jumbo Frames](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-jumboframes).\n\nStorage traffic is included in the total network usage of Public Virtual Servers. For more information about the limits that might be imposed by the service, see the [Virtual Server Documentation](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-public-virtual-servers).\n\n\n\n\n\n NFS version \n\nBoth NFSv3 and NFSv4.1 are supported in the IBM Cloud\u00ae environment. Network File System (NFS) is a networking protocol for distributed file sharing. It allows remote hosts to mount file systems over a network and interact with those file systems as if they are mounted locally.\n\nUse NFSv3 protocol when possible. NFSv3 supports safe asynchronous writes and is more robust at error handling than the previous NFSv2. It supports 64-bit file sizes and offsets, allowing clients to access more than 2 GB of file data. NFSv3 natively supports no_root_squash that allows root clients to retain root permissions on the NFS share.\n\nWhen File Storage for Classic is used in a VMware\u00ae deployment, NFSv4.1 might be the better choice for your implementation. For more information about the different features of each version and what is supported by VMware\u00ae, see [NFS Protocols and ESXi](https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.storage.doc/GUID-8A929FE4-1207-4CC5-A086-7016D73C328F.html).\n\n\n\n\n\n\n\n Step 2: Submitting your Order", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-getting-started"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09437-12274-13892", "score": 0.646648108959198, "text": "\njobid=<job_id>/<part-number>\n\n\n\nOnly one object contains the result set (jobid=<job_id>/<part-number>), and the other two are empty and don't contain any data.\n\nIt is important not to delete any of the files if you want to use the result set.\n\nEach result is stored with an own job ID prefix that allows you to use the result directly in a query.\n\nWhen you want to specify a result as input in your SQL query, specify the first (jobid=<job_id>) or the third one (jobid=<job_id>/<part-number>).\n\n[Learn more about the result set created per query](https://cloud.ibm.com/docs/services/sql-query?topic=sql-query-overviewresult).\n\n\n\n\n\n Step 3.5. Run a query to find errors of the last 30 days \n\nFor example, to find all ERROR log rows for the last 30 days, run the following command:\n\nSELECT _source.data\nFROM RESULTS_BUCKET STORED AS JSON\nwhere dayofyear(_dayofyear > current_date - INTERVAL 30 day) and _source.level = \"ERROR\"\nLIMIT 50\nINTO QUERY_RESULTS_BUCKET STORED AS JSON\n\nWhere\n\n\n\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you use to upload the query results after transforming the data into partitioned JSON objects\n* QUERY_RESULTS_BUCKET is the SQL URL of the custom COS bucket that you use to upload the query results\n\n\n\n\n\n\n\n Step 3.6. Run a query to find all ERROR log rows within a time range \n\nFor example, to find all ERROR log rows in the timeframe between 7 am and 8 am on July 17th, run the following command:\n\nSELECT _source.data\nFROM RESULTS_BUCKET STORED AS JSON\nwhere _dayofyear=198 and _hour=07 and _source.level = \"ERROR\"\nLIMIT 50\nINTO QUERY_RESULTS_BUCKET STORED AS JSON\n\nWhere", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-sqlquery"}, {"document_id": "ibmcld_13493-2289-4276", "score": 0.6398475170135498, "text": "\n* Use the INTO clause of a [query](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos://us-geo/sql/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}, {"document_id": "ibmcld_02522-12274-13749", "score": 0.6382196545600891, "text": "\nSELECT COUNT() AS logLines FROM cos://eu-de/results-at/jobid=f178778e-7707-46a9-982d-1e89261b63a5 STORED AS PARQUET\nINTO cos://eu-de/results-marisa STORED AS CSV\n\n\n\n\n\n Step 3.6. Run a query to get a custom view of a subset of the event fields \n\nTo see information about each event, run the following query:\n\nSELECT <FIELDS> FROM <PARQUET_FILE> STORED AS PARQUET\nINTO <RESULTS_BUCKET> STORED AS CSV\n\nWhere\n\n\n\n* FIELDS is the list of fields that you want to get information on for the different records. For example, you can enter _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME, _source.o_initiator.id AS INITIATOR_ID, _source.o_initiator.name AS INITIATOR_NAME\n* PARQUET_FILE is the Result location URL that you get when you transform the archive file from JSON to PARQUET\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nFor example, to get the list of actions, you can run the following query:\n\nSELECT DISTINCT _source.action\nFROM cos://eu-gb/sql-results/jobid=17cee056-4da1-4429-8aca-3a7eb320ee27 STORED AS PARQUET\nINTO cos://eu-gb/sql-results STORED AS CSV\n\nFor example, to get the list of actions for a user, you can run the following query:\n\nSELECT _source.eventTime, _source.action, _source.o_target.name\nFROM cos://eu-gb/sql-results/jobid=3aa9e732-ba88-4ffe-b9fc-b8a265876467 STORED AS PARQUET\nWHERE _source.o_initiator.name = \"xxx@ibm.com\"", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_02522-8519-10234", "score": 0.6381127834320068, "text": "\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format \n\nWhen you query an archive file, the format of the data is JSON. You must transform the format to PARQUET to query successfully the data.\n\nParquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n\nThe Data Engine UI is an editor that lets you immediately start composing SQL queries. Since SQL Query uses Spark SQL, you can use Spark SQL functions and ANSI SQL to compose both simple and complex queries that involve large amounts of data.\n\nComplete the following steps to run the query to transform content from JSON into PARQUET:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT * FROM cleancols(SQL_URL STORED AS JSON)\nINTO RESULTS_BUCKET STORED AS PARQUET\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n* Use [cleancols](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference) to avoid transformation problems into PARQUET format when the name of the columns include special characters or blanks.\n\n\n\nFor example, the following query is used to transform an archive file:\n\nSELECT * FROM cleancols(cos://ams03/at-eu-de/999999d8f1f.2019-06-03.62.json.gz STORED AS JSON)\nINTO cos://eu-de/results-at STORED AS PARQUET\n2. Click Run.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_05152-4777-6005", "score": 0.6361042857170105, "text": "\n[SQL Query Window](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https://www.ibm.com/cloud/blog/analyzing-data-with-ibm-cloud-sql-query).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_09437-8631-10180", "score": 0.6353700160980225, "text": "\nIdentify the file that you want to query.\n\nNotice that the file name has the ID of your Log Analysis instance and the date, in UTC format.\n6. For that file, copy the Object Data Engine URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file \n\nComplete the following steps to run the query to transform content from JSON into partitioned JSON objects:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT , date_format(from_unixtime(_source._ts / 1000, 'yyyy-MM-dd HH:mm:ss'), 'yyyy') AS _year,\ndayofyear(from_unixtime(_source._ts / 1000, 'yyyy-MM-dd HH:mm:ss')) AS _dayofyear,\ndate_format(from_unixtime(_source._ts / 1000, 'yyyy-MM-dd HH:mm:ss'), 'HH') AS _hour\nFROM SQL_URL STORED AS JSON\nINTO RESULTS_BUCKET STORED AS JSON PARTITIONED BY (_year, _dayofyear, _hour)\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nIn the statement, the timestamp information is captured in the _ts entry of each row and is used to generate the year, day of year, and hour information. The result reflects the specified partitioning as Hive style partitioning.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-sqlquery"}, {"document_id": "ibmcld_16670-5968-7639", "score": 0.6317237615585327, "text": "\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!/bin/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_join_data"}, {"document_id": "ibmcld_02522-13463-15240", "score": 0.6301180124282837, "text": "\nFor example, to get the list of actions for a user, you can run the following query:\n\nSELECT _source.eventTime, _source.action, _source.o_target.name\nFROM cos://eu-gb/sql-results/jobid=3aa9e732-ba88-4ffe-b9fc-b8a265876467 STORED AS PARQUET\nWHERE _source.o_initiator.name = \"xxx@ibm.com\"\nORDER BY _source.eventTime\nINTO cos://eu-gb/sql-results STORED AS CSV\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.7. Run a query to get a subset of the event fields ordered by the event time \n\nTo see information about each event, run the following query:\n\nSELECT FIELDS FROM PARQUET_FILE STORED AS PARQUET\nORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\nWhere\n\n\n\n* FIELDS is the list of fields that you want to get information on for the different records. For example, you can enter _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME\n* PARQUET_FILE is the Result location URL that you get when you transform the archive file from JSON to PARQUET\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET ORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.8.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_13039-1404-3116", "score": 0.6299378275871277, "text": "\nSelect Everything or a view.\n\n\n\n\n\n\n\n Step 2. Select the set of events to display through a view by applying a search query \n\nTo search for specific events, you can apply a search query.\n\n\n\n* You can do simple searches (single term string search), compound search (multiple search terms and operators), field searches if the log line can be parsed, and others.\n* AND and OR operators are case-sensitive and must be capitalized.\n* Use FieldName:==FieldValue to search for a specific field value.\n* Use FieldName:Value to search for field values that start with that value.\n\n\n\nYou can only search events for the number of days that is specified through the instance's service plan.\n\nComplete the following steps:\n\n\n\n1. Enter a search query.\n2. Press Enter.\n\n\n\nAs you apply a query, notice that the name of the view changes to Unsaved View.\n\n\n\n Query for events that are generated by a service \n\nTo filter out events for a specific service, you need to enter the following query:\n\n_platform:==SERVICENAME\n\nWhere SERVICENAME is the name of the service in the IBM Cloud.\n\nThe following table lists core services:\n\n\n\nTable 2. Query by service name\n\n Events that are generated by Value Sample query \n\n [IAM Access Management service](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-at_events_iamat_events_iam_policies) iam-am _platform:==iam-am \n [IAM Identity service](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-at_events_iamat_events_iam_login) iam-identity _platform:==iam-identity \n [IAM Access Groups service](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-at_events_iamat_events_iam_access) iam-groups _platform:==iam-groups", "title": "", "source": "https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-views"}, {"document_id": "ibmcld_02522-10870-12580", "score": 0.6277323365211487, "text": "\nOnly one object contains the result set (jobid=<job_id>/<part-number>), and the other two are empty and don't contain any data.\n\nIt is important not to delete any of the files if you want to use the result set.\n\nEach result is stored with an own job ID prefix that allows you to use the result directly in a query.\n\nWhen you want to specify a result as input in your SQL query, specify the first (jobid=<job_id>) or the third one (jobid=<job_id>/<part-number>).\n\n[Learn more about the result set created per query](https://cloud.ibm.com/docs/services/sql-query?topic=sql-query-overviewresult).\n\nAfter you have the file converted to 'PARQUET` format, you can run queries to analyze its content.\n\n\n\n\n\n Step 3.5. Run a query to determine the number of events in the archive file \n\nTo report on the total number of events that are included in the archive file, run the following query:\n\nSELECT COUNT() AS NUMBER_EVENTS FROM <PARQUET_FILE> STORED AS PARQUET\nINTO <RESULTS_BUCKET> STORED AS CSV\n\nWhere\n\n\n\n* NUMBER_EVENTS is the name of the field that you want to use to report the numerical value\n* PARQUET_FILE is the Result location URL that you get when you transform the archive file from JSON to PARQUET\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nFor example, to get the total number of events in a file, you can run the following query:\n\nSELECT COUNT() AS logLines FROM cos://eu-de/results-at/jobid=f178778e-7707-46a9-982d-1e89261b63a5 STORED AS PARQUET\nINTO cos://eu-de/results-marisa STORED AS CSV\n\n\n\n\n\n Step 3.6. Run a query to get a custom view of a subset of the event fields \n\nTo see information about each event, run the following query:", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00644-7-2122", "score": 0.6779070496559143, "text": "\nUsing Views \n\nUse views to search for content within a database that matches specific criteria. The criteria are specified within the view definition.\n\nCriteria can also be supplied as arguments when you use the view.\n\n\n\n Querying a view \n\nTo query a view, submit a GET request with the following format:\n\nMethod\n: Issue a partition query by using the following command, GET $SERVICE_URL/$DATABASE/_partition/$PARTITION_KEY/_design/$DDOC/_view/$VIEW_NAME. Or issue a global query by using the following command, GET $SERVICE_URL/$DATABASE/_design/$DDOC/_view/$VIEW_NAME.\n\nRequest\n: None\n\nResponse\n: JSON of the documents that are returned by the view.\n\nRoles permitted\n: _reader\n\nThe request runs either:\n\n\n\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database, which is constrained to results within the specified $PARTITION_KEY data partition.\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database.\n\n\n\nThe examples in this document vary between partition and global queries for illustrative purposes. Unless otherwise noted, modifying the path to embed or remove the partition name works for any view query type.\n\n\n\n Query and JSON Body Arguments \n\nGlobal queries can use all query and JSON body arguments. Partition queries can use only the subset that is indicated in the table.\n\n\n\nTable 1. Subset of query and JSON body arguments available for partitioned queries\n\n Argument Description Optional Type Default Supported values Partition query \n\n conflicts Specify whether to include a list of conflicted revisions in the _conflicts property of the returned document. Ignored if include_docs isn't set to true. Yes Boolean False Yes \n descending Return the documents in descending by key order. Yes Boolean False Yes \n end_key Stop returning records when the specified key is reached. Yes String or JSON array Yes \n end_key_docid Stop returning records when the specified document ID is reached. Yes String Yes \n group Specify whether to group reduced results by key. Valid only if a reduce function is defined in the view.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-views"}, {"document_id": "ibmcld_07086-6808-9095", "score": 0.6241429448127747, "text": "\nFor relevancy training to be used, you must successfully train the project either programmatically ([Create training query method](https://cloud.ibm.com/apidocs/discovery-datacreatetrainingquery)) or by using the product user interface.\n\nQPP\n: A Query Performance Prediction algorithm that, given a query and a list of top results, produces a score that determines how relevant a document is. Used only if no Relevancy training ranker is available.\n\nfilter\n: The filter parameter can be passed along with query and natural_language_query requests to remove documents that don't meet certain criteria from the result set. The filter is shown as the last step within the document retrieval phase. However, it is used at different times in the flow. Its placement in the diagram is chosen to emphasize the fact that any documents that don't match the filter definition are excluded from the result set. The exclusion applies even to documents that might be specified in a curation.\n\nPassage retrieval\n: Returns passages from documents when the passages.enabled=true parameter is included with a natural language query request.\n\nAnswer finding\n: When the passages.find_answers=true parameter is included with a natural language query request, returns succinct answers from passages along with the passages that are extracted from documents. If answer finding is enabled, then the final confidence score for each search result is a combination of the confidence scores from answer finding, passage retrieval, and QPP or Reranked search, whichever method is used.\n\nTable retrieval\n: Returns information from tables in documents when the table_results.enabled=true parameter is included with a natural language query request.\n\n\n\n\n\n Query limits \n\nA query is any operation that submits a POST request to the /query endpoint of the API. Such operations include queries that are submitted by using the API. It does not include queries that are submitted from the search bar on the Improve and customize page of the product user interface.\n\nA query is counted only if the request is successful, meaning it returns a response (with message code 200).\n\nThe number of search queries that you can submit per month per service instance depends on your Discovery plan type.\n\n\n\nNumber of queries per month", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts"}, {"document_id": "ibmcld_09991-7-1416", "score": 0.619971752166748, "text": "\nQuerying historical data \n\nYou can run the queries by using the command-line or the [query editor inside the web console](https://cloud.ibm.com/docs/netezza?topic=netezza-query-editor).\n\nThe following table definition is used for the example queries.\n\nCREATE TABLE PRODUCT (PRODUCTID INTEGER, DESC VARCHAR (100), PRICE DECIMAL) DATA_VERSION_RETENTION_TIME 30;\n\nThe following rows are inserted at different times. The commit times of the inserts (the insert timestamps or _SYS_START values) are indicated in SQL comments.\n\nINSERT INTO PRODUCT VALUES(1001, 'Jacket', 102.00); -- 2020-10-23 16:00:00\nINSERT INTO PRODUCT VALUES(1002, 'Gloves', 20.50); -- 2020-10-23 16:05:00\nINSERT INTO PRODUCT VALUES(1003, 'Hat', 18.99); -- 2020-10-23 16:10:00\nINSERT INTO PRODUCT VALUES(1004, 'Shoes', 125.25); -- 2020-10-23 16:15:00\n\n\n\n Showing data with the insert and delete timestamps \n\nThis SELECT command shows the table data with the associated insert and delete timestamp values at that instant when the query was issued. The _SYS_START and _SYS_END timestamps are available only in time travel queries, hence the use of AS OF NOW().\n\nSELECT , _SYS_START, _SYS_END FROM <table_name> FOR SYSTEM_TIME AS OF NOW();\n\nExample:\n\nSELECT , _SYS_START, _SYS_END FROM PRODUCT FOR SYSTEM_TIME AS OF NOW();\nPRODUCTID | DESCRIPTION | PRICE | _SYS_START | _SYS_END\n----------+-------------+---------+---------------------+-----------", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-queryingdata_tt"}, {"document_id": "ibmcld_00539-7-1755", "score": 0.6104791164398193, "text": "\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST /{db}/_index](https://cloud.ibm.com/apidocs/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_09994-7-1823", "score": 0.6086664199829102, "text": "\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-runningqueries_tt"}, {"document_id": "ibmcld_00539-6216-7731", "score": 0.6019850969314575, "text": "\nIf in doubt, use the [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.\n\nFor more information, see [Explain plans](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryexplain-plans).\n\n\n\n\n\n Can I use IBM Cloudant Query with a Lucene index? \n\nYes! IBM Cloudant Query supports two types of indexes:\n\n\n\n* \"type\": \"json\" - a fixed-order index powered by IBM Cloudant's MapReduce API. Good for fixed, boilerplate queries that match every term in the index.\n* \"type\": \"text\" - a Lucene index powered by IBM Cloudant's Search API. Good for general-purpose queries across one, some, or all indexed fields.\n\n\n\nA type=text index is created with an index definition like this:\n\n{\n\"index\": {\n\"fields\": [\n{ \"name\": \"firstname\", \"type\": \"string\"},\n{ \"name\": \"surname\", \"type\": \"string\"},\n{ \"name\": \"date\", \"type\": \"string\"}\n]\n},\n\"ddoc\": \"textindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"text\"\n}\n\nNotice that the fields array requires each attribute to be named and typed (unlike type=json indexes).\n\nThe resultant index can be used by queries that contain one or more of the indexed fields:\n\n{\n\"selector\": {\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_02628-4002-5694", "score": 0.6006531715393066, "text": "\nWith your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition\n\n Name Type \n\n zip string \n temperature integer \n humidity integer \n city string \n state string \n\n\n\n\n\n![definition-current-1.png](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/tutorials/images/definition-current-1.png)\n\n\n\n5. Save your API.\n\n\n\n12. In the previous step, you defined the response object. Next you'll need to ensure the response object is associated with the get /current path. In the navigation, scroll back up to the Paths panel. a. Open the GET /current operation, and scroll to the Responses section. b. Change the schema of the 200OK response from \"object\" to \"Current\". c. Save your API.\n13. The GET /current path and operation get the current weather data. Now you'll need to create a similar path and operation to get today's weather data. Similar to how you created the /current path in step 11, create a new path: /today.\n14. Add a Parameter to the GET /today operation.\n\n\n\n* Parameter Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n\n\n\n15. Create a new definition: Today.\n16. Add new properties for the Today definition as shown in Table 2.\n\n\n\nTable 2. Properties for the Today definition\n\n Name Type \n\n zip string \n hi integer \n lowe integer \n nighthumidity integer \n dayhumidity integer \n city string", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"}, {"document_id": "ibmcld_04516-95857-97768", "score": 0.5865998268127441, "text": "\nThe number must be a positive integer between 1 and 200. The default value is -1. \n --offset or -m Optional The position of the resource query in the list of resource queries. For example, if you have three resource queries in your account, the command returns these resource queries as a list with three elements. To see a specific resource query in this list, you must enter the position number that the resource query has in the list. To list the first resource query in the list, enter 0. To list the second resource query, enter 1 and so forth. Negative numbers are not supported and are ignored. The default value is -1. \n --output or -o Optional Specify the output format. Only JSON format is supported. \n\n\n\nExample\n\nibmcloud schematics resource-query list --output listoutput.json\n\n\n\n\n\n ibmcloud schematics resource query update \n\nUpdate or replace a resource query creates a copy of an resource query and relaunches an existing resource query by updating the information of an existing IBM Cloud Schematics resource query.\n\nSyntax\n\nibmcloud schematics resource-query update --id ID --name RESOURCE_QUERY_NAME [--type RESOURCE_QUERY_TYPE] [--query-file QUERY_FILE_PATH] [--file FILE_NAME ] [--output OUTPUT] [--no-prompt]\n\nCommand options\n\n\n\nSchematics resource query update flags\n\n Flag Required / Optional Description \n\n --id or -i Required The resource query ID. \n --name or -n Required The unique name for a resource query. \n --type or -t Optional The type of the resource query. such as vsi \n --query-file or -f Optional The path to the JSON file containing queries. \n --file or -f Optional Path to the JSON file containing the definition of an inventory. \n --output or -o Optional Returns the command-line output in JSON format. Currently only JSON file format is supported. \n --no-prompt Optional Set this flag to create the resource query without an interactive command-line session. \n\n\n\nExample", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-schematics-cli-reference"}, {"document_id": "ibmcld_08331-88617-90528", "score": 0.5865998268127441, "text": "\nThe number must be a positive integer between 1 and 200. The default value is -1. \n --offset or -m Optional The position of the resource query in the list of resource queries. For example, if you have three resource queries in your account, the command returns these resource queries as a list with three elements. To see a specific resource query in this list, you must enter the position number that the resource query has in the list. To list the first resource query in the list, enter 0. To list the second resource query, enter 1 and so forth. Negative numbers are not supported and are ignored. The default value is -1. \n --output or -o Optional Specify the output format. Only JSON format is supported. \n\n\n\nExample\n\nibmcloud schematics resource-query list --output listoutput.json\n\n\n\n\n\n ibmcloud schematics resource query update \n\nUpdate or replace a resource query creates a copy of an resource query and relaunches an existing resource query by updating the information of an existing IBM Cloud Schematics resource query.\n\nSyntax\n\nibmcloud schematics resource-query update --id ID --name RESOURCE_QUERY_NAME [--type RESOURCE_QUERY_TYPE] [--query-file QUERY_FILE_PATH] [--file FILE_NAME ] [--output OUTPUT] [--no-prompt]\n\nCommand options\n\n\n\nSchematics resource query update flags\n\n Flag Required / Optional Description \n\n --id or -i Required The resource query ID. \n --name or -n Required The unique name for a resource query. \n --type or -t Optional The type of the resource query. such as vsi \n --query-file or -f Optional The path to the JSON file containing queries. \n --file or -f Optional Path to the JSON file containing the definition of an inventory. \n --output or -o Optional Returns the command-line output in JSON format. Currently only JSON file format is supported. \n --no-prompt Optional Set this flag to create the resource query without an interactive command-line session. \n\n\n\nExample", "title": "", "source": "https://cloud.ibm.com/docs/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"}, {"document_id": "ibmcld_12258-95857-97768", "score": 0.5865998268127441, "text": "\nThe number must be a positive integer between 1 and 200. The default value is -1. \n --offset or -m Optional The position of the resource query in the list of resource queries. For example, if you have three resource queries in your account, the command returns these resource queries as a list with three elements. To see a specific resource query in this list, you must enter the position number that the resource query has in the list. To list the first resource query in the list, enter 0. To list the second resource query, enter 1 and so forth. Negative numbers are not supported and are ignored. The default value is -1. \n --output or -o Optional Specify the output format. Only JSON format is supported. \n\n\n\nExample\n\nibmcloud schematics resource-query list --output listoutput.json\n\n\n\n\n\n ibmcloud schematics resource query update \n\nUpdate or replace a resource query creates a copy of an resource query and relaunches an existing resource query by updating the information of an existing IBM Cloud Schematics resource query.\n\nSyntax\n\nibmcloud schematics resource-query update --id ID --name RESOURCE_QUERY_NAME [--type RESOURCE_QUERY_TYPE] [--query-file QUERY_FILE_PATH] [--file FILE_NAME ] [--output OUTPUT] [--no-prompt]\n\nCommand options\n\n\n\nSchematics resource query update flags\n\n Flag Required / Optional Description \n\n --id or -i Required The resource query ID. \n --name or -n Required The unique name for a resource query. \n --type or -t Optional The type of the resource query. such as vsi \n --query-file or -f Optional The path to the JSON file containing queries. \n --file or -f Optional Path to the JSON file containing the definition of an inventory. \n --output or -o Optional Returns the command-line output in JSON format. Currently only JSON file format is supported. \n --no-prompt Optional Set this flag to create the resource query without an interactive command-line session. \n\n\n\nExample", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-cli-reference&interface=cli"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07045-7-2118", "score": 0.6949201822280884, "text": "\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-improvements"}, {"document_id": "ibmcld_07175-1564-2340", "score": 0.690548300743103, "text": "\nFor more about training requirements and options, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https://cloud.ibm.com/apidocs/discoverycreate-event) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboard"}, {"document_id": "ibmcld_13075-1823-3835", "score": 0.6871310472488403, "text": "\nFor more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}, {"document_id": "ibmcld_07080-12732-13273", "score": 0.6798112988471985, "text": "\n[checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Take actions to improve your results. [Improving your query results](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-improvements) \n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Analyze the data. [Understanding contracts](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-contracts-schema)", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-product-overview"}, {"document_id": "ibmcld_07175-7-2035", "score": 0.6758352518081665, "text": "\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-performance-dashboard"}, {"document_id": "ibmcld_07163-1627-3707", "score": 0.6752995848655701, "text": "\nSee [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\nThe components needed to train a Discovery instance include the following:\n\n\n\n* Training data. This is the set of queries and examples the service uses to refine query results.\n* Query. A natural-language query that applies to the training-data set. Each query has one or more associated examples, as described in the following bullet point. Each query must be unique within the training-data set.\n* Example. This is a document indexed in a Discovery collection that acts as an exemplar, good or bad, for the associated query. When you add an example to a training-data query, you include a relevance label that indicates the relevance (or \"goodness\" versus \"badness\") of the document as it applies to the specified query.\n\nExamples are identified by the indexed document ID. As noted, every example must include a label that indicates the \"goodness\" or \"badness\" of the document as it pertains to the query.\n\nExamples can optionally specify a cross-reference query. The cross-reference query needs to return only the example document and must be independent of the unique Watson Discovery document ID. Cross-reference queries are not currently used automatically but can be used to repair training data in the event that new IDs are assigned to documents during an ingestion event.\n\n\n\n\n\n Training data requirements", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07108-7-1958", "score": 0.663275420665741, "text": "\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-settings"}, {"document_id": "ibmcld_07163-7-1995", "score": 0.6596037149429321, "text": "\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/).\n\nFor comprehensive information about the training APIs, see the [API reference](https://cloud.ibm.com/apidocs/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07242-2547-4328", "score": 0.6588820219039917, "text": "\n\"document_id\": \"bdcd6a9cc1438a3faa8c925f6a8d9429\"\n}\n]\n},\n\"event_type\": \"query\",\n\"session_token\": \"1_LKczxWGEWx5TJAi1_Qs35yOoa7\",\n\"created_timestamp\": \"2018-09-12T05:20:07.469Z\"\n}\nShow more\n\nWith query logs you can investigate the type of results returned to your end users and investigate ways to improve result quality using the approaches available in Discovery. For example:\n\n\n\n* relevancy training, see [Improving result relevance with the API](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api) and [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling)\n* [query operators](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators)\n* [query expansion](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsquery-expansion)\n* custom configurations, see the [Configuration reference](https://cloud.ibm.com/docs/discovery?topic=discovery-configref)\n\n\n\n\n\n\n\n Creating event logs \n\nEvent logs are used to track the interactions of users within your application. This can help you understand how well your application is performing, as well as identify areas that you might need to focus on to improve results. Discovery provides an API that can be embedded in your application to track events. Calling this API with the appropriate information when a user performs an action sends a signal back to Discovery, which can then be viewed in the logs.\n\nEvents can help gather information on computing metrics (like clickthrough rate) to measure how effective the application is at helping end users find relevant information, or can be used to help seed training by reviewing the queries and clicks to start to build ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-usage"}, {"document_id": "ibmcld_07176-1848-3996", "score": 0.6576763391494751, "text": "\nThere are many ways to run queries against Discovery and the different operations used can impact performance. These query characteristics can impact performance:\n\n\n\n1. Length - Longer queries most likely have poorer performance.\n2. Aggregations - Aggregations are a more complex query type, with nested aggregations having the highest impact on performance.\n3. Operators - Wldcarding and fuzzy matching can impact performance.\n4. Counts - Reducing the count of documents returned can improve performance; if you need to page through results, use the offset parameter.\n5. Return fields - Limiting the fields returned to only those needed for your application can help (For example, don\u2019t return the full text of the document if only the title and passage are needed.)\n\n\n\nSee [Query reference](https://cloud.ibm.com/docs/discovery?topic=discovery-query-reference) for details.\n\n\n\n\n\n Features used \n\nThere are a number of features that enhance query results. The following features can impact performance:\n\n\n\n1. Passage Retrieval - Passage retrieval searches within documents to find relevant snippets of text for your query. Use the passages.fields parameter to adjust which fields in the documents that passage retrieval searches. The parameter can help reduce the latency of passage retrieval when your content has many fields. For more information about passage retrieval, see [Passages](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameterspassages).\n2. Relevancy Training - Relevancy training computes features for each top-level text field (fields at the same level as document_id in the JSON) in the collection. If there are many top level fields, this can cause a performance impact for a natural_language_query when using training. Reducing the number of top level fields can improve performance. This can be done via normalization or by manually editing the JSON to put fields that are not helpful to finding relevant content in a nested structure. Changing the fields used for training also has an impact on the model so you\u2019ll need to consider both the impact to performance and accuracy of results if making this change.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-qp"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07214-74576-76512", "score": 0.7098249197006226, "text": "\nNew support for 'sort' parameter in the query API : The query API (GET /v1/environments/{environment_id}/collections/{collection_id}/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https://cloud.ibm.com/apidocs/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https://cloud.ibm.com/docs/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https://cloud.ibm.com/apidocs/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07214-41790-43719", "score": 0.6764814853668213, "text": "\nImproved query limits for Advanced and Premium plans : [Query expansion](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsquery-expansion) limits are increased for Advanced and Premium plans to 5,000 query expansions and 25,000 total terms. See [Discovery pricing plans](https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans) for details.\n\n\n\n\n\n 28 February 2018 \n\nDeprecated AlchemyLanguage enrichments : AlchemyLanguage enrichments are deprecated, effective 1 March 2018.\n\n\n\n\n\n 23 February 2018 \n\nNew document similarity query feature : Added the ability to query by document similarity. You can query for similar documents by document ids, and optionally further refine the similarity by specifying fields. See [Document similarity](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsdoc-similarity) for more information.\n\nImproved highlight parameter : The [highlight parameter](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametershighlight) in query results is enhanced. Query results return complete sentences, ordered by their score.\n\n\n\n\n\n 21 February 2018 \n\nFixed PDF file type : Previously, when ingesting PDF documents, the file_type returned when ingestion notices were queried, in the extracted_metadata object, and from the document details API was html. This is no longer the case. The file_type returned is now pdf.\n\n\n\n\n\n 26 January 2018 \n\nNew Korean and Spanish accessibility in Discovery News : Added the ability to access Korean and Spanish collections to the [IBM Watson\u2122 Discovery News](https://cloud.ibm.com/docs/discovery?topic=discovery-watson-discovery-news) tile in the tooling. Previously, these collections could only be queried via the API.\n\n\n\n\n\n 23 January 2018 \n\nNew query expansion : Added the ability to expand the scope of a query - for example, you can expand a query for \"car\" to include \"automobile\" and \"motor vehicle\".", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07213-3538-5222", "score": 0.66050124168396, "text": "\nTo extract the training data, use the API to download the queries and the ratings from Discovery.\n\n\n\n1. [List the training data](https://cloud.ibm.com/apidocs/discoverylist-training-data)\n2. [List the examples](https://cloud.ibm.com/apidocs/discoverylist-examples-for-a-training-data-query) for each query.\n3. [Get the details](https://cloud.ibm.com/apidocs/discoveryget-details-for-training-data-example) for a training data examples.\n\n\n\nThe document IDs that you use in your training data point to the documents in your current collection. Use the same IDs in your new collections to ensure that the correct documents are referenced. If the IDs do not match, your restored relevancy training will not work.\n\n\n\n\n\n Queries \n\nBy default, Discovery stores the queries that you send to it, unless you opt out.\n\nIf you want to be able to restore your queries for [statistical purposes](https://cloud.ibm.com/apidocs/discoverynumber-of-queries-over-time), it is recommended that you store those queries separately.\n\nYou can [extract queries](https://cloud.ibm.com/apidocs/discoverysearch-the-query-and-event-log) from Discovery, however a maximum of 10,000 queries are stored. There is no paging API. Restoring queries is not recommended; we recommend starting from scratch.\n\n\n\n\n\n Feedback/clicks \n\nIf you are storing clicks in the form of feedback events, there is currently no easy way to back up and restore this information. The recommendation is to start from scratch with the [clicks/feedback data](https://cloud.ibm.com/apidocs/discoverycreate-event) API.\n\n\n\n\n\n Expansion lists \n\nIf you are using expansions for query modification, back up your expansion list, and store it locally.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-recovery"}, {"document_id": "ibmcld_07214-57536-59639", "score": 0.6600251197814941, "text": "\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https://cloud.ibm.com/apidocs/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https://cloud.ibm.com/apidocs/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07096-7-1899", "score": 0.659976065158844, "text": "\nQuery operators \n\nYou can use operators when you write queries to submit to Discovery by using the Query API.\n\nThe types of operators that are supported differ by query type:\n\n\n\n* [Natural language queries](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operatorsnlq-operator)\n* [Discovery Query Language (DQL) queries](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operatorsdql-operators)\n\n\n\n\n\n Natural Language Query (NLQ) operator \n\nThe natural_language_query parameter accepts a string value.\n\n\n\n \"\" (Phrase query) \n\nUse quotation marks to emphasize a single word or phrase in the query that is most important to match. For example, the following request boosts documents that contain the term \u201cnomination\u201d in them.\n\n{\n\"natural_language_query\":\"What is the process for \"nomination\" of bonds?\"\n}\n\nSpecifying a quoted phrase does not prevent documents without the phrase from being returned. It merely gives more weight to documents with the phrase than those without it. For example, the query results might also contain documents that mention \u201cbonds\u201d or \u201cprocess\u201d and do not contain the word \u201cnomination\u201d.\n\nThe following request boosts the phrase \u201cchange in monetary policy\u201d and also matches \u201cchange\u201d or \u201cmonetary\u201d or \u201cpolicy\u201d.\n\n{\n\"natural_language_query\":\"\"change in monetary policy\"\"\n}\n\nSingle quotation marks (') are not supported. You cannot use wildcards (*) in phrase queries.\n\n\n\n\n\n\n\n Discovery Query Language (DQL) operators \n\nOperators are the separators between different parts of a query.\n\n\n\n . (JSON delimiter) \n\nThis delimiter separates the levels of hierarchy in the JSON schema\n\nFor example, the following query argument identifies the section of the enriched_text object that contains entities and the text recognized as an entity.\n\nenriched_text.entities.text\n\nThe JSON representation of this section looks as follows:\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-operators"}, {"document_id": "ibmcld_00580-39512-41555", "score": 0.6524657011032104, "text": "\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_02636-6894-8546", "score": 0.6494380235671997, "text": "\n![subbucket.png](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/tutorials/images/subbucket.png)\n7. Click Run to see your chart.\n8. Click Save and give your chart a name API Calls by App.\n9. To see your visualization in context, add it to the Subscriber dashboard.\n\n\n\n![apichartfinal.png](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/tutorials/images/apichartfinal.png)\n\nThere is other information available for visualizing details about API calls, callers, and so on. A full list of API events is available in the API Connect Knowledge Center, or in the list of Terms when you create visualizations.\n\n\n\n\n\n Conclusion \n\nThe ability to visualize API analytics in different styles and combinations gives you an opportunity to draw conclusions or go deeper into your API data. You can use this insight to make decisions about which APIs to offer, when to replace or retire an API, who is consuming your APIs, and so on.\n\nFor example, APIs version 1 (v1) and version 2 (v2) from a provider named \"ACME\" have been running for several years. They deprecated v1 when they released v2. They also ensured that existing v1 consumers were aware that they had a certain timeline to move to v2. As this deadline approaches, ACME wants to see how quickly consumers are moving off v1, so they can offer assistance to valued partners.\n\nUsing a visualization similar to the one we just built, ACME has this information available at a glance.\n\nIn this tutorial, we walked through a number of activities to help you create useful combinations of API and consumer data.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-tut_insights_analytics"}, {"document_id": "ibmcld_07163-7-1995", "score": 0.6462526321411133, "text": "\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/).\n\nFor comprehensive information about the training APIs, see the [API reference](https://cloud.ibm.com/apidocs/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07068-18922-20116", "score": 0.6379410624504089, "text": "\nAction v1 API v2 API \n\n List training data [GET /v1/environments/{environment_id}/collections/{collection_id}/training_data](https://cloud.ibm.com/apidocs/discoverylisttrainingdata) [GET /v2/projects/{project_id}/training_data /queries](https://cloud.ibm.com/apidocs/discovery-datalisttrainingqueries) \n Add query to training data [POST /v1/environments/{environment_id}/collections/{collection_id}/training_data](https://cloud.ibm.com/apidocs/discoveryaddtrainingdata) [POST /v2/projects/{project_id}/training_data /queries](https://cloud.ibm.com/apidocs/discovery-datacreatetrainingquery) \n Delete all training data [DELETE /v1/environments/{environment_id}/collections/{collection_id}/training_data](https://cloud.ibm.com/apidocs/discoverydeletealltrainingdata) [DELETE /v2/projects/{project_id}/training_data /queries](https://cloud.ibm.com/apidocs/discovery-datadeletetrainingqueries) \n Get details about a query [GET /v1/environments/{environment_id}/collections/{collection_id}/training_data/{query_id}](https://cloud.ibm.com/apidocs/discoverygettrainingdata) [GET /v2/projects/{project_id}/training_data /queries/{query_id}](https://cloud.ibm.com/apidocs/discovery-datagettrainingquery)", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api"}, {"document_id": "ibmcld_13493-2289-4276", "score": 0.6372357606887817, "text": "\n* Use the INTO clause of a [query](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos://us-geo/sql/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-running"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16551-0-1579", "score": 0.7685774564743042, "text": "\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"}, {"document_id": "ibmcld_01225-7204-8862", "score": 0.6830145120620728, "text": "\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Resizing storage with Terraform \n\nYou can increase your storage capacity by using the ibm_storage_file resource, and specifying a different number in the capacity argument. The following example increases the capacity of an Endurance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_endurance\" {\ntype = \"Endurance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 0.25\n}\n\nThe following example increases the capacity of a Performance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_performance\" {\ntype = \"Performance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 100\n}\n\nFor more information about the arguments and attributes, see [ibm_storage_file](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/storage_file).\n\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Expanding Storage over 12 TB \n\nIf you need to increase your Storage volume capacity beyond 12 TB, you can request to be added to the allowlist by submitting a [support case](https://cloud.ibm.com/unifiedsupport/cases/add). When the request is approved by the Offering Manager, you're going to be notified through the case process. You're also going to see the option to increase your storage up to 24 TB in the console.\n\nThe number of operations that can be performed on the storage is limited. This limit is 180k IOPS. So if you want to provision a volume with 10 IOPS, your maximum volume size is 18 TB. If you want to provision the maximum size of 24 TB, then the maximum rate of reads and writes to the volume is 4 IOPS per GB.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacity"}, {"document_id": "ibmcld_01241-8897-11095", "score": 0.6764853596687317, "text": "\nOptions: id, name, created, size_bytes\n-h, --help Show this message and exit.\n\nNotifications are sent when you reach three different space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold. If the space is manually increased or snapshots are manually deleted, the warning is reset, and reissued if the threshold is exceeded again. If no actions are taken, this notification is the only warning that you receive.\n\n\n\nIf snapshot space usage increases too rapidly, then you might receive one notification before autodeletion of the oldest scheduled snapshot occurs. For example, if usage jumps from 76% to 96% within 15 minutes, you receive one notification about exceeding 75% and one notification about exceeding 95%. The system skips the 90%-exceeded warning.\n\nBy default, snapshot warning notifications are enabled for every customer. However, you can choose to disable them. When this feature is disabled, all ticket generation and notifications are stopped. You can disable and enable notifications for the volume at any time.\n\nTo check whether the notifications are enabled for the storage volume, use the following command.\n\n slcli file snapshot-get-notification-status", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managingSnapshots"}, {"document_id": "ibmcld_00241-8998-11208", "score": 0.675460696220398, "text": "\nOptions: id, name, created, size_bytes\n-h, --help Show this message and exit.\n\nNotifications are sent when you reach three different space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold. If the space is manually increased or snapshots are manually deleted, the warning is reset and reissued if the threshold is exceeded again. If no actions are taken, this notification is the only warning that you receive.\n\n\n\nIf snapshot space utilization increases too rapidly, then you might receive one notification before autodeletion of the oldest scheduled snapshot occurs. For example, if utilization jumps from 76% to 96% within 15 minutes, you receive one notification about exceeding 75% and one notification about exceeding 95%. The system skips the 90%-exceeded warning.\n\nBy default, snapshot warning notifications are enabled for every customer. However, you can choose to disable them. When this feature is disabled, all ticket generation and notifications are stopped. You can disable and enable notifications for the volume at any time.\n\nTo check whether the notifications are enabled for the storage volume, use the following command.\n\n slcli block snapshot-get-notification-status", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}, {"document_id": "ibmcld_11910-18283-20023", "score": 0.6713050603866577, "text": "\nFrom the Satellite storage dashboard, select the storage configuration you want to delete.\n2. Select Actions > Delete\n3. Enter the name of your storage configuration.\n4. Select Delete.\n\n\n\n\n\n\n\n\n\n Parameter reference \n\n\n\n 21.04 parameter reference \n\n\n\nTable 1. 21.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N/A \n SVM svm Config The name of the SVM. true N/A \n User Name username Secret The username to connect to the storage device. true N/A \n User Password password Secret The password to connect to the storage device. true N/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default \n Limit Volume Size limitVolumeSize Config Maximum requestable volume size (in Gibibytes) and qtree parent volume size true 50Gi \n Limit AggregateUsage limitAggregateUsage Config Fail provisioning if usage is above this percentage. true 80% \n NFS Mount Options nfsMountOptions Config The NFS mount options. true nfsvers=4 \n\n\n\n\n\n\n\n 22.04 parameter reference \n\n\n\nTable 2. 22.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N/A \n SVM svm Config The name of the SVM. true N/A \n User Name username Secret The username to connect to the storage device. true N/A \n User Password password Secret The password to connect to the storage device. true N/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-storage-netapp-ontap-nas"}, {"document_id": "ibmcld_04693-5720-7686", "score": 0.6702700853347778, "text": "\nFor example, you might scale from 256 - 1256 MB by changing the memory quota on the app details page. However, because the disk quota remained the same, you didn't get more disk space.\n\n Why it\u2019s happening \n\nThe default disk quota that is allocated for an app is 1 GB. If you need more disk space, you must manually specify the disk quota.\n\n How to fix it \n\nUse one of the following methods to specify your disk quota. The maximum disk quota that you can specify is 2 GB. If 2 GB is still not enough, try an external service such as [Cloud Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n* In the manifest.yml file, add the following item:\n\ndisk_quota: <disk_quota>\n* Use the -k option with the ibmcloud cf push command when you push your app to IBM Cloud:\n\nibmcloud cf push appname -p app_path -k <disk_quota>\n\n\n\n\n\n\n\n Org's services limit is exceeded \n\nIf you are a Lite account user, you might be unable to create an app in IBM Cloud if you exceeded your organization's services limit.\n\n What\u2019s happening \n\nWhen you try to create an app in IBM Cloud, the following error message is displayed:\n\nBXNUI2032E: The <service_instances> resource wasn't created. While Cloud Foundry was being contacted to create the resource, an error occurred. Cloud Foundry message: \"You have exceeded your organization's services limit.\"\n\n Why it\u2019s happening \n\nThis error occurs when you exceed the limit on the number of service instances that you can have for your account.\n\n How to fix it \n\nDelete any services instances that aren't needed, or remove the limit on the number of service instances that you can have.\n\n\n\n* To delete a services instance, you can use the IBM Cloud console or the command line interface.\n\nTo use the IBM Cloud console to delete a service instance, complete the following steps: 1. In the resource list, click the Actions menu for the service that you want to delete. 2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ts-cf-apps"}, {"document_id": "ibmcld_07578-1234045-1235864", "score": 0.662939190864563, "text": "\nYou can obtain more information about the volume, such as how much disk space is taken and how much is available, from your Compute host's operating system.\n\nYou can use the following commands.\n\n\n\n* Linux\u00ae:\n\ndf -h\n\nThe command provides an output that shows how much space is available space and the percentage used.\n\n$ df -hT /dev/sda1\nFilesystem Type Size Used Avail Use% Mounted on\n/dev/sda1 disk 6.0G 1.2G 4.9G 20% /\n* Windows\u00ae: you have two options.\n\nfsutil volume diskfree C:\n\ndir C:\n\nThe last line of the output shows how much space is unused.\n\nYou can also view the free disk space in the File Explorer by clicking This PC.\n\n\n\n* Does the volume need to be pre-warmed to achieve expected throughput?\n\nPre-warming is not needed. You can observe specified throughput immediately upon provisioning the volume.\n* Can more throughput be achieved by using a faster Ethernet connection?\n\nThroughput limits are set at the LUN level and a faster Ethernet connection doesn't increase that limit. However, with a slower Ethernet connection, your bandwidth can be a potential bottleneck.\n* Do firewalls and security groups impact performance?\n\nIt's best to run storage traffic on a VLAN, which bypasses the firewall. Running storage traffic through software firewalls increases latency and adversely affects storage performance.\n* How do I route Block Storage for Classic traffic to its own VLAN interface and bypass a firewall?\n\nTo enact this best practice, complete the following steps.\n\n\n\n1. Provision a VLAN in the same data center as the host and the Block Storage for Classic device. For more information, see [Getting started with VLANs](https://cloud.ibm.com/docs/vlans?topic=vlans-getting-started).\n2. Provision a secondary private subnet to the new VLAN.3\n3. Trunk the new VLAN to the private interface of the host.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1236678-1238497", "score": 0.662939190864563, "text": "\nYou can obtain more information about the volume, such as how much disk space is taken and how much is available, from your Compute host's operating system.\n\nYou can use the following commands.\n\n\n\n* Linux\u00ae:\n\ndf -h\n\nThe command provides an output that shows how much space is available space and the percentage used.\n\n$ df -hT /dev/sda1\nFilesystem Type Size Used Avail Use% Mounted on\n/dev/sda1 disk 6.0G 1.2G 4.9G 20% /\n* Windows\u00ae: you have two options.\n\nfsutil volume diskfree C:\n\ndir C:\n\nThe last line of the output shows how much space is unused.\n\nYou can also view the free disk space in the File Explorer by clicking This PC.\n\n\n\n* Does the volume need to be pre-warmed to achieve expected throughput?\n\nPre-warming is not needed. You can observe specified throughput immediately upon provisioning the volume.\n* Can more throughput be achieved by using a faster Ethernet connection?\n\nThroughput limits are set at the LUN level and a faster Ethernet connection doesn't increase that limit. However, with a slower Ethernet connection, your bandwidth can be a potential bottleneck.\n* Do firewalls and security groups impact performance?\n\nIt's best to run storage traffic on a VLAN, which bypasses the firewall. Running storage traffic through software firewalls increases latency and adversely affects storage performance.\n* How do I route Block Storage for Classic traffic to its own VLAN interface and bypass a firewall?\n\nTo enact this best practice, complete the following steps.\n\n\n\n1. Provision a VLAN in the same data center as the host and the Block Storage for Classic device. For more information, see [Getting started with VLANs](https://cloud.ibm.com/docs/vlans?topic=vlans-getting-started).\n2. Provision a secondary private subnet to the new VLAN.3\n3. Trunk the new VLAN to the private interface of the host.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01270-6886-8578", "score": 0.6450218558311462, "text": "\nFor more information about the limit on simultaneous authorizations, see the [FAQs](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-file-storage-faqsauthlimit).\n\n\n\n\n\n\n\n Ordering File Storage for Classic with the API \n\nThe method order_file_volume (storage_type, location, size, iops=None, tier_level=None, snapshot_size=None, service_offering='storage_as_a_service', hourly_billing_flag=False) places an order for a file volume.\n\nYou must specify the following parameters for a successful order.\n\n\n\n* storage_type \u2013 \"performance\" or \"endurance\".\n* location \u2013 Data center in which to order iSCSI volume.\n* size \u2013 Size of the new volume, in GB.\n* iops \u2013 Number of IOPs for a \u201cPerformance\u201d order.\n* tier_level \u2013 Tier level to use for an \u201cEndurance\u201d order.\n* snapshot_size \u2013 The size of optional snapshot space, if snapshot space is also to be ordered. (None if not ordered.)\n* service_offering \u2013 Requested offering package to use in the order (\"storage_as_a_service\", \"enterprise\", or \"performance\").\n* hourly_billing_flag \u2013 Billing type, monthly (False) or hourly (True), default to monthly.\n\n\n\nTo be able to access all the new features, order Storage-as-a-Service Package 759.\n\nFor more information about ordering File Storage for Classic through the API, see [order_file_volume](https://softlayer-python.readthedocs.io/en/latest/api/managers/file/SoftLayer.managers.file.FileStorageManager.order_file_volume).\n\nBy default, you can provision a combined total of 700 File Storage for Classic volumes. To increase the number of your volumes, contact your sales representative. Read about increasing limits [here](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managinglimits).", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-orderingFileStorage"}, {"document_id": "ibmcld_00294-2562-4120", "score": 0.6282205581665039, "text": "\n[Actions icon](https://cloud.ibm.com/docs-content/v1/content/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45/icons/action-menu-icon.svg), then click Change Snapshot Space.\n4. Select the storage size that you need.\n5. Click Continue.\n6. Enter any Promo Code that you have, and click Recalculate. The Charges for this order and Order Review fields are completed by default.\n\nDiscounts are applied when the order is processed.\n7. Review your order, and read the service agreement. If you agree with the terms, check the box. Cick Place Order. Your snapshot space is provisioned in a few minutes.\n\n\n\n\n\n\n\n Ordering Snapshot space from the SLCLI \n\n slcli block snapshot-order --help\nUsage: slcli block snapshot-order [OPTIONS] VOLUME_ID\n\nOptions:\n--capacity INTEGER Size of snapshot space to create in GB [required]\n--tier [0.25|2|4|10] Endurance Storage Tier (IOPS per GB) of the block\nvolume for which space is ordered [optional, and only\nvalid for endurance storage volumes]\n--upgrade Flag to indicate that the order is an upgrade\n-h, --help Show this message and exit.\n\n\n\n\n\n Ordering Snapshot space with Terraform \n\nWhen you provision a storage volume with Terraform, use the ibm_storage_block resource and specify the snapshot_capacity argument. The following example defines 10 GB snapshot space.\n\nresource \"ibm_storage_block\" \"test1\" {\ntype = \"Endurance\"\ndatacenter = \"dal05\"\ncapacity = 20\niops = 0.25\nos_format_type = \"Linux\"\n\n Optional fields\nallowed_virtual_guest_ids = [ 27699397 ]\nallowed_ip_addresses = [\"10.40.98.193\", \"10.40.98.200\"]\nsnapshot_capacity = 10", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-orderingsnapshots"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16728-6533-8457", "score": 0.7216682434082031, "text": "\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a database-driven Slackbot](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_09984-0-1283", "score": 0.7073513269424438, "text": "\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https://cloud.ibm.com/docs/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https://cloud.ibm.com/docs/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity"}, {"document_id": "ibmcld_13162-7-1878", "score": 0.7013341188430786, "text": "\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_16729-11586-13439", "score": 0.6874161958694458, "text": "\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_13162-12751-14416", "score": 0.6533449292182922, "text": "\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https://cloud.ibm.com/docs/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https://cloud.ibm.com/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https://cloud.ibm.com/docs/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https://github.com/IBM-Cloud/sql-query-clients/tree/master/Python)\n* [Jupyter Notebooks](https://jupyter.org/)\n* [Folium](https://python-visualization.github.io/folium/)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_13162-11690-13171", "score": 0.6496398448944092, "text": "\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https://cloud.ibm.com/docs/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_16729-326786-328759", "score": 0.6460760831832886, "text": "\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine\n\nIn this tutorial, you will create a serverless web application using a bucket in Object Storage and implementing the application backend using IBM Cloud Code Engine and IBM Cloudant as JSON document database.\n\nCode Engine Cloudant\n\n+1\n\nObject Storage\n\n\n\n* 1 hour\n* 2023-06-16\n\n\n\n[Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\nContent Delivery Network (CDN) Object Storage\n\n\n\n* 2 hours", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16728-5097-7108", "score": 0.643049955368042, "text": "\n[solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Bring Your Own IP Address](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_13497-1510-3518", "score": 0.6179381608963013, "text": "\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https://www.ibm.com/cloud/blog/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https://www.ibm.com/cloud/blog/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-query-relnotes"}, {"document_id": "ibmcld_11581-14676-15914", "score": 0.5929251313209534, "text": "\nBI.S4.H4.3000 (VMware) IBM Cloud for VMware 112 224 3,072 257,373 Intel Cascade Lake SP 13.71 TDI OLAP/OLTP Classic \n BI.S4.H4.6000 (VMware) IBM Cloud for VMware 112 224 6,144 257,373 Intel Cascade Lake SP 27.43 TDI OLAP/OLTP Classic \n BI.S4.H8.6000 (VMware) IBM Cloud for VMware 224 448 6,144 495,603 Intel Cascade Lake SP 13.71 TDI OLAP/OLTP Classic \n BI.S4.H2.384GB RAM + 1.5TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 56 112 1884 Intel Cascade Lake SP 16.82 TDI OLTP Classic \n BI.S4.H2.768GB RAM + 1.5TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 56 112 2268 Intel Cascade Lake SP 20.25 TDI OLTP Classic \n BI.S4.H2.768GB RAM + 3TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 56 112 3072 Intel Cascade Lake SP 27.43 TDI OLTP Classic \n BI.S4.H2.1.5TB RAM + 1.5TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 56 112 3768 Intel Cascade Lake SP 33.64 TDI OLAP/OLTP Classic \n BI.S4.H2.1.5TB RAM + 3TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 112 224 3768 Intel Cascade Lake SP 16.82 TDI OLAP/OLTP Classic \n BI.S4.H4.768GB RAM + 3TB PMEM IBM Cloud Bare Metal (Local SSD + Intel Optane DC PMEM) 56 112 4608 Intel Cascade Lake SP 41.14 TDI OLTP Classic", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-faq-profile-specs"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16638-0-764", "score": 0.7289258241653442, "text": "\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-import_data"}, {"document_id": "ibmcld_16627-0-1141", "score": 0.7001503705978394, "text": "\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-exp_objects"}, {"document_id": "ibmcld_16669-1692-3354", "score": 0.6990272998809814, "text": "\nAlternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1. Run the following command to create schema for the data you want to access.\n\nCREATE SCHEMA <SCHEMA_NAME> WITH ( location = '<SCHEMA_LOCATION>' );\n\nFor example:\n\nCREATE SCHEMA hive.gosales WITH ( location = 's3a://lhbeta/gosales' );\n2. Run the following command to create table by using an external location by pointing to an existing table.\n\nCREATE TABLE IF NOT EXISTS <TABLE_NAME> (\"<COLUMN_NAMES>\" <DATA_TYPE>) WITH ( format = '<DATA_FORMAT>', external_location = '<TABLE_LOCATION>' );\n\nFor example:\n\nCREATE TABLE IF NOT EXISTS hive.gosales.branch (\"BRANCH_CODE\" int, \"ADDRESS1\" varchar, \"ADDRESS1_MB\" varchar, \"ADDRESS2\" varchar, \"ADDRESS2_MB\" varchar, \"CITY\" varchar, \"CITY_MB\" varchar, \"PROV_STATE\" varchar, \"PROV_STATE_MB\" varchar, \"POSTAL_ZONE\" varchar, \"COUNTRY_CODE\" int, \"ORGANIZATION_CODE\" varchar, \"WAREHOUSE_BRANCH_CODE\" int) WITH ( format = 'CSV', external_location = 's3a://lhbeta/gosales/branch' );\n\n\n\n\n\n\n\n Step 3: Generate statistics with analyze table \n\nIf you want to use the data without creating a new copy for a different table format or more table optimizations, you can generate statistics alone with analyze table.\n\n\n\n1. To generate statistics with analyze table, run the following command:\n\nanalyze <TABLE_NAME>;\n\nFor example:", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"}, {"document_id": "ibmcld_16640-7-2035", "score": 0.6661068201065063, "text": "\nKnown issues (Limitations) \n\nThe following limitations and known issues, apply to IBM\u00ae watsonx.data.\n\n\n\n Issue: Unable to view created schema \n\nWhen a user with the User role and the Create access (the user only has the Create access) is added to an external database, they cannot see the schemas that they created. Though the user can create schemas, they cannot view them. Following is the system response:\n\npresto:default> show schemas;\nSchema\n--------\n(0 rows)\n\nWorkaround: Provide select privilege for the schema the user created.\n\n\n\n\n\n Issue: Access denied message occurs when querying an external database \n\nWhen a user with the User role and Create access (the user only has Create access), is added to an external database, they cannot run the select query from the table they have created. Though the user can connect to the Presto engine and create tables and schemas, they cannot query from the table. The system displays an Access Denied message.\n\nQuery 20230608_132213_00042_wpmk2 failed: Access Denied: Cannot select from columns [id] in table or view tab_appiduser_01\n\nWorkaround: Provide select privilege for the table the user created.\n\n\n\n\n\n Issue: Schema created under different catalog \n\nSchemas are available across Iceberg and Hive catalogs. When a schema is created under Iceberg catalog, it is listed under Hive catalog and vice versa.\n\n\n\n\n\n Issue: Presto does not support deletion of Iceberg tables \n\n\n\n\n\n Issue: DROP SCHEMA in Db2 \n\nIn Db2, the schema can be dropped only if it is empty. Initiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-known_issues"}, {"document_id": "ibmcld_13498-108109-110305", "score": 0.6649184226989746, "text": "\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_13480-3420-5386", "score": 0.6643532514572144, "text": "\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogpartitioned).\n\nYou can then query the table by name instead of specifying the Object Storage URI directly in the SQL statement:\n\nSELECT * FROM employees LIMIT 10\n\nIf you want to use more specific data types than the data types inferred by automatic schema detection, you can also specify the table schema explicitly:\n\nCREATE TABLE employees (\nemployeeID int,\nlastName string,\nfirstName string,\ntitle string,\ntitleOfCourtesy string,\nbirthDate timestamp,\nhireDate timestamp,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nhomePhone string,\nextension int,\nphoto string,\nnotes string,\nreportsTo string,\nphotoPath string\n)\nUSING PARQUET\nLOCATION cos://us-geo/sql/employees.parquet\nShow more\n\nIf accessing the table in a SELECT statement does not work as expected, it is possibly caused by improper specification of the table schema in the CREATE TABLE statement. The column names and their data types in your CREATE TABLE statement must match the result of the following query:\n\nSELECT * FROM describe (<data-location> stored as <storage-format>)\n\nColumn names are case-sensitive. Incorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_09958-5588-7326", "score": 0.6591142416000366, "text": "\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https://www.ibm.com/docs/en/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted-console).\n2. Create a temporal table as described in [Creating tables](https://cloud.ibm.com/docs/netezza?topic=netezza-create-tablescreating-tables).\n\n\n\nYou must set retention time interval to a nonzero value.\n\nDatabases, schemas, and table names containing a dot character (\".\") do not show in the time travel statistics and graphs when you set the retention time interval to a nonzero value. When you do not set the retention time interval, all special characters are supported.\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the web console \n\nTo create a temporal schema, set retention time interval to a nonzero value.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted-console).\n2. Create a temporal schema as described in [Creating schemas](https://cloud.ibm.com/docs/netezza?topic=netezza-create-schemas).", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-enablingdisabling_tt"}, {"document_id": "ibmcld_16471-188589-190073", "score": 0.6528668403625488, "text": "\n+ arg1Schema.size (), returnSchema.getFieldTypeByIx (i + arg1Schema.size ()), arg2Schema.getFieldTypeByIx (i)); }\n}\n}\n\n}\nShow more\n\n\n\n\n\n\n\n Declaring user-defined functions \n\nYou can make the user-defined scalar functions and machine learning models from PMML files available to AQL by using the create function statement.\n\n\n\n Syntax \n\nThe general syntax of the create function statement is as follows:\n\ncreate function <function-name>(<input-schema-definition>)\nreturn <return-type> [like <column-name>] | table ( <output-schema-definition)\nexternal_name <ext-name>\nlanguage [java | pmml]\n[deterministic | not deterministic]\n[return null on null input | called on null input];\n\n<input-schema-definition>\n<column-name> <data-type> | table (<output-schema-definition>) as locator [,<column-name> <data-type> | table (<output-schema-definition>) as locator ]\n\n<output-schema-definition>\n<column-name> <data-type> [,<column-name> <data-type>]\n\n\n\n\n\n Description \n\n\n\n* <function-name>\n\nThe <function-name> declares the AQL name of the UDF. The UDF is referred to in the AQL code with this name\n* <input-schema-definition>\n\nSpecifies the input parameters of the UDF. An input parameter has a name, which is specified as <column-name>, and can be either a scalar type or a table locator. When the language is PMML, the function must take a single table that is called params as the argument.\n* <column-name>\n\nSpecifies the name of a column in the input or the output of the UDF.\n* <data-type>", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_13472-4479-5403", "score": 0.6524701714515686, "text": "\nIf you don't use Hive-style partitioning or catalog tables, all objects in the source location must be listed as part of the query execution, even if only a single row from a single object is required for the query.\n\nTo successfully query the source location, use the following best practices.\n\n\n\n* Create a table with the correct schema specified. If you don't specify the schema, schema inference causes the same error to be returned.\n* If you use more than 10 UNION/JOIN constructs for different source URIs, try to lower the number of different sources.\n* Depending on the number of table partitions, you can either add the partition manually one by one, or use the ALTER TABLE \u2026 RECOVER PARTITION command. Although the limit is 20,000 partitions per table by default, stay below 10,000 partitions for a single table.\n* Lay your data out by using Hive-style partitioning and aim for an object size of 128 MB if possible.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-faq"}, {"document_id": "ibmcld_16664-1011-1647", "score": 0.6487655639648438, "text": "\nHudi X X X \u2713 -- X X X X X \u2713 X X X X X X X X \n\n\n\n\n\n Limitations \n\n\n\n1. For CREATE TABLE, MySQL connector supports only CREATE TABLE AS.\n2. For ALTER TABLE, MongoDB connector supports only table rename.\n3. Db2 connector partially supports ALTER TABLE, CREATE VIEW, and DROP SCHEMA.\n4. Netezza connector partially supports ALTER TABLE and CREATE VIEW.\n5. MySQL, PostgreSQL, MongoDB, Db2, and Netezza connectors support DROP TABLE only when enabled in catalog.\n6. The CREATE SCHEMA, CREATE TABLE, DROP SCHEMA, DROP TABLE, DELETE, DROP VIEW, ALTER TABLE, and ALTER SCHEMA are not available for database based catalogs in the Data Manager UI.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-supported_sql_statements"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00539-7-1755", "score": 0.8128775358200073, "text": "\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST /{db}/_index](https://cloud.ibm.com/apidocs/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00491-7-1604", "score": 0.7912358045578003, "text": "\nUsing IBM Cloudant Query \n\nIn this tutorial, we demonstrate how to create an index and use the index to query the database. You also learn to create different types of queries to more easily find data.\n\nHere you run the commands from the command line, but you can also complete these tasks with the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard, which gives you a visual example of each task. For more information about the dashboard, see [Using the IBM Cloudant Dashboard](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query) tutorial.\n\n\n\n Before you begin \n\nBefore you begin, follow these tutorials to create an instance, and then create and populate a database.\n\n\n\n1. [Create an IBM Cloudant instance](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-an-ibm-cloudant-instance-on-ibm-cloud).\n2. [Create a database](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudcreating-a-database-within-the-service-instance).\n3. [Populate the database](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudstoring-a-small-collection-of-data-as-documents-within-the-database).\n4. (Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}, {"document_id": "ibmcld_00491-1283-3050", "score": 0.7894381284713745, "text": "\n(Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}, {"document_id": "ibmcld_00580-39512-41555", "score": 0.7865164279937744, "text": "\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00512-28883-30259", "score": 0.7805413007736206, "text": "\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n Querying for recent results for a device \n\nTo get the results for a device, you issue a partition query for the device within the bridge-9876 partition. The selector is only slightly more complicated, but still the same as an equivalent global query.\n\n\n\n Query for recent results assuming today is 13 December 2018 \n\nThe partition is embedded in the HTTP path when issuing the request to IBM Cloudant:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL/readings/_partition/bridge-9876/_find\" -H 'Content-Type: application/json' --data '{\n\"selector\": {\n\"deviceID\": {\n\"$eq\": \"device-123456\"\n},\n\"ts\": {\n\"$gte\": \"20181213\"\n}\n}\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.FindResult;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionFindOptions;\nimport com.ibm.cloud.cloudant.v1.model.Selector;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\nCloudant service = Cloudant.newInstance();\n\nMap equalWithDeviceID = new HashMap<>();\nequalWithDeviceID.put(\"$eq\", \"device-123456\");\n\nMap greaterThanOrEqualWithTs = new HashMap<>();", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00539-6216-7731", "score": 0.7791566848754883, "text": "\nIf in doubt, use the [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.\n\nFor more information, see [Explain plans](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryexplain-plans).\n\n\n\n\n\n Can I use IBM Cloudant Query with a Lucene index? \n\nYes! IBM Cloudant Query supports two types of indexes:\n\n\n\n* \"type\": \"json\" - a fixed-order index powered by IBM Cloudant's MapReduce API. Good for fixed, boilerplate queries that match every term in the index.\n* \"type\": \"text\" - a Lucene index powered by IBM Cloudant's Search API. Good for general-purpose queries across one, some, or all indexed fields.\n\n\n\nA type=text index is created with an index definition like this:\n\n{\n\"index\": {\n\"fields\": [\n{ \"name\": \"firstname\", \"type\": \"string\"},\n{ \"name\": \"surname\", \"type\": \"string\"},\n{ \"name\": \"date\", \"type\": \"string\"}\n]\n},\n\"ddoc\": \"textindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"text\"\n}\n\nNotice that the fields array requires each attribute to be named and typed (unlike type=json indexes).\n\nThe resultant index can be used by queries that contain one or more of the indexed fields:\n\n{\n\"selector\": {\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00472-16393-17597", "score": 0.7773715257644653, "text": "\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nSee the following example that uses HTTP to query a global index:\n\nGET /$DATABASE/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1 HTTP/1.1\nContent-Type: application/json\nHost: $ACCOUNT.cloudant.com\n\nSee the following example that uses the command line to query a global index:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"https://$ACCOUNT.cloudant.com/$DATABASE/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostSearchOptions searchOptions = new PostSearchOptions.Builder()\n.db(\"<db-name>\")\n.ddoc(\"<ddoc>\")\n.index(\"<index-name>\")\n.query(\":\")\n.includeDocs(true)\n.limit(1)\n.build();\n\nSearchResult response =\nservice.postSearch(searchOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nimport { CloudantV1 } from '@ibm-cloud/cloudant';\n\nconst service = CloudantV1.newInstance({});\n\nservice.postSearch({\ndb: '<db-name>',\nddoc: '<ddoc>',\nindex: '<index-name>',\nquery: ':',\nincludeDocs: true,\nlimit: 1", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}, {"document_id": "ibmcld_00620-25943-27384", "score": 0.7767250537872314, "text": "\n* IBM Cloudant provides an array of 10 IBM Cloudant documents and a bookmark, an opaque key that represents a pointer to the next documents in the result set. * When the next set of results is required, the search is repeated. However, the query is sent, with the bookmark from the first response, to IBM Cloudant in the request. * IBM Cloudant replies with the second set of documents and another bookmark, which can be used to get a third page of results. * Repeat<-- </ul> -->Now you can see how to do that with code.<-- </section \"id=\"section-how-do-cloudant-bookmarks-work\" \"> --><-- <section \"id=\"section-use-cloudant-query-search\" \"> --> How can I use IBM Cloudant Query to search? First, you search for all the cities in the US. You're using IBM Cloudant Query]IBM Cloudant Query 1] , so the operation is specified as a block of JSON: {\n\"selector\": {\n\"$eq\": {\n\"country\": \"US\"\n}\n},\n\"limit\": 5\n}\nBy using the /db/_find]IBM Cloudant Query] ! ! API endpoint, the results are passed to IBM Cloudant.<-- <ul> --> * Curl * Java * Node * Python * Go<-- </ul> --> curl -X POST -H \"Authorization: Bearer $API_BEARER_TOKEN\" -H 'Content-type: application/json' -d '{\"selector\":{\"country\":{\"$eq\": \"US\"}},\"limit\":5}' \"$SERVICE_URL/cities/_find\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.FindResult;\nimport com.ibm.cloud.cloudant.v1.model.PostFindOptions;\n\nimport java.util.Collections;\nimport java.util.Map;", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pagination-and-bookmarks"}, {"document_id": "ibmcld_00472-18152-19959", "score": 0.7756907939910889, "text": "\n}\n\nb, _ := json.MarshalIndent(searchResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\n\n\n Query Parameters \n\nYou must enable [faceting](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-searchfaceting) before you can use the following parameters: counts and drilldown.\n\n\n\nTable 3. Query parameters\n\n Argument Description Optional Type Supported Values Partition Query \n\n bookmark A bookmark that was received from a previous search. This parameter enables paging through the results. If no results exist after the bookmark, you get a response with an empty rows array and the same bookmark, confirming the end of the result list. yes String Yes \n counts This field defines an array of names of string fields, for which counts are requested. The response includes counts for each unique value of this field name among the documents that match the search query. [Faceting](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. Yes JSON A JSON array of field names. No \n drilldown This field can be used several times. Each use defines a pair of a field name and a value. The search matches only documents that include the value that was provided in the named field. It differs from using \"fieldname:value\" in the q parameter only in that the values aren't analyzed. [Faceting](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. No JSON A JSON array that includes two elements: the field name and the value. Yes \n group_field Field by which to group search matches. Yes String A string that includes the name of a string field.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}, {"document_id": "ibmcld_00472-14617-15752", "score": 0.7726786136627197, "text": "\ncurl \"https://$ACCOUNT.cloudant.com/$DATABASE/_partition/$PARTITION_KEY/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostPartitionSearchOptions searchOptions =\nnew PostPartitionSearchOptions.Builder()\n.db(\"<db-name>\")\n.partitionKey(\"<partition-key>\")\n.ddoc(\"<ddoc>\")\n.index(\"<index-name>\")\n.query(\":\")\n.includeDocs(true)\n.limit(1)\n.build();\n\nSearchResult response =\nservice.postPartitionSearch(searchOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nimport { CloudantV1 } from '@ibm-cloud/cloudant';\n\nconst service = CloudantV1.newInstance({});\n\nservice.postSearch({\ndb: '<db-name>',\npartitionKey: '<partition-key>',\nddoc: '<ddoc>',\nindex: '<index-name>',\nquery: ':',\nincludeDocs: true,\nlimit: 1\n}).then(response => {\nconsole.log(response.result);\n});\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()\n\nresponse = service.post_search(\ndb='<db-name>',", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16258-1324-3123", "score": 0.7794995307922363, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-2570-3569", "score": 0.7298879623413086, "text": "\n[Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-side.png)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-7-1952", "score": 0.6905314922332764, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16364-36153-38148", "score": 0.6663470268249512, "text": "\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_06953-1532-3194", "score": 0.6281735897064209, "text": "\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.\n\nThe Emphasize the answer feature is available from instances that are managed by IBM Cloud only.\n\n{\n\"aggregation\": \"\",\n\"sort\": \"\",\n\"count\": 10,\n\"return\": [],\n\"filter\": <custom_filter_specified_in_assistant>\n\"passages\": {\n\"enabled\": \"true\",\n\"fields\": [\n<search_config_body_field_specified_in_assistant>\n],\n\"characters\": 325,\n\"per_document\": true,\n\"max_per_document\": 3,\n\"find_answers\": true,\n\"max_answers_per_passage\": 1\n},\n\"highlight\": false,\n\"spelling_suggestions\": false,\n\"table_results\": {\n\"enabled\": false\n},\n\"suggested_refinements\": {\n\"enabled\": false\n}\n}\nShow more\n\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project"}, {"document_id": "ibmcld_16364-34499-36597", "score": 0.6242455244064331, "text": "\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week. This feature is available with the date response type and the Current date built-in variable.\n\nFor example, you might [define a customer response](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-collect-infochoose-type) in step 1 with the date response type. When the customer responds to that step, they choose a date. You can then condition a later step on whether the date that the customer chose is Wednesday.\n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The free text response type now has the contains, does not contain, matches, and does not match operators available. For more information, see [Operators](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nExtensions support for arrays\n: Custom extensions now support passing arrays as parameters and accessing arrays in response variables. For more information, see [Calling a custom extension](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-call-extension).\n\n\n\n\n\n 26 August 2022 \n\nNew filter on the Analyze page\n: You can now filter customer conversation data by the Greet customer system action. From the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03273-3976-5874", "score": 0.6233271360397339, "text": "\nTo add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime-context) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.\n\n\n\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog.\n\n\n\n\n\n\n\n What to do next \n\nMake changes to the dialog to address issues you see when testing:\n\n\n\n* If you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n* If the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\n\n\nIf you are ready to put the conversation to work helping your users, integrate your assistant with a messaging platform or custom application. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add).\n\n\n\n\n\n\n\n Searching your dialog \n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. Select the Search icon: ![Search icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search_icon.png)\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait while the text in your dialog nodes is indexed.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}, {"document_id": "ibmcld_03043-1537-3553", "score": 0.621997594833374, "text": "\nTo train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor in the tool to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. In the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_07578-84096-86060", "score": 0.616746723651886, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat). \n Webhook A mechanism for calling out to an external program as part of the dialog. For example, if a customer asks the assistant to translate a string from English to French, the dialog can call an external language translation service to translate the phrase and return the translation to the customer in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks). \n\n\n\n* I don\u2019t see the Analytics page\n\nYou can only view the Analytics page if the system administrator enabled the feature in your deployment. A prerequisite service that is required by the feature is only available on OpenShift Red Hat 4.5; it is not available on 3.11.\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-84071-86035", "score": 0.616746723651886, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat). \n Webhook A mechanism for calling out to an external program as part of the dialog. For example, if a customer asks the assistant to translate a string from English to French, the dialog can call an external language translation service to translate the phrase and return the translation to the customer in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks). \n\n\n\n* I don\u2019t see the Analytics page\n\nYou can only view the Analytics page if the system administrator enabled the feature in your deployment. A prerequisite service that is required by the feature is only available on OpenShift Red Hat 4.5; it is not available on 3.11.\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03037-1358-3485", "score": 0.7162945866584778, "text": "\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Enabling user metrics", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_16252-3899-5971", "score": 0.7099581956863403, "text": "\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2messagestateless)\n* [v2 stateful /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in /message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan"}, {"document_id": "ibmcld_16258-1324-3123", "score": 0.7085235118865967, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-2570-3569", "score": 0.7041122317314148, "text": "\n[Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-side.png)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_03107-3801-5605", "score": 0.6977931261062622, "text": "\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2messagestateless)\n* [v2 stateful /message](https://cloud.ibm.com/apidocs/assistant-v2/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in /message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new /message API call.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_16259-1485-3642", "score": 0.6889411807060242, "text": "\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery/takeout, Small/Medium/Large, Cheese/Pepperoni/Mushrooms/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-overview"}, {"document_id": "ibmcld_03042-1241-3131", "score": 0.6765159368515015, "text": "\n* [Skills](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-addskill-add-limits)\n* [Versions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-versionsversions-limits)\n\n\n\n\n\n\n\n User information \n\nA unique user is recognized by the user ID that is associated with the person that interacts with your assistant. It is your responsibility to pass the user ID information to the service. Watson Assistant checks for the following information from API requests in this order:\n\n1. user_id: A property defined in the API that is sent in the context object of a /message API call. Using this property is the best way to ensure that you accurately attribute /message API calls to unique users. For more information about the user ID property, see the API reference documentation:\n\n- context.global.system.user_id: [v2 API](https://cloud.ibm.com/apidocs/assistant-data-v2message)\n- context.metadata.user_id: [v1 API](https://cloud.ibm.com/apidocs/assistant-data-v1message)\n\n1. session_id (v2 only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in /message API calls that are generated by the built-in integrations. The session ends when a user closes integration or after the inactivity time limit is reached.\n\nIf you use the stateless v2 /message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a /message API call. This property can be used to identify multiple /message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-services-information"}, {"document_id": "ibmcld_16258-7-1952", "score": 0.6640766859054565, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_03363-4413-6535", "score": 0.6506091356277466, "text": "\nFor more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_16262-6573-7996", "score": 0.6491698026657104, "text": "\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client-get-context"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08423-6549-8265", "score": 0.7311704158782959, "text": "\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the SO user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, SO user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the SO user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 2. Create service IDs and API keys for the normal user \n\nTo create a service ID for the normal user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the normal user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Normal user and description for the normal user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Normal user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Normal user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the normal user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"}, {"document_id": "ibmcld_11472-2693-4203", "score": 0.723299503326416, "text": "\nStep 3: Integrate the App ID instance as the ID provider for the administrator's account \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Identity Providers](https://cloud.ibm.com/iam/identity-providers). For Type, choose IBM Cloud App ID, then click Create.\n2. Specify a name and select the App ID instance from the drop-down list.\n3. Select the checkbox to enable the ID provider.\n\nZoom\n\n![Create identity provider](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-idp-reference.png)\n\nFigure 3. Create identity provider page\n4. The default IdP URL is shown. Share this URL with users when they need to log in.\n\n\n\n\n\n\n\n Step 4: Add Users \n\nWhen you use App ID as ID provider with the Cloud directory, you can create users in the IBM Cloud user interface.\n\n\n\n1. Open the App ID instance page from the [resource list](https://cloud.ibm.com/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 5: Create or modify users' project assignments \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Users](https://cloud.ibm.com/iam/users) and click the user.\n\nZoom\n\n![Change User Access](https://cloud.ibm.com/docs-content/v1/content/5f399fa794584e8a662591b494b9a99aa927c74c/quantum-computing/images/org-guide-manage-user.png)\n\nFigure 11. Change User Access\n\nIf you don't see the user that you want to manage, verify that they logged in to IBM Cloud at least once.", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-appid-cloud-org"}, {"document_id": "ibmcld_08423-7919-9687", "score": 0.7069851756095886, "text": "\n3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Anonymous user and description for the anonymous user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Anonymous user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Anonymous user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the anonymous user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\nFor more information about creating services IDs, see [Creating and working with service IDs](https://cloud.ibm.com/docs/account?topic=account-serviceids). For detailed instructions on creating service ID API keys, see [Managing service ID API keys](https://cloud.ibm.com/docs/account?topic=account-serviceidapikeys).\n\n\n\n\n\n\n\n Step 3: Assign IAM roles to the service IDs \n\nYou can grant access to service IDs within a Hyper Protect Crypto Services service instance by using the IBM Cloud console.\n\n\n\n 1. Assign the custom roles to the SO user service ID \n\nTo assign the custom roles that are defined in [Step 1](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-best-practice-pkcs11-accessstep1-create-custom-roles) to the SO user service ID, follow these steps:\n\nTo assign access to the keystores for the SO user, follow these steps:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"}, {"document_id": "ibmcld_02732-7949-9378", "score": 0.6888813972473145, "text": "\n\"id\": \"123454231-1234-1234-3334-12345687012\",\n\"name\": \"developer\",\n\"description\": \"Can perform administrative tasks.\",\n\"access\":\n{\n\"application_id\": \"de33d272-f8a7-4406-8fe8-ab28fd457be5\",\n\"scopes\":\n\"write\",\n\"read\"\n]\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n Assigning roles to users with the UI \n\nAfter you create roles, you can assign them to your user's profile. You can also assign roles when you create a future user.\n\n\n\n1. Go to Profiles and roles > User profiles in your App ID dashboard.\n2. From the Actions menu in the row of the specific user you're assigning a role to, click Assign role.\n3. Select the role or roles that you want to add from the list of available roles.\n4. Optional: If you don't see the role that you're looking for, click Create role and provide the information to add another option.\n5. Click Save.\n\n\n\n\n\n\n\n Assigning roles to users with the API \n\nAfter you create roles, you can assign them to your user's profile. You can also assign roles when you create a future user.\n\n\n\n1. Get your user ID by searching your App ID users with an identifying query, such as an email address.\n\ncurl -X GET \"https://<region>.appid.cloud.ibm.com/management/v4/<tenantID>/Users?query=<identifyingSearchQuery>\" -H \"accept: application/json\" -H \"authorization: Bearer <token>\"\n\nExample:\n\ncurl -X GET https://us-south.appid.cloud.ibm.com/management/v4/e19a2778-3262-4986-8875-8khjafsdkhjsdafkjh/cloud_directory/Users?query=example@domain.com", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-access-control"}, {"document_id": "ibmcld_01035-13446-14858", "score": 0.6874775886535645, "text": "\nSelecting Manage Users page from drop-down menu\n3. With the Users tab selected, click Add.\n\nZoom\n\n![View of the web console Manage Users page](https://cloud.ibm.com/docs-content/v1/content/2a59ee244ed61eb35ab50e45757b42d22f720132/Db2onCloud/images/add_users.png)\n\nFigure 2. Clicking Add to create a user\n4. Select Add IBMid user.\n\nZoom\n\n![View of the web console Add IBMid user page](https://cloud.ibm.com/docs-content/v1/content/2a59ee244ed61eb35ab50e45757b42d22f720132/Db2onCloud/images/add_ibmid_user.png)\n\nFigure 3. Creating an IBMid user\n5. Enter a User ID and an IBMid in the provided fields. Click Create.\n\nThe IBMid field can be used to specify either an IBMid or a service ID for the user.\n\n\n\n\n\n\n\n REST API experience \n\nThe Db2 on Cloud REST API was enhanced to also accept an IAM access token for the functions that previously accepted a database service-generated access token.\n\n\n\n* To add a new IBMid user, run the following example API call:\n\ncurl --tlsv1.2 \"https://<IPaddress>/dbapi/v3/users\" -H \"Authorization: Bearer <access_token>\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\"id\":\"<userid>\",\"ibmid\":\"<userid>@<email_address_domain>\",\"role\":\"bluadmin\",\"locked\":\"no\",\"iam\":true}\"\n\nThe userid value for \"id\" cannot match the full email ID. It can match the first part of the email ID, but that is not necessary. The two different IDs are not linked together in any way.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-iam"}, {"document_id": "ibmcld_03080-9575-11239", "score": 0.6818886995315552, "text": "\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* User-based service plans use the user_id associated with user input for billing purposes.\n\n\n\n\n\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter.\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\n\n\nTo support these user-based capabilities, add the [updateUserID() method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\ncloudPrivateHostURL: 'YOUR_HOST_URL',\nonLoad: function(instance) {\ninstance.updateUserID('L12345');\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16378-1689-3407", "score": 0.6812705397605896, "text": "\nThis example in this tutorial, which is based on an Express server for Node.js, shows how to start a session with an anonymous user ID and then authenticate the user during the session.\n\n\n\n1. Create a function called getOrSetAnonymousID() that generates a unique anonymous user ID for each customer and stores it in a cookie (or, if the cookie already exists, uses the stored user ID).\n\nUse a cookie that lasts for at least 45 days. If you do not store the user ID for more than 30 days, the same customer might be counted as multiple different users during the same billing period. (This can still happen if the same user deletes the cookie or uses a different browser.)\n\n\n\nfunction getOrSetAnonymousID(request, response) {\nlet anonymousID = request.cookies['ANONYMOUS-USER-ID'];\nif (!anonymousID) {\nanonymousID = anon-${uuid()};\n}\n\nresponse.cookie('ANONYMOUS-USER-ID', anonymousID, {\nexpires: new Date(Date.now() + 1000 * 60 * 60 * 24 * 45), // 45 days.\nhttpOnly: true,\n});\n\nreturn anonymousID;\n}\n\n\n\n1. In the function you use to create a JWT, use the anonymous ID returned from the getOrSetAnonymousID() function as the value of the sub claim. This sets the value of the user ID that will be used to uniquely identify the customer for billing purposes.\n\nIn addition, retrieve any value from the SESSION_INFO cookie, which we will use to store authenticated login information. If a value exists, store it in the user_payload private claim of the JWT. (If the user has not yet authenticated, this cookie does not yet exist.)\n\n\n\nconst jwtContent = {\nsub: anonymousUserID,\nuser_payload: {\nname: 'Anonymous',\ncustom_user_id: anonymousUserID,\n},\n};\n\nif (sessionInfo) {\njwtContent.user_payload.name = sessionInfo.userName;", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security"}, {"document_id": "ibmcld_02855-17972-19576", "score": 0.6778677701950073, "text": "\nFor more information, see [Authenticating users](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. See [Labeling and deleting data](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-information-securityinformation-security-gdpr-wa).\n\n\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the updateUserID() method in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nonLoad: function(instance) {\ninstance.updateUserID(L12345);\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_03421-9438-11232", "score": 0.6752004623413086, "text": "\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* User-based service plans use the user_id associated with user input for billing purposes. See [User-based plans](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. See [Labeling and deleting data](https://cloud.ibm.com/docs/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\n\n\nTo support these user-based capabilities, add the [updateUserID() method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_02174-4-2100", "score": 0.6695791482925415, "text": "\n* UI\n* Terraform\n\n\n\n\n\n\n\n Restricting users from creating service IDs \n\nBy default, all members of an account can create service IDs. However, access can be restricted so that only members with the correct access can create service IDs by using the Service ID creation setting. For more information about Service IDs, see [Creating and working with service IDs](https://cloud.ibm.com/docs/account?topic=account-serviceids).\n\n\n\n Enabling the restriction to create service IDs in the console \n\nTo enable the setting to restrict users from creating service IDs, you must have the following assigned access:\n\n\n\n* An IAM policy with the Administrator, Operator, or Editor role on the [IAM Identity Service](https://cloud.ibm.com/docs/account?topic=account-account-servicesidentity-service-account-management).\n\n\n\nIf you enable the Service ID creation setting, users in your account require specific access to create service IDs, including the account owner. To restrict who can create service IDs, use the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Settings.\n2. In the Account section, enable the Service ID creation setting.\n3. Click Yes to confirm.\n\n\n\nNow that the setting is enabled to restrict users from creating service IDs, you can assign the required access to enable specific users to continue creating service IDs. Remember, the account owner is also required to be assigned this explicit access.\n\n\n\n\n\n Enabling the restriction to create service IDs by using Terraform \n\nIf you enable the Service ID creation setting, users in your account require specific access to create service IDs, including the account owner.\n\nTo enable the setting to restrict users from creating service IDs, you must have the following assigned access:\n\n\n\n* An IAM policy with the Administrator, Operator, or Editor role on the [IAM Identity Service](https://cloud.ibm.com/docs/account?topic=account-account-servicesidentity-service-account-management).\n\n\n\nBefore you can set limits for login sessions by using Terraform, make sure that you have completed the following:", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-restrict-service-id-create"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02746-7-1681", "score": 0.7153434753417969, "text": "\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https://us-south.appid.cloud.ibm.com/swagger-ui//Management%20API%20-%20Config/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-cd-strength"}, {"document_id": "ibmcld_07765-0-1628", "score": 0.6948593854904175, "text": "\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"}, {"document_id": "ibmcld_05278-270769-272483", "score": 0.6341396570205688, "text": "\nValid values are json, yaml, jsonpath=JSONPATH_EXPRESSION, and jsonpath-as-json=JSONPATH_EXPRESSION. Use jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--password, --pw\n: The password for a basic auth or registry secret. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --spf\n: The path to a file containing the password for a basic auth or registry secret. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--password-from-json-file, --spfj\n: The path to a JSON file containing the password for a basic auth or registry secret. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--private-key-file, --pkf\n: Specify a file containing the private key for a TLS secret that matches the specified certificate chain with the cert-chain-file option. You must provide the path to the file as a value. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--rm\n: Remove an individual key-value pair in a generic secret by specifying the name of the key. This option can be specified multiple times. This value is optional.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli"}, {"document_id": "ibmcld_04335-239254-240968", "score": 0.6341396570205688, "text": "\nValid values are json, yaml, jsonpath=JSONPATH_EXPRESSION, and jsonpath-as-json=JSONPATH_EXPRESSION. Use jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--password, --pw\n: The password for a basic auth or registry secret. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --spf\n: The path to a file containing the password for a basic auth or registry secret. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--password-from-json-file, --spfj\n: The path to a JSON file containing the password for a basic auth or registry secret. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--private-key-file, --pkf\n: Specify a file containing the private key for a TLS secret that matches the specified certificate chain with the cert-chain-file option. You must provide the path to the file as a value. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--rm\n: Remove an individual key-value pair in a generic secret by specifying the name of the key. This option can be specified multiple times. This value is optional.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cli"}, {"document_id": "ibmcld_07761-2352-4487", "score": 0.5962412357330322, "text": "\nIA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br> \n IA-5 (f) <br><br> * Check whether App ID minimum period between password changes policy is set to greater than 0<br> * IBM Cloud IAM establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators, such as API keys<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * IBMid establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators<br> * Check whether App ID avoid password reuse policy is enabled<br><br><br> \n IA-5 (g) <br><br> * Check whether Secrets Manager user credentials are rotated at least every # days<br> * Check whether Secrets Manager arbitrary secrets are rotated at least every # days<br> * Check whether Hyper Protect Crypto Services encryption keys that are generated by the service are rotated automatically at least every # months<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nIndividual authenticators include, for example, passwords, tokens, biometrics, PKI certificates, and key cards. Initial authenticator content is the actual content (e.g., the initial password) as opposed to requirements about authenticator content (e.g., minimum password length).", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"}, {"document_id": "ibmcld_00708-32460-34303", "score": 0.5942144393920898, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-32460-34303", "score": 0.5942144393920898, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-32441-34284", "score": 0.5942144393920898, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_05278-229504-231143", "score": 0.5897499322891235, "text": "\nIf neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --pf\n: The path to a file containing the password to access the registry server. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-json-file, --pfj\n: The path to a JSON file containing the password to access the registry server. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--server, -s\n: The URL of the registry server. This value is optional. The default value is us.icr.io.\n\n--username, -u\n: The username to access the registry server. This value is optional. The default value is iamapikey.\n\n\n\n\n\n Example \n\nThe following example creates image registry access that is called myregistry to a Container Registry instance that is located at us.icr.io and uses a username of iamapikey and the IAM API key as a password.\n\nibmcloud ce registry create --name myregistry --server us.icr.io --username iamapikey --password API_KEY\n\n\n\n\n\n Example output \n\nCreating image registry access secret myregistry...\n\nOK\n\n\n\n\n\n\n\n ibmcloud ce registry delete \n\nDelete an image registry access secret.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli"}, {"document_id": "ibmcld_07761-1647-3208", "score": 0.589187741279602, "text": "\n* [Handling and securing secrets](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-secrets)\n\n\n\n\n\n\n\n IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\nRules for IA-5 in IBM Cloud for Financial Services v1.2.0 profile\n\n Requirement ID Rules \n\n IA-5 (b) <br><br> * IBM Cloud IAM establishes initial authenticator content for authenticators that are defined by the organization (for example, API keys)<br><br><br> \n IA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-4413-6535", "score": 0.687553882598877, "text": "\nFor more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03354-4-1897", "score": 0.6781944632530212, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs"}, {"document_id": "ibmcld_04866-27024-28791", "score": 0.6482517123222351, "text": "\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nSupported ISO 8601 format for New-Retention-Expiration-Date is [YYYY]-[MM]-[DD]T[hh]:[mm]:[ss]Z or [YYYY][DD]T[hh][ss]Z (for example, 2020-11-28T03:10:01Z or 20201128T031001Z are both valid).\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nSyntax\n\nPOST https://{endpoint}/{bucket-name}/{object-name}?extendRetention= path style\nPOST https://{bucket-name}.{endpoint}/{object-name}?extendRetention= virtual host style\n\nExample request\n\nPOST /BucketName/ObjectName?extendRetention HTTP/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00GMT\nAuthorization: authorization string\nContent-Type: text/plain\nAdditional-Retention-Period: 31470552\n\nExample response\n\nHTTP/1.1 200 OK\nDate: Fri, 8 Dec 2018 17:50:00GMT\nConnection: close\n\n\n\n* Java\n* Python\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-27003-28770", "score": 0.6482517123222351, "text": "\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nSupported ISO 8601 format for New-Retention-Expiration-Date is [YYYY]-[MM]-[DD]T[hh]:[mm]:[ss]Z or [YYYY][DD]T[hh][ss]Z (for example, 2020-11-28T03:10:01Z or 20201128T031001Z are both valid).\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nSyntax\n\nPOST https://{endpoint}/{bucket-name}/{object-name}?extendRetention= path style\nPOST https://{bucket-name}.{endpoint}/{object-name}?extendRetention= virtual host style\n\nExample request\n\nPOST /BucketName/ObjectName?extendRetention HTTP/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00GMT\nAuthorization: authorization string\nContent-Type: text/plain\nAdditional-Retention-Period: 31470552\n\nExample response\n\nHTTP/1.1 200 OK\nDate: Fri, 8 Dec 2018 17:50:00GMT\nConnection: close\n\n\n\n* Java\n* Python\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04939-57496-59284", "score": 0.6434019804000854, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-57476-59264", "score": 0.6434019804000854, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_09994-5971-8165", "score": 0.6367956399917603, "text": "\nThe retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.\n\nIf you want to query historical data as far back as possible, you can use the RETENTION_START_TIMESTAMP keyword in time travel queries. If you do this, you can avoid having to try to compute the right timestamp on your own. By extension, you eliminate the risk of running into an error if the value turns out to be too old (older than the retention start timestamp).\n* GROOM TABLE Historical rows that were deleted before the retention start timestamp are no longer needed for time travel queries and can be reclaimed.\n\n\n\n\n\n\n\n Row timestamps and validity \n\nThe insert timestamp of a current or historical row is the date/time that the transaction inserting the row committed. It is not the time when a particular INSERT, UPDATE, or MERGE statement that inserted the row was run.\n\nIf the inserting transaction for a row committed before the retention start timestamp, the row is treated as having been inserted at the retention start timestamp. This generally applies only to existing rows at the time of altering a nontemporal table to a temporal table.\n\nAn inserted row whose transaction has not yet committed does not have an insert timestamp. Such a row will never be visible to a time travel query.\n\nIn a time travel query, you can select the insert timestamp by using the _SYS_START virtual column of a temporal table.\n\nThe delete timestamp of a historical row is the date/time that the transaction deleting the row committed. It is not the time when a particular DELETE, UPDATE, MERGE, or TRUNCATE statement that deleted the row was run.\n\nIf a temporal table is truncated, the existing table rows are available to time travel queries and are treated as having been deleted as of the time the truncating transaction committed.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-runningqueries_tt"}, {"document_id": "ibmcld_03036-5624-7724", "score": 0.6308643817901611, "text": "\n[Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_09956-7-2100", "score": 0.6292858719825745, "text": "\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https://cloud.ibm.com/docs/docs/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https://cloud.ibm.com/docs/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-dataretentioninterval_tt"}, {"document_id": "ibmcld_09956-3082-3744", "score": 0.6267382502555847, "text": "\nIdentify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a database:\n\n\n\n\n\n1. Go to Databases.\n2. Identify the database for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-dataretentioninterval_tt"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16481-3559-5682", "score": 0.7291296720504761, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16417-3559-5683", "score": 0.7290046215057373, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16464-13891-15856", "score": 0.7195955514907837, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16417-5155-7505", "score": 0.684808075428009, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 0.684808075428009, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16417-1764-4158", "score": 0.6719591617584229, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-1764-4158", "score": 0.6719591617584229, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16425-14122-16407", "score": 0.6715553402900696, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}, {"document_id": "ibmcld_16490-14092-16377", "score": 0.6715553402900696, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"}, {"document_id": "ibmcld_10073-7350-9139", "score": 0.6509808301925659, "text": "\nScored 1 Pass IBM \n 1.2.32 Ensure that the --etcd-cafile argument is set as appropriate Scored 1 Pass IBM \n 1.2.33 Ensure that the --encryption-provider-config argument is set as appropriate Scored 1 [Fail](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 1.2.34 Ensure that encryption providers are appropriately configured Scored 1 [Fail](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-411ibm-remediations-and-explanations-411) Shared \n 1.2.35 Ensure that the API Server only makes use of Strong Cryptographic Ciphers Not Scored 1 Pass IBM \n\n\n\n\n\n\n\n 1.3 Controller manager \n\n\n\nSection 1.3 Controller manager benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.3.1 Ensure that the --terminated-pod-gc-threshold argument is set as appropriate Scored 1 Pass IBM \n 1.3.2 Ensure that the --profiling argument is set to false Scored 1 Pass IBM \n 1.3.3 Ensure that the --use-service-account-credentials argument is set to true Scored 1 Pass IBM \n 1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate Scored 1 Pass IBM \n 1.3.5 Ensure that the --root-ca-file argument is set as appropriate Scored 1 Pass IBM \n 1.3.6 Ensure that the RotateKubeletServerCertificate argument is set to true Scored 2 Pass IBM \n 1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1 Scored 1 Pass IBM \n\n\n\n\n\n\n\n 1.4 Scheduler \n\n\n\nSection 1.4 Scheduler benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.4.1 Ensure that the --profiling argument is set to false Scored 1 Pass IBM \n 1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1 Scored 1 Pass IBM \n\n\n\n\n\n\n\n\n\n 2 Etcd node configuration", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-411"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16454-13234-15485", "score": 0.7342863082885742, "text": "\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50. Annotate only mentions initially, examine the results, and refine your annotation guidelines and the type system as needed. When you're satisfied with the results of mention annotation, move on to annotate relations and coreferences.\n\nWhile fundamental work is underway to define a set of entity types and mention-annotation guidelines, avoid putting a lot of effort into annotating relation mentions. Mention changes will undo relation annotation work. Do take some time to define a set of relation types and their allowable entity type pairs so that relation type needs are taken into consideration before the entity type inventory is finalized.\n\nExpect the type system to evolve with the experience of people trying to annotate to it. If you revise the type system after you create human annotation tasks, you must decide whether to apply the changes to each task. If you apply the changes, human annotators will have to revisit the documents that they annotated previously.\n\nWhen you test the model, you can review statistics that show how frequently the entity types and relation types occur in your sample documents. Be sure to review these statistics. To ensure that your application receives enough context to accurately annotate large collections of documents, your test data must include a large sampling of the most important entity types and relation types.\n\n> Important: After you train your first model, you will likely need to make modifications based on the performance statistics. However, to create a reliable statistical model for machine annotation, you want the type system to be as close to final as possible before you begin large-scale annotation tasks.\n\n\n\n\n\n When to define roles \n\nUsing roles enables you to define more precise entity types.\n\nEvery entity that you add has a role.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}, {"document_id": "ibmcld_16468-6902-8930", "score": 0.7107076644897461, "text": "\nIn addition, some percentage of documents must occur in all of the annotation sets that you add to the task (you specify the overlap percentage when you create the annotation sets).\n\n\n\n Important \n\n\n\n* An annotation task is a temporal concept that exists to allow human annotators to annotate text in isolated spaces. It also ensures that only approved annotations are promoted to ground truth.\n* An annotation set can be included in one active task at a time. To add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16507-3099-4772", "score": 0.7056152820587158, "text": "\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16410-6875-8784", "score": 0.7043007612228394, "text": "\nTo add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16425-14122-16407", "score": 0.6947249174118042, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}, {"document_id": "ibmcld_16490-14092-16377", "score": 0.6947249174118042, "text": "\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"}, {"document_id": "ibmcld_16527-12995-15319", "score": 0.6930433511734009, "text": "\nThe document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50. Annotate only mentions initially, examine the results, and refine your annotation guidelines and the type system as needed. When you're satisfied with the results of mention annotation, move on to annotate relations and coreferences.\n\nWhile fundamental work is underway to define a set of entity types and mention-annotation guidelines, avoid putting a lot of effort into annotating relation mentions. Mention changes will undo relation annotation work. Do take some time to define a set of relation types and their allowable entity type pairs so that relation type needs are taken into consideration before the entity type inventory is finalized.\n\nExpect the type system to evolve with the experience of people trying to annotate to it. If you revise the type system after you create human annotation tasks, you must decide whether to apply the changes to each task. If you apply the changes, human annotators will have to revisit the documents that they annotated previously.\n\nWhen you test the model, you can review statistics that show how frequently the entity types and relation types occur in your sample documents. Be sure to review these statistics. To ensure that your application receives enough context to accurately annotate large collections of documents, your test data must include a large sampling of the most important entity types and relation types.\n\nAfter you train your first model, you will likely need to make modifications based on the performance statistics. However, to create a reliable statistical model for machine annotation, you want the type system to be as close to final as possible before you begin large-scale annotation tasks.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"}, {"document_id": "ibmcld_16425-15959-18174", "score": 0.6918036937713623, "text": "\nThe guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on. Be sure to include examples of difficult decisions and their preferred resolutions. The best way to determine what you need to add to the annotation guidelines is to carefully review document conflicts. Real examples of annotations that real people disagreed upon and how they were resolved can be a great help to human annotators as they tackle the annotation of new documents.\n* Update type system\n\nYou might need to update the type system for these reasons:\n\n\n\n* The documents that comprise the training data have references to concepts that are important types in the domain but are not represented anywhere in the type system. This suggests that you might need to add types that capture the missing concepts or relationships. Be careful not to try to define a type for every concept in a field, or every entity that occurs in domain documents; the type system should be limited to only the most fundamental types.\n* An existing type is being consistently misused by human annotators. If a type consistently causes confusion, then you might need to rename it or eliminate it if it is redundant.\n* An existing type is never used by human annotators because it is never referenced in the documents. If the type is unlikely to ever be used in literature from this domain, then remove it from the type system.\n* Two types are often interchanged when human annotators annotate documents. Consider whether the two types could be consolidated into one type that accurately represents the concept or relationship. For example, if the type system contains both PERSON and PEOPLE, which are often used interchangeably, it might be best to use one type named PERSONPEOPLE that covers both cases instead of two separate types.\n\n\n\nUse caution when you update the type system.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}, {"document_id": "ibmcld_16490-15929-18144", "score": 0.6918036937713623, "text": "\nThe guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on. Be sure to include examples of difficult decisions and their preferred resolutions. The best way to determine what you need to add to the annotation guidelines is to carefully review document conflicts. Real examples of annotations that real people disagreed upon and how they were resolved can be a great help to human annotators as they tackle the annotation of new documents.\n* Update type system\n\nYou might need to update the type system for these reasons:\n\n\n\n* The documents that comprise the training data have references to concepts that are important types in the domain but are not represented anywhere in the type system. This suggests that you might need to add types that capture the missing concepts or relationships. Be careful not to try to define a type for every concept in a field, or every entity that occurs in domain documents; the type system should be limited to only the most fundamental types.\n* An existing type is being consistently misused by human annotators. If a type consistently causes confusion, then you might need to rename it or eliminate it if it is redundant.\n* An existing type is never used by human annotators because it is never referenced in the documents. If the type is unlikely to ever be used in literature from this domain, then remove it from the type system.\n* Two types are often interchanged when human annotators annotate documents. Consider whether the two types could be consolidated into one type that accurately represents the concept or relationship. For example, if the type system contains both PERSON and PEOPLE, which are often used interchangeably, it might be best to use one type named PERSONPEOPLE that covers both cases instead of two separate types.\n\n\n\nUse caution when you update the type system.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"}, {"document_id": "ibmcld_16410-14917-17357", "score": 0.6882992386817932, "text": "\nAnnotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static. As your project evolves, you'll likely discover instances of mentions and relationships that are not accurately captured in the guidelines. And you'll likely discover inconsistencies between multiple human annotators who interpret the guidelines in different ways. By updating the guidelines as situations arise, you can help improve the accuracy and consistency of annotations over time.\n\nBefore documents can be considered ground truth, any conflicts between how different human annotators annotated the same documents must be resolved. A key way to resolve the conflicts is by discussing what caused the confusion, thus helping human annotators learn from their mistakes. Improving and clarifying the guidelines can help reduce the number of conflicts and help ensure that accurately and consistently annotated documents are promoted to ground truth.\n\nTo help you manage the guidelines, you might want to divide what could become a long document into multiple parts, such as guidelines for annotating entities, guidelines for annotating relations, and guidelines for annotating the ways that mentions can be coreferenced. Changes that you make in one area must be evaluated and coordinated with changes that you make in another area. For example, if you add an entity type, review the guidelines for annotating relation types and specify how the new entity type can relate to other entity types.\n\n\n\n\n\n Annotation guidelines example \n\nMost annotation guidelines will need a lot of detail and examples to ensure that human annotators consistently annotate text.\n\nThe example presented here is a simple guideline that was created for a small domain that contains traffic incident reports.\n\n\n\n Task Goals \n\n\n\n* As project members, become familiar with the iterative process of manual annotation and machine learning model refinement.\n* Annotate documents in the automotive domain with the ground truth editor and use the annotations to train a machine learning model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11408-10069-12000", "score": 0.6984061002731323, "text": "\nYou are billed based on the current volume size at the metering time. The following table shows an example of how you are billed based on your volume creation:\n\n\n\nTable 7. Calculation of data volume\n\n Volume size you create You are billed \n\n 10 GB 10 GB \n 10+5 GB 15 GB \n\n\n\n* Image backing volumes:These volumes are part of a boot image in your cloud-instance boot image catalog. You are billed based on the total volume size(s) contained in the image.\n\nWhen the image has a single backing volume, you are billed based on the GB size of the single volume. When the image has multiple backing volumes, you are billed based on tallying up the size(s) of all the image backing volumes. The following table shows an example of how you are billed based on your boot volume:\n\n\n\nTable 8. Calculation of image backing volume\n\n Image volume size Single or multiple backing You are billed \n\n 20 GB Single backing volume 20 GB \n volume 1 (20 GB), volume 2 (10 GB) Multiple backing volume 30 GB \n\n\n\n* Deployed VM volumes: These volumes are created when you deploy a VM with an image. The deployed VMs will get a copy of all the volumes in the image. Any additional data volumes attached to the deployed VM are already accounted for under Data Volumes. The following table shows an example of how you are billed based on the VMs that you deploy:\n\n\n\nTable 9. Calculation of deployed VMs volume\n\n Image backing volume You are billed \n\n 20 GB 20 GB \n 20 GB + 30 GB 50 GB \n\n\n\n\n\n\n\n Use case of account billable storage \n\nThe following table shows the use case on how you are billed based on the storage that you use (assuming tier 1):\n\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_07578-1285837-1287770", "score": 0.6897077560424805, "text": "\n* [sysstat](https://github.com/sysstat/sysstat/blob/master/README.md) - System performance tools for the Linux\u00ae operating system.\n* [typeperf](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/typeperf) - Windows\u00ae command that writes performance data to the command window or to a log file.\n* [esxtop](https://communities.vmware.com/t5/Storage-Performance/Interpreting-esxtop-Statistics/ta-p/2776936) - A command-line tool that gives administrators real-time information about resource usage in a VMware\u00ae vSphere environment. It can monitor and collect data for all system resources: CPU, memory, disk, and network.\n\n\n\n* What is the difference between a replica volume, a dependent and an independent duplicate volume?\n\nYou can create a replica or a duplicate volume by using a snapshot of your volume. Replication and cloning use one of your snapshots to copy data to a destination volume. However, that is where the similarities end.\n\nReplication keeps your data in sync in two different locations. Only one of the volume pair (primary volume and replica volume) can be active at a time. The replication process automatically copies information from the active volume to the inactive volume based on the replication schedule. For more information about replica volumes, see [Replicating data](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-replication).\n\nDuplication creates a copy of your volume based on a snapshot in the same availability zone as the parent volume. The duplicate volume inherits the capacity and performance options of the original volume by default and has a copy of the data up to the point-in-time of a snapshot. The duplicate volume can be dependent or independent from the original volume, and it can be manually refreshed with data from the parent volume. You can adjust the IOPS or increase the volume size of the duplicate without any effect on the parent volume.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1288486-1290419", "score": 0.6897077560424805, "text": "\n* [sysstat](https://github.com/sysstat/sysstat/blob/master/README.md) - System performance tools for the Linux\u00ae operating system.\n* [typeperf](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/typeperf) - Windows\u00ae command that writes performance data to the command window or to a log file.\n* [esxtop](https://communities.vmware.com/t5/Storage-Performance/Interpreting-esxtop-Statistics/ta-p/2776936) - A command-line tool that gives administrators real-time information about resource usage in a VMware\u00ae vSphere environment. It can monitor and collect data for all system resources: CPU, memory, disk, and network.\n\n\n\n* What is the difference between a replica volume, a dependent and an independent duplicate volume?\n\nYou can create a replica or a duplicate volume by using a snapshot of your volume. Replication and cloning use one of your snapshots to copy data to a destination volume. However, that is where the similarities end.\n\nReplication keeps your data in sync in two different locations. Only one of the volume pair (primary volume and replica volume) can be active at a time. The replication process automatically copies information from the active volume to the inactive volume based on the replication schedule. For more information about replica volumes, see [Replicating data](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-replication).\n\nDuplication creates a copy of your volume based on a snapshot in the same availability zone as the parent volume. The duplicate volume inherits the capacity and performance options of the original volume by default and has a copy of the data up to the point-in-time of a snapshot. The duplicate volume can be dependent or independent from the original volume, and it can be manually refreshed with data from the parent volume. You can adjust the IOPS or increase the volume size of the duplicate without any effect on the parent volume.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_15092-4396-6100", "score": 0.6763516664505005, "text": "\nAll volumes are assigned instance bandwidth proportional to their maximum bandwidth, where the sum of all volume bandwidth equals the overall \"volumes\" bandwidth.\n\nIn our [example](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidthvolume-adjust-bandwidth), the remaining bandwidth that is allocated on the instance for data volumes is 1,607 Mbps (2000 Mbps less 393 Mbps for the boot volume). After the data volume is attached to the instance, the volume optimally requires 640 Mbps. If this volume is the only attached volume, it gets the full bandwidth allocation. If you had two more volumes of greater capacity, the bandwidth allocation is less.\n\nUnattached volume bandwidth might not be the same as the actual bandwidth that you see after the volume is attached to an instance. The difference is due to the amount of bandwidth that is dedicated to the boot volume and all other attached data volumes.\n\n\n\n\n\n\n\n Estimating volume bandwidth \n\nThink about the type of data volume that your workloads require and select the right volume profile. Data intensive workloads might require the higher bandwidth performance of a 10 IOPS/GB profile. For more information about the relationship of volume profiles to compute profiles, see [How virtual server profiles relate to storage profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles&interface=uivsi-profiles-relate-to-storage). For more information about how block size affects performance, see [Block storage capacity and performance](https://cloud.ibm.com/docs/vpc?topic=vpc-capacity-performance&interface=uihow-block-size-affects-performance).\n\n\n\n\n\n Next steps \n\nAllocate total volume bandwidth by using the API or CLI.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidth"}, {"document_id": "ibmcld_14984-11953-13820", "score": 0.6648621559143066, "text": "\nA side panel displays for creating a new data volume.\n\n\n\n1. Select Import from snapshot. Expand the list to select a data snapshot. The most recent data snapshot is selected by default. Optionally, select a different snapshot from the list. The snapshot contains the properties of the original source volume, including the IOPS tier and encryption.\n2. Optionally, change the size of the volume.\n3. Click Save. The new data volume is created from the snapshot. It is attached to the instance, and shown in the Data volume list.\n\n\n\n5. When you're finished provisioning your new instance, click Create virtual server instance. The new instance appears in the list of virtual server instances.\n\n\n\nAfter the instance is created, you can click the instance name to see the instance details. The boot volume that you restored from the backup snapshot is listed under Storage volumes. The camera icon indicates that the volume was created from a snapshot.\n\n\n\n\n\n Creating a data volume from a backup snapshot for an existing virtual server instance \n\nYou can create a data volume from a snapshot for an existing instance. Choose from the list of virtual server instances.\n\n\n\n1. In the [IBM Cloud console](https://cloud.ibm.com/login), go to the menu ![menu icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/icon_hamburger.svg) > VPC Infrastructure > Compute > Virtual server instances.\n2. From the list, click the name of an instance. The instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore"}, {"document_id": "ibmcld_14996-12044-13911", "score": 0.6648621559143066, "text": "\nA side panel displays for creating a new data volume.\n\n\n\n1. Select Import from snapshot. Expand the list to select a data snapshot. The most recent data snapshot is selected by default. Optionally, select a different snapshot from the list. The snapshot contains the properties of the original source volume, including the IOPS tier and encryption.\n2. Optionally, change the size of the volume.\n3. Click Save. The new data volume is created from the snapshot. It is attached to the instance, and shown in the Data volume list.\n\n\n\n5. When you're finished provisioning your new instance, click Create virtual server instance. The new instance appears in the list of virtual server instances.\n\n\n\nAfter the instance is created, you can click the instance name to see the instance details. The boot volume that you restored from the backup snapshot is listed under Storage volumes. The camera icon indicates that the volume was created from a snapshot.\n\n\n\n\n\n Creating a data volume from a backup snapshot for an existing virtual server instance \n\nYou can create a data volume from a snapshot for an existing instance. Choose from the list of virtual server instances.\n\n\n\n1. In the [IBM Cloud console](https://cloud.ibm.com/login), go to the menu ![menu icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/icon_hamburger.svg) > VPC Infrastructure > Compute > Virtual server instances.\n2. From the list, click the name of an instance. The instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=ui"}, {"document_id": "ibmcld_11349-7-2069", "score": 0.6489369869232178, "text": "\nMoving data from your on-premise environment to Power Systems Virtual Servers \n\nDepending on your network bandwidth and data size constraints, the process of moving the data volume group is as simple as creating an Open Virtualization Appliance (OVA) file or an mksysb image (root volume group), and creating a set of savevg images for volume group data. By using an OVA file or an mksysb image, you can build or provision a VM and then migrate the data volume groups of the virtual machine (VM) by using the restvg command.\n\nYou can use the following methods to back up your on-premise data and move the data to IBM Power Systems Virtual Server.\n\n\n\n Migrating volume group data by using the savevg command \n\nA volume group is a collection of physical volumes of various sizes and types. When a physical volume is assigned to a volume group, the physical blocks of storage media are organized into physical partitions. You can specify the size of the physical partition when you create the volume group. You can use built-in AIX savevg and restvg commands to back up and restore non-root volume groups. The savevg and restvg commands simplify the creation of new volume groups and file systems on the new VM.\n\nThe savevg command finds and backs up all files that belong to a specified volume group. The volume group must be varied-on, and the file systems must be mounted. The savevg command uses the data file that the mkvgdata command creates.\n\nUse the following command to find and back up all files in a specific volume group.\n\n savevg \u2013f <destination path> -i <non root vg files to be backed up>\n\nFor example:\n\n savevg \u2013f /home/admin01/datavg_bkup \u2013i datavg\n\n\n\n\n\n Backing up multiple volume groups by using the mkvgdata and restvg commands \n\nSmall systems might require only one data volume group to contain all the physical volumes. For a non-root user you might want to create separate volume groups, for security reasons, because each volume group can have its own security permissions. If a volume group stops working, other volume groups remain active.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-move-data-to-cloud"}, {"document_id": "ibmcld_14904-4375-6051", "score": 0.6486812829971313, "text": "\nFor more information, see [Modifying a Linux OS for expanding boot volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-modifying-the-linux-os-expanded-boot-volume).\n\n\n\n\n\n\n\n Requirements \n\n\n\n Data volume requirements \n\nYou must meet the following requirements to increase a data volume's capacity.\n\n\n\n* The volume is expanded based on their predefined IOPS profile or custom IOPS range.\n* The volume must be attached to a virtual server instance.\n* The volume must be in an available state.\n* The instance must be powered on and in a running state.\n* To realize maximum [volume bandwidth](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-bandwidth), you must detach and reattach the volume from the instance.\n\n\n\n\n\n\n\n Boot volume requirements \n\nYou must meet these requirements to resize a boot volume:\n\n\n\n* When an instance is provisioned, the size of the boot volume can be larger than the existing image size but not smaller. The maximum boot volume size is 250 GB.\n* For an existing instance, you can increase the size of the boot volume up to the maximum size that was allowed during instance provisioning.\n* Encrypted boot volumes have no special requirements.\n* Supported operating systems are x86 and Linux.\n\n\n\n\n\n\n\n\n\n Limitations \n\nLimitations for resizing boot and data volumes apply in this release.\n\n\n\n Data volume limitations \n\n\n\n* You cannot expand a volume that is at its maximum capacity for its [IOPS tier profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profilestiers-beta) or [Custom](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profilescustom) volume range.\n* Data volumes can expand to 16,000 GB, with the following limitations:", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-increasing-volume-capacity"}, {"document_id": "ibmcld_15926-4-1908", "score": 0.6480014324188232, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore"}, {"document_id": "ibmcld_15934-4-1908", "score": 0.6480014324188232, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a snapshot \n\nRestoring data from a snapshot creates a new, fully provisioned volume that you can use to start an instance or attach as auxiliary storage. You can restore boot and data volumes during instance creation or when you modify an existing instance. You can also restore a data volume from a snapshot of a volume that is not attached to an instance. Volumes can be restored from snapshots that were created manually or by a backup policy. You can restore volumes from fast restore clones and cross-regional copies of snapshots, too. You can create volumes from snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a snapshot \n\nRestoring a volume from a snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable.\n\n\n\n* Restoring from a bootable snapshot creates a boot volume that you can use to start a virtual server instance. The boot volume uses a general-purpose profile and is limited to 250 GB.\n* A new data volume that was created from nonbootable snapshot inherits its properties from the original volume, such as [profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata. If the source volume used [customer-managed encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the volume inherits that encryption with the original customer root key (CRK). However, you can specify a larger volume size, different IOPS profile, and different CRK if you prefer.\n\n\n\nYou can restore volumes from a manually created snapshot or from a snapshot that was created by a backup policy. This type of snapshot is called a backup. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=api"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16507-7-2044", "score": 0.7723751664161682, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-10816-12778", "score": 0.7710074186325073, "text": "\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows you how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button, and then select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n\nYou can also associate an entity type with the dictionary from the Machine Learning Model > Pre-annotation page. Click the overflow menu button in the Dictionaries row in the page, then click Map entity types.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16444-5943-7800", "score": 0.7664920687675476, "text": "\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button. Select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16444-7-2064", "score": 0.7505683898925781, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16563-3072-4738", "score": 0.7351095676422119, "text": "\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows you how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n4. Select Dictionary, then click Next.\n5. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16507-9193-11335", "score": 0.7343345880508423, "text": "\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-12419-14261", "score": 0.7252413630485535, "text": "\nAdd entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n\n\n* [Creating dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Getting Started > Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16444-4487-6387", "score": 0.7205122709274292, "text": "\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16464-3021-4769", "score": 0.7139303088188171, "text": "\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16507-5862-8152", "score": 0.7071245312690735, "text": "\nHuman annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case. Review the list of supported [Natural Language Understanding service entity types and subtypes](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-types) to determine if there is a natural overlap between them and the types in your type system. If so, continue with this procedure. If not, choose a different pre-annotator to use.\n\n\n\n\n\n About this task \n\nNatural Language Understanding is a service that offers text analysis through natural language processing. When you use the Natural Language Understanding pre-annotator, it calls the Natural Language Understanding service to find and annotate entities in your documents.\n\nYou must specify the entity types that you want the service to look for by mapping the Natural Language Understanding entity types to corresponding Knowledge Studio entity types that you have added to the Knowledge Studio type system. Only mentions of entity types that you map will be found and annotated.\n\n\n\n\n\n Procedure \n\nTo use the Natural Language Understanding service to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Natural Language Understanding row, and then click Map entity types.\n\n\n\n* The drop-down list of the Natural Language Understanding entity types is pre-populated with entity types that are recognized by the Natural Language Understanding service.\n* You must map at least one entity type.\n* You cannot map an Natural Language Understanding entity type to a Knowledge Studio entity role, only Knowledge Studio entity types.\n* You can map more than one Natural Language Understanding entity type to a single Knowledge Studio entity type, or the other way around.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03369-36856-39124", "score": 0.6485845446586609, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-72601-74697", "score": 0.6432717442512512, "text": "\nFor more information, see [Actions skill overview](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overview).\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests. For more information, see [Response types](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-response-types).\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nFor more information, see [Adding and referencing variables](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-variables).\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03126-5596-6966", "score": 0.6303806304931641, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_00564-2769-4709", "score": 0.6156108379364014, "text": "\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precise \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, data in the database can change between the times when the first and last batches are read.\n* Index definitions that are held in design documents are backed up, but the content of indexes isn't backed up. This limitation means that when data is restored, the indexes must be rebuilt. The rebuilding might take a considerable amount of time, depending on how much data is restored.\n\n\n\n\n\n\n\n Using the tools \n\nThe [NPM page](https://www.npmjs.com/package/@cloudant/couchbackup) details the basics of using the command-line tools for backup and restore of data. The following examples show how to put those details into practice by describing the use of the tools for specific tasks.\n\nThe CouchBackup package provides two ways of using its core functions.\n\n\n\n* The command-line tools can be embedded into standard UNIX\u2122 command pipelines. For many scenarios, a combination of cron and simple shell scripting of the couchbackup application is sufficient.\n* A library usable from Node.js. The library allows more complicated backup processes to be created and deployed, such as determining dynamically which databases must be backed up.\n\n\n\nUse either the command-line backup tool, or the library with application code, to enable backup from IBM Cloudant databases as part of more complicated situations. A useful scenario is scheduling backups by using cron, and automatically uploading data to [Cloud Object Storage](https://www.ibm.com/cloud/object-storage/solutions?mhq=object%20storage%20public&mhsrc=ibmsearch_a) for long-term retention.\n\n\n\n\n\n Command line scripting examples \n\nYou frequently need to meet the following two requirements:", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"}, {"document_id": "ibmcld_03369-154863-157273", "score": 0.6098792552947998, "text": "\n: The median conversation time metric, and corresponding filters, are being temporarily removed from the Overview page of the Improve section. This removal will prevent the calculation of certain metrics from causing the median conversation time metric, and the conversations over time graph, to display inaccurate information. IBM regrets removing functionality from the tool, but is committed to ensuring that we are communicating accurate information to users.\n\nDialog node names\n: You can now assign any name to a dialog node; it does not need to be unique. And you can subsequently change the node name without impacting how the node is referenced internally. The name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16343-7-1927", "score": 0.5973855257034302, "text": "\nNeuralSeek extension setup \n\n[NeuralSeek](https://neuralseek.com) by [Cerebral Blue](https://cerebralblue.com/) is a combined search and natural-language generation system that is designed to [make conversational AI feel more conversational](https://garrettrowe.medium.com/making-conversational-ai-feel-more-conversational-8748009b3fda). It requires that you load all your content into [IBM Watson\u00ae Discovery](https://cloud.ibm.com/catalog/services/watson-discovery). Then, when a user asks a question, it has Discovery search for multiple relevant documents and then it generates a natural-language answer that uses the contents of those documents. In some cases, the answer might be taken directly from a single document, and in others, the answer can include information from multiple sources that are combined into a single coherent statement. For each query, NeuralSeek returns a single answer and a confidence score. In most cases, it also returns a URL of a document that influenced the answer, which might be one of several documents.\n\nTo set up the extension for NeuralSeek search:\n\n\n\n Set up IBM Watson\u00ae Discovery \n\n\n\n1. You need an instance of [IBM Watson\u00ae Discovery](https://cloud.ibm.com/catalog/services/watson-discovery). Because NeuralSeek can modify your data as needed to make it more effective, make sure it is not an instance with important data that you are using for other purposes.\n2. In Discovery, create a project and load the documents that you want to use.\n\n\n\n\n\n\n\n Get the NeuralSeek OpenAPI specification and API Key \n\n\n\n1. You also need an instance of [NeuralSeek on IBM Cloud](https://cloud.ibm.com/catalog/services/neuralseek).\n2. In NeuralSeek, open the Configure page and enter your information in the Discovery instance details section.\n3. On the Integrate page, and click the OpenAPI file link to download the NeuralSeek.json OpenAPI specification file configured for your instance.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-extension-neuralseek"}, {"document_id": "ibmcld_07578-75544-77185", "score": 0.5952562093734741, "text": "\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https://github.com/watson-developer-cloud/community/blob/master/watson-assistant/export_logs_py.py).\n* Can I change my plan to a Lite plan?\n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n* How many Lite plan instances of Watson Assistant can I create?\n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n* How do I create a webhook?\n\nTo define a webhook and add its details, go to the Live environment page and open the Environment settings page. From the Environment settings page, click Webhooks > Pre-message webhook. You can add details about your webhook. For more information, see [Making a call before processing a message](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-webhook-pre).\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-75519-77160", "score": 0.5952562093734741, "text": "\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the conversation page. However, you can use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https://github.com/watson-developer-cloud/community/blob/master/watson-assistant/export_logs_py.py).\n* Can I change my plan to a Lite plan?\n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n* How many Lite plan instances of Watson Assistant can I create?\n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n* How do I create a webhook?\n\nTo define a webhook and add its details, go to the Live environment page and open the Environment settings page. From the Environment settings page, click Webhooks > Pre-message webhook. You can add details about your webhook. For more information, see [Making a call before processing a message](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-webhook-pre).\n* Can I have more than one entry in the URL field for a webhook?\n\nNo, you can define only one webhook URL for an action. For more information, see [Defining the webhook](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-webhook-prewebhook-pre-create).\n* Is there a range of IP addresses that are being used by a webhook?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16364-191104-193438", "score": 0.5891849994659424, "text": "\n* Each pattern (regular expression) is limited to 128 characters.\n* Importing or exporting via a CSV file does not currently support patterns.\n* The REST API does not support direct access to patterns, but you can retrieve or modify patterns using the /values endpoint.\n\n\n\nFuzzy matching filtered by dictionary (English only)\n: An improved version of fuzzy matching for entities is now available, for English. This improvement prevents the capturing of some common, valid English words as fuzzy matches for a given entity. For example, fuzzy matching will not match the entity value like to hike or bike, which are valid English words, but will continue to match examples such as lkie or oike.\n\n\n\n\n\n 27 September 2017 \n\nCondition builder updates\n: The control that is displayed to help you define a condition in a dialog node has been updated. Enhancements include support for listing available context variable names after you enter the $ to begin adding a context variable.\n\n\n\n\n\n 31 August 2017 \n\nImprove section rollback\n: The median conversation time metric, and corresponding filters, are being temporarily removed from the Overview page of the Improve section. This removal will prevent the calculation of certain metrics from causing the median conversation time metric, and the conversations over time graph, to display inaccurate information. IBM regrets removing functionality from the tool, but is committed to ensuring that we are communicating accurate information to users.\n\nDialog node names\n: You can now assign any name to a dialog node; it does not need to be unique. And you can subsequently change the node name without impacting how the node is referenced internally. The name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_13266-16288-18091", "score": 0.5816670060157776, "text": "\nAlthough the Ogg format uses lossy compression, the combination of the Ogg format with the Opus codec showed the least degradation in speech accuracy among lossy compression algorithms.\n\n\n\nUsing other formats with greater levels of compression can compromise the accuracy of transcription. Experiment with the service to determine which format is best for your audio and application. For more ways to improve speech recognition, see [Tips for improving speech recognition](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-tips).\n\n\n\n\n\n\n\n Audio conversion \n\nYou can use various tools to convert your audio to a different format. The tools can be helpful when your audio is in a format that is not supported by the service or is in an uncompressed or lossless format. In the latter case, you can convert the audio to a lossy format to reduce its size.\n\nThe following freeware tools are available to convert your audio from one format to another:\n\n\n\n* Sound eXchange (SoX) ([sox.sourceforge.net](http://sox.sourceforge.net)).\n* FFmpeg ([ffmpeg.org](https://www.ffmpeg.org)). You can also use FFmpeg to separate audio from a multimedia file that contains both audio and video data. For more information, see [Transcribing speech from video files](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-video).\n* Audacity\u00ae ([audacityteam.org](https://www.audacityteam.org/)).\n* For Ogg format with the Opus codec, [opus-tools](https://opus-codec.org/release/dev/2018/09/18/opus-tools-0_2.html).\n\n\n\nThese tools offer cross-platform support for multiple audio formats. Moreover, you can use many of the tools to play your audio. Do not use the tools to violate applicable copyright laws.\n\n\n\n Converting to audio/ogg with the Opus codec", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formats"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11603-5479-6869", "score": 0.6394495368003845, "text": "\nsudo systemctl is-active sap-metrics-collector\n\n\n\n\n\n\n\n Verifying data collection \n\nAfter the installation completes and the service is started, it can take time for the IMCS begins collecting metrics. Wait at least 2 minutes after the installation before you expect full and accurate metrics.\n\n\n\n1. Run the following curl command for your localhost address to see your metrics:\n\ncurl http://localhost:18181/sap/metrics\n\n<metrics>\n<metric category=\"config\" context=\"vm\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Data Provider Version</name>\n<value>1.3</value>\n</metric>\n<metric category=\"config\" context=\"host\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Cloud Provider</name>\n<value>IBM Cloud</value>\n</metric>\n<metric category=\"config\" context=\"vm\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Instance Type</name>\n<value>bx2-8x32</value>\n</metric>\n<metric category=\"config\" context=\"host\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Virtualization Solution</name>\n<value>KVM</value>\n</metric>\n.\n.\n.\n</metrics>\n\n\n\nYou might experience a delay before your data is available.\n\n\n\n\n\n Troubleshooting \n\nUse the following troubleshooting tips for IMCS.\n\n\n\n Uninstalling the Metrics Collector \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-ibm-metrics-collector-for-sap-linux"}, {"document_id": "ibmcld_09834-5099-6740", "score": 0.6325231790542603, "text": "\nurl: \"http://10.245.0.5:9182/metrics\"\ntags:\nregion: us-east\ninstance: my-windows-hostname\njob: my-job-name\n3. Configure the monitoring agent to reduce the number of metrics that are collected by the Windows windows_exporter.\n\nYou can configure the metrics_filter section to remove metrics. For example, you can remove collector metrics. You can also remove specific metrics that you do not wish to collect.\n\nFor example, to remove go metrics and the logical disk request metrics, you can set the section in the following way:\n\nmetrics_filter:\n- exclude: go_\n- exclude: windows_logical_disk_requests_queued\n\nThe go_* metrics are metrics generated by the Go programming language, and are collected by default. The windows_logical_disk_requests_queued is the number of requests outstanding on the disk at the time the performance data is collected.\n4. Restart the monitoring agent. Run the following command:\n\nservice dragent restart\n\n\n\n\n\n\n\n Option 2. Collect metrics by running Prometheus as a client collector on Windows \n\nUse the Prometheus remote-write capabilities to push the metrics from the Windows system by running Prometheus as a client collector on Windows.\n\nComplete the following steps:\n\n\n\n1. Download the Prometheus monitoring system and time series database. [Download prometheus-2.27.1.windows-amd64.tar.gz](https://prometheus.io/download/)\n2. Unzip the file prometheus-2.27.1.windows-amd64.tar.gz.\n3. Edit the prometheus.yml file. For example, you can edit it with Notepad.\n4. Configure the scrape_configs section of prometheus.yml configuration file as follows to have prometheus scrape the windows_exporter.\n\nscrape_configs:", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-windows"}, {"document_id": "ibmcld_11603-6477-8007", "score": 0.6254734992980957, "text": "\n<metric category=\"config\" context=\"host\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Virtualization Solution</name>\n<value>KVM</value>\n</metric>\n.\n.\n.\n</metrics>\n\n\n\nYou might experience a delay before your data is available.\n\n\n\n\n\n Troubleshooting \n\nUse the following troubleshooting tips for IMCS.\n\n\n\n Uninstalling the Metrics Collector \n\n\n\n1. Run the following command to uninstall IMCS if you have any issues during the installation process. Then, reinstall it.\n\n./uninstall-linux.sh\n\nRemoving IBM Metric Collector for SAP...\nSuccessfully removed IBM Metric Collector for SAP.\n\n\n\n\n\n\n\n No metrics reported when you run the curl command \n\nNo reported metrics message is often due to the port not assigned to SAP Metrics Collector. It needs port 18181 available for localhost. If you have any other applications that use the port, you must close the applications.\n\n\n\n1. Use the following command to see whether the port is assigned to another application.\n\nnmap -sT -O localhost\n\nStarting Nmap 6.40 (http://nmap.org) at (date and time)\nNmap scan report for localhost (your localhost address)\nHost is up (0.0s latency).\nOther addresses for localhost (not scanned): (localhost addresses)\nrDNS record for (localhost): sap-mc-redhat\nNot shown: (number of) closed ports\nPORT STATE SERVICE\n(port)/tcp open ssh\n(port)/tcp open smtp\nDevice type: general purpose\nRunning: Linux 3.X\nOS CPE: cpe:/o:linux:linux_kernel:3\nOS details: Linux 3.7 3.9\nNetwork Distance: 0 hops\n\n\n\n\n\n\n\n nmap not found", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-ibm-metrics-collector-for-sap-linux"}, {"document_id": "ibmcld_09801-2595-4012", "score": 0.617112398147583, "text": "\ncpu [CPU metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.cpu.md) \n cs [Computer system metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.cs.md) \n logical_disk [Disk metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.logical_disk.md) \n os [Operating System metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.os.md) \n system [System metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.system.md) \n net [Network interface metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.net.md) \n memory [Memory metrics](https://github.com/prometheus-community/windows_exporter/blob/master/docs/collector.memory.md) \n\n\n\nTo learn how to configure the Windows exporter, see [Monitoring a Windows environment](https://cloud.ibm.com/docs/monitoring?topic=monitoring-windows).\n\nThe legacy Prometheus WMI Exporter is still supported, see [Monitoring a Windows environment using the legacy WMI Exporter](https://cloud.ibm.com/docs/monitoring?topic=monitoring-windows_wmi) for information on the WMI Exporter.\n\n\n\n\n\n IPMI exporter \n\nIn addition to the set of metrics that are automatically collected by the monitoring agent, you might want to collect other metrics such as sensor metrics.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-prometheus-exporters"}, {"document_id": "ibmcld_05068-7966-9235", "score": 0.6125785708427429, "text": "\n[Dashboard configuration](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/SysDig-pre-built-reports.png)\n\nFigure 2. Choose a pre-built report\n\n\n\n\n\n View your data in Monitoring \n\nOnce you've configured your dashboard, you can view your data. Figures 3-5 show different views of your usage.\n\nZoom\n\n![View bucket metrics](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/SysDig-COS-metrics.jpg)\n\nFigure 3. View sample data showing space used and number of objects\n\nZoom\n\n![View metrics by location](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/SysDig-COS-metrics-2.jpg)\n\nFigure 4. View space used by location\n\nZoom\n\n![View metrics by storage class](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/SysDig-COS-metrics-3.jpg)\n\nFigure 5. View used space by storage class\n\n\n\n\n\n\n\n Cloud Object Storage metrics details \n\n\n\n Usage metrics \n\nThere are a set of basic metrics that track usage:\n\n\n\n* ibm_cos_bucket_used_bytes\n* ibm_cos_bucket_object_count\n* ibm_cos_bucket_hard_quota_bytes\n\n\n\n\n\n\n\n Request metrics", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-mm-cos-integration&programming_language=Console"}, {"document_id": "ibmcld_05736-11432-12540", "score": 0.6121139526367188, "text": "\nIf you rely on these changed metrics, update accordingly.<br><br><br><br> * From gitVersion to git_version<br> * From gitCommit to git_commit<br> * From gitTreeState to git_tree_state<br> * From buildDate to build_date<br> * From goVersion to go_version<br><br><br> \n\n\n\n\n\n\n\n Update after worker nodes \n\nThe following table shows the actions that you must take after you update your worker nodes.\n\n\n\nChanges to make after you update the worker nodes to Kubernetes 1.19\n\n Type Description \n\n Deprecated: Beta worker node labels The following beta worker node labels are deprecated and replaced. For now, both sets of labels are supported, but update your workloads to use the new labels, such as in affinity rules for deployments.<br><br><br><br> * From beta.kubernetes.io/os to kubernetes.io/os<br> * From beta.kubernetes.io/arch to kubernetes.io/arch<br> * From failure-domain.beta.kubernetes.io/zone to topology.kubernetes.io/zone<br> * From failure-domain.beta.kubernetes.io/region to topology.kubernetes.io/region<br> * From beta.kubernetes.io/instance-type to node.kubernetes.io/instance-type<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_119"}, {"document_id": "ibmcld_05882-14443-15702", "score": 0.607170820236206, "text": "\nIt can take up to 10 minutes for the metrics-server to detect the change and roll out a new set of pods based on the updated settings.\n\n\n\n\n\n Restore the default settings \n\nTo restore the metrics-server to the default settings, delete the config map. It is recreated within a few minutes.\n\nkubectl delete cm metrics-server-config -n kube-system\n\n\n\n\n\n\n\n Determining which resources to tune \n\nUse the kubectl describe pod command to get the pod definition, state information, and recent events:\n\nkubectl get pod -n kube-system -l k8s-app=metrics-server\nNAME READY STATUS RESTARTS AGE\nmetrics-server-9fb4947d6-s6sgl 3/3 Running 0 2d4h\n\nkubectl describe pod -n kube-system metrics-server-9fb4947d6-s6sgl\n\nExample output\n\nContainers:\nmetrics-server:\nContainer ID: containerd://fe3d07c9a2541242d36da8097de3896f740c1363f6d2bfd01b8d96a641192b1b\nImage: registry.ng.bluemix.net/armada-master/metrics-server:v0.4.4\nImage ID: registry.ng.bluemix.net/armada-master/metrics-server@sha256:c2c63900d0e080c2413b5f35c5a59b5ed3b809099355728cf47527aa3f35477c\nPort: 4443/TCP\nHost Port: 0/TCP\nCommand:\n/metrics-server\n--metric-resolution=45s\n--secure-port=4443\n--tls-cert-file=/etc/metrics-server-certs/tls.crt\n--tls-private-key-file=/etc/metrics-server-certs/tls.key\nState: Running", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kernel"}, {"document_id": "ibmcld_09635-4419-5996", "score": 0.6040542721748352, "text": "\nTable 3. Activity Tracker auditing event action\n\n Task Activity Tracker auditing event action \n\n Create a target metrics-router.target.create \n List all targets metrics-router.target.list \n Get details of a target metrics-router.target.read \n Modify a target metrics-router.target.update \n Delete a target metrics-router.target.delete \n\n\n\n\n\n\n\n CLI prerequisites \n\nBefore you use the CLI to manage targets, complete the following steps:\n\n\n\n1. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-iam)\n2. [Install the IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli).\n3. [Install the IBM Cloud Metrics Routing CLI](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli-config).\n\n\n\n\n\n\n\n CLI commands \n\nThe following table lists the actions that you can run to manage targets:\n\n\n\nTable 4. Target actions\n\n Action Command \n\n Create a target ibmcloud metrics-router target create \n Update a target ibmcloud metrics-router target update \n Delete a target ibmcloud metrics-router target rm \n Read a target ibmcloud metrics-router target get \n List all targets ibmcloud metrics-router target ls \n\n\n\nFor more information, see [IBM Cloud Metrics Routing v3 CLI](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli).\n\n\n\n\n\n API prerequisites \n\nBefore you use the API to manage targets, complete the following steps:\n\n\n\n1. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing.]", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-target"}, {"document_id": "ibmcld_09807-6204-7430", "score": 0.6020839214324951, "text": "\n!/usr/bin/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\n\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Parse arguments.\ndef usage():\nprint('usage: %s <ENDPOINT_URL> <MONITOR_TOKEN> <INSTANCE_GUID>' % sys.argv[0])\nprint('ENDPOINT_URL: IBM Cloud endpoint URL (e.g. https://us-south.monitoring.cloud.ibm.com')\nprint('MONITOR_TOKEN: token that is associated to a team.')\nsys.exit(1)\n\nif len(sys.argv) != 3:\nusage()\n\nURL = sys.argv[1]\nMONITOR_TOKEN = sys.argv[2]\n\n Instantiate the client\nsdclient = SdMonitorClient(token=MONITOR_TOKEN,sdc_url=URL)\nShow more\n\n\n\n\n\n References \n\n\n\n* [Extracting metrics from a Monitoring instance by using the Monitoring Python client](https://cloud.ibm.com/docs/monitoring?topic=monitoring-metrics_python)\n* [Managing dashboards by using the Monitoring Python client](https://cloud.ibm.com/docs/monitoring?topic=monitoring-dashboard_python)\n* [Managing alerts by using the Python client](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_python)\n* [Python Client](https://github.com/draios/python-sdc-client)\n* [Monitoring Python samples](https://github.com/draios/python-sdc-client/tree/master/examples)", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-python-client"}, {"document_id": "ibmcld_15712-1706-4015", "score": 0.5974923372268677, "text": "\n* Metric name - The name for the collected metric.\n* Metric type - Metric type determines whether the metric value is a counter metric or a gauge metric. Each of these metrics is of the type gauge, which represents a single numerical value that can arbitrarily fluctuate over time.\n* Value type - A unit of measurement for a specific metric. Examples include bytes or counts. A value type of none means that the metric value represents individual occurrences of that metric type.\n* Segment - How you want to divide and display the monitoring metrics.\n\n\n\nOnly the resources in the same zone as the selected subnet can connect through this VPN gateway.\n\n\n\n Active connections \n\nActive connections are the number of connections that are established on a load balancer at a specific time.\n\nThe active connection metric contains the following metadata:\n\n\n\nTable 1: Application load balancer active connections metrics metadata\n\n Metadata Description \n\n Metric name ibm_is_load_balancer_active_connections \n Metric type gauge \n Value type none \n Segment by Application load balancer appliance metrics and Application load balancer listener metrics \n\n\n\n\n\n\n\n Connection rate \n\nConnection rate is the number of new incoming active connections per second to your load balancer.\n\n\n\nTable 2: Application load balancer connection rate metric metadata\n\n Metadata Description \n\n Metric name ibm_is_load_balancer_connection_rate \n Metric type gauge \n Value type none \n Segment by Application load balancer appliance metrics and Application load balancer listener metrics \n\n\n\n\n\n\n\n Throughput \n\nThroughput is the amount of data that passes in and out of a load balancer over a period of time.\n\n\n\nTable 3: Application load balancer throughput metric metadata\n\n Metadata Description \n\n Metric name ibm_is_load_balancer_throughput \n Metric type gauge \n Value type byte \n Segment by Application load balancer appliance metrics and Application load balancer listener metrics \n\n\n\n\n\n\n\n Request Count \n\nThe request count is the total number of HTTP/HTTPS requests that are sent by the load balancer to the back-end servers per minute. This metric is only available for HTTP and HTTPS listeners.\n\n\n\nTable 4: Application load balancer request count metric metadata\n\n Metadata Description \n\n Metric name ibm_is_load_balancer_request_count", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-monitoring-metrics-alb"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04488-78402-79292", "score": 0.7362690567970276, "text": "\ndelete the root key\n$ ibmcloud kp key delete $KEY_ID\n\nDeleting key: 62ad0cd5-70a4-4c4d-9d87-5f4db620b120, from instance: a192d603-0b8d-452f-aac3-f9e1f95e7411...\nOK\nDeleted Key\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120\n\n list keys - verify the key was deleted\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n\n restore the deleted key\n$ ibmcloud kp key restore $KEY_ID -k $KEY_MATERIAL --output json\n\n{\n\"id\": \"62ad0cd5-70a4-4c4d-9d87-5f4db620b120\",\n\"name\": \"my-base64-root-key\",\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"extractable\": false,\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:62ad0cd5-70a4-4c4d-9d87-5f4db620b120\"\n}\n\n list keys - verify the key was restored\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120 my-base64-root-key\n\n\n\n\n\n Example 2", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-reference"}, {"document_id": "ibmcld_08988-80289-81179", "score": 0.7362690567970276, "text": "\ndelete the root key\n$ ibmcloud kp key delete $KEY_ID\n\nDeleting key: 62ad0cd5-70a4-4c4d-9d87-5f4db620b120, from instance: a192d603-0b8d-452f-aac3-f9e1f95e7411...\nOK\nDeleted Key\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120\n\n list keys - verify the key was deleted\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n\n restore the deleted key\n$ ibmcloud kp key restore $KEY_ID -k $KEY_MATERIAL --output json\n\n{\n\"id\": \"62ad0cd5-70a4-4c4d-9d87-5f4db620b120\",\n\"name\": \"my-base64-root-key\",\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"extractable\": false,\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:62ad0cd5-70a4-4c4d-9d87-5f4db620b120\"\n}\n\n list keys - verify the key was restored\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120 my-base64-root-key\n\n\n\n\n\n Example 2", "title": "", "source": "https://cloud.ibm.com/docs/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"}, {"document_id": "ibmcld_08987-77539-78429", "score": 0.7362690567970276, "text": "\ndelete the root key\n$ ibmcloud kp key delete $KEY_ID\n\nDeleting key: 62ad0cd5-70a4-4c4d-9d87-5f4db620b120, from instance: a192d603-0b8d-452f-aac3-f9e1f95e7411...\nOK\nDeleted Key\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120\n\n list keys - verify the key was deleted\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n\n restore the deleted key\n$ ibmcloud kp key restore $KEY_ID -k $KEY_MATERIAL --output json\n\n{\n\"id\": \"62ad0cd5-70a4-4c4d-9d87-5f4db620b120\",\n\"name\": \"my-base64-root-key\",\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"extractable\": false,\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:62ad0cd5-70a4-4c4d-9d87-5f4db620b120\"\n}\n\n list keys - verify the key was restored\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120 my-base64-root-key\n\n\n\n\n\n Example 2", "title": "", "source": "https://cloud.ibm.com/docs/key-protect-cli-plugin"}, {"document_id": "ibmcld_09120-79189-80079", "score": 0.7362690567970276, "text": "\ndelete the root key\n$ ibmcloud kp key delete $KEY_ID\n\nDeleting key: 62ad0cd5-70a4-4c4d-9d87-5f4db620b120, from instance: a192d603-0b8d-452f-aac3-f9e1f95e7411...\nOK\nDeleted Key\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120\n\n list keys - verify the key was deleted\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n\n restore the deleted key\n$ ibmcloud kp key restore $KEY_ID -k $KEY_MATERIAL --output json\n\n{\n\"id\": \"62ad0cd5-70a4-4c4d-9d87-5f4db620b120\",\n\"name\": \"my-base64-root-key\",\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"extractable\": false,\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:62ad0cd5-70a4-4c4d-9d87-5f4db620b120\"\n}\n\n list keys - verify the key was restored\n$ ibmcloud kp keys\n\nRetrieving keys...\nOK\nKey ID Key Name\n62ad0cd5-70a4-4c4d-9d87-5f4db620b120 my-base64-root-key\n\n\n\n\n\n Example 2", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference"}, {"document_id": "ibmcld_09070-6713-7479", "score": 0.7327446937561035, "text": "\nFor a detailed description of the request, see the Key Protect [REST API reference doc](https://cloud.ibm.com/apidocs/key-protect).\n\n\n\n\n\n What's next \n\nTo learn how to delete and purge a key using the UI, check out [Deleting keys using a single authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys). For information about how to do this using the API, click the API tab at the beginning of the topic.\n\nTo learn how to delete and purge a key that holds a dual-authorization deletion policy using the UI, check out [Deleting keys using dual authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys). For information about how to do this using the API, click the API tab at the beginning of the topic.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys"}, {"document_id": "ibmcld_02314-13559-15025", "score": 0.7320230007171631, "text": "\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n\n\n Deleting an API key \n\nIf you are using a key rotation strategy, you might want to delete an older key and replace it with a new key.\n\nTo delete an API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM) > API keys.\n2. Identify the row of the API key that you want to delete, and select Delete from the Actions![List of actions icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/action-menu-icon.svg) menu.\n3. Confirm the deletion by clicking Delete.\n\n\n\nTo delete an API key that is not your own, but you have access to manage, go to the API keys page. Then, select the All user IBM Cloud API keys option from the View menu to find the API key.\n\n\n\n\n\n Deleting an API key by using the CLI \n\nTo delete an API key by using the CLI:\n\nEnter ibmcloud iam api-key-delete NAME in your command prompt, specifying the name of the key to delete.\n\n\n\n\n\n Deleting an API key by using the API \n\nTo delete an API key by using the API, call the [IAM Identity Service API](https://cloud.ibm.com/apidocs/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https://iam.cloud.ibm.com/v1/apikeys/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui"}, {"document_id": "ibmcld_16045-15510-17033", "score": 0.731753408908844, "text": "\nDelete key [Deleting keys in the console (single authorization)](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-key-gui). [Deleting keys with the GUI (single authorization)](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui). \n [Deleting a key with dual authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-api). [Authorize deletion for a key with the GUI (dual authorization)](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-console). \n Restore key [Restoring a deleted key with the console](https://cloud.ibm.com/docs/key-protect?topic=key-protect-restore-keysrestore-ui). [Restoring a deleted key with the GUI](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-keysrestore-ui). \n\n\n\n\n\n\n\n Manage root keys with the API \n\nYou can use the API to disable, enable, delete, or restore your root keys. Table 6 describes each action and links to detailed steps for the Key Protect or Hyper Protect Crypto Services API. For more information about the relationship of user actions and key states, see [Root key states and user actions](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-root-key-states).\n\nBecause deleting a root key makes all resources that are protected by it unusable (status = unusable), program your applications to check the status of the resource (such as a volume, snapshot, or image) before it attempts to use it.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing"}, {"document_id": "ibmcld_13028-13559-15025", "score": 0.7260848879814148, "text": "\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n\n\n Deleting an API key \n\nIf you are using a key rotation strategy, you might want to delete an older key and replace it with a new key.\n\nTo delete an API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM) > API keys.\n2. Identify the row of the API key that you want to delete, and select Delete from the Actions![List of actions icon](https://cloud.ibm.com/docs-content/v1/content/814aeaf04800bb4f74ea1c057d4abb166a5f357a/icons/action-menu-icon.svg) menu.\n3. Confirm the deletion by clicking Delete.\n\n\n\nTo delete an API key that is not your own, but you have access to manage, go to the API keys page. Then, select the All user IBM Cloud API keys option from the View menu to find the API key.\n\n\n\n\n\n Deleting an API key by using the CLI \n\nTo delete an API key by using the CLI:\n\nEnter ibmcloud iam api-key-delete NAME in your command prompt, specifying the name of the key to delete.\n\n\n\n\n\n Deleting an API key by using the API \n\nTo delete an API key by using the API, call the [IAM Identity Service API](https://cloud.ibm.com/apidocs/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https://iam.cloud.ibm.com/v1/apikeys/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)", "title": "", "source": "https://cloud.ibm.com/docs/services/account?topic=account-userapikey"}, {"document_id": "ibmcld_09087-19156-20902", "score": 0.7077468633651733, "text": "\n6 - Key could not be deleted... \n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict client error response code indicates that an error in the client request can be resolved per the specified reason code returned.\n\n\n\n\n\n Context \n\nThe message returns a reason in the message that provides the specific context.\n\n\n\n\n\n Message \n\nReason code: AUTHORIZATIONS_NOT_MET\n\nThe key cannot be deleted because it failed the dual authorization request. Before you delete this key, make sure dual authorization procedures are followed. See the topic, [Deleting keys using dual authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys).\n\nReason code: PROTECTED_RESOURCE_ERR\n\nThe key cannot be deleted because the key has one or more associated resources. See the topic, [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\nReason code: PREV_KEY_DEL_ERR\n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy. Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key. See the topic, [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Example Response 1 \n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"AUTHORIZATIONS_NOT_MET\",\n\"message\": \"The key cannot be deleted because it failed the dual authorization request.\"", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-error-messages"}, {"document_id": "ibmcld_16059-15477-16778", "score": 0.7054486274719238, "text": "\nEnable key [Enabling a root key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-ui). [Enabling a root key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-disable-keysenable-ui). \n Delete key [Deleting keys in the console (single authorization)](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-key-gui). [Deleting keys with the GUI (single authorization)](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui). \n [Deleting a key with dual authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-api). [Authorize deletion for a key with the GUI (dual authorization)](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-console). \n Restore key [Restoring a deleted key with the console](https://cloud.ibm.com/docs/key-protect?topic=key-protect-restore-keysrestore-ui). [Restoring a deleted key with the GUI](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-keysrestore-ui). \n\n\n\n\n\n\n\n Manage root keys with the API \n\nYou can use the API to disable, enable, delete, or restore your root keys. Table 6 describes each action and links to detailed steps for the Key Protect or Hyper Protect Crypto Services API.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=ui"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09061-1334-3188", "score": 0.7946231365203857, "text": "\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-1255-3053", "score": 0.7599854469299316, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08776-2908-4519", "score": 0.7584434747695923, "text": "\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-keys"}, {"document_id": "ibmcld_08435-3634-5079", "score": 0.7560612559318542, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09088-10880-12721", "score": 0.75539231300354, "text": "\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_08435-4752-6201", "score": 0.7481175661087036, "text": "\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-6176-7874", "score": 0.7409813404083252, "text": "\n<br> <br>For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<keyID_or_alias>/actions/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_07578-1211120-1213024", "score": 0.7379982471466064, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1213753-1215657", "score": 0.7379982471466064, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_09061-4-1966", "score": 0.7358256578445435, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08435-4752-6201", "score": 0.6701239943504333, "text": "\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_04120-1663-2947", "score": 0.6679447889328003, "text": "\nSelect from the actions listed, and specify the timeout period. In this case, the timeout refers to the ban period that the action takes place. A 60 second timeout means the action is applied for 60 seconds.\n\n\n\nTable 1. Actions for rate limiting\n\n Action Description \n\n Block Issues a 429 error when the threshold is exceeded \n Challenge User must pass a Google reCaptcha Challenge before proceeding. If successful, we accept the request. Otherwise, the request gets blocked. \n JS Challenge User must pass a Javascript Challenge before proceeding. If successful, we accept the request. Otherwise, the request gets blocked. \n Simulate You can use this option to test your rule before applying any of the other options in your live environment. \n\n\n\nIn the Advanced response section, specify the response type when a rule's threshold is exceeded.\n\n\n\n\n\n Bypassing URLs \n\nBypass lets you create the equivalent of a allowlist or exception for a set of URLs. No actions trigger for those URLs, even if the Rate Limiting rule is matched.\n\n\n\n\n\n\n\n Protecting login \n\nProtect login creates a standard rule that protects login pages against brute-force attacks. Clients attempting to log in more than 5 times in 5 minutes are blocked for 15 minutes.\n\nEnter a name for the rule, and the login URL.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-rate-limiting"}, {"document_id": "ibmcld_08435-8253-9823", "score": 0.6596755385398865, "text": "\nDuring this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_10007-1574-3749", "score": 0.633884072303772, "text": "\nPassword expiration Specifies when a user password expires. \n Created on Specifies when the user was created. \n Authentication type Specifies the authentication type. \n\n\n\n\n\n\n\n User actions \n\nIn the users list view, there is an overflow menu that lists the actions that can be taken on the user.\n\n\n\nTable 1. The table lists user actions and their definitions.\n\n Value Description \n\n Assign owner Set the owner of the user account. \n Change password Change the password for the system user. \n Account expiration Set a date that the system user account will be valid until. \n Password expiration Set a number of days until the password for the user account expires. \n Rename Change the username of the user account. \n Admin privileges View and grant admin privileges. \n Object privileges View and grant object privileges. \n Remove Delete the user account from the system. \n\n\n\n\n\n\n\n Granting admin privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant admin privileges and select Admin privileges from the overflow menu.\nIn this view, you can see different admin privileges, which are already granted or that can be granted to the selected user.\nGranting these privileges allows the user to do the actions that the privileges correspond to. Granting privileges on global database and global schema unlocks all the privileges to the user equivalent to an admin.\n3. Click Edit.\n4. Update, grant, or revoke object privileges by putting ticks in corresponding boxes.\n5. Click Save.\n\n\n\n\n\n\n\n Granting object privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant object privileges and select Object privileges from the overflow menu.\n3. Select a database.\nYou can choose between the Global database and a specific database.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-users-groups"}, {"document_id": "ibmcld_14887-1960-4248", "score": 0.6286864280700684, "text": "\nThe regular live migration process is nondisruptive and use of dedicated hosts and virtual servers is not interrupted.\n\nWhen nondisruptive live migration occurs, the virtual server experiences a brief pause of around 10 seconds, and in some cases up to 30 seconds. You are not notified in advance of nondisruptive migration. The virtual server instance is not restarted as part of this process.\n\nIn cases where a disruptive migration is required, you are notified 30 days in advance of the scheduled migration. The virtual server instance is restarted as part of this process.\n\nIn limited cases, a virtual server restart might be required to complete the host or data center maintenance. This scenario can occur when specialized VMs are used or if the virtual server encounters a migration problem. In this case, a scheduled maintenance event occurs.\n\nFor more information about unscheduled migrations that result from an unexpected host failure, see [Host failure recovery policies](https://cloud.ibm.com/docs/vpc?topic=vpc-host-failure-recovery-policies&interface=cli).\n\n\n\n\n\n What to expect during a scheduled maintenance event \n\nIn scenarios where workloads cannot migrate automatically, a scheduled maintenance event occurs. When workloads can't migrate automatically, the account owner receives an email about the upcoming maintenance that requires their attention. The account owner has a maintenance period typically 30 days in length. Exceptional cases can necessitate different timelines as outlined in [Getting advanced notice for disruptive maintenance](https://cloud.ibm.com/docs/get-support?topic=get-support-viewing-notificationsdisruptive-maintenance).\n\nTo start the maintenance event, the account owner needs to power-off their virtual server and then power it back on. This power cycle can be initiated as soon as a maintenance notification is received. When the virtual server resumes, it starts on the updated infrastructure. By doing so, the customer can choose when to perform the maintenance anytime ahead of the scheduled window.\n\nIf the account owner takes no action before the maintenance window, the server restarts during the window that is specified in the notification email.\n\nWhen the virtual server is started, customer data and configurations are restored.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-cloud-maintenance"}, {"document_id": "ibmcld_10859-0-1629", "score": 0.6272832751274109, "text": "\n\n\n\n\n\n\n  Action terminates after one minute \n\n  What\u2019s happening \n\nYou are invoking an action that returns after one min with an http code 202 and the result is only showing the activation ID.\n\n  Why it\u2019s happening \n\nWhen invoking an action, there are two modes possible: blocking or non-blocking. The default for regular action invocations is non-blocking and for web actions, it is blocking. Blocking invocations use a request-response style and wait for the activation result to be available. The wait period is the lesser of 60 seconds or the action's timeout limit. At the end of the wait period (for example, after 60 sec), all invocations switch to non-blocking and instead of the result, these actions return the activation ID.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"27eca80056d54f93aca80056d5cf93b9\"\n}\n\nIf an invocation of a web action reaches the end of wait period, the response shows both the activation ID and the transaction ID as well as an indication that the request is returned, but the action continues to run.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"d13cfd3ce4b14f7cbcfd3ce4b11f7cce\",\n\"code\": \"42c15dc7f450df1e9a01104de158d489\",\n\"error\": \"Response not yet ready.\"\n}\n\n  How to fix it \n\nWith the activation ID, you can poll for the completion of the action and the result. For more information, see [CLI](https://cloud.ibm.com/docs/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_activation).\n\nFor more information about blocking actions, see [Testing blocking actions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-testtest-block).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-ts_action_terminated"}, {"document_id": "ibmcld_08435-1255-3053", "score": 0.62320876121521, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_05007-3201-4787", "score": 0.614235520362854, "text": "\nThis could be a specific date in the future, or a period of time after new objects are written.\n\n\n\n\n\n NoncurrentVersionExpiration \n\nThe number of days after which non-current versions of objects are automatically deleted.\n\n\n\n\n\n Prefix \n\nAn optional string that will be matched to the prefix of the object name in the bucket. A rule with a prefix will only apply to the objects that match. You can use multiple rules for different expiration actions for different prefixes within the same bucket. For example, within the same lifecycle configuration, one rule could delete all objects that begin with logs/ after 30 days, and a second rule could delete objects that begin with video/ after 365 days.\n\n\n\n\n\n Status \n\nA rule can either be enabled or disabled. A rule is active only when enabled.\n\n\n\n\n\n\n\n Sample lifecycle configurations \n\nThis configuration expires any new objects after 30 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-after-30-days</ID>\n<Filter />\n<Status>Enabled</Status>\n<Expiration>\n<Days>30</Days>\n</Expiration>\n</Rule>\n</LifecycleConfiguration>\n\nThis configuration deletes any objects with the prefix foo/ on June 1, 2020.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-on-a-date</ID>\n<Filter>\n<Prefix>foo/</Prefix>\n</Filter>\n<Status>Enabled</Status>\n<Expiration>\n<Date>2020-06-01T00:00:00.000Z</Date>\n</Expiration>\n</Rule>\n</LifecycleConfiguration>\n\nThis configuration expires any non-current versions of objects after 100 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>DeleteAfterBecomingNonCurrent</ID>\n<Filter/>\n<Status>Enabled</Status>\n<NoncurrentVersionExpiration>", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry"}, {"document_id": "ibmcld_05075-1845-4162", "score": 0.5960032939910889, "text": "\nThe object version can be be deleted after this date is passed (assuming there are no legal holds on the object version).\n\nThe retention period for new objects can be inherited from the default value set on the bucket, or it can be explicitly defined when writing the object by specifying a Retain Until Date.\n\nWhen you use bucket default settings, you don\u2019t specify a Retain Until Date. Instead, you specify a duration, in either days or years, for which every object version placed in the bucket should be protected. When you place an object in the bucket, a Retain Until Date is calculated for the object version by adding the specified duration to the time of the object write.\n\nIf your request to place an object version in a bucket contains an explicit retention mode and Retain Until Date, those settings override any bucket default settings for that object version.\n\nLike all other Object Lock settings, the Retain Until Date applies to individual object versions. Different versions of a single object can have different retention modes and periods.\n\nImagine an object that is 60 days into a 90-day retention period, and you overwrite that object with the same name and a two year retention period. The operation will succeed and a new version of the object with a two year retention period is created. Meanwhile, after 30 more days the original version is eligible for deletion.\n\n\n\n\n\n Extending a retention period \n\nTo extend the retention period of an object, simply send a request to set a new, longer, retention period. The old value will be overwritten with the new, assuming the requestor has the cloud-object-storage.object.put_object_lock_retention and cloud-object-storage.object.put_object_lock_retention_version actions.\n\n\n\n\n\n Legal Hold \n\nA legal hold is like a retention period in that it prevents an object version from being overwritten or deleted. However, legal holds are more flexible and don't have a defined temporal component. Instead they simply remain in effect until removed. Legal holds can be freely placed and removed by any user who has the cloud-object-storage.object.put_object_lock_legal_hold and cloud-object-storage.object.put_object_lock_legal_hold_version actions.\n\nLegal holds have the additional benefit of acting as method for applying indefinite retention on an object.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_10007-4766-6938", "score": 0.5925704836845398, "text": "\nIn the Include users section, specify which users to add to the group when it's created.\n7. Click Create.\n\n\n\n\n\n\n\n Information about groups \n\n\n\nTable 1. The table lists group-related values and their definitions.\n\n Value Description \n\n Name Specifies the name of the group. \n Owner Specifies the database user who owns the group. \n Default priority Specifies the workload management control that specifies the default priority for queries that are run by the users in this group. \n Max priority Specifies the workload management control that specifies the maximum priority that a user in the group can assign to sessions or queries. \n Password expiration Specifies when a group password expires. \n Created on Specifies when the group was created. \n\n\n\n\n\n\n\n Groups actions \n\nIn the Groups list view, there is an overflow menu that lists the actions that can be taken on each group.\n\n\n\nTable 1. The table lists group-related actions and their definitions.\n\n Value Description \n\n Password expiration Set the time in days after which the password expires for the members of a group. \n Assign owner Set the owner of the group. \n Manage users Add or remove users from the group. \n Rename Change the group name. \n Admin privileges View and grant admin privileges. \n Object privileges View and grant object privileges. \n Remove Delete the group from the system. \n\n\n\n\n\n\n\n Granting admin privileges to groups \n\nGroup privileges dictate what actions can be taken by users who are a part of the group.\n\n\n\n1. Go to Users and groups > Groups.\n2. Select the group for which you want to grant admin privileges and select Admin privileges from the overflow menu.\nIn this view, you can see different admin privileges, which are already granted or that can be granted to the selected group.\nGranting these privileges allows the users that belong to the group to do the actions that the privileges correspond to. Granting privileges on global database and global schema unlocks all the privileges to the user equivalent to an admin.\n3. Click Edit.\n4. Update, grant, or revoke object privileges by putting ticks in corresponding boxes.\n5. Click Save.\n\n\n\n\n\n\n\n Granting object privileges to groups", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-users-groups"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08211-2628-3483", "score": 0.8382079005241394, "text": "\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}, {"document_id": "ibmcld_08217-3469-5347", "score": 0.681983470916748, "text": "\nHow to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail. Instead a message is displayed, which informs you that the maximum number of servers is reached in the selected data center for this account, or that you've reached the maximum number of free plans for this account. When you look in the resource list, you see that you haven't reached the limit.\n\n Why it\u2019s happening \n\nThe resource list is not a complete list of your servers. If you \u201cdelete\u201d a server from the resource list, it's made inaccessible and marked for deletion, but it's still available for you within the [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) for a limited amount of time, as described in [Deleting a virtual server](https://cloud.ibm.com/docs/services/hp-virtual-servers?topic=hp-virtual-servers-remove_vs).\n\n How to fix it \n\nDepending on your requirements, you must either delete the resource from the resource reclamations, or select a different data center (maximum number of servers is reached), or select the appropriate paid plan that meets your requirements if you reach the maximum number of free plans. For more information, see [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n VoiceOver on MacOS does not announce all information on the dashboard in Firefox \n\nVoiceOver on MacOS does not announce information presented on the dashboard in Firefox.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"}, {"document_id": "ibmcld_08211-1158-3123", "score": 0.678874135017395, "text": "\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https://cloud.ibm.com/docs/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}, {"document_id": "ibmcld_14622-2909-3395", "score": 0.676628053188324, "text": "\nLog in to the Active Directory appliance and open the DNS tools.\n2. Go to the instance subdomain, which is the subdomain under the root domain. Its name resembles the name of the vCenter Server instance.\n3. Remove the hostname entries for the specific deleted service appliances.\n4. Open the associated reverse lookup table and remove the DNS entries from the table.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [FAQ](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_deletingservices"}, {"document_id": "ibmcld_14622-1706-3297", "score": 0.6674776673316956, "text": "\nAfter you delete the service, unused DNS entries remain in Active Directory\u2122. These entries do not cause any problems. However, in the future, they might create conflicts with reverse lookups. It is recommended that you remove the entries as soon as possible.\n\nThe following table shows the services that are affected. The table also shows the pattern for hostnames for various service offerings. The actual hostname might differ from the pattern in various ways. Use the pattern to locate all of the registered DNS hostnames associated with a service. Many services have more than one registered hostname.\n\n\n\nTable 1. Hostname patterns and examples for affected services\n\n Service Hostname Pattern Example \n\n Caveonix RiskForesight riskforesight riskforesight <br>inst01-riskforesight \n F5 BIG-IP nickname-bigip1 <br>nickname-bigip2 edgefw-bigip1 \n FortigateVM nickname-fortigate edgefw-fortigate01 \n Entrust CloudControl htccnn-id htcc02-GY67239 \n Entrust DataControl htdcnn-id htcc02-GY67239 \n Entrust KeyControl htkcnn-id htcc02-GY67239 \n VMware Aria Operations vrli <br>vrops <br>vrlog vrli-master <br>vrops-data1 <br>vrlog-master \n\n\n\nTo remove the DNS entires, complete the following steps:\n\n\n\n1. Log in to the Active Directory appliance and open the DNS tools.\n2. Go to the instance subdomain, which is the subdomain under the root domain. Its name resembles the name of the vCenter Server instance.\n3. Remove the hostname entries for the specific deleted service appliances.\n4. Open the associated reverse lookup table and remove the DNS entries from the table.\n\n\n\n\n\n\n\n Related links", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_deletingservices"}, {"document_id": "ibmcld_14622-7-2169", "score": 0.6396454572677612, "text": "\nDeleting services from vCenter Server instances \n\nYou can delete the services that were provisioned for your VMware vCenter Server\u00ae instances when you no longer need these services.\n\n\n\n Before you delete services from vCenter Server instances \n\n\n\n* Deleting services from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n* You are billed until the end of the IBM Cloud\u00ae infrastructure billing cycle for the deleted services.\n\n\n\n\n\n\n\n Procedure to delete services from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance for which you want to delete services.\n3. Click the Services tab.\n4. On the Services page, locate the service instance that you want to delete, click the vertical overflow menu next to the Status column, and then click Delete service.\n5. In the Remove service window, review the considerations or warnings if there are any and select I Understand. Click Delete.\n\n\n\n\n\n\n\n Results after you delete services from vCenter Server instances \n\nAfter your request to delete a service is accepted, the service status is changed to Removing.\n\nWhen the service deletion is completed successfully, you are notified by email, and the service is deleted from the Services page of the instance.\n\nYou are billed until the end of the IBM Cloud infrastructure billing cycle for the deleted services.\n\n\n\n\n\n Manually removing the DNS entries for specific services \n\nFor specific services, if you installed the service in a VMware Solutions release earlier than V4.0 and you delete that service, you must manually remove the DNS entries.\n\nAfter you delete the service, unused DNS entries remain in Active Directory\u2122. These entries do not cause any problems. However, in the future, they might create conflicts with reverse lookups. It is recommended that you remove the entries as soon as possible.\n\nThe following table shows the services that are affected. The table also shows the pattern for hostnames for various service offerings. The actual hostname might differ from the pattern in various ways.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_deletingservices"}, {"document_id": "ibmcld_14360-7-2153", "score": 0.6339230537414551, "text": "\nDeleting services from Cyber Recovery instances \n\nYou can delete the services that were provisioned for your Cyber Recovery instances when you no longer need these services.\n\n\n\n Before you delete services from Cyber Recovery instances \n\nYou are billed until the end of the IBM Cloud\u00ae infrastructure billing cycle for the deleted services.\n\n\n\n\n\n Procedure to delete services from Cyber Recovery instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > Cyber Recovery from the left navigation pane.\n2. In the Cyber Recovery table, click the instance for which you want to delete services.\n3. Click the Services tab.\n4. Locate the service instance that you want to delete, click the vertical overflow menu next to the Status column, and then click Delete service.\n5. In the Remove service window, review the considerations or warnings if there are any and select I Understand. Click Delete.\n\n\n\n\n\n\n\n Results after you delete services from Cyber Recovery instances \n\nAfter your request to delete a service is accepted, the service status is changed to Removing.\n\nWhen the service deletion is completed successfully, you are notified by email, and the service is deleted from the Services page of the instance.\n\nYou are billed until the end of the IBM Cloud infrastructure billing cycle for the deleted services.\n\n\n\n\n\n Manually removing the DNS entries for specific services \n\nAfter you delete the service, unused DNS entries remain in Active Directory\u2122. These entries do not cause any problems. However, in the future, they might create conflicts with reverse lookups. It is recommended that you remove the entries as soon as possible.\n\nThe following table shows the services that are affected and the pattern for hostnames for these services. The hostname might differ from the exact pattern displayed. Use the pattern to locate all the registered DNS hostnames associated with a service. Services might have more than one registered hostname.\n\n\n\nTable 1. Hostname patterns and examples for affected services\n\n Service Hostname Pattern Example \n\n Caveonix RiskForesight\u2122 riskforesight riskforesight <br>inst01-riskforesight", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-cr_deletingservices"}, {"document_id": "ibmcld_06614-4388-6143", "score": 0.6273871660232544, "text": "\n{region}.databases.cloud.ibm.com/v5/ibm/deployments/{id}/allowlists/ip_addresses -H 'Authorization: Bearer <>' -H 'Content-Type: application/json' -d '{\"ip_address\": {\"address\": \"http://172.16.254.1/16\", \"description\": \"Dev IP space 3\"}}'\n\nFor more information, see [Cloud Databases API Security](https://cloud.ibm.com/apidocs/cloud-databases-api/cloud-databases-api-v5getallowlist).\n\n\n\n\n\n Removing an allowlist in the UI \n\nIn the UI, remove an IP address or netmask from the allowlist by clicking Remove.\n\n\n\n\n\n Removing an allowlist in the CLI \n\nThe cdb deployment-whitelist-delete command removes an IP address or range from the current allowlist for a deployment.\n\nThe command looks like:\n\nibmcloud cdb deployment-allowlist-delete <deployment name or CRN> <allowlist address or range> [--nowait] [--json]\n\nWhen all entries on the allowlist are removed, the allowlist is disabled and all IP addresses are accepted by your deployment.\n\n\n\n\n\n Removing an allowlist in the API \n\nDelete an IP address or range with the Cloud Databases API [Authorization endpoint](https://cloud.ibm.com/apidocs/cloud-databases-api/cloud-databases-api-v5deleteallowlistentry).\n\nThe command looks like:\n\ncurl -X DELETE https://api.{region}.databases.cloud.ibm.com/v5/ibm/deployments/{id}/allowlists/ip_addresses/{ipaddress} -H 'Authorization: Bearer <>'\n\nWhen all entries in the allowlist are removed, the allowlist is disabled and all IP addresses are accepted by your deployment.\n\n\n\n\n\n\n\n Allowlist Cloud Databases in your Environment \n\nIf you use allowlists to control connections in your environment, use the following IP lists to allowlist Cloud Databases deployments. We recommend you allowlist all of the subnet ranges for the entire region that your deployments live in.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-allowlisting"}, {"document_id": "ibmcld_13234-25629-27131", "score": 0.622262716293335, "text": "\nBy now, you should have seen that most of the time you are accessing the servers in region 1 as it's assigned higher weight compared to the servers in region 2. Let's introduce a health check failure in the region 1 origin pool,\n\n\n\n1. Navigate to the list of virtual server instances.\n2. Click three dots(...) next to the server(s) running in zone 1 of region 1 and click Stop.\n3. Repeat the same for server(s) running in zone 2 of region 1.\n4. Return to GLB under CIS service and wait until the health status changes to Critical.\n5. Now, when you refresh your domain url, you should always be hitting the servers in region 2.\n\nDon't forget to start the servers in zone 1 and zone 2 of region 1.\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n* Remove the global load balancer, origin pools and health checks under the CIS service\n* Remove the certificates in the Secrets Manager service.\n* Remove the load balancers, VSIs, subnets and VPCs.\n* Under [Resource list](https://cloud.ibm.com/resources), delete the services used in this tutorial.\n\n\n\n\n\n\n\n Related content \n\n\n\n* [Getting started with Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started)\n* [Using Load Balancers in IBM Cloud VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-nlb-vs-elb)\n* [Getting started with IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Getting started with Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-multi-region"}, {"document_id": "ibmcld_06231-52175-53906", "score": 0.6200841069221497, "text": "\nLog in to the [IBM Cloud console](https://cloud.ibm.com/). From the menu bar, select Manage > Access (IAM).\n2. Click the Users page, and then click the name of the user that you want to remove permissions from.\n3. Click the Cloud Foundry access tab.\n\n\n\n* To remove the user's space role\n\n\n\n1. Expand the table entry for the organization that the space is in.\n2. In the table entry for the space role, click the actions menu and select Edit space role.\n3. Delete a role by clicking the close button.\n4. To remove all space roles, select No space role in the drop-down list.\n5. Click Save role.\n\n\n\n* To remove the user's organization role\n\n\n\n1. In the table entry for the organization role, click the actions menu and select Edit organization role.\n2. Delete a role by clicking the close button.\n3. To remove all organization roles, select No organization role in the drop-down list.\n4. Click Save role.\n\n\n\n\n\n\n\n\n\n\n\n Remove classic infrastructure permissions \n\nYou can remove IBM Cloud infrastructure permissions for a user by using the IBM Cloud console.\n\nClassic infrastructure permissions apply only to classic clusters. For VPC clusters, see [Granting user permissions for VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-user-permissions-for-vpc-resources).\n\n\n\n1. Log in to the [IBM Cloud console](https://cloud.ibm.com/). From the menu bar, select Manage > Access (IAM).\n2. Click the Users page, and then click the name of the user that you want to remove permissions from.\n3. Click the Classic infrastructure tab, then click the Permissions, Devices, or VPN subnets tabs.\n4. In each tab, deselect specific permissions.\n5. To save your changes, click Set and Save. Permissions are downgraded after a few minutes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-users"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09087-19156-20902", "score": 0.73573237657547, "text": "\n6 - Key could not be deleted... \n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict client error response code indicates that an error in the client request can be resolved per the specified reason code returned.\n\n\n\n\n\n Context \n\nThe message returns a reason in the message that provides the specific context.\n\n\n\n\n\n Message \n\nReason code: AUTHORIZATIONS_NOT_MET\n\nThe key cannot be deleted because it failed the dual authorization request. Before you delete this key, make sure dual authorization procedures are followed. See the topic, [Deleting keys using dual authorization](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys).\n\nReason code: PROTECTED_RESOURCE_ERR\n\nThe key cannot be deleted because the key has one or more associated resources. See the topic, [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\nReason code: PREV_KEY_DEL_ERR\n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy. Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key. See the topic, [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Example Response 1 \n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"AUTHORIZATIONS_NOT_MET\",\n\"message\": \"The key cannot be deleted because it failed the dual authorization request.\"", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-error-messages"}, {"document_id": "ibmcld_08695-7-1852", "score": 0.7115128040313721, "text": "\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"}, {"document_id": "ibmcld_09087-21484-22833", "score": 0.6913825273513794, "text": "\n\"collectionType\": \"application/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https://cloud.ibm.com/apidocs/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-error-messages"}, {"document_id": "ibmcld_16045-10806-12293", "score": 0.689167857170105, "text": "\nIf you can't delete the key, see [troubleshooting key management service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.\n\n\n\n* All instances with an unusable boot volume do not restart.\n* You can't attach unusable data volumes to an instance.\n* You can't restore a volume from a snapshot.\n* You can't access a file share.\n* You can't provision instances from unusable images.\n* Billing continues for unusable resources until you delete them.\n\n\n\nBefore you force delete a root key, it's best to review all resources that are associated with that root key. Consider [temporarily disabling the key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-disable-root-keys) instead of deleting it to suspend the use of that root key. Root keys can be restored within 30 days, but only if they are imported root keys, not KMS generated.\n\nFor more information about deleting root keys, see the following topics.\n\n\n\n* [Key Protect - Deleting keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys)\n* [Hyper Protect Crypto Services - Deleting keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys)", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing"}, {"document_id": "ibmcld_09070-7-2084", "score": 0.6846120357513428, "text": "\nAbout deleting and purging keys \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material if you are a manager for your Key Protect instance.\n\nBefore you can delete an instance, you must delete every key in that instance. However, if you close your account, any existing instances and keys are automatically hard deleted. Check out [Account cancelation and data deletion](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-complianceaccount-cancelation) for more information.\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\nThe following table lists the time frames in which you can view, restore, and purge a key after it has been deleted.\n\n\n\nTable 1. Lists how users can interact with keys during certain time intervals after a key has been deleted", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys"}, {"document_id": "ibmcld_09064-4-1760", "score": 0.6810529232025146, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys using a single authorization \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material, if you are a manager for your Key Protect instance.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys in the console \n\nBy default, Key Protect requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Delete key and confirm the key deletion in the next screen by ensuring the key has no associated resources. Note that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_08442-4-1646", "score": 0.6791234016418457, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using a single authorization \n\nIf you are a manager for your IBM Cloud\u00ae Hyper Protect Crypto Services instance, you can use Hyper Protect Crypto Services to delete root keys or standard keys and the contents.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys with the console \n\nBy default, Hyper Protect Crypto Services requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4. On the KMS keys page, use the Keys table to browse the keys in your service.\n5. Select the key that you want to delete and click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) to open a list of options for the key.\n6. From the options menu, click Delete key, enter the key name to confirm the key to be deleted, and click Delete key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys"}, {"document_id": "ibmcld_09061-4-1966", "score": 0.6668020486831665, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_16059-10732-12449", "score": 0.6663830280303955, "text": "\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.\n\n\n\n* All instances with an unusable boot volume do not restart.\n* You can't attach unusable data volumes to an instance.\n* You can't restore a volume from a snapshot.\n* You can't access a file share.\n* You can't provision instances from unusable images.\n* Billing continues for unusable resources until you delete them.\n\n\n\nBefore you force delete a root key, it's best to review all resources that are associated with that root key. Consider [temporarily disabling the key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-disable-root-keys) instead of deleting it to suspend the use of that root key. Root keys can be restored within 30 days, but only if they are imported root keys, not KMS generated.\n\nFor more information about deleting root keys, see the following topics.\n\n\n\n* [Key Protect - Deleting keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys)\n* [Hyper Protect Crypto Services - Deleting keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys)", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=ui"}, {"document_id": "ibmcld_08442-1359-2864", "score": 0.663672924041748, "text": "\n[Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) to open a list of options for the key.\n6. From the options menu, click Delete key, enter the key name to confirm the key to be deleted, and click Delete key.\n\n\n\nAfter you delete a key, the key moves to the Destroyed state. You can [restore the deleted key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-keys) within 30 days after its deletion. Metadata that is associated with the key, such as the key's deletion date, is kept in the Hyper Protect Crypto Services database.\n\n\n\n\n\n Deleting keys with the API \n\nBy default, Hyper Protect Crypto Services requires one authorization to delete a key. You can delete a key and the contents by making a DELETE call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>\n\nThis action can't succeed if the key is actively protecting one or more cloud resources. You can [review the resources](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key, or [use the force parameter](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) at query time to delete the key.\n\n\n\n1. [Retrieve your service and authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n2. Retrieve the ID of the key that you would like to delete.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09088-9397-11338", "score": 0.7624067068099976, "text": "\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_09064-9212-10938", "score": 0.7622072696685791, "text": "\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each registered IBM Cloud resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET /v2/keys/ request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to force delete the key and its contents.\n\n$ curl -X DELETE \"https://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>?force=true\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete keys with the Key Protect API.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_16727-1212381-1214315", "score": 0.7609519958496094, "text": "\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1209748-1211682", "score": 0.7609519362449646, "text": "\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_09064-8216-9792", "score": 0.7475824356079102, "text": "\n\"algorithmMode\": \"Deprecated\",\n\"lastUpdateDate\": \"2020-03-16T20:41:27Z\",\n\"dualAuthDelete\": {\n\"enabled\": false\n},\n\"deleted\": true,\n\"deletionDate\": \"2020-03-16T21:46:53Z\",\n\"deletedBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the available parameters, see the Key Protect [REST API reference doc](https://cloud.ibm.com/apidocs/key-protect).\n\n\n\n Using the force query parameter \n\nKey Protect blocks the deletion of a key that's protecting a cloud resource, such as a Cloud Object Storage bucket. You can force delete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>?force=true\n\nWhen you delete a key that has registrations associated with it, you immediately deactivate its key material and the data encrypted by the key. Any data that is encrypted by the key becomes inaccessible. Thirty days after a key is deleted, the key can no longer be restored and the key material will be destroyed after 90 days.\n\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) for the key.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_07578-1211120-1213024", "score": 0.7365862131118774, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1213753-1215657", "score": 0.7365862131118774, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16059-9270-11112", "score": 0.7358031272888184, "text": "\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=ui"}, {"document_id": "ibmcld_09088-10880-12721", "score": 0.7343574166297913, "text": "\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_01019-1608-2449", "score": 0.7278319597244263, "text": "\nIf you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables. The physical pages that contain the data are not immediately erased and might still exist on the disk, but will be overwritten as needed. There is no ability to recover this data. The database provides the REORG and REDUCE MAX capability to reclaim this space for other activities or it will be reused when the database needs to store more data.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-del_db"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06341-2428-3641", "score": 0.5719492435455322, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}, {"document_id": "ibmcld_06499-2416-3629", "score": 0.5719492435455322, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"}, {"document_id": "ibmcld_06443-2410-3623", "score": 0.5719492435455322, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-deprovisioning"}, {"document_id": "ibmcld_06627-2422-3635", "score": 0.5719492435455322, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"}, {"document_id": "ibmcld_06696-2412-3625", "score": 0.5719492435455322, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-deprovisioning"}, {"document_id": "ibmcld_01034-3831-4923", "score": 0.571628212928772, "text": "\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-hpcs"}, {"document_id": "ibmcld_01041-3464-4855", "score": 0.562753438949585, "text": "\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events).", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-key-management-services"}, {"document_id": "ibmcld_09559-3849-5260", "score": 0.5589872598648071, "text": "\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"}, {"document_id": "ibmcld_01034-2639-4203", "score": 0.5575560331344604, "text": "\n\"target\": \"blue-us-south\",\n\"resource_group\": \"5g9f447903254bb58972a2f3f5a4c711\",\n\"resource_plan_id\": \"databases-for-x-standard\",\n\"disk_encryption_key_crn\": \"crn:v1:<...>:key:<id>\"\n}'\n\nIf you provision a deployment through the CLI or API, the HPCS key needs to be identified by its full CRN, not just its ID. An HPCS CRN is in the format crn:v1:<...>:key:<id>.\n\n\n\n\n\n Key Rotation \n\nHPCS offers manual and automatic [key rotation](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-rotation-policy) and key rotation is supported by Cloud Databases deployments. When you rotate a key, the process initiates a Syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks panel on your deployment's Overview and the associated HPCS and Cloud Databases events are sent to Activity Tracker.\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 7 days). If you need to delete the key in the soft-deletion period, you must [force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-hpcs"}, {"document_id": "ibmcld_09551-2545-3629", "score": 0.5510722994804382, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": []}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03039-0-644", "score": 0.7013334035873413, "text": "\n\n\n\n\n\n\n  Disaster recovery \n\nRecovering from potential disasters requires planning and preparation.\n\nYou are responsible for understanding your configuration, customization, and usage of Watson Assistant. You are also responsible for being ready to re-create an instance of the service and to restore your data.\n\n\n\n  Disaster recovery \n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud\u00ae. See [Backing up and restoring data](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-backup) for information about how to back up your service instances.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-recovery"}, {"document_id": "ibmcld_11164-6586-7646", "score": 0.6749542951583862, "text": "\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime"}, {"document_id": "ibmcld_01328-7-2398", "score": 0.6659553050994873, "text": "\nBusiness continuity and disaster recovery for Container Registry \n\nFind out about the business continuity and disaster recovery strategy for IBM Cloud\u00ae Container Registry.\n\nDisaster recoveryinvolves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n Your responsibilities when you're using Container Registry \n\nFor more information about your responsibilities when you're using IBM Cloud Container Registry, see [Shared responsibilities for IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_responsibilities).\n\n\n\n\n\n Disaster recovery strategy \n\nIBM Cloud has\n\nbusiness continuityplans in place to provide for the recovery of services within hours if a disaster occurs. You're responsible for your data backup and associated recovery of your content.\n\nContainer Registry provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted\n\nrecovery point objective(RPO) andrecovery time objective(RTO) for the service. The following table outlines the targets for Container Registry.\n\n\n\nTable 1. RPO and RTO for Container Registry\n\n Disaster recovery objective Target Value \n\n Recovery point objective (RPO) 48 hours \n Recovery time objective (RTO) 24 hours \n\n\n\n\n\n\n\n Locations for service availability \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\n\n\n Frequently asked questions about disaster recovery \n\nReview the following FAQs about disaster recovery.\n\n\n\n Does the service replicate the data? \n\nAll customer data in IBM Cloud Container Registry is replicated and backed up. Backups include service and policy settings and image data, but not vulnerability results, which can be reconstructed. All data, including vulnerability results, is replicated within each region so that the loss of a single availability zone is tolerated transparently. Regular point-in-time backups are used by IBM to restore the content if the data is corrupted.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-bc-dr"}, {"document_id": "ibmcld_08669-6042-7847", "score": 0.6655300855636597, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}, {"document_id": "ibmcld_12706-0-1826", "score": 0.6614342331886292, "text": "\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for Security and Compliance Center \n\nDisaster recoveryinvolves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\nIn case of failure, a failover design is established to keep your resources running without needing you to act. See [How IBM Cloud ensures high availability and disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimezero-downtime) to learn more about the high availability and disaster recovery standards in IBM Cloud.\n\n\n\n  Responsibilities \n\nTo find out more about responsibility ownership for using IBM Cloud products between IBM and customer, see [Shared responsibilities for IBM Cloud products](https://cloud.ibm.com/docs/overview?topic=overview-shared-responsibilities).\n\n\n\n\n\n  Disaster recovery strategy \n\nIBM Cloud has\n\nbusiness continuityplans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data backup and associated recovery of your content.\n\nSecurity and Compliance Center provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted\n\nrecovery point objective(RPO) andrecovery time objective(RTO) for the service. The following table outlines the targets for Security and Compliance Center.\n\n\n\nTable 1. RPO and RTO for Security and Compliance Center\n\n Disaster recovery objective  Target value \n\n RPO                          12 hours     \n RTO                          4 hours      \n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-bc-dr"}, {"document_id": "ibmcld_00057-5736-7021", "score": 0.6609448194503784, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Restore or rebuild the provisioning environments in the affected regions.<br> * Restore existing Spark clusters, where possible.<br><br><br> <br><br> * Track instance state.<br> * Provision new Spark instances in alternatively available regions.<br> * Ensure that the Spark instance is stateless by making sure that all data, metadata and applications reside outside of the cluster. This activity must be completed before disaster recovery can be initiated.<br> * Provision a new service instance in an alternatively available region if the current instances can't be accessed.<br> * Track instance state.<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"}, {"document_id": "ibmcld_12584-10119-11773", "score": 0.6604189276695251, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery, see the [IBM Disaster Recovery Plan](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery). Customers can help meet disaster recovery objectives by deploying their project in a development or test environment before they deploy to production. <br>\\nThe customer does not have to take other actions to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM Cloud is available globally and load balanced from a single URL. It is highly available and continues to run even if your resources are unavailable. For more information about high availability, see the [IBM service level objectives](https://cloud.ibm.com/docs/overview?topic=overview-slo) and the [sample application architecture](https://cloud.ibm.com/docs/overview?topic=overview-bcdr-app-recovery). N/A", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"}, {"document_id": "ibmcld_09190-4838-5447", "score": 0.6552399396896362, "text": "\nNone. IBM and Key Protect are fully responsible for managing disaster recovery. \n Virtual Private Endpoints (VPE) VPE does not support automatically switching to backup during failover at this time. VPE settings, specifically the Internet Protocol (IP) address, need to be manually updated during disaster recovery procedures. \n Private Endpoint (PE) PE will not support allowed IP settings during disaster recovery at this time, but an announcement on this topic will be made soon. PE settings, specifically the Internet Protocol (IP) address, need to be manually updated during disaster recovery procedures.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-shared-responsibilities"}, {"document_id": "ibmcld_11164-4529-7122", "score": 0.6513626575469971, "text": "\nFor more information about particular high availability and disaster recovery practices specific to each service or infrastructure option, refer the documentation for that service.\n\n\n\n\n\n High availability for the network \n\nExcept for the oldest pod that still has some single points of failure, the IBM Cloud network is designed in such a way that a single point of failure never happens. Diverse, redundant connectivity exists at every point of the network, by using diverse telecommunication providers for the same service connectivity whenever possible within each region. Diverse dark fiber providers are used to connect every edge site to all of the regional compute facilities. Each edge site additionally has redundant backbone connectivity into other regions, and peers with multiple providers, both directly and indirectly, through a local exchange. No single event should ever result in a service disruption that is noticed by our customers.\n\nYou can always choose to \"break\" having no single point of failure with how you order or configure your SoftLayer classic servers. For Direct Link, you must order redundant connections if you want full redundancy because it's not built-in or automatic.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location. For the console and platform services, there are no actions that you need to take to prepare for an event of a catastrophic failure in a region.\n\n\n\n Disaster recovery plan \n\nIBM Cloud follows best practices for disaster recovery. All IBM Cloud applications automatically recover and restart after any disaster event. Recovery is from electronic backups at a recovery center or alternative computing facilities that restore computing. Before any potential disaster, the disaster recovery plan includes the systems and hosting requirements for hardware, software, networking connectivity, and offsite backup capabilities.\n\nThe following list includes the requirements that IBM adheres to for a disaster recovery plan:\n\n\n\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime"}, {"document_id": "ibmcld_16202-0-878", "score": 0.6511259078979492, "text": "\n\n\n\n\n\n\n  High availability and disaster recovery \n\nVPC+ Cloud Migration is a third-party service that is managed by Wanclouds. This service is highly available, and it has no backup and restore requirements for disaster recovery.\n\n\n\n  High availability \n\nVPC+ Cloud Migration application deployment is based on Kubernetes, which is available both as a single and multi-master. If one master goes down, Kubernetes shifts the control to another master. Furthermore, POD replicas are deployed across different nodes. This service achieves high availability automatically and is apparent to the customer.\n\n\n\n\n\n  Disaster recovery \n\nFor this service, there is no action that you need to take to prepare for an event of a catastrophic failure in a region. Wanclouds follows best practices for disaster recovery and automatically recovers and restarts after any disaster event.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/wanclouds-vpc-plus?topic=wanclouds-vpc-plus-high-availability-disaster-recovery"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08259-0-511", "score": 0.822412371635437, "text": "\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-release-notes"}, {"document_id": "ibmcld_07578-396975-399135", "score": 0.8103936910629272, "text": "\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-396949-399109", "score": 0.8103936910629272, "text": "\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_14491-1340-3282", "score": 0.809676468372345, "text": "\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https://cloud.redhat.com/openshift/install/vsphere/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"}, {"document_id": "ibmcld_10154-7-1896", "score": 0.8011888861656189, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_14492-7-1792", "score": 0.7994340658187866, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_10214-3003-4898", "score": 0.7989141345024109, "text": "\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system. With the [IBM Cloud Kubernetes Service version](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionscs_versions), you get access to community Kubernetes API features that are considered beta or higher by the community. Kubernetes alpha features, which are subject to change, are generally not enabled by default. With Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\n\n\n\n\n Does the service come with a managed Red Hat OpenShift master and worker nodes? \n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10422-7-1877", "score": 0.7933627367019653, "text": "\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https://cloud.ibm.com/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https://docs.openshift.com/container-platform/4.13/release_notes/ocp-4-13-release-notes.html)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions"}, {"document_id": "ibmcld_07968-7-1612", "score": 0.7933228611946106, "text": "\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"}, {"document_id": "ibmcld_08265-7-2115", "score": 0.791278600692749, "text": "\nSetting up a Red Hat OpenShift for HPC cluster \n\nWhile IBM values the use of inclusive language, terms that are outside of IBM's direct influence are sometimes required for the sake of maintaining user understanding. As other industry leaders join IBM in embracing the use of inclusive language, IBM will continue to update the documentation to reflect those changes.\n\n\n\n Objective \n\n\n\n* Deploy a Red Hat\u00ae OpenShift\u00ae for HPC cluster with your choice of configuration properties\n\n\n\n\n\n\n\n Architecture overview and NFS file system setup \n\nThe Red Hat OpenShift for HPC cluster consists of a login (bastion) node, a storage node where the block storage volume is attached, one or more instances of your Red Hat OpenShift master, and a number of worker nodes.\n\n\n\n* The login node serves as a jump host and it is the only node that has a public IP address. The NFS node has only a private IP address and the only way to reach it is through the login node.\n* By default, every cluster in Red Hat OpenShift on IBM Cloud\u00ae is set up with multiple Red Hat OpenShift master instances to ensure the availability and accessibility of your cluster resources, even if one or more of these masters become unavailable. Worker nodes are created across multiple availability zones in a region.\n* Every cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all of the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). Since [Red Hat OpenShift on IBM Cloud](https://www.ibm.com/cloud/openshift) is a managed service, you cannot SSH directly into the master and worker nodes.\n* The storage node is configured as an NFS server and the block storage is mounted to /data, which is exported to share with Red Hat OpenShift cluster worker nodes. If you want to use the NFS storage inside the pods, then you need to create persistent volumes and persistent volume claims and attach them into the pods.", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-setting-up-red-hat-openshift-hpc-cluster"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10534-1903-3343", "score": 0.6259463429450989, "text": "\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksoverview-by-resource)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10170-10609-12793", "score": 0.6119709014892578, "text": "\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10170-8677-11078", "score": 0.6048750281333923, "text": "\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_12439-3077-4740", "score": 0.6015569567680359, "text": "\nFor a higher level of security and control, your business might benefit from the data isolation that a single-tenant offering provides, such as Secrets Manager or Hyper Protect Crypto Services. You might also decide that the reduced cost and scalability benefits of a multi-tenant service, such as Key Protect and Certificate Manager, are better suited to your needs. The following table lists key features for each service.\n\n\n\nTable 2. Key features for IBM Cloud data protection services\nThe table compares features across Secrets Manager, Certificate Manager, Key Protect, and Hyper Protect Crypto Services. The first column lists the names of the services. The second column lists the types of secrets that are supported by each service. The third column uses checkmarks to indicate whether a service is multi-tenant. The fourth column uses checkmarks to indicate whether a service is single-tenant. The last column uses checkmarks to indicate whether a service is backed by a hardware security module (HSM).\n\n Service Secret types Multi-tenant<br><br>[1] Single-tenant<br><br>[2] HSM backed<br><br>[3] \n\n Secrets Manager Arbitrary secrets <br>IAM credentials <br>Key-value secrets <br>SSL/TLS certificates <br>User credentials ![Checkmark icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/checkmark-icon.svg) \n Key Protect Symmetric encryption keys ![Checkmark icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/checkmark-icon.svg) ![Checkmark icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/checkmark-icon.svg)", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud"}, {"document_id": "ibmcld_07578-565403-567284", "score": 0.5915696620941162, "text": "\nFor more information, see the [End of Service announcement](https://cloud.ibm.com/docs/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https://www.hover.com/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https://opensrs.com/wp-content/uploads/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https://opensrs.com/resources/documentation/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-565357-567238", "score": 0.5915696620941162, "text": "\nFor more information, see the [End of Service announcement](https://cloud.ibm.com/docs/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https://www.hover.com/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https://opensrs.com/wp-content/uploads/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https://opensrs.com/resources/documentation/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_14389-3006-4736", "score": 0.5910864472389221, "text": "\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS\n* Open Web Application Security Project (OWASP) top 10 threats\n* Common application vulnerabilities\n\n\n\n\n\nBIG-IP Access Policy Manager\u2122 (APM) offers users secure, simplified access to applications located anywhere within a multicloud environment, incorporating features such as SSO (Single Sign-On) and MFA (Multifactor Authentication).\n\nYou cannot change the license model after service installation. To change the license model, you must delete the existing service and reinstall the service by choosing a different license model.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [F5 BIG-IP overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-f5_considerations)\n* [Managing F5 BIG-IP](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-managing_f5)\n* [Ordering services for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservices)\n* [Contacting IBM\u00ae Support](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-trbl_support)\n* [FAQ](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)\n* [F5 Deployment Guides](https://www.f5.com/services/resources/deployment-guides)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-f5_ordering"}, {"document_id": "ibmcld_05727-8804-11229", "score": 0.5872754454612732, "text": "\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nIBM Cloud Kubernetes Service provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_transport"}, {"document_id": "ibmcld_16278-7-2318", "score": 0.5673933029174805, "text": "\nComparing actions and dialog \n\nChoose the right type of conversation for your use case.\n\n\n\n Actions benefits \n\nUsing actions is the best choice when you want to approach the assistant with a focus on content. Actions offers the following benefits:\n\n\n\n* The process of creating a conversational flow is easier. People who have expertise with customer care can write the words that your assistant says. With a simplified process anyone can build a conversation. You don't need knowledge about machine learning or programming.\n* Actions provide better visibility into the customer's interaction and satisfaction with the assistant. Because each task is discrete and has a clear beginning and ending, you can track user progress through a task and identify snags.\n* The conversation designer doesn't need to manage data collected during the conversation. By default, your assistant collects and stores information for the duration of the current action. You don't need to take extra steps to delete saved data or reset the conversation. But if you want, you can store certain types of information, such as the customer's name, for the duration of a conversation.\n* Many people can work at the same time in separate, self-contained actions. The order of actions within a conversation doesn't matter. Only the order of steps within an action matters. And the action author can use drag and drop to reorganize steps in the action for optimal flow.\n\n\n\n\n\n\n\n Dialog benefits \n\nA dialog-based conversation is the best choice when you want greater control over the logic of the flow. The dialog editor exposes more of the underlying artifacts (such as intents and entities) used to build the AI models. The dialog flow uses an if-then-else style structure that might be familiar to developers, but not to content designers or customer-care experts.\n\n\n\n\n\n How actions are different from dialog \n\nIf you are already familiar with dialog-based conversations, learn more about how actions compares.\n\n\n\nConversational flow skill feature support\nThis table has row and column headers. The row headers identify features. The column headers identify the different skill types. To understand which features are supported by a skill, go to the row that describes the feature, and find the columns for the skill you are interested in.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-comparing-actions-dialog"}, {"document_id": "ibmcld_05727-10686-13084", "score": 0.5646783113479614, "text": "\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith IBM Cloud Kubernetes Service, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nIBM Cloud Kubernetes Service provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_transport"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14112-1091-1931", "score": 0.7602370977401733, "text": "\n[Set up a hypervisor](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-a-hypervisor). [Setting up a virtual machine Network](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-a-virtual-machine-network) is an important part of this process. \n __ 3. Depending on which virtualization solutions that you are using, you can [set up Hyper-V](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-hyper-v), [Get started with Virtuozzo](https://cloud.ibm.com/docs/virtualization?topic=virtualization-getting-started-with-virtuozzo), [Get started with VMware vSphere 6](https://cloud.ibm.com/docs/vmware?topic=vmware-vmware-getting-started), or [Install XenServer tools](https://cloud.ibm.com/docs/virtualization?topic=virtualization-installing-xenserver-tools-when-using-linux).", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-getting-started"}, {"document_id": "ibmcld_03647-0-472", "score": 0.7443146109580994, "text": "\n\n\n\n\n\n\n  Virtualization \n\nYou can use IBM Cloud\u00ae Virtualization to run multiple virtual machines in a single dedicated environment. Virtual machines that run on an IBM Cloud network can integrate with other physical and virtual devices that are on the network and are managed through both the IBM Cloud\u00ae console and API. For more information, see [Getting started with Virtualization](https://cloud.ibm.com/docs/virtualization?topic=Virtualization-getting-started).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-bm-virtualization"}, {"document_id": "ibmcld_14112-7-1387", "score": 0.7242295742034912, "text": "\nGetting started with virtualization \n\nYou can use the virtualization solution to run multiple virtual machines in a single dedicated environment within IBM Cloud\u00ae Classic Infrastructure. Virtual machines that run on the IBM Cloud network can integrate with other physical and virtual devices on the network and can be managed through both the console and API. Running virtual machines on the IBM Cloud proprietary architecture and automated platform offers high levels of stability suitable for enterprise-level virtualization, and virtualization on a smaller scale.\n\n\n\nTable 1. Getting started with Virtualization\n\n Get started \n\n __ 1. For more information about virtualization options, see [Citrix XenServer](https://cloud.ibm.com/docs/virtualization?topic=virtualization-what-is-citrix-xenserver-), [Hyper-V](https://cloud.ibm.com/docs/virtualization?topic=virtualization-what-is-hyper-v-), [Virtuozzo](https://cloud.ibm.com/docs/virtualization?topic=virtualization-what-is-virtuozzo-), and [VMware](https://cloud.ibm.com/docs/vmware?topic=vmware-vmware-getting-started). \n __ 2. [Set up a hypervisor](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-a-hypervisor). [Setting up a virtual machine Network](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-a-virtual-machine-network) is an important part of this process. \n __ 3.", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-getting-started"}, {"document_id": "ibmcld_14109-7-2316", "score": 0.6861297488212585, "text": "\nFAQs: Hyper-V \n\n\n\n What are the requirements to run Hyper-V? \n\nSee [Hyper-V: Hardware requirements](https://cloud.ibm.com/docs/virtualization?topic=virtualization-hyper-v-hardware-requirements)\n\n\n\n\n\n What operating systems can be installed on a virtual machine? \n\nSee [Obtaining installation media](https://cloud.ibm.com/docs/virtualization?topic=virtualization-setting-up-hyper-v&locale=enobtaining-installation-media)\n\n\n\n\n\n How many virtual machines can a server run? \n\nThe number of virtual machines a server can run varies depending upon server processors, RAM, and hard disk space.\n\n\n\n\n\n Is the RAM customizable on each virtual machine? \n\nYes. You can use Hyper-V to customize the system resources for each virtual machine, including memory.\n\n\n\n\n\n How much RAM does a virtual machine need? \n\nRAM needs vary based on requirements for the virtual machine. Check the system requirements for your guest operating system. The amount of memory that is provided to a virtual machine can be changed at any time.\n\n\n\n\n\n Can a virtual machine access to more than one processor? \n\nYou can grant a virtual machine access to multiple processors with any Windows virtual machine. However, Linux virtual machines are limited to a single processor.\n\n\n\n\n\n Can hard disk sizes change after a virtual machine is created? \n\nYes.\n\n\n\n\n\n Does each virtual operating system need to have a license? \n\nWindows virtual machines are licensed through IBM Cloud. Linux virtual machines are freely licensed and require no action.\n\n\n\n\n\n Will the virtual machines have access to the private network? \n\nYes. Virtual machines can connect to both a public and private network.\n\n\n\n\n\n What advantages are there to providing private network access to virtual machines? \n\nProviding private network access to virtual machines allows virtual machines to communicate with each other. Private network access also allows virtual machines to communicate with other internal systems such as NAS and iSCSI and any other servers that you have with IBM Cloud.\n\n\n\n\n\n Can virtual machines use the secondary IP block that came with the server? \n\nNo. The secondary IP that was provided with your server is routed specifically to work on the physical server and not a virtual machine. You need portable IP blocks to connect your virtual machine to the network.", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-faqs-hyper-v"}, {"document_id": "ibmcld_14010-1507-3605", "score": 0.6813715696334839, "text": "\n[Transient virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-vs-transient) IBM-managed, multi-tenancy virtual server deployments offered at a reduced cost and best suited for flexible workloads \n [Reserved virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-reserved-virtual-servers) IBM-managed, multi-tenancy virtual server deployments with guaranteed capacity for a contract term \n [Dedicated virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-dedicated-virtual-servers) IBM-managed, single-tenancy virtual server deployments \n\n\n\nIBM Cloud\u00ae Virtual Servers are powered by Citrix Hypervisor. As with most hypervisors, guest additions help maintain a properly working computing environment. IBM Cloud\u00ae uses the information from guest additions to make informed decisions about routine server maintenance. Without the required guest additions, your virtual servers might miss critical maintenance updates. So, don't disable or remove any default guest additions. If you are brining your own image to, you need to install the associated guest images. For more information about installing guest additions, see [Preparing and importing images](https://cloud.ibm.com/docs/image-templates?topic=image-templates-preparing-and-importing-images).\n\n\n\n\n\n Provisioning a virtual server \n\nAfter you decide upon a deployment option, begin the provisioning process.\n\n\n\nTable 2. Provisioning information\n\n Provisioning instructions Description \n\n [Provisioning public instances](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-ordering-vs-public) Provision public instances with various options \n [Provisioning transient instances](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-ordering-vs-transient) Provision transient instances with various options \n [Provisioning reserved capacity and instances](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-provisioning-reserved-capacity-and-instances) Provision reserved capacity and instances with various options", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial"}, {"document_id": "ibmcld_04716-7-1823", "score": 0.6811610460281372, "text": "\nCompute services \n\nYour server is the base of your infrastructure. Depending on your needs, you have various options, or you can mix it up if that's what your environment requires. Check out the following table for a summary of your compute options.\n\n\n\n Virtual servers \n\n\n\nTable 1. Compute options - Virtual Servers\n\n Option Description \n\n [Virtual Servers for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers) Scalable virtual servers for VPC that are purchased with cores and memory allocations. \n [Hyper Protect Virtual Servers](https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-getting-started) Hyper Protect Virtual Servers is an IBM Cloud\u2122 service that provides highly secure virtual servers that can run Linux applications and containerized workloads. \n [Power Systems Virtual Server](https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-getting-started) A Power Systems Virtual Server integrates your AIX and IBM i capabilities into the IBM Cloud\u2122 experience. \n\n\n\n\n\n\n\n VPC infrastructure \n\n\n\nTable 2. Compute options - VPC\n\n Option Description \n\n [Virtual Servers for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers) Scalable virtual servers for VPC that are purchased with cores and memory allocations. \n\n\n\n\n\n\n\n Classic infrastructure \n\n\n\nTable 3. Compute options - Classic\n\n Option Description \n\n [Bare Metal Servers](https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-about-bmabout-bm) Hourly or monthly, single-tenant servers that are dedicated to you and not shared in any part, including server resources, with other customers. \n [Virtual Servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial) Scalable virtual servers that are purchased with cores and memory allocations.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-compute"}, {"document_id": "ibmcld_13963-3069-3723", "score": 0.6692987680435181, "text": "\n[GPU](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesgpu) Best for high-performance workloads. \n\n\n\nSome of these families are also available for IBM Cloud\u00ae Virtual Servers for Virtual Private Cloud. For more information, see [Virtual Servers for VPC](https://cloud.ibm.com/docs/vpc-on-classic-vsi?topic=vpc-on-classic-vsi-getting-started).\n\n\n\n Next steps \n\nAfter you review and decide upon your virtual server profile, it's time to provision your public virtual server. To get started, see [Provisioning public instances](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-ordering-vs-public).", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-public-virtual-servers"}, {"document_id": "ibmcld_14010-7-1961", "score": 0.6650020480155945, "text": "\nGetting started with virtual servers \n\nYou can deploy IBM Cloud\u00ae Virtual Servers in a matter of minutes. The virtual servers are deployed from your choice of virtual server images and in the geographic region that makes sense for your workloads.\n\nNewer version available. Try our Virtual Servers for VPC. For more information, see [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\nWhen you create a virtual server in the classic infrastructure, you can choose between a public (multi-tenancy) environment or a dedicated (single-tenancy) environment. Then, depending on the chosen environment, you must also select hourly, monthly, or transient virtual servers. With public virtual servers, you also choose to use either SAN-based storage or local storage.\n\n\n\n Before you begin \n\nBefore you begin, review the following prerequisites.\n\n\n\n1. You must have an upgraded account to order virtual servers. This process can take some time and requires your request to be approved before you can continue. For more information about upgrading your account, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n2. Review and choose your deployment options. For more information, see the following topics:\n\n\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Public virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-public-virtual-servers) IBM-managed, multi-tenancy virtual server deployments \n [Transient virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-vs-transient) IBM-managed, multi-tenancy virtual server deployments offered at a reduced cost and best suited for flexible workloads \n [Reserved virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-reserved-virtual-servers) IBM-managed, multi-tenancy virtual server deployments with guaranteed capacity for a contract term", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial"}, {"document_id": "ibmcld_13963-1725-3470", "score": 0.662702739238739, "text": "\nFor more information, see the single-tenant environment, [Dedicated virtual server](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-dedicated-virtual-servers) offering.\n\nThe following families of public instances are available for this offering.\n\n\n\nTable 1. Public virtual server family selections\n\n Families Description \n\n [Balanced](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesbalanced) Best for common cloud workloads that require a balance of performance and scalability. Uses network-attached storage. \n [Balanced local storage](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesbalanced-local-storage) Best for large database workloads that require high I/O performance with low latency. \n [Variable compute](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesvariable-compute) Best for workloads that don\u2019t require steady, high-CPU performance. \n [Compute](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilescompute) Best for moderate to high web traffic workloads. \n [Memory](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesmemory) Best for memory caching and real-time analytics workloads. \n [GPU](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesgpu) Best for high-performance workloads. \n\n\n\nSome of these families are also available for IBM Cloud\u00ae Virtual Servers for Virtual Private Cloud. For more information, see [Virtual Servers for VPC](https://cloud.ibm.com/docs/vpc-on-classic-vsi?topic=vpc-on-classic-vsi-getting-started).\n\n\n\n Next steps", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-public-virtual-servers"}, {"document_id": "ibmcld_13975-1393-3059", "score": 0.6626877784729004, "text": "\n[Compute](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilescompute) Best for moderate to high web traffic workloads. \n [Memory](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profilesmemory) Best for memory caching and real-time analytics workloads. \n\n\n\n\n\n Notifications \n\nWhen configured, you can receive automated reclaim notifications that help you prepare and reduce lost data. For more information, see [Configuring automated reclaim notifications](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-configuring-notifications-for-reclaims-of-transient-virtual-serversconfiguring-notifications-for-reclaims-of-transient-virtual-servers).\n\n\n\n\n\n Limitations \n\nConsider the following limitations before you provision a transient virtual server.\n\n\n\n* The number of supported, concurrent instances are part of your account-wide device quota. For more information about concurrent instance limits, see [FAQ: Virtual servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-faqs-virtual-serversfaqs-virtual-servers).\n* Transient instances cannot be upgraded or downgraded.\n* Resources can be reclaimed at any time, without notification.\n* Transient instances cannot use local storage.\n* Transient instances cannot use GPU-based or variable compute profiles.\n\n\n\n\n\n\n\n Next steps \n\nAfter you review and select your virtual server profile, it's time to provision your transient virtual server. To get started, see [Provisioning transient instances](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-ordering-vs-transientordering-vs-transient).", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-vs-transient"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16728-5097-7108", "score": 0.6020824909210205, "text": "\n[solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Bring Your Own IP Address](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_14293-3-1284", "score": 0.5988736152648926, "text": "\nVMware Solutions docs \n\nVMware Solutions is a group of IBM Cloud offerings that provide deployment and management of VMware virtualized environments. Learn how to make the most of your VMware Solutions experience by using the user documentation, REST API documentation reference, solution architectures, and solution guides.\n\n Developer tools \n\n[API & SDK reference](https://cloud.ibm.com/docs?tab=api-docs&category=compute&subCategory=vmwaresolutions)\n\n Recommended content \n\n[Getting started with VMware Solutions Get familiar with the process of ordering an instance and some services for it.](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-getting-started)[Signing up for required accounts Sign up for an IBM Cloud account and an IBM Cloud infrastructure account.](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts)[Accessing the VMware Solutions console Review the entry points into the IBM Cloud for VMware Solutions console.](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-loginmethod)[Setting up your environment for your first order Ensure that your environment is ready for your order.](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-completing_checklist)\n\n Video library \n\n[!", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions"}, {"document_id": "ibmcld_02821-0-910", "score": 0.5903201103210449, "text": "\n\n\n\n\n\n\n  Designing a cloud solution by using the architecture framework \n\nCloud applications cross many aspects. For each aspect there are requirements and architecture decisions that must be assessed.\n\nYou can simplify cloud architecture design and create a fit-for-purpose cloud solution by following five simple steps:\n\n\n\n1.  Use the architecture framework as a template, create a solution architecture heat map that highlights the aspects and domains relevant to the solution requirements.\n2.  Identify component options for each applicable domain in the solution architecture heat map.\n3.  Use decision tools to select the best-fit components for each domain based on requirements and constraints.\n4.  Document architecture decisions for the components associated with each domain.\n5.  Create a reference architecture diagram that illustrates how the main components of the solution come together.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/architecture-framework?topic=architecture-framework-create-solution"}, {"document_id": "ibmcld_01545-23339-24197", "score": 0.5783709287643433, "text": "\n* [Best practices solution guide](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications) for organizing users, teams and apps.\n* [Analyze logs and monitor application health](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysisapplication-log-analysis).\n* Set up [continuous integration and delivery pipeline](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-continuous-deployment-to-kubernetescontinuous-deployment-to-kubernetes) for containerized apps that run in Kubernetes.\n* Use [multiple clusters across multiple locations](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones) for high availability.\n* Re-platform applications to Kubernetes using [Konveyor Move2Kube](https://move2kube.konveyor.io/).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_13180-23247-24105", "score": 0.5783709287643433, "text": "\n* [Best practices solution guide](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications) for organizing users, teams and apps.\n* [Analyze logs and monitor application health](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysisapplication-log-analysis).\n* Set up [continuous integration and delivery pipeline](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-continuous-deployment-to-kubernetescontinuous-deployment-to-kubernetes) for containerized apps that run in Kubernetes.\n* Use [multiple clusters across multiple locations](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones) for high availability.\n* Re-platform applications to Kubernetes using [Konveyor Move2Kube](https://move2kube.konveyor.io/).", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes"}, {"document_id": "ibmcld_16728-25832-27646", "score": 0.5739246606826782, "text": "\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [PHP web application on a LAMP Stack in VPC](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-lamp-stack-on-vpc)PHP web application on a LAMP Stack in VPC Solution tutorial\n\nThis tutorial walks you through the creation of an Ubuntu Linux virtual server with Apache web server, MySQL database and PHP scripting on IBM Cloud Virtual Private Cloud (VPC) Infrastructure. This combination of software - more commonly called a LAMP stack - is often used to deliver websites and web applications. Using IBM Cloud VPC you will quickly deploy your LAMP stack and if desired add logging and monitoring. To experience the LAMP server in action, you will also install and configure the free and open source WordPress content management system.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Plan, create and update deployment environments](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-plan-create-update-deployments)Plan, create and update deployment environments Solution tutorial\n\nMultiple deployment environments are common when building a solution. They reflect the lifecycle of a project from development to production. This tutorial introduces tools like the IBM Cloud CLI and Terraform to automate the creation and maintenance of these deployment environments.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Power Systems Virtual Server for SAP HANA](https://cloud.ibm.com/docs/sap-powervs)Power Systems Virtual Server for SAP HANA Deployment guide\n\nDeploy your first SAP-ready landscape by using SAP solution provisioning with a deployable architecture.\n\nDeployable!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16728-24486-26124", "score": 0.5735345482826233, "text": "\n[solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Modern web application using MEAN stack](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-mean-stack)Modern web application using MEAN stack Solution tutorial\n\nThis tutorial walks you through the creation of a web application using the popular MEAN stack. It is composed of a MongoDB, Express web framework, Angular front end framework and a Node.js runtime. You will learn how to run a MEAN sample app locally, create and use a managed database-as-a-service (DBasS), deploy the app to IBM Cloud and scale both the runtime and database resources.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Moving a VM based app to Kubernetes](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes)Moving a VM based app to Kubernetes Solution tutorial\n\nThis tutorial walks you through the process of moving a VM based app to a Kubernetes cluster by using Kubernetes Service. Kubernetes Service delivers powerful tools by combining container and Kubernetes technologies, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [PHP web application on a LAMP Stack in VPC](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-lamp-stack-on-vpc)PHP web application on a LAMP Stack in VPC Solution tutorial", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_02827-0-889", "score": 0.5705764293670654, "text": "\n\n\n\n\n\n\n  Why use the architecture framework? \n\nDesigning a cloud solution by using the architecture framework enables a more consistent approach to solutioning across the breadth of your cloud portfolio, which in turn decreases the solution process time and delivery risks.\n\nUsing the architecture framework also provides the structure to create reusable, repeatable solution architecture references and guidance which leads to the standardization of enterprise cloud solution design and the avoidance of one-of-a-kind snowflake solutions that are expensive to deploy, enhance, and maintain.\n\nThe architecture framework can be used as a guide to ensure you have considered applicable requirements for each \"aspect\" and \"domain\". After you have identified the applicable requirements, you can evaluate and select the best fit for purpose components for your enterprise cloud solution.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/architecture-framework?topic=architecture-framework-why-use-framework"}, {"document_id": "ibmcld_16728-2287-4207", "score": 0.5639805197715759, "text": "\nAll solution docs[Accelerate a dynamic website using Dynamic Content Acceleration](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-dynamic-content-cdn)Accelerate a dynamic website using Dynamic Content Acceleration Solution tutorial\n\nWeb applications are composed of static content like text, images, cascading style sheets, and JavaScript files. The tutorial Accelerate delivery of static files using a CDN shows how to host and serve static assets (images, videos, and documents) of a website from IBM Cloud Object Storage with IBM\u00ae Content Delivery Network (CDN).\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN Solution tutorial\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Analyze logs and monitor application health ](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-application-log-analysis)Analyze logs and monitor application health Solution tutorial\n\nThis tutorial shows how the IBM Log Analysis service can be used to configure and access logs of a Kubernetes application that is deployed on IBM Cloud. You will deploy a Python application to a cluster provisioned on IBM Cloud Kubernetes Service, configure a logging agent, generate different levels of application logs and access worker logs, pod logs or network logs. Then, you will search, filter and visualize those logs through Log Analysis Web UI.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16728-7741-9365", "score": 0.5597351789474487, "text": "\n[solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Centralize communication through a VPC Transit Hub and Spoke architecture - Part one](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-transit1)Centralize communication through a VPC Transit Hub and Spoke architecture - Part one Solution tutorial\n\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances. This tutorial will walk through the implementation of a hub and spoke architecture depicted in this high-level view:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10140-34792-36631", "score": 0.750351071357727, "text": "\n* Removes the deprecated region get, region set, and region ls commands from help output.\n* Updates command structure to the new spaced format in help output.\n* Adds a warning to the output of legacy cluster config behavior. For more information, see the [version 1.0 plug-in documentation](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n* Fixes a bug so that worker reload and messages commands now fail if the command errors.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.23 \n\nVersion 0.4.23 of the CLI was released on 16 September 2019.\n\n\n\n* Decreases startup time for the plug-in.\n* Fixes a Go version issue for macOS users.\n* Improves debug tracing.\n* In ibmcloud oc logging filter commands, the syntax of the --logging-config option changes from accepting multiple values in a comma-separated list to requiring repeated options.\n* Minor bug and security fixes.\n* Updates message, warning, and help text.\n\n\n\n\n\n\n\n Version 0.4.3 \n\nVersion 0.4.3 of the CLI was released on 4 September 2019.\n\n\n\n* Adds deprecation warnings for legacy commands to error messages that are sent to stderr.\n\n\n\n\n\n\n\n Version 0.4.1 \n\nVersion 0.4.1 of the CLI was released on 3 April 2019.\n\n\n\n* Sets the Red Hat OpenShift on IBM Cloud plug-in to the redesigned format by default. This redesigned version includes changes such as categorical lists instead of an alphabetical list of commands in the output of ibmcloud oc help, spaced-structured commands instead of hyphenated-structure commands, repeated options instead of multiple values in comma-separated lists, and more. For a full list of the changes between version 0.3 and 0.4, see the comparison table in [Using the beta Red Hat OpenShift on IBM Cloud plug-in](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelogchangelog_beta).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_10358-3632-5051", "score": 0.7249295711517334, "text": "\n* [Deploying apps through the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appdeploy_apps_cli).\n* [Deploying apps to specific worker nodes by using labels](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appnode_affinity).\n\n\n\nNeed help? Check out [Troubleshooting apps and integrations](https://cloud.ibm.com/docs/openshift?topic=openshift-debug_apps).\n\n\n\n\n\n Test, log, and monitor \n\nWhile you conduct performance testing on your app, set up logging and monitoring to help you troubleshoot issues, gain visibility into your workloads, and improve the health and performance of your apps.\n\nIn a test environment, deliberately create various non-ideal scenarios, such as deleting all worker nodes in a zone to replicate a zonal failure. Review the logs and metrics to check how your app recovers.\n\n\n\n1. Test access: Test access to your app by creating a public or private [NodePort](https://cloud.ibm.com/docs/openshift?topic=openshift-nodeport) on your worker nodes.\n2. Understand logging and monitoring options: [Choose solutions for app and cluster logging, audit logging, and monitoring](https://cloud.ibm.com/docs/openshift?topic=openshift-healthoc_logmet_options) based on your needs.\n3. Monitoring through the console: Open the [OpenShift web console](https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_appopenshift_console) to view information about your app resources.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-dev"}, {"document_id": "ibmcld_10358-9349-10325", "score": 0.7214085459709167, "text": "\n* [IBM Cloud services and third-party integrations](https://cloud.ibm.com/docs/openshift?topic=openshift-ibm-3rd-party-integrations)\n* [Cloud Paks](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_cloud_paks)\n* [Operators](https://cloud.ibm.com/docs/openshift?topic=openshift-operators)\n\n\n\n2. Add services to your cluster: Ask your cluster administrator to [add the integration to your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-adminadmin_integrate).\n3. Access services from your app: Ensure that your app can access the service. For example, to access an IBM Cloud service instance from your app, you must [make the service credentials that are stored in the Kubernetes secret available to your app](https://cloud.ibm.com/docs/openshift?topic=openshift-service-bindingadding_app).\n\n\n\nNeed help? Check out [Troubleshooting apps and integrations](https://cloud.ibm.com/docs/openshift?topic=openshift-debug_worker_nodes). {: tip}f", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-learning-path-dev"}, {"document_id": "ibmcld_10140-44572-46044", "score": 0.7189984917640686, "text": "\n* Updates the Go version to 1.12.2.\n\n\n\n\n\n\n\n Version 0.2.95 \n\nVersion 0.2.95 of the CLI was released on 3 April 2019.\n\n\n\n* Adds versioning support for managed cluster add-ons.\n* Adds the [ibmcloud oc addon-versions](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_addon_versions) command.\n* Adds the --version option to [ibmcloud oc cluster addon enable](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_cluster_addon_enable) commands.\n* Updates the help text in various languages.\n* Updates short links to documentation in help text.\n* Fixes a bug where JSON error messages printed in an incorrect format.\n* Fixes a bug where using the silent option (-s) on some commands prevented errors from printing.\n\n\n\n\n\n\n\n Version 0.2.80 \n\nVersion 0.2.80 of the CLI was released on 19 March 2019.\n\n\n\n* Adds support for enabling [master-to-worker communication with service endpoints](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_basicsworkeruser-master) in standard clusters in [VRF-enabled accounts](https://cloud.ibm.com/docs/account?topic=account-vrf-service-endpointvrf).\n* Adds the --private-service-endpoint and --public-service-endpoint options to the [ibmcloud oc cluster-create](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_cluster_create) command.\n* Adds the Public Service Endpoint URL and Private Service Endpoint URL fields to the output of ibmcloud oc cluster get.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_10140-20734-22235", "score": 0.71843421459198, "text": "\n* Beta: Adds the [ibmcloud oc storage](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_storage) set of commands to view and modify storage resources in your cluster.\n* Moves the ibmcloud oc locations command to the Informational Commands group in the help output of ibmcloud oc.\n* Updates the help text for options in the ibmcloud oc nlb-dns monitor configure command.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 1.0.84 \n\nVersion 1.0.84 of the CLI was released on 26 May 2020.\n\n\n\n* Fixes bugs for credentials in Kubernetes configuration contexts:\n\n\n\n* When you download the contexts for clusters that run Kubernetes version 1.17 or later, those contexts are merged into your kubeconfig file. The tokens from the version 1.17 or later contexts now don't overwrite tokens for any version 1.16 or later contexts.\n* Credentials are now correctly added to your kubeconfig file when you download the context for a cluster.\n* Fixes credential issues for CLI plug-in installations on macOS that don't use cgo.\n\n\n\n* Adds commands for creating and managing VPC clusters.\n\n\n\n* [alb configure vpc-gen2](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clicli_alb_configure_vpc_gen2)\n* [alb create vpc-gen2](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clicli_alb-create-vpc-gen2)\n* [cluster create vpc-gen2](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clicli_cluster-create-vpc-gen2)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_10140-49448-51079", "score": 0.7182920575141907, "text": "\nVersion 0.2.19 of the CLI was released on 16 January 2019.\n\n\n\n* Adds the IKS_BETA_VERSION environment variable to enable the redesigned beta version of the Red Hat OpenShift on IBM Cloud plug-in CLI. To try out the redesigned version, see [Using the beta command structure](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n* Increases the default timeout value for ibmcloud oc subnets to 60s.\n* Fixes a minor bug and updates the help text in various languages.\n\n\n\n\n\n\n\n\n\n Version 0.1 \n\nReview the following changes for 0.1 versions of the CLI plug-in.\n\nVersion 0.1 of the CLI plug-in is deprecated. To update to the latest version, see [Updating to version 1.0 of the plug-in](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n\n\n\n Version 0.1.668 \n\nVersion 0.1.68 of the CLI was released on 18 December 2018.\n\n\n\n* Changes the default API endpoint from containers.bluemix.net to containers.cloud.ibm.com.\n* Fixes bug so that command help text and error messages display properly for various languages.\n* Displays command help faster.\n\n\n\n\n\n\n\n Version 0.1.654 \n\nVersion 0.1.654 of the CLI was released on 5 December 2018.\n\n\n\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.1.638 \n\nVersion 0.1.638 of the CLI was released on 15 November 2018.\n\n\n\n* Adds the [ibmcloud oc cluster-refresh](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_apiserver_refresh) alias to the apiserver-refresh command.\n* Adds the resource group name to the output of ibmcloud oc cluster get and ibmcloud oc cluster ls.\n\n\n\n\n\n\n\n Version 0.1.635", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_10367-7-1905", "score": 0.7181954383850098, "text": "\nAdding services by using managed add-ons \n\nManaged Red Hat OpenShift on IBM Cloud add-ons are an easy way to enhance your cluster with extra capabilities and open-source capabilities, such as the Diagnostics and Debug Tool, Block Storage for VPC, or the Cluster Autoscaler. The version of the driver, plug-in, or open-source tool that you add to your cluster is tested by IBM and approved to be used in Red Hat OpenShift on IBM Cloud.\n\nThe managed add-ons that you can install in your cluster depend on the type of cluster, the container platform, and the infrastructure provider that you choose.\n\nSupport\n: Managed add-ons are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using the managed add-ons, you can use one of the Red Hat OpenShift on IBM Cloud support channels. For more information, see [Getting help and support](https://cloud.ibm.com/docs/openshift?topic=openshift-get-help).\n\nBilling\n: If the tool that you add to your cluster incurs costs, these costs are automatically integrated and listed as part of your Red Hat OpenShift on IBM Cloud billing. The billing cycle is determined by IBM Cloud depending on when you enabled the add-on in your cluster.\n: In general, no additional setup, such as opening ports or IP addresses is required. However, refer to the documentation of each managed add-on to find the prerequisites that your cluster must meet before you install the managed add-on.\n\n\n\n Adding managed add-ons \n\nTo enable a managed add-on in your cluster from the CLI, use the [ibmcloud oc cluster addon enable command](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_cluster_addon_enable). To enable a managed add-on in your cluster in the [Red Hat OpenShift clusters console](https://cloud.ibm.com/kubernetes/clusters?platformType=openshift), use the Add-ons pane of the cluster details page.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-managed-addons"}, {"document_id": "ibmcld_10154-9468-11364", "score": 0.7152950763702393, "text": "\nIn this sense, the installation is similar to IPI for you because you don't have to manage all the infrastructure and network settings. IBM also provides patch updates that you can choose to apply to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). SSH is disabled for added security. \n OCP versions and patch updates You are responsible for updating the underlying infrastructure for the master and worker nodes. You can use the Red Hat OpenShift web console to update OCP versions. IBM automatically applies updates to the master, and provides version updates and security patch updates for the worker nodes. You choose when to apply these updates to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). Supported versions might vary from standard OpenShift Container Platform. \n Autoscaling compute machines You can set up a ClusterAutoscaler resource. You can set up the [cluster autoscaler plug-in](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc). \n Worker node operating system CoreOS or RHEL For a list of supported operating systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions). \n Support Provided per the terms of your Red Hat subscription or cloud provider. You can use the oc adm must-gather tool to help gather information. Provided by [IBM Cloud Support](https://www.ibm.com/cloud/support). You can use the oc adm must-gather tool, or the [Diagnostics and Debug Tool](https://cloud.ibm.com/docs/openshift?topic=openshift-debug-tool) to help gather information. \n Red Hat OpenShift web console You set up and can configure or disable the Red Hat OpenShift web console. The Red Hat OpenShift web console is set up for you. You can't configure or disable the web console.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10227-7-1673", "score": 0.7132505178451538, "text": "\nGetting help and support for Red Hat OpenShift on IBM Cloud \n\nStill having issues with your cluster? Review different ways to get help and support for your Red Hat OpenShift on IBM Cloud clusters. For any questions or feedback, post in Slack.\n\n\n\n General ways to resolve cluster issues \n\n\n\n1. Keep your cluster environment up to date.\n\n\n\n* Check monthly for available security and operating system patches to [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n* [Update your cluster](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster) to the latest default version for [Red Hat OpenShift](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\n\n\n2. Make sure that your command line tools are up to date.\n\n\n\n* In the command line, you are notified when updates to the ibmcloud CLI and plug-ins are available. Be sure to keep your CLI up-to-date so that you can use all available commands and options.\n* Make sure that [your oc CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-install) client matches the same Kubernetes version as your cluster server. [Kubernetes does not support](https://kubernetes.io/releases/version-skew-policy/)oc client versions that are 2 or more versions apart from the server version (n +/- 2).\n\n\n\n\n\n\n\n\n\n Reviewing issues and status \n\n\n\n1. To see whether IBM Cloud is available, [check the IBM Cloud status page](https://cloud.ibm.com/status?selected=status).\n2. Filter for the Kubernetes Service component.\n3. Review the [limitations and known issues documentation](https://cloud.ibm.com/docs/containers?topic=containers-limitations).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-get-help"}, {"document_id": "ibmcld_10702-17279-18051", "score": 0.7077575922012329, "text": "\n* [Setting up block storage for your apps](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-block)\n* [Backing up your internal image registry to IBM Cloud Object Storage](https://cloud.ibm.com/docs/openshift?topic=openshift-registrycos_image_registry)\n* [Overview of the differences between classic and VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers)\n* [VPC cluster limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits)\n* [About the v2 API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_installapi_about)\n\n\n\nNeed help, have questions, or want to give feedback on VPC clusters? Try posting in the [Slack channel](https://cloud.ibm.com/kubernetes/slack).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09508-4607-6675", "score": 0.6074762940406799, "text": "\nFor production environments, the IBM SRE team highly discourages requests to run sql scripts with insert/update/delete statement(s). These are considered high risk and can break overall data integrity. SRE will only execute statements that have been tested by the client on their non-production environments. Every effort should be made to use [automation scripts](https://www.ibm.com/docs/en/maximo-manage/continuous-delivery?topic=scripts-automation) or standard tools through the Maximo front end rather than altering data directly. If a SQL script of this type is required, clients can request this via [IBM case ticket](https://www.ibm.com/mysupport), with sql script attached along with business justification as to why its needed and why changing from Maximo front end is not possible. There is a 3 day lead time for SQL scripts. The case needs to include:\n\n\n\n* SQL Script (as an attachment)\n* Design or description of what the script is doing to the data\n* Business justification of why the script is required\n* Technical justification of why the script's commands cannot be done via Maximo front end using DB configuration\n* Request to take full offline backup of target database prior to running script\n\n\n\nSQL Script Limitations:\n\n\n\n* SQL scripts cannot be run in Non-Production environments.\n* DBC Scripts are not allowed in any environment.\n* Backups will be done in offline mode which will require target site to be down / unavailable. Backups can take several hours based on database size.\n* IBM SRE team is not responsible for script not working, script corrections and any issues that arise during or after sql execution. If issues arise, IBM SRE can only restore from backup.\n* Any outages caused by the execution of the script and time to recover will not be counted as an SLA breach.\n\n\n\n\n\n\n\n How to Access IBM COS (Cloud Object Storage) Buckets \n\n\n\n* To access IBM COS bucket you have to configure Rclone. Rclone is the utility via which you can access IBM COS bucket(s) and upload/download the content.\n* To configure Rclone please use steps below.", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-support"}, {"document_id": "ibmcld_14050-6191-8276", "score": 0.6021757125854492, "text": "\nProvision script Provisioning scripts are commonly used to apply a customer-specific configuration to a server and to aid in automation of your scaling strategy. Provisioning scripts can be any file that the operating system (OS) can run, including combined binary files or any OS-supported language. Provisioning scripts can't be used on cloud-init images. For more information, see [Provisioning scripts](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-provisioning-scripts). \n User data You can add user data that automatically performs common configuration tasks or runs scripts. User data can be used on cloud-init and non-cloud-init images. \n\n\n\n\n\n\n\n Attached storage disks \n\nIf you need extra storage, you can attach storage disks to your instance. The type of storage disks that are available to you depend on the profile that you select. For example, balanced local profiles and a few of the GPU profiles use local storage disks. If you select monthly billing, you can add IBM Cloud Backup for Classic and choose the option that best fits your needs. For more information, see [IBM Cloud Backup for Classic services](https://cloud.ibm.com/docs/Backup?topic=Backup-getting-started).\n\n\n\n\n\n Network interface \n\n\n\nTable 3. Network interface options\n\n Field Details \n\n Uplink port speeds You can select the uplink speed for your instance, up to 1 Gbps. These virtual uplinks are backed by redundant physical uplinks to the IBM public and dedicated networks. The public and dedicated speed is always the same at the time of order, with the option to upgrade or downgrade a link if needed. If you select the 100 Mbps rate-limited option, the maximum instance throughput is limited only by the physical bandwidth available to the virtual server host. If you select the 1 Gbps non rate-limited option, you can achieve higher network performance through extra configuration. For more information, see [Configuring virtual server settings for improved network performance](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-configuring-network-performance).", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-ordering-vs-public"}, {"document_id": "ibmcld_07018-2125-3827", "score": 0.601494550704956, "text": "\n[Rich document preview](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/search-doc-preview-example.png)\n\nFigure 4. Rich document view\n\n[Try it](https://watson-developer-cloud.github.io/discovery-components/storybook/?path=/story/documentpreview--default)\n\n\n\n\n\n Deploying a project \n\nTo deploy your project, complete the following steps:\n\n\n\n1. To use the API, you need to know the project ID for your project. Go to the Integrate and Deploy > API Information page.\n2. From the Integrate and Deploy > UI Components page, find links to resources that a developer can use to get started.\n\n\n\n* [GitHub](https://github.com/watson-developer-cloud/discovery-componentsusing-discovery-components)\n* [Storybook](https://watson-developer-cloud.github.io/discovery-components/storybook/)\n\n\n\n\n\n\n\n\n\n Getting started with the GitHub sample app \n\nFrom resources available in GitHub, you can run a script to start a sample app with prebuilt UI components. In fact, the sample app looks a lot like the Improve and customize page of the product because the product itself uses these UI components.\n\nThe script requires some prerequisite software to function. After you start the script, it checks whether you have the necessary software installed on your system. If not, it lets you know what software you need to install. Install the following packages if they are not installed already:\n\n\n\n* [Node.js](https://nodejs.org/en/)\n* [Yarn](https://yarnpkg.com/getting-started/install)\n\n\n\nThe script needs information about your service instance and project to use the data and search settings that you configured for your project and apply them to the sample app.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-deploy"}, {"document_id": "ibmcld_16416-1312-2998", "score": 0.6008628606796265, "text": "\n* Download the [scripts](https://github.com/watson-developer-cloud/doc-tutorial-downloads/tree/master/knowledge-studio).\n* Review information about the script's use of the MinIO client. The client is required for the MinIO commands.\n\n\n\n* The scripts download the client from the [MinIO website](https://dl.min.io/) if the client isn't installed.\n* If you want the script to use your installed version, verify that you can run the client by issuing the command mc on the command line.\n\n\n\n\n\n\n\n\n\n all-backup-restore script \n\nThe all-backup-restore.sh script backs up and restores the MongoDB, PostgreSQL, and Minio databases, and PVC.\n\nUnless you only need to back up a single database, it is recommended that you use the all-backup-restore script, which deactivates and reactivates Knowledge Studio.\n\nThe script backs up or restores the data in the following order:\n\n\n\n1. MongoDB\n2. PostgreSQL\n3. MinIO\n4. PVC\n\n\n\nall-backup-restore.sh [backup|restore] [RELEASE_NAME] [BACKUP_DIR] [-n NAMESPACE]\n\nUse either the backup or restore command.\n\nbackup\n: Backs up each database to a subdirectory of the `BACKUP_DIR` directory.\n\nrestore\n: Restores the data from each database in the `BACKUP_DIR` directory.\n\n\n\n Arguments and options \n\nRELEASE_NAME\n: Required. The release name that was specified when the Knowledge Studio Helm chart was installed in your cluster.\n: You can find the release name as the prefix of the pod name, for example, {release_name}-ibm-watson-ks-yyy-xxx. For version 1.2.0, the value is always `wks`.\n\nBACKUP_DIR\n: Required. The base directory of each database where backups are stored to or restored from. Each database is stored in a subdirectory of the backup directory.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-backup-restore-databases-1.2.0"}, {"document_id": "ibmcld_16415-1339-3013", "score": 0.5974006056785583, "text": "\n* Review information about the script's use of the MinIO client. The client is used for the for MinIO commands.\n\n\n\n* The scripts download the client from the [MinIO website](https://dl.min.io/) if the client isn't installed.\n* If you want the script to use your installed version, verify that you can run the client by issuing the command mc on the command line.\n\n\n\n\n\n\n\n\n\n all-backup-command script \n\nThe all-backup-command script.sh script backs up or restores the MongoDB, PostgreSQL, Minio databases, and PVC.\n\nUnless you need to back up a single database, use the all-backup-command script, which deactivates and reactivates Knowledge Studio.\n\nThe script backs up or restores the data in the following order:\n\n\n\n1. MongoDB\n2. PostgreSQL\n3. MinIO\n4. PVC\n\n\n\nall-backup-restore.sh backup | restore RELEASE_NAME BACKUP_DIR -n NAMESPACE\n\nUse either the backup or restore command.\n\nbackup\n: Backs up each database to a subdirectory of the `BACKUP_DIR` directory.\n\nrestore\n: Restores the data from each database in the `BACKUP_DIR` directory.\n\n\n\n Arguments and options \n\nRELEASE_NAME\n: The release name that was specified when the Knowledge Studio Helm chart was installed in your cluster. Required.\n: For version 1.1.2, the value is `wks`.\n\nBACKUP_DIR\n: The base directory of each database where backups are stored to or restored from. Each database is stored in a subdirectory of the backup directory (`mongodb`, `postgresql`, `minio`, or `pvc`). Required.\n\n-n NAMESPACE\n: Namespace for the pods.\n: The default value is `zen`.\n\n\n\n\n\n Output \n\nThe script returns the following output:\n\n[SUCCESS] MongoDB,PostgreSQL,Minio,PVC\n\nand indicates either the backup or restore command.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-backup-restore-databases-1.1.2"}, {"document_id": "ibmcld_16416-13036-14549", "score": 0.5870783925056458, "text": "\nYou don't need to deactivate when you run the all-backup-restore.sh script because the script handles the process.\n\nTo ensure that users don't have access to Knowledge Studio when you back up or restore a single database, stop the Knowledge Studio front-end pods before you back up or restore data.\n\n\n\n1. Make sure that no training and evaluation processes are running. You can check job status with the following command:\n\nkubectl -n NAMESPACE get jobs\n\nTraining jobs of Knowledge Studio are named in the format wks-train-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxxx, and evaluation jobs are named in the format wks-batch-apply-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx. If the COMPLETIONS column of a training job reads 0/1, that job is still running. Wait until all of the training jobs finish.\n2. kubectl -n NAMESPACE patch --type=merge wks wks -p '{\"spec\":{\"global\":{\"quiesceMode\":true}}}' kubectl -n NAMESPACE patch --type=merge wks wks -p '{\"spec\":{\"mma\":{\"replicas\":0}}}'\n3. Ensure that no Knowledge Studio pods exist, except datastore pods, by running the following command (this may takes few minutes):\n\nkubectl -n NAMESPACE get pod | grep -Ev 'minio|etcd|mongo|postgresql|gw-instance|Completed' | grep wks\n\n\n\n\n\n\n\n Reactivate Knowledge Studio \n\nYou don't need to reactivate when you run the all-backup-restore.sh script because the script handles the process.\n\nTo reactivate Knowledge Studio, use the following command:\n\nkubectl -n NAMESPACE patch --type=merge wks wks -p '{\"spec\":{\"global\":{\"quiesceMode\":false}}}'", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-backup-restore-databases-1.2.0"}, {"document_id": "ibmcld_16414-1429-3030", "score": 0.5826689004898071, "text": "\n* The scripts download the client from the [MinIO website](https://dl.min.io/) if the client isn't installed.\n* If you want the script to use your installed version, verify that you can run the client by issuing the command mc on the command line.\n\n\n\n\n\n\n\n\n\n all-backup-restore script \n\nThe all-backup-restore.sh script backs up and restores the MongoDB, PostgreSQL, and Minio databases, and PVC.\n\nUnless you only need to back up a single database, it is recommended that you use the all-backup-restore script, which deactivates and reactivates Knowledge Studio.\n\nThe script backs up or restores the data in the following order:\n\n\n\n1. MongoDB\n2. PostgreSQL\n3. MinIO\n4. PVC\n\n\n\nall-backup-restore.sh [backup|restore] [RELEASE_NAME] [BACKUP_DIR] [-n NAMESPACE]\n\nUse either the backup or restore command.\n\n\n\n* backup\n\nBacks up each database to a subdirectory of the BACKUP_DIR directory.\n* restore\n\nRestores the data from each database in the BACKUP_DIR directory.\n\n\n\n\n\n Arguments and options \n\n\n\n* RELEASE_NAME\n\nRequired. The release name that was specified when the Knowledge Studio Helm chart was installed in your cluster.\n\nYou can find the release name as the prefix of the pod name, for example, {release_name}-ibm-watson-ks-yyy-xxx. For version 1.2.0, the value is always wks.\n* BACKUP_DIR\n\nRequired. The base directory of each database where backups are stored to or restored from. Each database is stored in a subdirectory of the backup directory. A new folder with timestamp wks-backup-yyyymmdd_hhmmss will be created under [backupDir], for example: [backupDir]/wks-backup-yyyymmdd_hhmmss/mongodb", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-backup-restore-databases"}, {"document_id": "ibmcld_00713-3844-4965", "score": 0.5794787406921387, "text": "\n[IBM Cloud Container Registry credentials](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/custom-image-private-repository.png)\n\nFigure 2. Authentication credentials\n\n\n\n\n\n\n\n Specifying the script \n\nYou can use the script block in custom Docker image jobs to create a script file that runs in a task folder, similar to how regular pipeline jobs work.\n\nENTRYPOINT and CMD from your Docker image's Dockerfile are overridden and are not called. In some cases that might mean that you need to add initialization steps to your script.\n\nCustom Docker image jobs give you greater flexibility over how to run your script; specifically, you can control the command interpreter. Typically, if the first line of the script begins with ! and the name of a command interpreter, that entry is used to run the commands in the job. If you do not specify a command interpreter, the default shell for the Docker image is used. Typically, !/bin/bash or !/bin/sh are used; image command interpreters for awk, node, and ruby also work if you specify an appropriate Docker image.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-custom_docker_images"}, {"document_id": "ibmcld_04262-10472-11599", "score": 0.5774906873703003, "text": "\nThe scripts create a Schematics workspace for you where you can see your script logs and the resources that are provisioned.\n\nIf you want to further customize your resources, you select Enable configuration customization after 'Create' and then Create. The scripts create the Schematics workspace for you and show you the parameters that you can customize. After you are done customizing the parameters, you select Generate Plan then Apply plan. The Terraform scripts run and create your resources.\n\nFor more information about Schematics, see [Getting started: IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-getting-started).\n\n\n\n\n\n Next steps \n\nAs the components are provisioned, you are directed to the Schematics workspace page for your deployment, where you can view the script logs.\n\nAfter the Citrix DaaS for IBM Cloud components are provisioned, you need to complete a few post-provisioning steps to get you up and running. For more information, see [Post-provisioning steps for Citrix DaaS on VPC](https://cloud.ibm.com/docs/citrix-daas?topic=citrix-daas-post-provisioning-citrix-daas-vpc).", "title": "", "source": "https://cloud.ibm.com/docs/citrix-daas?topic=citrix-daas-provisioning-citrix-daas-vpc"}, {"document_id": "ibmcld_06731-4489-6384", "score": 0.5698565244674683, "text": "\nIf you don\u2019t know the password for your deployment, either get that from your generated service credentials or you can create a new password by running:\n\nibmcloud cdb deployment-user-password <Redis deployment name> admin <new password>\n\nWith this information, you have what you need for the destination and the source databases.\n\n\n\n\n\n Running the script and migrating data \n\nSince you have all the credentials for both databases (source and new Databases for Redis destination), you're now ready to run the script. The Python script file name is pymigration.py. All you need to do now is run the code from your terminal by using the credentials from the prior steps:\n\npython pymigration.py <source host> <source password> <source port>\n<destination host> <destination password> <destination port>\n<destination ca certificate path> --sslsrc --ssldst\n\nSince you are copying data from a Databases for Redis database, you need to add the --sslsrc flag if your Databases for Redis database is SSL/TLS enabled. If it isn\u2019t, then don\u2019t add the flag. This makes sure that Redis is connecting to a SSL/TLS enabled database. You also need to add --ssldst since the destination database is your new Databases for Redis which also is SSL/TLS enabled. Supplementary flags that you might add are --db and --flush. Using --db, you can indicate the database that your keys are copied from, which is the database that they recopied into in your new Databases for Redis deployment. The --flush flag flushes the destination database before importing the keys from the source database. If you want to keep things fresh in your new Databases for Redis deployment, flush will delete all the keys first then import the new keys from your source database.\n\nRunning the aformentioned script that uses OldDB as the source for the data migration and NewDB as the destination for the migrated data, you get something like:", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-upgrading"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04481-1349-2997", "score": 0.6111065149307251, "text": "\n* For Linux\u2122, extract the package and run the install script.\n\n\n\n3. Log in to IBM Cloud:\n\nibmcloud login\n\nNow, you're ready to manage IBM Cloud resources. Enter ibmcloud help to view the command descriptions.\n\nIf you're using a federated ID, [log in with a one-time passcode or an API key](https://cloud.ibm.com/docs/account?topic=account-federated_id).\n\n\n\n\n\n\n\n Installing from the shell \n\nTo install the latest CLI for your OS from the shell manually, use the following command for your OS:\n\nIf you don't want to install from the shell because it might utilize root permissions, you can [download and run the installer](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cliibmcloud-cli-installer).\n\n\n\n* For Mac, copy and paste the following command to a terminal and run it:\n\ncurl -fsSL https://clis.cloud.ibm.com/install/osx | sh\n* For Linux\u2122, copy and paste the following command to a terminal and run it:\n\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n* For Windows\u2122, copy and paste the following command to a [Windows\u2122 PowerShell](https://msdn.microsoft.com/en-us/powershell/scripting/getting-started/getting-started-with-windows-powershell) terminal console and run it:\n\niex (New-Object Net.WebClient).DownloadString('https://clis.cloud.ibm.com/install/powershell')\n\nIf you encounter errors like The underlying connection was closed: An unexpected error occurred on a send, make sure you have .Net Framework 4.5 or later installed. Also try to enable TLS 1.2 protocol by running the following command:\n\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n\n\n\n\n\n\n\n Installing to a custom directory", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli"}, {"document_id": "ibmcld_03009-7-1439", "score": 0.6044832468032837, "text": "\nInstalling \n\nLearn how to install Watson Assistant for IBM Cloud Pak\u00ae for Data.\n\nThe IBM Cloud Pak for Data environment is a Kubernetes-based container platform that can help you quickly modernize and automate workloads that are associated with the applications and services you use. You can develop and deploy on your own infrastructure and in your data center which helps to mitigate risk and minimize vulnerabilities.\n\nThe installation process differs depending on the version you are installing. The following table shows the available versions.\n\n\n\nAvailable versions\n\n Version Cluster Installation instructions \n\n 4.7.0 IBM Cloud Pak for Data 4.7.x [Installing 4.7.0](https://www.ibm.com/docs/SSQNUZ_4.7.x/svc-assistant/assistant-svc-install.html) \n 4.6.5 IBM Cloud Pak for Data 4.6.x [Installing 4.6.5](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-assistant/assistant-svc-install.html) \n 4.6.3 IBM Cloud Pak for Data 4.6.x [Installing 4.6.3](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-assistant/assistant-svc-install.html) \n 4.6.2 IBM Cloud Pak for Data 4.6.x [Installing 4.6.2](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-assistant/assistant-svc-install.html) \n 4.6.0 IBM Cloud Pak for Data 4.6.x [Installing 4.6.0](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-assistant/assistant-svc-install.html) \n 4.5.3 IBM Cloud Pak for Data 4.5.x [Installing 4.5.3](https://www.ibm.com/docs/SSQNUZ_4.5.x/svc-assistant/assistant-svc-install.html)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-install"}, {"document_id": "ibmcld_05171-3109-4618", "score": 0.5930631756782532, "text": "\nGo ahead and create a Docker account online at [Docker hub](https://hub.docker.com), run the Docker app, and sign in.\n\n\n\n\n\n Installing Node.js \n\nThe app that you build uses [Node.JS](https://nodejs.org/) as the server-side engine to run the JavaScript code for this web application. To use the Node Package Manager (npm) to manage your app's dependencies, you must install Node locally. Also, a local installation of Node simplifies testing, speeding up development.\n\nBefore you start, you might consider a version manager, like Node Version Manager, or nvm, to install Node. A version manager reduces the complexity of managing different versions of Node.js.\n\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n\n...or wget (just one is necessary, but not both; use whichever is available on your system):\n\nwget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n\nOr, for Windows, you can use [nvm for Windows](https://github.com/coreybutler/nvm-windows) with installers and source code at the link.\n\nUsing nvm, install Node.\n\nnvm install v6.17.1\n\nWhichever approach you use after you install Node.js and npm (included with Node) on your computer, congratulate yourself on a job well started!\n\n\n\n\n\n Installing Git \n\nYou're probably already familiar with Git, as it's the most widely used source code versioning system. We use Git later when we create a Continuous Deployment (CD) Toolchain in the IBM Cloud Platform for continuous delivery and deployment.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_04727-3143-4678", "score": 0.59003746509552, "text": "\nLog in with root.\n2. Run yum -y install rsync.\n\n\n\n\n\n\n\n\n\n Windows systems \n\nComplete the following steps to install rsync on your Windows 2012, 2012R2, or 2016 system.\n\n\n\n1. Download Cygwin setup-x86_64 ([https://cygwin.com/install.html](https://cygwin.com/install.html)).\n2. Install downloaded setup ([https://cygwin.com/setup-x86_64.exe](https://cygwin.com/setup-x86_64.exe)).\n3. Follow through all of the steps until you see a list of all Linux packages.\n4. Select rsync (in net category section).\n5. Select OpenSSH (in net category section).\n6. Click Continue and finish installation.\n7. Open \u2018Cygwin Terminal\u2019, type rsync command, and press enter.\n8. If the output shows rsync command details with options, then it is installed.\n\n\n\n\n\n\n\n\n\n Step 3: Install OpenSSH \n\n\n\n Linux systems \n\nIf you have a Linux system, you don't need to install OpenSSH because it is installed by default.\n\n\n\n\n\n Windows systems \n\n\n\n Windows 2016 \n\nTo install OpenSSH on your Windows 2016 system, review the following information:\n\n\n\n1. Microsoft's documentation on [Installation of OpenSSH for Windows Server 2019 and Windows 10](https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse)\n2. GitHub instructions on [Installation of OpenSSH for Windows](https://github.com/MicrosoftDocs/windowsserverdocs/blob/master/WindowsServerDocs/administration/OpenSSH/OpenSSH_Install_FirstUse.md)\n\n\n\n\n\n\n\n Windows 2012 and 2012R2 \n\nTo install OpenSSH on your Windows 2012 or 2012R2 system, review the following information:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-data-migration-classic-to-vpc"}, {"document_id": "ibmcld_13929-10674-12012", "score": 0.5856741666793823, "text": "\n[AMI Installation Guide, 17.2.0](https://public.dhe.ibm.com/cloud/bluemix/network/vra/18_vrouter_ami_installation_5600.pdf) This guide describes how to install AT&T Vyatta vRouter Amazon Machine Image (AMI) within the Amazon Web Services (AWS) cloud. \n [Deployment Options Configuration Guide, 17.2.0](https://public.dhe.ibm.com/cloud/bluemix/network/vra/18_vrouter_deployment_options_configuration_5600.pdf) This guide describes deployment options for the AT&T Vyatta vRouter. \n [Hard Disks and Persistent Devices Installation Guide, 17.2.0](https://public.dhe.ibm.com/cloud/bluemix/network/vra/18_vrouter_hard_disks_and_persistent_devices_installation_5600.pdf) This guide describes how to install and upgrade software on a persistent device, such as hard disk, flash drive, or USB stick on AT&T products that run on the AT&T Vyatta Network Operating System. \n [Hyper-V Installation Guide, 17.2.0](https://public.dhe.ibm.com/cloud/bluemix/network/vra/18_vrouter_hyper-v_installation_5600.pdf) This guide describes how to install and upgrade the AT&T Vyatta vRouter running on Hyper-V systems. \n [Linux KVM Installation Guide, 17.2.0](https://public.dhe.ibm.com/cloud/bluemix/network/vra/18_vrouter_linux_kvm_installation_5600.pdf) This guide describes how to install and upgrade the AT&T Vyatta vRouter running on Linux KVM environment.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-supplemental-vra-documentation"}, {"document_id": "ibmcld_05173-10345-12132", "score": 0.5788410902023315, "text": "\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/install/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/install/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-pak-data"}, {"document_id": "ibmcld_05174-10419-12206", "score": 0.5788410902023315, "text": "\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/install/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https://www.ibm.com/docs/SSQNUZ_4.6.x/cpd/install/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-pak-data?topic=cloud-pak-data-getting-started"}, {"document_id": "ibmcld_14711-958-2813", "score": 0.578099250793457, "text": "\nAn optional step is included to [install the Ansible NSX-T collections](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sag-ansibleveeam-cr-sag-ansible-nsxt). The optional step is needed only if Ansible\u00ae is used to create sandboxes.\n\n\n\n Installing Ansible \n\nAt a command line on the automation server, run the following commands.\n\nsudo apt update\nsudo apt install ansible -y\nsudo apt install python3-pip -y\nansible --version\n\nThese commands are used for the following items:\n\n\n\n* Refresh the system\u2019s package index.\n* Install the Ansible\u00ae software.\n* Install the pip package that is required for the use if WinRM with Ansible.\n* Verify that Ansible is installed.\n\n\n\n\n\n\n\n Adding Ansible collections \n\nAnsible collections are extra modules. In this deployment, use the following commands to add the required collections:\n\nansible-galaxy collection install ansible.posix\nansible-galaxy collection install community.general\nansible-galaxy collection install ansible.windows\nansible-galaxy collection install community.windows\nansible-galaxy collection install juniper.device\nansible-galaxy collection install junipernetworks.junos\n\nThe juniper.device and junipernetworks.junos collections are required only if you are building an isolated recovery environment.\n\n\n\n\n\n Creating an Ansible inventory file \n\n\n\n1. Create a directory structure for the Ansible files and create an initial inventory file to test Ansible connections to the Ansible hosts. Use the following commands, when connected as the ansible user:\n\nsudo mkdir /swlib\nsudo mkdir /swlib/ansible\n2. Create an inventory file called hosts that has two groups: [LHBR] and [VBR], with the IP addresses or FQDN of the Linux\u00ae hardened repository and Veeam\u00ae backup server:\n\ntouch /swlib/ansible/hosts\nvi /swlib/ansible/hosts\n\n\n\n\n\n Examples \n\nA hosts file for the immutable backup.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sag-ansible"}, {"document_id": "ibmcld_13114-9694-10905", "score": 0.5763397812843323, "text": "\nInstall Docker Engine - Community for Ubuntu following the instructions from [https://docs.docker.com/install/linux/docker-ce/ubuntu/](https://docs.docker.com/install/linux/docker-ce/ubuntu/).\n3. Verify the installation with:\n\ndocker --version\nsudo docker run hello-world\n\nTo run Docker under your own user instead of root, perfom the [post install](https://docs.docker.com/install/linux/linux-postinstall/) steps.\n\n\n\n\n\n\n\n kubectl \n\n\n\n1. Download kubectl from\n\n[https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl/install-kubectl-on-linux).\n2. Make the kubectl binary executable.\n\nchmod +x ./kubectl\n3. Move the binary to your PATH.\n\nsudo mv ./kubectl /usr/local/bin/kubectl\n4. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/).\n2. Extract openshift-client-linux.tar.gz:\n\ntar zxvf openshift-client-linux.tar.gz oc\n3. Move the oc binary to your PATH.\n\nsudo mv ./oc /usr/local/bin/oc\n4. Verify the installation with:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials"}, {"document_id": "ibmcld_13168-9904-11115", "score": 0.5763397812843323, "text": "\nInstall Docker Engine - Community for Ubuntu following the instructions from [https://docs.docker.com/install/linux/docker-ce/ubuntu/](https://docs.docker.com/install/linux/docker-ce/ubuntu/).\n3. Verify the installation with:\n\ndocker --version\nsudo docker run hello-world\n\nTo run Docker under your own user instead of root, perfom the [post install](https://docs.docker.com/install/linux/linux-postinstall/) steps.\n\n\n\n\n\n\n\n kubectl \n\n\n\n1. Download kubectl from\n\n[https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl/install-kubectl-on-linux).\n2. Make the kubectl binary executable.\n\nchmod +x ./kubectl\n3. Move the binary to your PATH.\n\nsudo mv ./kubectl /usr/local/bin/kubectl\n4. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/).\n2. Extract openshift-client-linux.tar.gz:\n\ntar zxvf openshift-client-linux.tar.gz oc\n3. Move the oc binary to your PATH.\n\nsudo mv ./oc /usr/local/bin/oc\n4. Verify the installation with:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11889-0-903", "score": 0.6716049909591675, "text": "\n\n\n\n\n\n\n  Setting up cluster groups \n\nThe cluster group specifies all clusters that you want to include in the deployment of your Kubernetes resources. The clusters can run in your Satellite location or in IBM Cloud.\n\nIf you want to use the console to create Satellite configurations, you can create cluster groups as part of the configuration creation process. If you want to use the CLI to create Satellite configurations, you must create a cluster group first. Follow these steps to create a cluster group with the CLI:\n\n\n\n1.  List the clusters that are registered with the Satellite Config component and note their ID.\n\nibmcloud sat cluster ls\n2.  Add the cluster to your cluster group.\n\nibmcloud sat group attach --cluster <cluster_ID> --group <cluster_group_name>\n3.  Verify that your cluster is successfully added to your cluster group.\n\nibmcloud sat group get --group <cluster_group_name>\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-setup-clusters-satconfig-groups"}, {"document_id": "ibmcld_14619-7-2038", "score": 0.6324326992034912, "text": "\nDeleting clusters from vCenter Server instances \n\nYou can delete clusters from VMware vCenter Server\u00ae instances when you do not need them.\n\nDeleting clusters from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n\n\n\n Before you delete clusters from vCenter Server instances \n\n\n\n* Whenever possible, delete clusters by using the IBM Cloud\u00ae for VMware Solutions console and not the VMware vSphere\u00ae Web Client. Changes that you make on the vSphere Web Client are not synchronized with the VMware Solutions console. If you want to delete clusters from vCenter Server instances by using the vSphere Web Client, do so only for on-premises clusters or clusters that you don't manage in the VMware Solutions console.\n* You can delete any cluster except for the first cluster (the one that is created during initial deployment).\n* You can delete multiple clusters at a time. You can also delete a cluster while another cluster is being created or deleted.\n* Ensure that all nodes in a cluster are powered on and operational before you delete the cluster.\n* When you delete a cluster, all VMs from the cluster are also deleted and they can't be recovered. If you want to keep the VMs, migrate them to other clusters.\n* When you delete a cluster, all storage and subnets that are associated with the cluster are deleted as well. To view the storage and subnets that are associated with a cluster, see the cluster details page.\n* You do not have to delete any services that are installed on the cluster, including services on a gateway cluster. The services are automatically deleted when you delete the cluster.\n\n\n\n\n\n\n\n Procedure to delete clusters from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance that you want to delete clusters from.\n\nEnsure that the instance status is Available. Otherwise, you can't delete clusters from the instance.\n3. Click the Infrastructure tab.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_deletingclusters"}, {"document_id": "ibmcld_10290-51818-53668", "score": 0.6130601763725281, "text": "\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--show-resources\n: Show more cluster resources such as add-ons, VLANs, subnets, and storage.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster get command \n\nibmcloud oc cluster get --cluster my_cluster --show-resources\n\n\n\n\n\n\n\n ibmcloud oc cluster image-security disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable [image security enforcement](https://cloud.ibm.com/docs/openshift?topic=openshift-imagesportieris-image-sec). When you disable the feature, the underlying ClusterImagePolicy CRD is removed, which removes all the default image policies and any custom images policies that you created.\n\nibmcloud oc cluster image-security disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster image-security disable command \n\nibmcloud oc cluster image-security disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud oc cluster image-security enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable [image security enforcement](https://cloud.ibm.com/docs/openshift?topic=openshift-imagesportieris-image-sec) by installing the Portieris Kubernetes admission controller and the associated default image policies in your cluster.\n\nibmcloud oc cluster image-security enable --cluster CLUSTER [-f] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_05638-1360-3085", "score": 0.6044236421585083, "text": "\nIf the issue persists when creating additional clusters, open an [IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud ks worker ls --cluster <cluster_name_or_ID>. If worker nodes are listed, see [Unable to create or delete worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-cluster_infra_errors). If no workers are listed, open an [IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help).\n\n\n\n\n\n Deleted \n\nReview the following description of the Deleted cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is deleted but not yet removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help).\n\n\n\n\n\n Deleting \n\nReview the following description of the Deleting cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is being deleted and cluster infrastructure is being dismantled. You can't access the cluster.\n\n\n\n\n\n Deploy failed \n\nReview the following description of the Deploy failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe deployment of the Kubernetes master can't be completed. You can't resolve this state.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cluster-states-reference"}, {"document_id": "ibmcld_05638-7-1853", "score": 0.5989052057266235, "text": "\nCluster states \n\nYou can view the current cluster state by running the ibmcloud ks cluster ls command and locating the State field.\n\n\n\n Aborted \n\nReview the following description of the Aborted cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nYou sent a delete request before the Kubernetes master deployment completed. After your cluster is deleted, it is removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help).\n\n\n\n\n\n Critical \n\nReview the following description of the Critical cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master can't be reached or all worker nodes in the cluster are down. If you enabled IBM Key Protect in your cluster, the Key Protect container might fail to encrypt or decrypt your cluster secrets. If so, you can view an error with more information when you run kubectl get secrets.\n\n\n\n\n\n Create failed \n\nReview the following description of the Create failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster cannot be created. Delete the failed cluster and try to create another one. If the issue persists when creating additional clusters, open an [IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud ks worker ls --cluster <cluster_name_or_ID>.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cluster-states-reference"}, {"document_id": "ibmcld_10041-5131-6632", "score": 0.5986456274986267, "text": "\nDELETE/v1/clusters/{idOrName}/usersubnets/{subnetId}/vlans/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET/v1/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/apiserverconfigs/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET/v1/clusters/{idOrName}/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/services/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/webhooks List all webhooks for a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-api-at-iam"}, {"document_id": "ibmcld_05567-5113-6614", "score": 0.5986456274986267, "text": "\nDELETE/v1/clusters/{idOrName}/usersubnets/{subnetId}/vlans/{vlanId} Remove a user-managed subnet from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.vlan.delete \n GET/v1/clusters List the clusters that you have access to. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName} View details for a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/addons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/apiserverconfigs/auditwebhook View details for an audit webhook configuration. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/config Get the cluster-specific configuration and certificates. containers-kubernetes.cluster.read containers-kubernetes.cluster.config \n GET/v1/clusters/{idOrName}/services List the IBM Cloud services bound to a cluster across all namespaces. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/services/{namespace} List the IBM Cloud services bound to a specific namespace in a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/webhooks List all webhooks for a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-api-at-iam"}, {"document_id": "ibmcld_10094-7-1844", "score": 0.5970830917358398, "text": "\nCluster states \n\nYou can view the current cluster state by running the ibmcloud oc cluster ls command and locating the State field.\n\n\n\n Aborted \n\nReview the following description of the Aborted cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nYou sent a delete request before the Kubernetes master deployment completed. After your cluster is deleted, it is removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https://cloud.ibm.com/docs/openshift?topic=openshift-get-help).\n\n\n\n\n\n Critical \n\nReview the following description of the Critical cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master can't be reached or all worker nodes in the cluster are down. If you enabled IBM Key Protect in your cluster, the Key Protect container might fail to encrypt or decrypt your cluster secrets. If so, you can view an error with more information when you run oc get secrets.\n\n\n\n\n\n Create failed \n\nReview the following description of the Create failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster cannot be created. Delete the failed cluster and try to create another one. If the issue persists when creating additional clusters, open an [IBM Cloud support case](https://cloud.ibm.com/docs/openshift?topic=openshift-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud oc worker ls --cluster <cluster_name_or_ID>.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-states-reference"}, {"document_id": "ibmcld_10042-2889-4827", "score": 0.5869340896606445, "text": "\ncontainers-kubernetes.cluster-private-service-endpoint.disable The private cloud service endpoint for a cluster is disabled. \n containers-kubernetes.cluster-private-service-endpoint.enable The private cloud service endpoint for a cluster is enabled. \n containers-kubernetes.cluster-public-service-endpoint.disable The public cloud service endpoint for a cluster is disabled. \n containers-kubernetes.cluster-public-service-endpoint.enable The public cloud service endpoint for a cluster is enabled. \n containers-kubernetes.cluster-pull-secret.enable An image pull secret to IBM Cloud Container Registry is created in the default project of the cluster. \n containers-kubernetes.cluster-rbac.apply IBM Cloud IAM service access roles are synchronized with Kubernetes RBAC roles in the cluster. This event commonly happens while retrieving the Kubernetes configuration file (kubeconfig) for a cluster (the containers-kubernetes.cluster.config event). \n containers-kubernetes.cluster-rbac.update The IBM Cloud IAM service access roles are synchronized with Kubernetes RBAC roles in the cluster. This event commonly happens after you update the service access role for a user in IAM. \n containers-kubernetes.cluster-rbac.status The status of the RBAC roles in the cluster is retrieved. \n containers-kubernetes.cluster-service.bind An IBM Cloud service is bound to the cluster. \n containers-kubernetes.cluster-service.list The IBM Cloud services that are bound to a cluster are listed. The list might be filtered by the cluster project. \n containers-kubernetes.cluster-service.unbind An IBM Cloud service is removed from the cluster. \n containers-kubernetes.cluster-subnet.add A public or private portable subnet is added to a cluster. \n containers-kubernetes.cluster-subnet.create A public or private subnet is created for the cluster. \n containers-kubernetes.cluster-subnet.detach A public or private portable subnet is detached from a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-at_events"}, {"document_id": "ibmcld_10041-6268-7781", "score": 0.5854655504226685, "text": "\nGET/v1/clusters/{idOrName}/subnets List subnets from your IBM Cloud infrastructure account that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/usersubnets List user-managed subnets that are bound to a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/webhooks List all webhooks for a cluster. containers-kubernetes.cluster.read N/A \n GET/v1/clusters/{idOrName}/workerpools List the worker pools in a cluster. containers-kubernetes.cluster.read N/A \n GET/v2/classic/getCluster Get detailed cluster information. containers-kubernetes.cluster.read N/A \n GET/v2/classic/getClusters List the classic clusters that you have access to. containers-kubernetes.cluster.read N/A \n GET/v2/classic/getVLANs List available classic infrastructure VLANs for a zone. containers-kubernetes.cluster.read N/A \n GET/v2/getCluster View details for a cluster. containers-kubernetes.cluster.read N/A \n GET/v2/getClusterAddons View details of the add-ons that are enabled in a cluster. containers-kubernetes.cluster.read N/A \n GET/v2/getCRKs List the root keys for a key management service (KMS) instance. containers-kubernetes.cluster.read N/A \n GET/v2/getFlavors List available flavors types for a VPC zone (data center). N/A N/A \n GET/v2/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N/A \n GET/v2/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-api-at-iam"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04334-199697-200931", "score": 0.7860506772994995, "text": "\n<-- </section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- </section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- </section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-152301-153381", "score": 0.7519306540489197, "text": "\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- </section \"id=\"section-command-options-origin-certificate-delete\" \"> --><-- <section \"id=\"section-command-example-origin-certificate-delete\" \"> --> Examples Delete origin certificate a5836c2a7ea72d2e225890caea70ae32. ibmcloud cis origin-certificate-delete 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 -i cis-demo\n<-- </section \"id=\"section-command-example-origin-certificate-delete\" \"> --><-- </section \"id=\"section-origin-certificate-delete\" \"> --><-- </section \"id=\"section-origin-certificates-cli-ref\" \"> --><-- <section \"id=\"section-overview\" \"> --> Overview View the overview information for a domain.<-- <section \"id=\"section-get-overview\" \"> --> ibmcloud cis overview Show the overview information for a domain. ibmcloud cis overview DNS_DOMAIN_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! ! ! !\n<-- <section \"id=\"section-get-overview-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.-i, --instance: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04186-18298-19703", "score": 0.7443088293075562, "text": "\n[Page Rules](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cis"}, {"document_id": "ibmcld_04334-230067-231067", "score": 0.7418041825294495, "text": "\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- </section \"id=\"section-delete-cert-options\" \"> --><-- <section \"id=\"section-delete-cert-examples\" \"> --> Examples Delete custom certificate 5a7805061c76ada191ed06f989cc3dac. ibmcloud cis certificate-delete 31984fea73a15b45779fa0df4ef62f9b 5a7805061c76ada191ed06f989cc3dac -i \"cis-demo\"\n<-- </section \"id=\"section-delete-cert-examples\" \"> --><-- </section \"id=\"section-delete-cert\" \"> --><-- </section \"id=\"section-tls\" \"> --><-- <section \"id=\"section-waf\" \"> --> Web application firewall (WAF) Manage Web Application Firewalls by using the following waf commands.<-- <section \"id=\"section-show-waf-setting\" \"> --> ibmcloud cis waf-setting Show WAF setting. ibmcloud cis waf-setting DNS_DOMAIN_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-show-waf-setting-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.-i, --instance: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_01391-18343-19753", "score": 0.728363037109375, "text": "\n[Page Rules](https://cloud.ibm.com/docs-content/v1/content/cbb80bf851fb762a838129cba09d5674f8bfffda/Registry/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-multi-region-k8s-cis"}, {"document_id": "ibmcld_04334-85221-86244", "score": 0.7279267907142639, "text": "\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- </section \"id=\"section-delete-a-firewall-rule-options\" \"> --><-- <section \"id=\"section-delete-a-firewall-rule-examples\" \"> --> Examples Delete firewall-rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis firewall-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- </section \"id=\"section-delete-a-firewall-rule-examples\" \"> --><-- </section \"id=\"section-delete-a-Firewall-rule\" \"> --><-- <section \"id=\"section-validate-a-firewall-rule-expression\" \"> --> ibmcloud cis firewall-rule-validate Validate a firewall-rule expression. ibmcloud cis firewall-rule-validate DNS_DOMAIN_ID EXPRESSION -i, --instance INSTANCE] ! ! ! ! ! ! ! !\n<-- <section \"id=\"section-validate-a-firewall-rule-expression-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.EXPRESSION: The filter expression. For example, ip.src eq 93.184.216.0. Required.-i, --instance: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-151724-152727", "score": 0.7270171046257019, "text": "\n<-- </section \"id=\"section-command-example-origin-certificate\" \"> --><-- </section \"id=\"section-origin-certificate\" \"> --><-- <section \"id=\"section-origin-certificate-delete\" \"> --> ibmcloud cis origin-certificate-delete Delete an origin certificate. ibmcloud cis origin-certificate-delete DNS_DOMAIN_ID CERT_ID --instance INSTANCE_NAME] ! ! ! ! ! ! ! !\n<-- <section \"id=\"section-command-options-origin-certificate-delete\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.CERT_ID: The ID of Origin Certificate. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- </section \"id=\"section-command-options-origin-certificate-delete\" \"> --><-- <section \"id=\"section-command-example-origin-certificate-delete\" \"> --> Examples Delete origin certificate a5836c2a7ea72d2e225890caea70ae32. ibmcloud cis origin-certificate-delete 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 -i cis-demo", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-285779-286748", "score": 0.7249262928962708, "text": "\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.-f, --force: Attempt to delete policy without prompting for confirmation.<-- </section \"id=\"section-delete-alert-policy-options\" \"> --><-- <section \"id=\"section-delete-alert-policy-examples\" \"> --> Examples delete an alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy delete a2633e68-1a64-2512-a321-b64a17c7db7a -f -i \"cis-demo\"\n<-- </section \"id=\"section-delete-alert-policy-examples\" \"> --><-- </section \"id=\"section-delete-alert-policy\" \"> --><-- </section \"id=\"section-alert-policy\" \"> --><-- <section \"id=\"section-alert-webhook\" \"> --> Alert Webhook <-- <section \"id=\"section-list-alert-webhooks\" \"> --> ibmcloud cis alert-webhooks List all alert webhooks. ibmcloud cis alert-webhooks -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-list-alert-webhooks\" \"> --> Command options -i, --instance: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_07578-755905-757955", "score": 0.7186858654022217, "text": "\nYou can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https://cloud.ibm.com/docs/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_04334-198873-200152", "score": 0.7163265347480774, "text": "\n<-- </section \"id=\"section-set-context-cis-service-examples\" \"> --><-- </section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- </section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04195-6086-8151", "score": 0.8085662722587585, "text": "\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https://en.wikipedia.org/wiki/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-set-up-your-dns-for-cis"}, {"document_id": "ibmcld_04149-3050-4970", "score": 0.7899518609046936, "text": "\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04166-1564-3481", "score": 0.74848473072052, "text": "\nA non-CIS domain cannot CNAME to a CIS domain unless the non-CIS domain is added to a CIS account.\n\nAttempting to directly access DNS records used for CIS CNAME setups also causes error 1001.\n\nDisable Always Online if using Custom Hostnames (SSL for SaaS).\n\n\n\n\n\n\n\n Error 1002: DNS points to Prohibited IP \n\nCommon causes for 1002 errors when a DNS points to a prohibited IP address are:\n\n\n\n* A DNS record in your CIS DNS points to one of CIS's IP addresses.\n* An incorrect target is specified for a CNAME record in your CIS DNS.\n* Your domain is not on CIS but has a CNAME that refers to a CIS domain.\n\n\n\n\n\n Resolution \n\nUpdate your CIS A or CNAME record to point to your origin IP address instead of a CIS IP address:\n\n\n\n1. Contact your hosting provider to confirm your origin IP address or CNAME record target.\n2. Log in to your CIS account.\n3. Select the domain that generates error 1002.\n4. Select the DNS app.\n5. Click Value for the A record to update.\n6. Update the A record.\n\n\n\nTo ensure your origin web server doesn\u2019t proxy its own requests through CIS, configure your origin webserver to resolve your CIS domain to:\n\n\n\n* The internal NAT-ed IP address, or\n* The public IP address of the origin web server.\n\n\n\n\n\n\n\n\n\n Error 1002: Restricted \n\nThe most common cause of 1002: Restricted errors is when the CIS domain resolves to a local or disallowed IP address or an IP address not associated with the domain.\n\n\n\n Resolution \n\nIf you own the website:\n\n\n\n1. Confirm your origin web server IP addresses with your hosting provider\n2. Log in to your CIS account\n3. Update the A records in the CIS DNS to the IP address confirmed by your hosting provider\n\n\n\n\n\n\n\n\n\n Error 1003 Access Denied: Direct IP Access Not Allowed \n\nThe most common cause of 1003 errors is when a client or browser directly accesses a CIS IP address.\n\n\n\n Resolution \n\nBrowse to the website domain name in your URL instead of the CIS IP address.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-html-1xxx-errors"}, {"document_id": "ibmcld_04145-3314-5349", "score": 0.7469208240509033, "text": "\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n\n\n\n\n\n Who is the registrar for my domain? \n\nConsult [https://whois.icann.org/](https://whois.icann.org/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n\n\n\n\n\n I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS? \n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-faq"}, {"document_id": "ibmcld_04149-4598-6150", "score": 0.7417334318161011, "text": "\nIf you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS. See [Managing DNS records in Cloudflare](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/) for detailed instructions by provider.\n\nAfter you configure your registrar or DNS provider, it can take up to 24 hours for the changes to take effect. When we verify that the specified name servers were configured correctly for your domain or subdomain, the domain's status changes from Pending to Active.\n\nYour domain must move to Active state within 60 days or your domain and any configuration data is removed.\n\n\n\n\n\n Step 5. Ensure that CIS is resolving the domain information for your application, hostname, or website \n\nTo proceed, select Reliability > DNS. Be sure to add the appropriate DNS records. Add the A Record and any AAAA or MX entries that are populated. If you forget to add these records before the registrar's delegation is complete, IBM Cloud Internet Services cannot resolve the domain information for your internet-facing applications.\n\n\n\n\n\n\n\n Next steps \n\nTo begin managing CIS functions and features, see [Managing your IBM Cloud Internet Services deployment](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04334-25771-26954", "score": 0.7409489154815674, "text": "\nCreate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-update \n\nUpdate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID [--type TYPE] [--name NAME] [--content CONTENT] [--proxied PROXIED] [--ttl TTL] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-21927-23195", "score": 0.7359062433242798, "text": "\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.\n\n--ttl\n: Time to live for DNS record. Value of 1 is automatic. The default value is 1.\n\n--proxied\n: Control whether or not traffic should flow through the security and performance functions on CIS. CIS only proxies traffic for A, AAAA, and CNAME records. Valid values: true, false.\n\n--json\n: The JSON file or JSON string used to describe a DNS Record. Supported DNS Record types are: A, AAAA, CNAME, NS, TXT, MX, LOC, SRV, CAA, PTR.\n\n\n\n* For type A, AAAA, CNAME, NS, TXT:\n\n\n\n* The required fields in JSON data are name, type, content.\n* The optional fields are ttl, proxied:\n\n\n\n* proxied Control whether traffic should flow through the security and performance functions on CIS. CIS only proxies traffic for A,AAAA, and CNAME records.\n\n\n\n\n\n\n\nSample JSON data:\n\n{\n\"name\": \"testA\",\n\"type\": \"A\",\n\"content\": \"127.0.0.1\",\n\"proxied\": true\n}\n\n{\n\"name\": \"testAAAA\",\n\"type\": \"AAAA\",\n\"content\": \"2001:0db8:0012:0001:3c5e:7354:0000:5db1\",\n\"proxied\": false\n}\n\n{\n\"name\": \"testCNAME\",\n\"type\": \"CNAME\",", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04148-0-1895", "score": 0.7345467209815979, "text": "\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-get-started-new-subdomain"}, {"document_id": "ibmcld_08871-54071-55066", "score": 0.7339468598365784, "text": "\ndns_records_import](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_dns_records_import)<br> * [ibm_cis_domain](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_domain)<br> * [ibm_cis_domain_settings](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_domain_settings)<br> * [ibm_cis_edge_functions_action](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_edge_functions_action)<br> * [ibm_cis_edge_functions_trigger](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_edge_functions_trigger)<br> * [ibm_cis_filter](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_filter)<br> * [ibm_cis_firewall](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_firewall)<br> * [ibm_cis_firewall_rules](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cis_firewall_rules", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-resources-datasource-list"}, {"document_id": "ibmcld_07446-1341-2194", "score": 0.730133056640625, "text": "\n* Wildcard records are only allowed for the following record types.\n\n\n\n* A\n* AAAA\n* CNAME\n* MX\n\n\n\n* PTR records are not supported for A and AAAA type wildcard records.\n* [Importing DNS records](https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-managing-dns-zonesimport-resource-records-api) does not support wildcard records.\n* To avoid causing conflicts when importing a DNS zone file, do not create or delete DNS records until the import is complete.\n* When importing a DNS zone file, ensure that no other import operations occur that might cause a conflict.\n\n\n\n\n\n\n\n Managing wildcard DNS records \n\nYou can manage a wildcard record the same way as any other record. Refer to [Managing DNS records](https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-managing-dns-records) to learn more about creating, reading, updating, and deleting wildcard records.", "title": "", "source": "https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-what-are-wildcard-records"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07449-1067-2038", "score": 0.7280042171478271, "text": "\n[Sample domains expanded image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.\n* To delete a custom name server, delete the information from the field for the appropriate name server.\n* To edit a custom name server, edit the details in the corresponding field for the appropriate name server.\n\n\n\n9. Click the Associate button to save the changes, or click Cancel to cancel the action.\n\n\n\n\n\n Next steps \n\nAfter you update the name server details, they appear under the Custom Name Servers section of the domain. You can update the details at any time.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"}, {"document_id": "ibmcld_07449-7-1566", "score": 0.7233204245567322, "text": "\nManaging custom name servers for a domain \n\nDomains running on the IBM Cloud\u00ae network can point to a maximum of five (5) custom name servers. Custom name servers can be added, deleted, or changed at any time. Follow these steps to add, edit, or delete custom name servers for a domain.\n\n\n\n1. From your browser, open the [IBM Cloud\u00ae console](https://cloud.ibm.com/) and log in to your account.\n2. Select the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), then click Classic Infrastructure.\n3. From the Classic Infrastructure menu, select Services > Domain Registration to open the Domains page.\n4. Select the Domain Name to expand the domain into its snapshot view.\n5. Select Unlocked from the Lock Domain.\n6. Click the > character to expand the domain and configure name servers.\n\nZoom\n\n![Sample domains collapsed image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-collapsed.png)\n\nFigure 1. Domains page with the domain collapsed\n\nZoom\n\n![Sample domains expanded image](https://cloud.ibm.com/docs-content/v1/content/86dadb3996e7fa2b119c2c09bda56dbc01297416/dns/images/custom-name-server-expanded.png)\n\nFigure 2. Domains page with the domain expanded\n7. Select the Add/Edit NS option in the Custom Name Servers section of the page. A dialog appears.\n8. To complete the appropriate action based on the task, refer to one of the following bullets:\n\n\n\n* To add a custom name server, enter the hostname for the name server in the empty field.", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain"}, {"document_id": "ibmcld_04625-7-1865", "score": 0.7178474068641663, "text": "\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_04625-1502-3026", "score": 0.7049838304519653, "text": "\nGo to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com), click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg), and select Resource List.\n2. On the Resource List page, click Cloud Foundry Apps.\n3. Click the app that you want to add the route to. The app's Overview page is displayed.\n4. Select the Routes menu, and select Edit routes.\n5. Click Add route, and specify the route that you want to use for the app.\n6. Confirm your updates by clicking Save.\n\n\n\nAs an example, you can use .mycompany.com to associate the route www.mybluemix.net to your app. You can also use example.mycompany.com to associate the route www.example.bluemix.net to your app.\n\n\n\n\n\n Adding a custom domain from the IBM Cloud command-line interface \n\n\n\n1. For Cloud Foundry apps, connect to your targeted Cloud Foundry API endpoint by typing the following command:\n\nibmcloud target --cf-api <CF_ENDPOINT>\n\nCloud Foundry API endpoints:\n\n\n\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_04625-2824-4330", "score": 0.702333927154541, "text": "\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2. Create a custom domain for your organization by typing the following command:\n\nibmcloud app domain-create <MY_ORGNAME> <MY_DOMAIN>\n3. Add the route with the custom domain to an app.\n\nFor Cloud Foundry apps, run the following command:\n\nibmcloud app route-map <MY_APPNAME> <MY_DOMAIN> -n <MY_HOSTNAME>\n\n\n\n\n\n\n\n Mapping the custom domain to the system domain \n\nAfter you configure the custom domain in IBM Cloud, map the custom domain to the IBM Cloud system domain on your registered DNS server:\n\n\n\n1. Set up a 'CNAME' record for the custom domain name on your DNS server. Steps for setting up the CNAME record vary depending on your DNS provider. For example, if you use GoDaddy, you follow the [Domains Help](https://www.godaddy.com/help/add-a-cname-record-19236) guidance from GoDaddy.\n2. Map the custom domain name to the secure endpoint for the IBM Cloud region where your app is running. Use the following region endpoints to provide the URL route that is allocated to your organization in IBM Cloud. For example, point your CNAME to custom-domain.us-east.cf.cloud.ibm.com.\n\nCloud Foundry endpoints:\n\n\n\n* US-SOUTH - custom-domain.us-south.cf.cloud.ibm.com\n* US-EAST - custom-domain.us-east.cf.cloud.ibm.com\n* EU-DE - custom-domain.eu-de.cf.cloud.ibm.com\n* EU-GB - custom-domain.eu-gb.cf.cloud.ibm.com", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"}, {"document_id": "ibmcld_05353-1394-3012", "score": 0.6909258961677551, "text": "\n[Prepare to add a custom domain mapping](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain) (outside of Code Engine).\n3. [Configure custom domain mappings](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingscustom-domain) (from the Code Engine console or CLI).\n4. [Complete the custom domain configuration with your domain registrar](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-registrar) (outside of Code Engine).\n\n\n\nAfter the custom domain mapping is created, you can [test](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingstest-custom-domain), [update](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsupdate-custom-domain), [view](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsview-domain-mapping), or [delete](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsdelete-custom-domain) your custom domain mappings.\n\n\n\n Considerations before you use custom domain mappings in Code Engine \n\nBefore you implement custom domain mappings in Code Engine, be aware of the following considerations:\n\n\n\n* Code Engine supports custom domain mappings for domains that are protected with a SSL/TLS certificate, which is signed by a public, trusted certificate authority (CA).\n* You can define custom domain mappings that point to public domain names.\n* If your domain name can be resolved only by a nonpublic domain name system (DNS), you must provide a certificate that lists the domain name and is signed by a public, trusted CA.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_05353-2587-4725", "score": 0.6869463324546814, "text": "\n* Code Engine supports custom domain mappings for domains that are protected with a SSL/TLS certificate, which is signed by a public, trusted certificate authority (CA).\n* You can define custom domain mappings that point to public domain names.\n* If your domain name can be resolved only by a nonpublic domain name system (DNS), you must provide a certificate that lists the domain name and is signed by a public, trusted CA.\n* You must provide the entire certificate chain, starting with the certificate that corresponds to the custom domain, followed by all intermediate certificates up to the root certificate.\n* You cannot use self-signed certificates.\n* You cannot use certificates that are signed by an untrusted or a nonpublic enterprise CA.\n\n\n\n\n\n\n\n Preparing to add a custom domain mapping \n\nWhen you want to use a custom domain mapping with Code Engine application, you must take the following actions outside of Code Engine before you can create the custom domain mapping.\n\n\n\n1. From a domain registrar, obtain your custom domain; for example, www.example.com.\n2. From your certificate authority (CA), you must obtain a signed SSL/TLS certificate for your custom domain. This certificate is a type of digital certificate that is used to establish communication privacy between a server and a client. Certificates contain information that is used to create trusted and secure connections between endpoints. You must also obtain a matching private key for the TLS certificate. For security reasons, Code Engine supports only custom domain mappings that are configured with a TLS/SSL certificate that is signed by a public, trusted CA.\n\n\n\n\n\n How can I obtain a certificate for my custom domain? \n\nIn an enterprise environment, work with your corporate domain administrator to obtain the necessary certificates. However, if the custom domain is within your control and you want quickly create a certificate that is not self-certified, then you can optionally use the [Let's Encrypt](https://letsencrypt.org/) service and [Certbot](https://certbot.eff.org/) to obtain a certificate.\n\n\n\n1. Install [Certbot](https://certbot.eff.org/).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_10273-8447-10310", "score": 0.6857969760894775, "text": "\nIf you already have a domain provisioned with an internal or external provider and have set up any necessary credentials, you can use this command to add that domain to your cluster. Or, you can provision a new domain in both your cluster and in your provider account. To specify an existing domain, include the full domain name with the external provider zone, such as exampledomain.externalzone.com. To create a new domain, you must still include the external provider zone, but you can customize the subdomain portion, such as new-exampledomain.externalzone.com.\n\nibmcloud oc ingress domain create --cluster CLUSTER [--is-default] [--domain DOMAIN] [--hostname HOSTNAME] [--ip IP] [--output OUTPUT] [--domain-provider PROVIDER] [-q] [--secret-namespace NAMESPACE]\n\n-c, --cluster CLUSTER\n: Required. The name or ID of the cluster where you want to create the domain.\n\n--is-default\n: Optional. Include this option to set the relevant domain as the default domain for the cluster.\n\n--domain DOMAIN\n: The domain to create or add to your cluster. This can be a domain that exists in your provider account, or a new domain.\n\n--hostname HOSTNAME\n: For VPC clusters. The hostname to register for the domain.\n\n--ip IP\n: The IP addresses to register for the domain.\n\n--output OUTPUT\n: Optional: Prints the command output in JSON format.\n\n--domain-provider PROVIDER\n: Optional. The external DNS provider type. Specify akamai-ext for Akamai or cloudflare-ext for Cloudflare.\n\n--secret-namespace NAMESPACE\n: Optional. The namespace that the domain TLS secret is created in. If no namespace is specified, the secret is created in the default namespace.\n\n\n\n\n\n\n\n Managing domains \n\nLearn how to manage the domains that exist in your cluster.\n\n\n\n Viewing domains in a cluster \n\nYou can view the status of all domains in your cluster, or you can view details of a single domain.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ingress-domains"}, {"document_id": "ibmcld_05980-10127-11813", "score": 0.6840908527374268, "text": "\nTo register your custom domain, work with your Domain Name Service (DNS) provider or [IBM Cloud DNS](https://cloud.ibm.com/docs/dns?topic=dns-getting-started). If the apps that you want Ingress to expose are in different namespaces in one cluster, register the custom domain as a wildcard domain, such as .custom_domain.net. Note that domains are limited to 130 characters or fewer in Kubernetes version 1.20 or later.\n2. Define an alias for your custom domain by specifying the IBM-provided subdomain as a Canonical Name record (CNAME). To find the IBM-provided Ingress domain, run ibmcloud ks cluster get --cluster <cluster_name> and look for the Ingress subdomain field.\n\nSpecifying the IBM-provided subdomain as a CNAME is required for automatic health checks to remove any failing IPs from the DNS response, and to ensure that your custom domain updates when you add or remove ALBs.\n\n\n\n\n\n\n\n Creating custom domains for private ALBs \n\nFollow the steps to create a custom domain for private ALBs. Note that custom domains are required to use Ingress with private ALBs.\n\nIf you have a classic cluster with only a private VLAN, you must first configure your own [DNS service that is available on your private network](https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/).\n\n\n\n1. Create a custom domain through your DNS service provider. Note that Ingress URLs must be 130 characters or fewer.\n2. Map your custom domain to the private ALBs by adding their IP addresses as A records (classic clusters) or their VPC hostname as a CNAME (VPC clusters). To find the ALB IP addresses (classic) or hostname (VPC), run ibmcloud ks ingress alb ls -c <cluster_name_or_ID>.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-managed-ingress-setup"}, {"document_id": "ibmcld_05866-8447-10310", "score": 0.6831294894218445, "text": "\nIf you already have a domain provisioned with an internal or external provider and have set up any necessary credentials, you can use this command to add that domain to your cluster. Or, you can provision a new domain in both your cluster and in your provider account. To specify an existing domain, include the full domain name with the external provider zone, such as exampledomain.externalzone.com. To create a new domain, you must still include the external provider zone, but you can customize the subdomain portion, such as new-exampledomain.externalzone.com.\n\nibmcloud ks ingress domain create --cluster CLUSTER [--is-default] [--domain DOMAIN] [--hostname HOSTNAME] [--ip IP] [--output OUTPUT] [--domain-provider PROVIDER] [-q] [--secret-namespace NAMESPACE]\n\n-c, --cluster CLUSTER\n: Required. The name or ID of the cluster where you want to create the domain.\n\n--is-default\n: Optional. Include this option to set the relevant domain as the default domain for the cluster.\n\n--domain DOMAIN\n: The domain to create or add to your cluster. This can be a domain that exists in your provider account, or a new domain.\n\n--hostname HOSTNAME\n: For VPC clusters. The hostname to register for the domain.\n\n--ip IP\n: The IP addresses to register for the domain.\n\n--output OUTPUT\n: Optional: Prints the command output in JSON format.\n\n--domain-provider PROVIDER\n: Optional. The external DNS provider type. Specify akamai-ext for Akamai or cloudflare-ext for Cloudflare.\n\n--secret-namespace NAMESPACE\n: Optional. The namespace that the domain TLS secret is created in. If no namespace is specified, the secret is created in the default namespace.\n\n\n\n\n\n\n\n Managing domains \n\nLearn how to manage the domains that exist in your cluster.\n\n\n\n Viewing domains in a cluster \n\nYou can view the status of all domains in your cluster, or you can view details of a single domain.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ingress-domains"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07024-2933-4407", "score": 0.6286595463752747, "text": "\n[Transportation dictionary in the product ui](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/dict-transportation.png)\n\nFigure 1. Transportation dictionary\n\nThe resulting facet that is created for the dictionary is displayed in the search page.\n\nZoom\n\n![Search page with Transportation facet](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/dict-facet.png)\n\nFigure 2. Transportation facet\n\nThe document where the enrichment is applied contains the following sentence:\n\nSome car fluids can be acidic, such as battery fluid.\n\nThe following JSON snippet illustrates how a Transportation dictionary enrichment mention is stored when the term car, which is a synonym for the vehicle dictionary entry, is found in the document. In this collection, the dictionary enrichment is applied to the text field, so the mention is listed in the entities array that is in the enriched_text array.\n\n{\n\"enriched_text\": [\n{\n\"entities\":\n{\n\"model_name\": \"Dictionary:.Transportation\",\n\"mentions\":\n{\n\"confidence\": 1,\n\"location\": {\n\"end\": 91122,\n\"begin\": 91119\n},\n\"text\": \"car\"\n}\n],\n\"text\": \"vehicle\",\n\"type\": \"Transportation\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n Uploading dictionary terms \n\nTo add dictionary from a CSV file, complete the following steps:\n\n\n\n1. Create a CSV file that contains the dictionary terms that you want to add.\n\nUse UTF-8 encoding. Specify one entry per line.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary"}, {"document_id": "ibmcld_16000-0-2579", "score": 0.6118736267089844, "text": "\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-understanding-icp"}, {"document_id": "ibmcld_14311-7-1811", "score": 0.6115192770957947, "text": "\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_14311-3835-5367", "score": 0.6063958406448364, "text": "\n[Layer 2 bridge setup with a new bridge edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https://cloud.ibm.com/docs/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.2/installation/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_15141-7808-9997", "score": 0.6017987728118896, "text": "\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-client-to-site-vpn-planning"}, {"document_id": "ibmcld_11788-8466-10910", "score": 0.5945031642913818, "text": "\nFor any other connections into your location that your applications require, you can use Satellite Link to create layer 4 communications by setting up an endpoint for each destination resource in your location. All connections through your endpoints are always under your control, including completely disabling endpoints.\n\n\n\n\n\n How do I make my data secure in transit? \n\nLink endpoints between your location and IBM Cloud are secured through two levels of encryption: high-security encryption from the location\u2019s connector to IBM Cloud that is provided by IBM , and an optional additional encryption layer between the source and destination resources.\n\nAll data that is transported over Satellite Link is encrypted using TLS 1.3 standards. This level of encryption is managed by IBM.\n\nWhen you create an endpoint, you can optionally provide another level of encryption by specifying [data encryption protocols](https://cloud.ibm.com/docs/satellite?topic=satellite-link-location-cloudlink-protocols) for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify TLS encryption for the connection that goes over the internet. You can provide your own signed certificates to ensure both internal security and operational auditability without exposing any data contents. IBM only transports the encrypted connection, and your resources must be configured for the data encryption protocols that you specify.\n\n\n\n\n\n\n\n Encryption protocols \n\nAll communication over Satellite Link is encrypted by IBM. When you create an endpoint, you can optionally specify an additional data encryption protocol for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify your own additional TLS encryption for the connection that goes over the internet. Note that your resources must be configured for the data encryption protocols that you specify.\n\nReview the following information about how Satellite Link handles each type of connection protocol.\n\nIf you use the Satellite console to create an endpoint, the destination protocol is inherited from the source protocol that you select. To specify a destination protocol, use the CLI to create an endpoint and include the --dest-protocol option in the ibmcloud sat endpoint create command.\n\n\n\n TCP and TLS", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-link-location-cloud"}, {"document_id": "ibmcld_04122-7-1660", "score": 0.5844374895095825, "text": "\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-options"}, {"document_id": "ibmcld_14755-1277-3301", "score": 0.583908200263977, "text": "\n* NSX Manager provides a graphical user interface (GUI) and REST APIs for creating, configuring, and monitoring NSX-T Data Center components such as segments, logical routers, and firewalls. NSX Manager provides a system view and it is the management component of NSX-T Data Center.\n* NSX Host Transport Nodes participate in an NSX-T Data Center overlay or NSX-T Data Center VLAN networking. Each provisioned ESXi host in the VPC must be enabled to be a Transport Node.\n* NSX Edge Transport Nodes are service appliances, which are dedicated to running centralized network services that cannot be distributed to the hypervisors. Edge Nodes are grouped in one or several gateway clusters, representing a pool of capacity.\n\n\n\nWhen deployed on IBM Cloud VPC, the VMware virtual machines (VMs) hosted on IBM Cloud bare metal server for IBM Cloud VPC can be connected to NSX-T overlay segments. NSX-T segments are logically abstracted network segments in a defined Transport Zone. A Transport Zone is a container that defines the potential reach of Transport Nodes, Hosts, or Edges. The NSX-T segments support line-rate switching and distributed routing in the ESXi hosts. Also, it uses Geneve encapsulation for this overlay traffic to identify and isolate L2 segments over a common L3 infrastructure. In this design, Geneve traffic traverses between the defined Transport Nodes that use IBM Cloud VPC as the underlying transport network.\n\nIn addition to basic software defined overlay networks, NSX-T brings many embedded advanced features. The features are Network Address translation, site to site IPsec VPNs, firewall policies, inclusion of guest introspection within firewall policies, and advanced netflow tracking. Describing these features in detail is beyond the scope of this document. For more information about NSX-T, see [VMware NSX-T Data Center Documentation](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/index.html).\n\n\n\n\n\n NSX-T data center deployment architecture \n\n\n\n vSphere distributed switch deployment", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-nsx-t"}, {"document_id": "ibmcld_13218-10110-11749", "score": 0.5748001337051392, "text": "\nAn NSX Edge Node is a transport node that runs the local control plane daemons and forwarding engines implementing the NSX-T data plane. It runs an instance of the NSX-T virtual switch called the NSX Virtual Distributed Switch, or N-VDS. The Edge Nodes are service appliances dedicated to running centralized network services that cannot be distributed to the hypervisors. An NSX Edge can belong to one overlay transport zone and multiple VLAN transport zones. In this example, the NSX edge belongs to one VLAN transport zone which represents the physical connectivity to provide the uplink access to IBM Cloud VPC.\n\nFollow the recommended order of procedures to add IBM Cloud Bare Metal Servers for Virtual Private Cloud with VMware ESXi as host transport nodes to NSX-T.\n\n\n\n1. Create host transport nodes. When configuring the host TEP IPs, configure each host individually by using the [previously provisioned TEP IPs](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-hostsvpc-bm-vmware-nsx-t-vlannics) of the related IBM Cloud Bare Metal Servers for Virtual Private Cloud VLAN interface for TEP. For more information, see [Prepare Standalone Hosts as Transport Nodes or Prepare ESXi Cluster Hosts as Transport Nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.1/installation/GUID-D7CA778B-6554-4A23-879D-4BC336E01031.htmlGUID-D7CA778B-6554-4A23-879D-4BC336E01031).\n\n\n\nWhen you deploy an NSX-T edge, you can think of it as an empty container. The NSX-T edge does not do anything until you create logical routers, it provides the compute backing for Tier 0 and Tier 1 logical routers.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-deploy"}, {"document_id": "ibmcld_09898-43184-46103", "score": 0.5654897689819336, "text": "\ntechnology and computing networking vpn and remote access \n technology and computing networking \n technology and computing operating systems linux \n technology and computing operating systems mac os \n technology and computing operating systems unix \n technology and computing operating systems windows \n technology and computing operating systems \n technology and computing programming languages c and c++ \n technology and computing programming languages java \n technology and computing programming languages javascript \n technology and computing programming languages visual basic \n technology and computing programming languages \n technology and computing software databases \n technology and computing software desktop publishing \n technology and computing software desktop video \n technology and computing software graphics software animation \n technology and computing software graphics software \n technology and computing software net conferencing \n technology and computing software shareware and freeware \n technology and computing software \n technology and computing tech news \n technology and computing technical support \n technology and computing technological innovation \n technology and computing \n travel budget travel \n travel business travel \n travel honeymoons and getaways \n travel hotels \n travel specialty travel adventure travel \n travel specialty travel ecotourism \n travel specialty travel sightseeing tours \n travel specialty travel vineyards \n travel tourist destinations africa \n travel tourist destinations australia and new zealand \n travel tourist destinations canada \n travel tourist destinations caribbean \n travel tourist destinations eastern europe \n travel tourist destinations europe \n travel tourist destinations france \n travel tourist destinations greece \n travel tourist destinations italy \n travel tourist destinations japan \n travel tourist destinations mexico and central america \n travel tourist destinations national parks \n travel tourist destinations seaside resort \n travel tourist destinations ski resorts \n travel tourist destinations south america \n travel tourist destinations spas \n travel tourist destinations theme parks \n travel tourist destinations united kingdom \n travel tourist destinations \n travel tourist facilities bed and breakfast \n travel tourist facilities camping \n travel tourist facilities hotel \n travel transports air travel air and space accident \n travel transports air travel airfare \n travel transports air travel airlines \n travel transports air travel airplanes \n travel transports air travel airports \n travel transports air travel helicopters \n travel transports air travel \n travel transports public transport \n travel transports road travel road accident \n travel transports sea travel cruises \n travel transports train travel \n travel travel agencies \n travel travel guides \n travel traveling with kids \n travel vacation rentals \n travel", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy-v1"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02776-3988-5695", "score": 0.6495743989944458, "text": "\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_09513-12728-14481", "score": 0.6218130588531494, "text": "\nThis is applicable to EU-US and Swiss-US customers: [https://www.ibm.com/privacy/details/us/en/privacy_shield.html](https://www.ibm.com/privacy/details/us/en/privacy_shield.html)\n\nData Responsibility at IBM [https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/](https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-Security"}, {"document_id": "ibmcld_09109-6121-7923", "score": 0.6165025234222412, "text": "\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keys"}, {"document_id": "ibmcld_08515-6389-8309", "score": 0.6025770902633667, "text": "\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://www.nist.gov/publications/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api/v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keys"}, {"document_id": "ibmcld_09492-16883-18851", "score": 0.5989655256271362, "text": "\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-Security"}, {"document_id": "ibmcld_13616-13587-15670", "score": 0.5983906388282776, "text": "\n[https://www.ibm.com/support/customer/zz/en/dpa.html](https://www.ibm.com/support/customer/zz/en/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.", "title": "", "source": "https://cloud.ibm.com/docs/tas-ms?topic=tas-ms-security"}, {"document_id": "ibmcld_07669-0-587", "score": 0.5938161611557007, "text": "\n\n\n\n\n\n\n  AR-2 - Privacy Impact And Risk Assessment \n\n\n\n  Control requirements \n\nThe organization:\n\nAR-2 (a)\n:   Documents and implements a privacy risk management process that assesses privacy risk to individuals resulting from the collection, sharing, storing, transmitting, use, and disposal of personally identifiable information (PII).\n\nAR-2 (b)\n:   Conducts Privacy Impact Assessments (PIAs) for information systems, programs, or other activities that pose a privacy risk in accordance with applicable law, OMB policy, or any existing organizational policies and procedures.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ar-2"}, {"document_id": "ibmcld_10889-1448-3175", "score": 0.5867917537689209, "text": "\nThe GDPR imposes strict rules on those hosting and processing personal data, anywhere in the world.\n\nIBM is committed to providing our clients and IBM Business Partners with innovative data privacy, security, and governance solutions to assist them in their journey to GDPR readiness. Data and data protection are becoming increasingly important to individuals and society. Enterprises must earn the client\u2019s trust in their ability to steward information.\n\nIBM Cloud is agile and scalable with built-in data security, and privacy services and solutions that can be consumed on premises or through public cloud. Our comprehensive data security platform helps safeguard sensitive data wherever it resides and provides a full range of data protection capabilities.\n\n\n\n\n\n Environmental information \n\nIBM Cloud, as a user and as a provider, is environmentally conscious and strives to provide power efficiency and recycling in our data centers. As such, the servers that are put in service within the IBM Cloud comply with Commission Regulation (EU) 2019/424 of 15 March 2019 laying down ecodesign requirements for servers and data storage products (EU Lot 9).\n\nFor details, see the following data sheets on our physical hardware in the cloud:\n\n\n\n* [Rack Mount Server 618U-TR4T+](https://cloud.ibm.com/media/docs/downloads/environment-info-datasheets/1U_X10DRU-i+.pdf)\n* [Rack Mount Server 6019U-TN4R4T](https://cloud.ibm.com/media/docs/downloads/environment-info-datasheets/1U_X11DPU.pdf)\n* [Rack Mount Server 5019C-WR-04](https://cloud.ibm.com/media/docs/downloads/environment-info-datasheets/1U_X11SCW.pdf)\n* [Rack Mount Server 5019S-W4TR](https://cloud.ibm.com/media/docs/downloads/environment-info-datasheets/1U_X11SSW-4TF.pdf)", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-compliance"}, {"document_id": "ibmcld_04997-3175-3972", "score": 0.5855801105499268, "text": "\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https://www.ibm.com/data-responsibility/gdpr/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https://www.ibm.com/support/customer/csol/terms/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https://www.ibm.com/privacy/details/us/en/privacy_shield.html).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-compliance"}, {"document_id": "ibmcld_09492-15644-17291", "score": 0.5836431980133057, "text": "\nApplication administration, including the logging configuration, are the responsibility of the customer, and it is highly recommended that logging PII/SPI not be configured unless absolutely required. The following document describes how to configure logs to exclude any data classified as PII or SPI:\n\n[https://www.ibm.com/support/pages/node/2801463](https://www.ibm.com/support/pages/node/2801463)\n\nIBM Data Security and Privacy Principles for IBM Cloud services can be found at the link below: [https://www.ibm.com/support/customer/csol/terms/?cat=data-security](https://www.ibm.com/support/customer/csol/terms/?cat=data-security)\n\nIBM Privacy Shield Privacy Policy for Certified IBM Cloud Services can be found below. This is applicable to EU-US and Swiss-US customers: [https://www.ibm.com/privacy/details/us/en/privacy_shield.html](https://www.ibm.com/privacy/details/us/en/privacy_shield.html)\n\nData Responsibility at IBM [https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/](https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/) If a government wants access to data held by IBM on behalf of a MAS-Dedicated client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below.", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-Security"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07859-4616-6150", "score": 0.5829100012779236, "text": "\nThe security engineering principles in SA-8 cannot be properly applied if individuals that design, code, and test information systems and system components (including information technology products) do not understand security. Therefore, organizations include qualified personnel, for example, chief information security officers, security architects, security engineers, and information system security officers in system development life cycle activities to ensure that security requirements are incorporated into organizational information systems. It is equally important that developers include individuals on the development team that possess the requisite security expertise and skills to ensure that needed security capabilities are effectively integrated into the information system. Security awareness and training programs can help ensure that individuals having key security roles and responsibilities have the appropriate experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security requirements into enterprise architecture also helps to ensure that important security considerations are addressed early in the system development life cycle and that those considerations are directly related to the organizational mission/business processes. This process also facilitates the integration of the information security architecture into the enterprise architecture, consistent with organizational risk management and information security strategies.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-sa-3"}, {"document_id": "ibmcld_12652-0-1613", "score": 0.549870491027832, "text": "\n\n\n IBM Cloud Data Security Broker docs \n\nExplore the data protection services that Data Security Broker offers and the ways to install, configure, and login to Data Security Broker Manager and perform data encryption.\n\n  Recommended content \n\n[Install Data Security Broker Installing Data Security Broker Manager and Data Security Broker Shield from IBM Cloud Catalog ](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_install_catalog)[Configure Data Security Broker Manager You can find details on configuring the Data Security Broker Manager console in this section.](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_configure)[Login to Data Security Broker Manager This section details the steps to log into the Data Security Broker Manager console.](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_login)[Data Protection Services You can find the details on the types of data protection services offered by Data Security Broker.](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_encrypt_postgress)[Configure IBM Key Protect and IBM Cloud Hyper Protect Crypto Services (HPCS) In this section, you can find details on how to configure IBM Key Protect and IBM Cloud Hyper Protect Crypto Services (HPCS) and add it as a keystore in Data Security Broker Manager.](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_configure_keyprotect)[FAQs This section provides answers to frequently asked questions about the Data Security Broker software.](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_faqs)\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-broker"}, {"document_id": "ibmcld_12670-7-2415", "score": 0.5474672913551331, "text": "\nFAQs for Data Security Broker \n\nThis section provides answers to common questions about the Data Security Broker service.\n\nWhat is Data Security Broker Manager?\n\nData Security Broker Manager enables encryption policies and configurations by communicating with the Data Security Broker Shield and the desired databases. Data Security Broker Manager constructs a privacy schema that maps key IDs to data columns, thus enabling encryption in a simplified manner. Data Security Broker Shield carries out de-identification, masking, and encryption tasks for cloud databases.\n\nData Security Broker integrates with key management stores through a key virtualization layer. It also provides for a local key store, so you can use your own keys for data protection in the cloud.\n\nIs the instance hosted by Data Security Broker?\n\nData Security Broker software is hosted entirely in the customer's environment. Data Security Broker Manager and Data Security Broker Shield may be hosted on-premises or on cloud platforms such as IBM Cloud.\n\nWhat size instance is good for getting set up?\n\n30 gigabytes are sufficient for Data Security Broker Manager because it controls the Shields and the memory needed stays static. Sizing for Data Security Broker Shield depends on the number of shields and the number of concurrent users.\n\nWhat are the prerequisites for installing Data Security Broker?\n\nMake sure you meet the following requirements before configuring Data Security Broker Manager and Data Security Broker Shield:\n\n\n\n* Admin privileges for your platform\n* The user account used to log in to the Data Security Broker Shield host machine must have a home directory on that system\n* SSH client\n* Private key pair\n* Database privileges for encryption and migration\n\n\n\nDo Data Security Broker Manager and Shield run on different instances?\n\nTechnically, it is possible for the Data Security Broker Manager and Data Security Broker Shield to both run on the same host. However, it is recommended that separate host instances are provisioned for the Data Security Broker Manager and Data Security Broker Shield, to accommodate different workloads.\n\nWhich OS is necessary to set up the Data Security Broker Shield?\n\nData Security Broker Shield can be installed on instances running with Ubuntu 18 for IBM Cloud Kubernetes cluster (IKS) or RedHat Enterprise Linux (RHEL) 7 for IBM Red Hat OpenShift Kubernetes cluster (ROKS).", "title": "", "source": "https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_faqs"}, {"document_id": "ibmcld_14690-4276-6282", "score": 0.5463916063308716, "text": "\nset security address-book global address-set SERVICE address SL19\nset security address-book global address-set SERVICE address SL20\nset security screen ids-option untrust-screen icmp ping-death\nset security screen ids-option untrust-screen ip source-route-option\nset security screen ids-option untrust-screen ip tear-drop\nset security screen ids-option untrust-screen tcp syn-flood alarm-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood attack-threshold 200\nset security screen ids-option untrust-screen tcp syn-flood source-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood destination-threshold 2048\nset security screen ids-option untrust-screen tcp syn-flood queue-size 2000\nset security screen ids-option untrust-screen tcp syn-flood timeout 20\nset security screen ids-option untrust-screen tcp land\nset security policies from-zone trust to-zone trust policy default-permit match source-address any\nset security policies from-zone trust to-zone trust policy default-permit match destination-address any\nset security policies from-zone trust to-zone trust policy default-permit match application any\nset security policies from-zone trust to-zone trust policy default-permit then permit\nset security policies from-zone trust to-zone untrust policy default-permit match source-address any\nset security policies from-zone trust to-zone untrust policy default-permit match destination-address any\nset security policies from-zone trust to-zone untrust policy default-permit match application any\nset security policies from-zone trust to-zone untrust policy default-permit then permit\nset security zones security-zone trust tcp-rst\nset security zones security-zone trust interfaces reth0.0 host-inbound-traffic system-services all\nset security zones security-zone untrust screen untrust-screen\nset security zones security-zone untrust interfaces reth1.0 host-inbound-traffic system-services all\nset interfaces ge-0/0/1 gigether-options redundant-parent reth0", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"}, {"document_id": "ibmcld_16016-9350-11500", "score": 0.545268177986145, "text": "\nUse Case 2: Customizing security groups and security group policies when creating a new resource \n\nThe following diagram illustrates the potential customization options when you create a new resource. If a User creates a new resource and take no further action to specify a security group to attach it to, their new resource is assigned to the VPC's default security group. This default security group will take on the default security group policy or follow a customized policy previously configured by members of your account.\n\nIf the User decides to assign the new resource to a new security group, the new security group is automatically assigned the default security group policy. Then the User can choose to take no further action, or choose to customize policy rules to create a custom security group policy for their new security group. These new rules also apply to the new resource created and assigned to the new security group:\n\nZoom\n\n![Security group and security group policy customization options when creating a new resource](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/sg-customization-options.svg)\n\nFigure 2. Security group and security group policy customization options when creating a new resource\n\n\n\n\n\n Use Case 3: Allow traffic between members of a security group \n\nThe more conventional way to set up your security group policy is to control traffic to and from your targets with specific rules that filter by IP addresses and ports.\n\nA more dynamic way you can set up your security group policy is to allow all inbound traffic from other targets that are also part of the security group. When you permit traffic between members of a security group, as resources are added or deleted from the security group, you don't have to set up individual permissions between each current member and each new member of a security group.\n\nFor example, say you have host A and host B in a security group, and you add a new host C. Normally, you would have to perform maintainance to allow host A and host B to send traffic to and from host C after you add host C to the security group.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-using-security-groups&interface=ui"}, {"document_id": "ibmcld_14953-5907-7890", "score": 0.5428117513656616, "text": "\nsecurity-group is.security-group.security-group.create Security Group was created \n security-group is.security-group.security-group.delete Security Group was deleted \n security-group is.security-group.security-group.update Security Group was updated \n security-group is.security-group.security-group.read One or more security groups were retrieved \n security-group is.security-group.security-group-rule.create Rule was added to Security Group \n security-group is.security-group.security-group-rule.delete Rule was removed from Security Group \n security-group is.security-group.security-group-rule.update Security Group Rule was updated \n security-group is.security-group.security-group-rule.read One or more security group rules was retrieved \n security-group is.security-group.security-group-interface.attach Interface was attached to Security Group \n security-group is.security-group.security-group-interface.detach Interface was removed from Security Group \n security-group is.security-group.security-group-interface.read One or more security group interfaces was retrieved \n\n\n\n\n\n\n\n Subnet events \n\n\n\nTable 8. Actions that generate events for Subnet\n\n Resource Action Description \n\n subnet is.subnet.subnet.create Subnet was created \n subnet is.subnet.subnet.update Subnet was updated \n subnet is.subnet.subnet.delete Subnet was deleted \n subnet is.subnet.subnet.read One or more subnets was retrieved \n subnet is.subnet.network-acl.update Subnet's Network ACL was replaced \n subnet is.subnet.public-gateway.attach Public Gateway was attached to Subnet \n subnet is.subnet.public-gateway.detach Public Gateway was detached from Subnet \n subnet is.subnet.public-gateway.read A subnet public-gateway attachment was retrieved \n\n\n\n\n\n\n\n Virtual private endpoints events \n\nThe following table lists the actions that are related to virtual private endpoints and the generation of events.\n\n\n\nTable 9. Actions that generate events for virtual private endpoints\n\n Resource Action Description", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-at-events"}, {"document_id": "ibmcld_12668-7-1884", "score": 0.541212260723114, "text": "\nData Protection Services \n\nData Security Broker offers Data Protection services which enables the provisioning of Data Security Broker Manager and Data Security Broker Shield. It also helps in configuring encryption or decryption rules against the IBM Cloud Databases such as PostgreSQL to encrypt and decrypt the database records or columns on the fly. It also helps in migrating the existing database records, apply record or column level encryption rules.\n\nData Security Broker supports two types of Data Protection services. They are:\n\n\n\n1. [Data Encryption](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_encrypt_data)\n2. [Data Masking](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_masking)\n\n\n\n\n\n Procedure \n\nAfter you have completed setting up and configuring the Data Security Broker Manager, you can perform standard encryption or data masking by defining a Data Protection policy. Ensure that you complete the steps below before you can use the data protection services offered by Data Security Broker.\n\n\n\n1. You must add a Keystore, so that the Data Security Broker Manager can access and create data encryption keys (DEKs) that is used to protect your data. For more information, see [Adding a Keystore in Data Security Broker Manager](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_add_keystore).\n2. Connect to a database in the Data Security Broker Manager. For more information, see [Connect to a Datastore in Data Security Broker Manager](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_add_db).\n3. Enroll an Application in Data Security Broker Manager. For more information, see [Enrolling an application in Data Security Broker Manager](https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_enroll_app).\n4. Assign and customize a Default Data Protection Policy.", "title": "", "source": "https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_encrypt_postgress"}, {"document_id": "ibmcld_10534-168541-169968", "score": 0.5366638898849487, "text": "\n* [Viewing Red Hat OpenShift on IBM Cloud created priority level configurations](https://cloud.ibm.com/docs/openshift?topic=openshift-kubeapi-prioritykube-api-prioritylevelconfig)\n\n\n\n\n\n[Pod security admission](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpod-security-admission)\n\n\n\n* [Understanding security profiles](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpod_security_profiles)\n* [What if Pod Security Admission isn't the right choice for me?](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionwhat-if-psa)\n* [Configuring Pod Security admission namespace labels](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpsa-namespace-labels)\n* [Default Pod Security Admission plug-in configuration](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpsa-plugin-config-default)\n* [Customizing the Pod Security Admission plug-in configuration](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpsa-plugin-config-custom)\n* [Configuring pod security admission](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpod-security-configure)\n* [Additional resources](https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admissionpod-sec-additional-resources)\n\n\n\n\n\n\n\n Securing the cluster network \n\n\n\n Controlling traffic in Classic clusters", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_16688-2022-3442", "score": 0.530026912689209, "text": "\nEU-DE https://private.eu-de.security-compliance-secure.cloud.ibm.com/api \n EU-GB https://private.eu-gb.security-compliance-secure.cloud.ibm.com/api \n JP-OSA https://private.jp-osa.security-compliance-secure.cloud.ibm.com/api \n JP-TOK https://private.jp-tok.security-compliance-secure.cloud.ibm.com/api \n US-EAST https://private.us-east.security-compliance-secure.cloud.ibm.com/api \n AU-SYD https://private.au-syd.security-compliance-secure.cloud.ibm.com/api \n CA-TOR https://private.ca-tor.security-compliance-secure.cloud.ibm.com/api \n BR-SAO https://private.br-sao.security-compliance-secure.cloud.ibm.com/api \n\n\n\n\n\n\n\n Public REST API endpoints \n\n\n\nTable 3. Public REST API endpoints for the IBM Cloud Security and Compliance Center Workload Protection service\n\n Region Public REST API endpoint \n\n US-SOUTH https://us-south.security-compliance-secure.cloud.ibm.com/api \n EU-DE https://eu-de.security-compliance-secure.cloud.ibm.com/api \n EU-GB https://eu-gb.security-compliance-secure.cloud.ibm.com/api \n JP-OSA https://jp-osa.security-compliance-secure.cloud.ibm.com/api \n JP-TOK https://jp-tok.security-compliance-secure.cloud.ibm.com/api \n US-EAST https://us-east.security-compliance-secure.cloud.ibm.com/api \n AU-SYD https://au-syd.security-compliance-secure.cloud.ibm.com/api \n CA-TOR https://ca-tor.security-compliance-secure.cloud.ibm.com/api \n BR-SAO https://br-sao.security-compliance-secure.cloud.ibm.com/api", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-endpoints"}, {"document_id": "ibmcld_12775-7-1982", "score": 0.5287283062934875, "text": "\nManaging security groups \n\nYou can manage security groups by using the Security Groups page, or the Device Details page in the IBM Cloud\u00ae console.\n\n\n\n Managing security groups from the Security Groups page \n\nTo manage security groups from the Security Groups page, complete the following steps:\n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com/), click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) > Classic Infrastructure to view the Classic Infrastructure landing page.\n2. From the Classic Infrastructure menu, select Security > Network Security > Security Groups to view the Security Groups page.\n3. On the Security Groups page, you can complete several management tasks.\n\n\n\n* View a list of security groups.\n* Create a group.\n* Edit group information.\n* Duplicate a group.\n* Delete a group.\n\n\n\n\n\n\n\n\n\n Managing security group rules from the Security Groups page \n\nTo manage security group rules from the Security Groups page, complete the following steps:\n\n\n\n1. From the [IBM Cloud console](https://cloud.ibm.com/), click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) > Classic Infrastructure to get to the Classic Infrastructure landing page.\n2. From the Classic Infrastructure menu, select Security > Network Security > Security Groups to get to the Security Groups page.\n3. On the Security Groups page, click on a security group name to open the Details page.\n4. On the Security Group Details page, you can complete several management tasks.\n\n\n\n* View a list of rules that are defined for the security group.\n* Create new rules.\n* Edit a rule.\n* Delete a rule.\n* View the virtual server instances and the associated interfaces that are assigned to the security group.\n\n\n\n\n\nIf you delete the last rule in a security group, then inbound and outbound traffic is not allowed by this security group.\n\n\n\n\n\n Managing security groups from the Device Details page", "title": "", "source": "https://cloud.ibm.com/docs/security-groups?topic=security-groups-managing-sg"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13893-3026-4810", "score": 0.6639842987060547, "text": "\n* Create a firewall rule named dmz2private with the default action to drop any packet.\n* Enable logging of accepted and denied traffic for the rule named dmz2private.\n\n\n\n\n\n1. Type configure in the command prompt.\n2. Enter the following commands in the prompt:\n\n\n\n* set firewall name dmz2private default-action drop\n* set firewall name dmz2private enable-default-log\n\n\n\nThe next set of commands is to enable iptables to allow traffic for an established session to return. By default, iptables does not allow this, which is why an explicit rule is required.\n\n\n\n* set firewall name dmz2private rule 1 action accept\n* set firewall name dmz2private rule 1 state established enable\n* set firewall name dmz2private rule 1 state related enable\n\n\n\nThe third set of commands allows TCP/UDP to get through port 22, the default for SSH.\n\n\n\n* set firewall name dmz2private rule 2 action accept\n* set firewall name dmz2private rule 2 protocol tcp_udp\n* set firewall name dmz2private rule 2 destination port 22\n\n\n\nThe final set of commands allows TCP/UDP to get through port 80, the default for HTTP.\n\n\n\n* set firewall name dmz2private rule 3 action accept\n* set firewall name dmz2private rule 3 protocol tcp_udp\n* set firewall name dmz2private rule 3 destination port 80\n\n\n\n3. Type commit to ensure that all rules are taken when finished.\n4. View your configuration by typing show firewall name dmz2private in the command prompt.\n\n\n\nThe next firewall rule is applied to our dmz zone. This rule is named public. Enter the following commands:\n\n\n\n* set firewall name public default-action drop\n* set firewall name public enable-default-log\n* set firewall name public rule 1 action accept\n* set firewall name public rule 1 state established enable\n* set firewall name public rule 1 state related enable", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-adding-firewall-functions-to-vyatta-5400-stateless-and-stateful-"}, {"document_id": "ibmcld_07578-1006129-1007999", "score": 0.6501798629760742, "text": "\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1006000-1007870", "score": 0.6501798629760742, "text": "\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_04109-7-2036", "score": 0.6376923322677612, "text": "\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-actions"}, {"document_id": "ibmcld_08169-0-2277", "score": 0.63463294506073, "text": "\n\n\n\n\n\n\n  Managing permissions \n\nTo view and manage your hardware firewalls, you need the correct permissions. After your account administrator grants your user account permissions and access, you can view your hardware firewall details by using the IBM Cloud\u00ae console, or by using the SoftLayer API. The information or actions that you see depend on your permissions.\n\nThe following permissions are required for viewing and managing various parts of your hardware firewalls:\n\n\n\n*  Manage firewalls - Allows you to view your list of firewalls. It also allows you to view and manage the details of a specific firewall.\n*  View hardware details - Allows you to view your list of hardware firewalls on bare metal servers. It also allows you to view and manage the details of a specific hardware firewall on a bare metal server.\n*  View virtual server details - Allows you to view your list of firewalls on virtual servers. It also allows you to view and manage the details of a specific hardware firewall on a virtual server.\n*  Manage firewall rules - Allows you to manage the rules of a specific hardware firewall.\n*  Cancel services - Allows you to cancel a firewall.\n\n\n\n\n\n  Adding permissions for your users \n\nIf you are the account administrator and you want to grant a user permission to view and manage gateway appliance details, complete the following steps.\n\n\n\n1.  Log in to the [Access (IAM)](https://cloud.ibm.com/iam/users) page in the IBM Cloud\u00ae console.\n2.  Select View: My classic infrastructure users.\n3.  Select a user, click the Classic infrastructure tab, then click the Permissions tab.\n4.  Expand the Devices category and select Manage firewalls.\n5.  Expand the Devices category and select View hardware details.\n6.  Expand the Devices category and select View virtual server details.\n7.  Expand the Devices category and select Manage firewall rules.\n8.  Expand the Account category and select Cancel services.\n9.  Click Apply.\n\n\n\n\n\n\n\n  Next steps \n\nUser permissions are updated immediately after the changes are submitted. If permissions are granted, the user can view or interact with the selected features. If permissions are removed, the user can no longer view or interact with the selected features. Permissions can be updated again at any time.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-managing-permissions"}, {"document_id": "ibmcld_13927-3027-3785", "score": 0.6246731877326965, "text": "\nThe following is an example of SERVICE-ALLOW. This is not a complete private IP rule set.\n\nset firewall name SERVICE-ALLOW rule 1 action 'accept'\nset firewall name SERVICE-ALLOW rule 1 destination address '10.0.64.0/19'\nset firewall name SERVICE-ALLOW rule 2 action 'accept'\nset firewall name SERVICE-ALLOW rule 2 destination address '10.1.128.0/19'\nset firewall name SERVICE-ALLOW rule 3 action 'accept'\nset firewall name SERVICE-ALLOW rule 3 destination address '10.0.86.0/24'\n\nAfter you define the firewall rules, you can assign them as you see fit. Two examples are listed.\n\nApplying to a zone: set zone-policy zone private from dmz firewall name SERVICE-ALLOW\n\nApplying to a bond interface: set interfaces bonding bond0 firewall local name SERVICE-ALLOW", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-setting-up-nat-rules-on-vyatta-5400"}, {"document_id": "ibmcld_13915-1601-3647", "score": 0.6171429753303528, "text": "\nAs GLOBAL_STATELESS does not specify protocol tcp, the global-state-policy tcp command would not apply on this rule.\n\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 action accept\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 protocol tcp\n\nIn this case protocol tcp is explicitly defined. The global-state-policy tcp command would enable stateful tracking of traffic that matches rule 1 of GLOBAL_STATEFUL_TCP\n\nTo make individual firewall rules 'stateful':\n\nset security firewall name TEST rule 1 allow\nset security firewall name TEST rule 1 state enable\n\nThis would enable stateful tracking of all traffic that can be tracked statefully and matches rule 1 of TEST, regardless of the existence of global-state-policy commands.\n\n\n\n\n\n ALG for assisted stateful tracking \n\nA few protocols such as FTP utilize more complex sessions that the normal stateful firewall operation can track. There are preconfigured modules that enable these protocols to be statefully managed.\n\nIt is suggested to disable these ALG modules, unless they are required for the successful use of the respective protocols.\n\nset system alg ftp 'disable'\nset system alg icmp 'disable'\nset system alg pptp 'disable'\nset system alg rpc 'disable'\nset system alg rsh 'disable'\nset system alg sip 'disable'\nset system alg tftp 'disable'\n\n\n\n\n\n Firewall rule sets \n\nFirewall rules are grouped together into named sets to make applying rules to multiple interfaces easier. Each rule set has a default action associated with it. Consider the following example:\n\nset security firewall name ALLOW_LEGACY default-action accept\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"}, {"document_id": "ibmcld_14705-2946-4892", "score": 0.6101074814796448, "text": "\n* A new T1 named Isolated-NW-T1 and links it to the workload T0. Isolated-NW-T1 is configured to advertise only all NAT IP addresses. This action stops the advertisement of connected segments and advertises only the NAT IP addresses of the segments.\n* The following distributed firewall groups.\n\n\n\n* Name Cyber-Tools-Segments, Category Segments, Members Cybertools\n* Name Cyber-Isolated-Segments, Criteria Segment Tag Equals Isolated-Segments, Scope Cyber\n\n\n\n* A distributed firewall policy that is named Cyber-Isolated, which contains the following rules to satisfy their isolation requirements:\n\n\n\n\n\nTable 1. NSX-T distributed firewall rules\n\n Rule Name Sources Destinations Services Action \n\n Allow access to Isolated Cyber-Tools-Segments Cyber-Isolated-Segments All Allow \n Allow access between Isolated Cyber-Isolated-Segments Cyber-Isolated-Segments All Allow \n Deny access to Isolated Any Cyber-Isolated-Segments All Deny \n Deny access from Isolated Any Cyber-Isolated-Segments All Deny \n\n\n\nWhen a sandbox is required, the customer uses their preferred scripting tool to automatically:\n\n\n\n* Create logical segments connected to Isolated-NW-T1 by using the IP address of the default gateway of that network on the T1. In the following diagram, you can see two Isolated-NW2 and Isolated-NW3 segments with subnets that match NW2 and NW3. These segments are created with Tags and Scopes, such as Scope Cyber and Tag Isolated-Segments. These tags and scope are used in the distributed firewall groups and rules that are listed in the previous table.\n* Create destination NAT rules that map destination subnets to translated subnets for IP packets with a source address from the cybertools segment. For example, Src=172.16.67.2->Dst=172.16.68.2 => Src=172.16.67.2->Dst=172.16.253.2.\n\n\n\nThe required traffic flow is shown in the following diagram where:\n\n\n\n* Green designates allowed traffic flow.\n* Red designates denied traffic flow.\n\n\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib-nw"}, {"document_id": "ibmcld_07604-0-1854", "score": 0.6095926761627197, "text": "\n\n\n\n\n\n\n  Managing permissions \n\nTo view and manage your FortiGate Security Appliance (FSA) 10 Gbps firewalls you need the correct permissions. After your account administrator grants your user account permissions and access, you can view your FSA 10 Gbps firewall details by using the IBM Cloud\u00ae console, or by using the SoftLayer API. The information or actions that you see depend on your permissions.\n\nThe following permissions are required for viewing and managing various parts of your FSA 10 Gbps firewalls:\n\n\n\n*  Manage firewalls - Allows you to view your list of firewalls. It also allows you to view and manage the details of a specific firewall.\n*  Manage network gateways - Allows you to view your list of FSA 10 Gbps firewalls. It also allows you to view and manage the details of a specific FSA 10 Gbps firewall.\n*  Cancel services - Allows you to cancel a firewall.\n\n\n\n\n\n  Adding permissions for your users \n\nIf you are the account administrator and you want to grant a user permission to view and manage gateway appliance details, complete the following steps.\n\n\n\n1.  Log in to the [Access (IAM)](https://cloud.ibm.com/iam/users) page in the IBM Cloud\u00ae console.\n2.  Select View: My classic infrastructure users.\n3.  Select a user, click the Classic infrastructure tab, then click the Permissions tab.\n4.  Expand the Devices category and select Manage firewalls.\n5.  Expand the Network category and select Manage network gateways.\n6.  Expand the Account category and select Cancel services.\n7.  Click Apply.\n\n\n\n\n\n\n\n  Next steps \n\nUser permissions are updated immediately after the changes are submitted. If permissions are granted, the user can view or interact with the selected features. If permissions are removed, the user can no longer view or interact with the selected features. Permissions can be updated again at any time.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/fortigate-10g?topic=fortigate-10g-managing-permissions"}, {"document_id": "ibmcld_08155-0-808", "score": 0.6023228764533997, "text": "\n\n\n\n\n\n\n  Release notes for IBM Cloud Hardware Firewall \n\nFind out about new and updated features in IBM Cloud Hardware Firewall.\n\n\n\n  8 December 2021 \n\nManaging permissions\n:   Account administrators can now assign permissions to allow users to view and manage various parts of a hardware firewall. The following permissions can now be assigned:\n\n\n\n*  Manage firewalls - Allows you to view your list of firewalls. It also allows you to view and manage the details of a specific firewall.\n*  Manage firewall rules - Allows you to manage the rules of a specific hardware firewall.\n*  Cancel services - Allows you to cancel a firewall.\n\n\n\n:   For more information, refer to [Managing permissions](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-managing-permissions).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-hardware-firewall-shared-release-notes"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 0.7143416404724121, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-7-1802", "score": 0.658353328704834, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-2884-4620", "score": 0.6575931310653687, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_02772-4213-5899", "score": 0.6181905269622803, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_06004-29614-31438", "score": 0.6109517812728882, "text": "\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_10852-43319-44485", "score": 0.6068794131278992, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10645-7-1995", "score": 0.6049734950065613, "text": "\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/openshift?topic=openshift-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/openshift?topic=openshift-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update_app"}, {"document_id": "ibmcld_06225-7-1999", "score": 0.5973528623580933, "text": "\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update_app"}, {"document_id": "ibmcld_00959-2830-5215", "score": 0.5929330587387085, "text": "\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}, {"document_id": "ibmcld_00962-3246-5702", "score": 0.5870978832244873, "text": "\nThe Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds. Over time, the traffic that is sent to the new version is increased until all of the traffic is sent there, at which point you can stop the old production environment. For rapid rollback while deployment is in progress, you can route all of the traffic to the original production environment. Since this strategy requires two full production environments only during deployment, the overall resource usage is lower than for the Blue-Green deployment. The Canary release deployment strategy is the slowest to move from a previous release to a current release of the software that is being deployed. Canary deployments allow organizations to test two different software versions side by side in production.\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https://cloud.ibm.com/registration), with a Standard plan.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-vpc"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07059-7-1693", "score": 0.5747668743133545, "text": "\nKnown issues \n\nKnown issues are listed by the release in which they were identified.\n\n\n\n* For the list of release notes, see [Release notes](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-release-notes-data).\n* For troubleshooting information, see [Troubleshooting](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-troubleshoot).\n\n\n\nIBM Cloud Pak for Data\n\nThe known issues that are described in this topic apply to installed deployments only.\n\nKnown issues are cumulative. Issues from previous releases persist in later releases unless otherwise noted.\n\n\n\n 4.7.x releases \n\nSee [Limitations and known issues in Watson Discovery](https://www.ibm.com/docs/SSQNUZ_4.7.x/svc-discovery/discovery-known-issues.html)\n\n\n\n\n\n 4.6.x releases \n\nSee [Limitations and known issues in Watson Discovery](https://www.ibm.com/docs/SSQNUZ_4.6.x/svc-discovery/discovery-known-issues.html)\n\n\n\n\n\n 4.5.x releases \n\nSee [Limitations and known issues in Watson Discovery](https://www.ibm.com/docs/SSQNUZ_4.5.x/svc-discovery/discovery-known-issues.html).\n\n\n\n\n\n 4.0.x releases \n\nFor more information about known issues, see the [IBM Cloud Pak for Data documentation](https://www.ibm.com/docs/SSQNUZ_4.0/svc-discovery/discovery-known-issues.html).\n\n\n\n\n\n 4.0.9, 25 May 2022 \n\n\n\n* Discovery generates a partial failure status message for the IBM Cloud Pak for Data Red Hat OpenShift APIs for Data Protection (OADP) backup and restore utility.\n\n\n\n* Error: When you check the status of the OADP backup utility after using it to backup a cluster where Discovery is installed, a Phase: PartiallyFailed message is displayed. One or more Discovery components are included in the Failed list.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-known-issues"}, {"document_id": "ibmcld_07059-25784-27694", "score": 0.5628914833068848, "text": "\nHowever, some pods attempt to parse the variable, which results in the error.\n* Solution: [Install patch cpd-watson-discovery-2.2.1-patch-1](https://www.ibm.com/docs/en/cloud-paks/cp-data/3.5.0?topic=iwd-installing-watson-discoverysvc-install__patches-section), which fixes this issue.\n\n\n\n\n\nAlso, see the issues in all previous releases.\n\n\n\n\n\n 2.2, 8 December 2020 \n\n\n\n* When a small CSV file (generally a CSV with 99 lines or fewer) is uploaded, the header and/or first row may not be ingested correctly. If this happens, in the tooling, navigate to the CSV Settings tab and update the settings. After reprocessing, navigate to the Manage fields tab and update the field types if needed.\n* If you have set up your collections using a custom crawler built with the [IBM Cloud Pak for Data custom connector](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-build-connector), and then remove the custom crawler deployment, the Processing Settings page will not display the crawler configuration. This is because the underlying crawler is not available. To work around this issue, confirm that the custom crawler is deployed when there are collections using it.\n* When using a [IBM Cloud Pak for Data custom connector](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-build-connector) with Discovery for IBM Cloud Pak for Data 2.2, the script scripts/manage_custom_crawler.sh used to deploy and remove the deployment of the custom crawler fails. To work around this issue, replace line 37 podname=\"gateway\" with podname=\"wd-discovery-gateway\" in scripts/manage_custom_crawler.sh, and then rerun the deploy command.\n* When you create a custom enrichment in the tooling, you must choose a field the enrichment should be applied to and click Apply. If no field is selected, then the Apply and reprocess button will be disabled for enrichments changes until the new enrichment has a field.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-known-issues"}, {"document_id": "ibmcld_12107-7381-8104", "score": 0.5352315902709961, "text": "\nInconsistencies that arise due to local or manual changes, or differences in the sequence of automated operations. Changes that make it harder to debug and resolve issues, and increase support costs.\n\nTo ensure immutability and eliminate drift, all changes should be made through the Schematics IaC configuration, and resources like VSIs should be redeployed when they need updating.\n\n\n\n\n\n\n\n Next steps \n\nNow you understand more about IaC, why not review the use of IaC in Schematics:\n\n\n\n* Learn more about the [Open-source tools in Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-open-projects)\n* Explore these [use cases](https://cloud.ibm.com/docs/schematics?topic=schematics-how-it-works).", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-infrastructure-as-code"}, {"document_id": "ibmcld_07059-34917-37067", "score": 0.5340532064437866, "text": "\n! ! ! . * You cannot upload CSV files that include a space in the file name (for example: file 1.csv) to a Content Mining project. Rename the file to work around the issue. * When performing Project level relevancy training, if you have multiple collections, and two or more of those collections contains a duplicate document_id, then project level relevancy training will fail. Example of duplicate document_ids: Collection A contains a document with the id of 1234, and Collection B also contains a document with the id of 1234. * Only the first facet using a field with the prefix extracted_metadata is saved correctly after creation. Others with that prefix will appear but after a screen refresh will be gone. This only happens once per project, so the workaround is to refresh and add the facet again. IBM Cloud Pak for Data\n\nDuring installation on IBM Cloud Pak\u00ae for Data 2.5.0.0, some Kubernetes Jobs may incorrectly report their status as OOMKilled, causing the install to timeout. To resolve this, once a Job returns OOMKilled verify the logs of the Pod associated with that Job. There should be no obvious error messages in the logs and the resources are reported in the logs as created. Manually verify these resources exist in the namespace and then delete the Job. This will cause the install to continue.\n* Some documents may show two html fields when applying an enrichment. Both html fields shown are the same and operate as such. * When creating a data source in Firefox, you may not see the entire list of options, including the More processing settings settings. To work around the issue, zoom out, increase the browser height, or use another supported browser. * When customizing the display of search results, the changes made sometimes do not save after clicking the Apply button. To work around this issue, refresh the browser and try to make the changes again. * When setting up a data source or web crawler for your collection, if you enter an incorrect configuration, then try to update it on the Processing settings page, the data source update or crawl may not start when you click the Apply changes and reprocess button.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-known-issues"}, {"document_id": "ibmcld_06872-7-2017", "score": 0.5246667861938477, "text": "\nProcessing incident and nonincident issues \n\nThe following types of issues are supported:\n\n\n\n* Incident issues, which can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts.\n* Nonincident issues, which do not arise from vulnerabilities, but rather represent a deviation from the compliance posture. For example, unit test failures and branch protection check failures.\n\n\n\n\n\n Adding default assignees to issues \n\nYou can define multiple default assignees for the issue by using the incident-assignees pipeline parameter. The incident-assignees parameter can be used only with GitHub accounts and GitLab Premium accounts. For more information about the incident-assignees parameter, see [Assigning issues to users](https://cloud.ibm.com/docs/devsecops?topic=devsecops-issue-processingassign-issues).\n\nYou can also set a default issue assignee for the pipeline with the incident-assignee pipeline parameter, however this parameter is deprecated and will be removed with the v1 evidence (legacy) collection.\n\n\n\n\n\n Filtering issues \n\nYou can filter and search for issues by using default and custom labels. The following default labels are assigned to the issues upon creation or update:\n\n\n\n* The [scan type](https://cloud.ibm.com/docs/devsecops?topic=devsecops-incident-issuesdue-date-supported-tools) that is used for the issue processing is added to the incident issue as a tool label (for example, tool:cra, tool:va, tool:sonarqube).\n* A severity label is also assigned to issues. The severity categories are defined based on the scan results and can be one of the following: severity:critical, severity:high, severity:medium, severity:low, severity:informational.\n* The has-exempt is a VA tool-specific label that is assigned to the issue if it is exempted based on the scan result. If the exempt status is not included in the scan result, you can exempt the issue manually by assigning the exempt label and adding a link to the source of the exempt issue ticket in a comment.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-issue-processing"}, {"document_id": "ibmcld_06873-7-2181", "score": 0.520200252532959, "text": "\nManaging nonincident issues \n\nUnlike incident issues that can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts, nonincident issues result from failing unit tests, failing acceptance tests, failing branch protection checks, an image signing failure, or an image not being pulled from the registry because of a bad token or expired credentials. These scenarios are not because of some vulnerabilities but are a deviation from the compliance posture. As a result, nonincident issues are captured whenever the pipelines encounter such scenarios.\n\nThe [collect-evidence script](https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-collect-evidence) captures nonincident issues inside the issues repository, and attaches the issue with the collected evidence. The collect-evidence script relies on the [cocoa incident process-legacy](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cliincident-process-legacy) command of the DevSecOps CLI tool, which can create issues or close existing issues based on the status of the current run.\n\n\n\n Nonincident issue processing \n\nNonincident issues do not have a due date assigned to them by default. Any pipeline can open nonincident issues, and in a subsequent run, if the issue is no longer detected for the incident-tool-subject combination, the issue is automatically closed. Issues can be found during build, deployment, or during the continuous monitoring phase.\n\nFor nonincident issues that are found during a CI run, a combination of the evidence_type and the app repo branch is used to construct the issue title so that a unit test failure found on branch master is dealt with separately from a unit test failure on branch dev. A similar combination is used for such issues that are found from the CC pipeline. Issues coming from CD pipeline have a different grouping criteria, where the combination of the evidence type id, target environment, and the pipeline namespace is used to construct the title of the issue. This different grouping criteria ensure that the issues found on CI and CC are not interfered by the CD run for similar tests like an acceptance test.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-non-incident-issues"}, {"document_id": "ibmcld_03182-3217-3845", "score": 0.5135818123817444, "text": "\nAs you find misclassifications or other issues, you can correct them in the development version of the skill, and then deploy the improved version to production after testing. See [Improving across assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-deploy-id) for more details.\n\n\n\nThe process of analyzing the logs and improving the dialog skill is ongoing. Over time, you might want to expand the tasks that the assistant can handle for you. Customer needs also change. As new needs arise, the metrics generated by your deployed assistants can help you identify and address them in subsequent iterations.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dev-process"}, {"document_id": "ibmcld_02569-4530-5596", "score": 0.513446569442749, "text": "\nIt is expected for message values to duplicate information from code, target, and custom extensions to the error model.\n\nImportantly, message values are still meant for developers and for this reason SHOULD NOT be localized or written for use in a user interface. Fields mentioned within a message SHOULD be mentioned by exact field name (e.g., first_name, not \"first name\").\n\nConsider the example above of an error code with value invalid_color. A poor message would be:\n\n\"The color provided for paint was invalid.\"\n\nUnlike the code, a message MAY prescribe a specific solution, thereby adding value. A better message would be:\n\n\"The color for paint must be red or blue.\"\n\nAs demonstrated in the above examples, message values SHOULD use the back-tick character to enclose field names, parameter names, header names, and specific values.\n\n\n\n\n\n\n\n Robustness tradeoffs \n\nThe robustness principle section has been moved to a [new page](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-robustness), and the previous guidance has been substantially repudiated.", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-errors"}, {"document_id": "ibmcld_02837-16655-18564", "score": 0.5072852969169617, "text": "\nIt also is responsible for removing a model from MinIO if the model is deleted. The system determines whether a training run completed successfully based on a flag that is stored in MinIO storage. The Master microservice must have API access to the Docker registry where the training images are stored. The image metadata that is obtained from the registry is used to correctly start the training pods.\n\nThe training pods that are started by this component are sometimes referred to as SLAD pods. SLAD stands for Statistical Learning and Discovery, which is the name of the research group that developed the language classifier that is used by the pods. The training pod names start with tr[12]?, followed by the internal vn-\u2026 ID. The training images are named nlclassifier-training or clu-training, depending on the chart version. The ${release-name}-master-config configuration map contains the JSON template for the training pods.\n\nThe ${release-name} is watson-assistant.\n\n\n\n\n\n Data store details \n\nThe following sections provide more detail about how the data stores are used by the Watson Assistant service. The objective is to help you troubleshoot issues that might arise during installation or after the service is deployed and running in a data center.\n\n\n\n Etcd store \n\nWatson Assistant uses Etcd as a key-value store. Etcd is used by LiteLinks for service discovery and by the language understanding pipeline as configuration storage.\n\nEtcd consists of five pods. The Etcd pod names follow the convention ${release-name}-etcd3-[0-9]. The Watson Assistant chart requires Etcd version 3 with enabled authorization.\n\n\n\n LiteLinks service discovery \n\nThe Dialog, NLU, Master, TAS, and ED-MM microservices act as LiteLinks servers. Each LiteLinks server is registered in Etcd with its own key under the /bluegoat/litelinks/ path. Each pod stores its metadata, such as its IP address and port, into Etcd.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-architecture"}, {"document_id": "ibmcld_12530-4747-5873", "score": 0.49735063314437866, "text": "\nThe evidence is reported to the IBM Cloud Security and Compliance Center, and included in an automated change rquest document.\n\nTwo types of issues are reported from your CI and CC pipelines: incident issues and nonincident issues. Incident issues can arise due to vulnerabilities or CVEs found inside the code or the deployed artifacts, and nonincident issues do not arise from vulnerabilities, but rather represent a deviation from the compliance posture, for example, unit test failures and branch protection check failures. For more information about managing issues, see [Processing incident and nonincident issues](https://cloud.ibm.com/docs/devsecops?topic=devsecops-issue-processing) and [Managing incident issues](https://cloud.ibm.com/docs/devsecops?topic=devsecops-incident-issues)\n\nCompliance evidence creates the trail that auditors look for during a compliance audit. One of the goals of DevSecOps is automated evidence generation and storage in auditable change requests and durable evidence lockers. For more information, see [Evidence](https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-evidence).", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-compliant-software-development"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02598-2975-4802", "score": 0.6130766868591309, "text": "\nOn Windows systems, there is a maximum path length, which is exceeded when you try to install all of the dependencies in a deep level folder.\n\n How to fix it \n\nYou can fix this problem in one of the following ways:\n\n\n\n* Ensure that you have installed the correct version of Node.js. For more information, see [Installing the Developer Toolkit](https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-creating_apis).\n* If you had to upgrade a program, try the installation again.\n\n\n\nIf that does not work, install API Connect at a level higher than the likely C:/program files/nodejs/bin/node_modules... folder. If you install at a top-level directory, you will not see this error.\n\n\n\n\n\n Unable to install the developer toolkit on Mac OS X \n\nAfter you provision the API Connect service, you try to install the developer toolkit and the installation fails.\n\n What\u2019s happening \n\nThe following errors are displayed during the developer toolkit installation:\n\nAgreeing to the Xcode/iOS license requires admin\nprivileges, please re-run as root via sudo\n\n Why it\u2019s happening \n\nYou recently upgraded or installed Xcode and have not agreed to the license yet.\n\n How to fix it \n\n\n\n1. Enter the following command to validate your Xcode license:\n\n\n\nsudo xcode-select\n\n\n\n2. Reinstall the developer toolkit.\n\n\n\n\n\n\n\n Unable to install the developer toolkit on Ubuntu \n\nAfter you provision the API Connect service, you try to install the developer toolkit and the installation fails.\n\n What\u2019s happening \n\nThe following errors are displayed during the developer toolkit installation:\n\nsqlite3@3.1.1 install /usr/local/lib/node_modules/strong-pm/node_modules/minkelite/node_modules/sqlite3\nnode-pre-gyp install --fallback-to-build\n/usr/bin/env: node: No such file or directory\nnpm WARN This failure might be due to the use of legacy binary \"node\"", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-apic_troubleshoot"}, {"document_id": "ibmcld_05278-78655-79972", "score": 0.5872471332550049, "text": "\n{\"level\":\"info\",\"ts\":1614089509.0128207,\"caller\":\"git/git.go:203\",\"msg\":\"Successfully initialized and updated submodules in path /workspace/source\"}\n\nmybuildrun-v2mb8-pod-tlzdx/step-build-and-push:\nINFO[0000] Retrieving image manifest node:12-alpine\nINFO[0000] Retrieving image node:12-alpine\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0001] Built cross stage deps: map[]\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0002] Retrieving image manifest node:12-alpine\nINFO[0002] Retrieving image node:12-alpine\nINFO[0002] Executing 0 build triggers\nINFO[0002] Unpacking rootfs as cmd RUN npm install requires it.\nINFO[0006] RUN npm install\nINFO[0006] Taking snapshot of full filesystem...\nINFO[0008] cmd: /bin/sh\nINFO[0008] args: [-c npm install]\nINFO[0008] Running: [/bin/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.27s\nfound 0 vulnerabilities", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli"}, {"document_id": "ibmcld_04335-77203-78520", "score": 0.5872471332550049, "text": "\n{\"level\":\"info\",\"ts\":1614089509.0128207,\"caller\":\"git/git.go:203\",\"msg\":\"Successfully initialized and updated submodules in path /workspace/source\"}\n\nmybuildrun-v2mb8-pod-tlzdx/step-build-and-push:\nINFO[0000] Retrieving image manifest node:12-alpine\nINFO[0000] Retrieving image node:12-alpine\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0001] Built cross stage deps: map[]\nINFO[0001] Retrieving image manifest node:12-alpine\nINFO[0001] Retrieving image node:12-alpine\nINFO[0002] Retrieving image manifest node:12-alpine\nINFO[0002] Retrieving image node:12-alpine\nINFO[0002] Executing 0 build triggers\nINFO[0002] Unpacking rootfs as cmd RUN npm install requires it.\nINFO[0006] RUN npm install\nINFO[0006] Taking snapshot of full filesystem...\nINFO[0008] cmd: /bin/sh\nINFO[0008] args: [-c npm install]\nINFO[0008] Running: [/bin/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.27s\nfound 0 vulnerabilities", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cli"}, {"document_id": "ibmcld_05758-3988-5631", "score": 0.5869953036308289, "text": "\n* If the status of the PVC shows Pending, describe the PVC and review the Events section of the output for any warnings or error messages. Note that PVCs that reference storage classes with the volume binding mode set to WaitForFirstConsumer remain Pending until an app pod is deployed that uses the PVC.\n\nkubectl describe pvc <pvc_name>\n\nExample output\n\nName: local-pvc\nNamespace: default\nStorageClass: sat-local-file-gold\nStatus: Pending\nVolume:\nLabels: <none>\nAnnotations: <none>\nFinalizers: [kubernetes.io/pvc-protection]\nCapacity:\nAccess Modes:\nVolumeMode: Filesystem\nMounted By: <none>\nEvents:\nType Reason Age From Message\n---- ------ ---- ---- -------\nWarning ProvisioningFailed 60s (x42 over 11m) persistentvolume-controller storageclass.storage.k8s.io \"sat-local-file-gold\" not found\n\n\n\n2. [Review the Block Storage for Classic troubleshooting documentation for steps to resolve common errors](https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemapsitemap_block_storage).\n\n\n\n\n\n\n\n Checking and updating the kubectl CLI version \n\nIf you use a kubectl CLI version that does not match at least the major.minor version of your cluster, you might experience unexpected results. For example, [Kubernetes does not support](https://kubernetes.io/releases/version-skew-policy/)kubectl client versions that are 2 or more versions apart from the server version (n +/- 2).\n\n\n\n1. Verify that the kubectl CLI version that you run on your local machine matches the Kubernetes version that is installed in your cluster. Show the kubectl CLI version that is installed in your cluster and your local machine.\n\nkubectl version\n\nExample output:", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_storage_block"}, {"document_id": "ibmcld_10192-3929-5532", "score": 0.5808142423629761, "text": "\n* If the status of the PVC shows Pending, describe the PVC and review the Events section of the output for any warnings or error messages. Note that PVCs that reference storage classes with the volume binding mode set to WaitForFirstConsumer remain Pending until an app pod is deployed that uses the PVC.\n\noc describe pvc <pvc_name>\n\nExample output\n\nName: local-pvc\nNamespace: default\nStorageClass: sat-local-file-gold\nStatus: Pending\nVolume:\nLabels: <none>\nAnnotations: <none>\nFinalizers: [kubernetes.io/pvc-protection]\nCapacity:\nAccess Modes:\nVolumeMode: Filesystem\nMounted By: <none>\nEvents:\nType Reason Age From Message\n---- ------ ---- ---- -------\nWarning ProvisioningFailed 60s (x42 over 11m) persistentvolume-controller storageclass.storage.k8s.io \"sat-local-file-gold\" not found\n\n\n\n2. [Review the Block Storage for Classic troubleshooting documentation for steps to resolve common errors](https://cloud.ibm.com/docs/openshift?topic=openshift-sitemapsitemap_block_storage).\n\n\n\n\n\n\n\n Checking and updating the oc CLI version \n\nIf you use a oc CLI version that does not match at least the major.minor version of your cluster, you might experience unexpected results. For example, [Kubernetes does not support](https://kubernetes.io/releases/version-skew-policy/)oc client versions that are 2 or more versions apart from the server version (n +/- 2).\n\n\n\n1. Verify that the oc CLI version that you run on your local machine matches the Kubernetes version that is installed in your cluster. Show the oc CLI version that is installed in your cluster and your local machine.\n\noc version\n\nExample output:", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-debug_storage_block"}, {"document_id": "ibmcld_06027-1539-3662", "score": 0.5720348954200745, "text": "\nFor more information about pod security profiles, see [Profile details](https://kubernetes.io/docs/concepts/security/pod-security-standards/) in the Kubernetes documentation.\n\nPod Security Admission contains three modes that define what action the control plane takes if a potential violation is detected.\n\nenforce\n: Policy violations cause the pod to be rejected.\n\naudit\n: Policy violations trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed.\n\nwarn\n: Policy violations trigger a user-facing warning, but are otherwise allowed.\n\nAs security standards or profiles implementations change to address new features, you can configure Pod Security Admission to use a specific version of the roles. The following versions are supported.\n\n\n\n* A Kubernetes major.minor version (for example, v1.25)\n* latest\n\n\n\n\n\n\n\n What if Pod Security Admission isn't the right choice for me? \n\nWhile Pod Security Admission is always enabled, it can be one of multiple admission controllers. You can configure third-party Kubernetes admission controllers to implement other security policy models that suit your use case.\n\nIf you configure Pod Security Admission to enforce, warn, and audit by using the privileged profile, then the control plane allows all pods to run. You can then configure other admission controllers to reject them.\n\nYou can install a third-party admission controller as long as it doesn't take either of the following actions.\n\n\n\n* It doesn't install its own pod security policies (PSPs).\n* It doesn't rely on PSPs to enforce parts of the policy.\n\n\n\n\n\n\n\n Configuring Pod Security admission namespace labels \n\nYou can define the admission control mode you want to use for pod security in each namespace. Kubernetes defines a set of labels that you can set to define which of the predefined Pod Security Standard profiles you want to use for a namespace. The label you select defines what action the control plane takes if a potential violation is detected.\n\nBy default, IBM Cloud Kubernetes Service adds the privileged Pod Security labels to the following namespaces.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-pod-security-admission&interface=ui"}, {"document_id": "ibmcld_10461-1543-3668", "score": 0.5706725120544434, "text": "\nFor more information about pod security profiles, see [Profile details](https://kubernetes.io/docs/concepts/security/pod-security-standards/) in the Kubernetes documentation.\n\nPod Security Admission contains three modes that define what action the control plane takes if a potential violation is detected.\n\nenforce\n: Policy violations cause the pod to be rejected.\n\naudit\n: Policy violations trigger the addition of an audit annotation to the event recorded in the audit log, but are otherwise allowed.\n\nwarn\n: Policy violations trigger a user-facing warning, but are otherwise allowed.\n\nAs security standards or profiles implementations change to address new features, you can configure Pod Security Admission to use a specific version of the roles. The following versions are supported.\n\n\n\n* A Kubernetes major.minor version (for example, v1.25)\n* latest\n\n\n\n\n\n\n\n What if Pod Security Admission isn't the right choice for me? \n\nWhile Pod Security Admission is always enabled, it can be one of multiple admission controllers. You can configure third-party Kubernetes admission controllers to implement other security policy models that suit your use case.\n\nIf you configure Pod Security Admission to enforce, warn, and audit by using the privileged profile, then the control plane allows all pods to run. You can then configure other admission controllers to reject them.\n\nYou can install a third-party admission controller as long as it doesn't take either of the following actions.\n\n\n\n* It doesn't install its own pod security policies (PSPs).\n* It doesn't rely on PSPs to enforce parts of the policy.\n\n\n\n\n\n\n\n Configuring Pod Security admission namespace labels \n\nYou can define the admission control mode you want to use for pod security in each namespace. Kubernetes defines a set of labels that you can set to define which of the predefined Pod Security Standard profiles you want to use for a namespace. The label you select defines what action the control plane takes if a potential violation is detected.\n\nBy default, Red Hat OpenShift on IBM Cloud adds the privileged Pod Security labels to the following namespaces.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-pod-security-admission"}, {"document_id": "ibmcld_13900-52291-53957", "score": 0.5600783824920654, "text": "\nVRVDR-51828 Major SIAD ACL: BCM SDK error when deleting ACL configuration \n VRVDR-51639 Critical Response for \"request hardware-diag version\" takes much longer with 1912b \n VRVDR-51619 Critical SIAD ACL: Ensure that rulesets which would exceed the TCAM are rejected \n VRVDR-51616 Critical Storm Control triggered snmpd warning messages in journal \n VRVDR-51543 Critical IPsec peers stuck in 'init' state after upgrade from 1801q to 1912d \n VRVDR-51539 Critical Repeated FAL BCM \"L3 Interface\" for VSI 0 Syslog \n VRVDR-51521 Critical NAT64 opd yang file missing required type field in 1908 and 1912 \n VRVDR-51518 Critical Dataplane performance fails for forward pkts when scatter mode driver is used \n VRVDR-51483 Major Removing guest configuration fails with scripting error \n VRVDR-51385 Critical Dataplane Crash in next_hop_list_find_path_using_ifp \n VRVDR-51348 Major libsnmp-dev built from DANOS/net-snmp is not API compatible with libsnmp-dev from upstream \n VRVDR-51345 Critical S9500-30XS: 100G Interface LED lit even when disabled \n VRVDR-51311 Blocker DAS Switch with 1912b seeing low rate of drops vs 1903m \n VRVDR-51295 Critical Changing speed on interface resets configured MTU to default \n VRVDR-51247 Major S9500 - missing hw_rev.cfg file \n VRVDR-51238 Major After broadcast storm, TACACS doesn't recover \n VRVDR-51185 Blocker Link doesn't come up after swapping 1000BASE-T SFP for 1000BASE-X SFP \n VRVDR-51183 Major 'FAL neighbor del' log is generated by dataplane for each ARP received for an unknown address \n VRVDR-51179 Critical live-cd installs should not install all unique state \n VRVDR-51148 Critical S9500 interface flaps when MTU is modified", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-ciena-vyatta-5600-vrouter-software-patches"}, {"document_id": "ibmcld_02598-4463-6196", "score": 0.5584429502487183, "text": "\nThe following errors are displayed during the developer toolkit installation:\n\nsqlite3@3.1.1 install /usr/local/lib/node_modules/strong-pm/node_modules/minkelite/node_modules/sqlite3\nnode-pre-gyp install --fallback-to-build\n/usr/bin/env: node: No such file or directory\nnpm WARN This failure might be due to the use of legacy binary \"node\"\nnpm WARN For further explanations, please read /usr/share/doc/nodejs/README.Debian\nnpm ERR! weird error 127\nnpm ERR! not ok code 0\n\n How to fix it \n\nEnter the following command to resolve the problem:\n\n$ update-alternatives --install /usr/bin/node node /usr/bin/nodejs 99\n\n\n\n\n\n Unable to debug the npm installation failure \n\nWhen you follow the steps to install the developer toolkit, the npm installation fails.\n\n What\u2019s happening \n\nThe npm installation fails without providing any useful information to debug.\n\n How to fix it \n\nWhen an installation fails, npm writes a line in the npm-debug.log</filepath> file to show where the error is located. Use the npm-debug.log file to determine the cause.\n\n\n\n\n\n Unable to open the API Designer \n\nYou enter the command apic edit and the API Designer does not open.\n\n What\u2019s happening \n\nYou are unable to open an instance of the API Designer after you enter the command:\n\napic edit\n\nand the following message is displayed:\n\n<time stamp>. 329Z ERROR apiConnect: listen EADDRINUSE <ip address> :9000\n\n Why it\u2019s happening \n\nYou have already started an instance of the API Designer from another command window.\n\n How to fix it \n\nTo fix this problem, you need to close the other command window as described in the following steps:\n\n\n\n1. In the other command window, press Ctrl + C.\n2. The following message is displayed.\n\n\n\nTerminate Batch job (Y/N)?\n\n\n\n3.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-apic_troubleshoot"}, {"document_id": "ibmcld_05503-18324-19557", "score": 0.5567063093185425, "text": "\nINFO[0008] RUN npm install\nINFO[0008] Taking snapshot of full filesystem...\nINFO[0010] cmd: /bin/sh\nINFO[0010] args: [-c npm install]\nINFO[0010] Running: [/bin/sh -c npm install]\nnpm WARN saveError ENOENT: no such file or directory, open '/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open '/package.json'\nnpm WARN !invalid2 No description\nnpm WARN !invalid2 No repository field.\nnpm WARN !invalid2 No README data\nnpm WARN !invalid2 No license field.\n\nup to date in 0.267s\nfound 0 vulnerabilities\n\nINFO[0011] Taking snapshot of full filesystem...\nINFO[0011] COPY server.js .\nINFO[0011] Taking snapshot of files...\nINFO[0011] EXPOSE 8080\nINFO[0011] cmd: EXPOSE\nINFO[0011] Adding exposed port: 8080/tcp\nINFO[0011] CMD [ \"node\", \"server.js\" ]\n\nmybuildrun-zg5rj-pod-z5gzb/step-image-digest-exporter-ngl6j:\n2021/02/26 18:21:02 warning: unsuccessful cred copy: \".docker\" from \"/tekton/creds\" to \"/tekton/home\": unable to open destination: open /tekton/home/.docker/config.json: permission denied\n{\"severity\":\"INFO\",\"timestamp\":\"2021-02-26T18:21:26.372494581Z\",\"caller\":\"logging/config.go:116\",\"message\":\"Successfully created the logger.\"}", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-view-logs"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02772-4213-5899", "score": 0.6263185739517212, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10817-1342-3184", "score": 0.6081793308258057, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 0.5892593860626221, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 0.5729596018791199, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-14062-16080", "score": 0.5651149153709412, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10852-43319-44485", "score": 0.5491615533828735, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_02934-36532-38745", "score": 0.5135266780853271, "text": "\nYou probably want either the Found response for all of them or none of them to be returned.\n\nTo prevent Found responses from being displayed, you can do one of the following things to each Found response:\n\n\n\n* Add a condition to the response that prevents it from being displayed if particular slots are filled. For example, you can add a condition, like !($size && $time), that prevents the response from being displayed if the $size and $time context variables are both provided.\n* Add the !all_slots_filled condition to the response. This setting prevents the response from being displayed if all of the slots are filled. Do not use this approach if you are including a confirmation slot. The confirmation slot is also a slot, and you typically want to prevent the Found responses from being displayed before the confirmation slot itself is filled.\n\n\n\n\n\n\n\n Handling requests to exit a process \n\nAdd at least one slot handler that can recognize it when a user wants to exit the node.\n\nFor example, in a node that collects information to schedule a pet grooming appointment, you can add a handler that conditions on the #cancel intent, which recognizes utterances such as, Forget it. I changed my mind.\n\n\n\n1. In the JSON editor for the handler, fill all of the slot context variables with dummy values to prevent the node from continuing to ask for any that are missing. And in the handler response, add a message such as, Ok, we'll stop there. No appointment will be scheduled.\n2. Choose what action you want your assistant to take next from the following options:\n\n\n\n* Prompt again (Default): Displays the prompt for the slot that the user was working with just before asking the off-topic question.\n* Skip current slot: Displays the prompt associated with the slot that comes after the slot that the user was working with just before asking the off-topic question. And your assistant makes no further attempts to fill the skipped slot.\n* Skip to response: Skips the prompts for all remaining empty slots including the slot the user was working with just before asking the off-topic question.\n\n\n\n3. In the node-level response, add a condition that checks for a dummy value in one of the slot context variables.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_04518-7-1743", "score": 0.5126378536224365, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 0.5108087062835693, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_03249-37219-39347", "score": 0.5098048448562622, "text": "\nYou probably want either the Found response for all of them or none of them to be returned.\n\nTo prevent Found responses from being displayed, you can do one of the following things to each Found response:\n\n- Add a condition to the response that prevents it from being displayed if particular slots are filled. For example, you can add a condition, like !($size && $time), that prevents the response from being displayed if the $size and $time context variables are both provided.\n- Add the !all_slots_filled condition to the response. This setting prevents the response from being displayed if all of the slots are filled. Do not use this approach if you are including a confirmation slot. The confirmation slot is also a slot, and you typically want to prevent the Found responses from being displayed before the confirmation slot itself is filled.\n\n Handling requests to exit a process {: dialog-slots-node-level-handler}\n\nAdd at least one slot handler that can recognize it when a user wants to exit the node.\n\nFor example, in a node that collects information to schedule a pet grooming appointment, you can add a handler that conditions on the cancel intent, which recognizes utterances such as, <q>Forget it. I changed my mind.</q>\n\n1. In the JSON editor for the handler, fill all of the slot context variables with dummy values to prevent the node from continuing to ask for any that are missing. And in the handler response, add a message such as, Ok, we'll stop there. No appointment will be scheduled.\n1. Choose what action you want your assistant to take next from the following options:\n\n- Prompt again (Default): Displays the prompt for the slot that the user was working with just before asking the off-topic question.\n- Skip current slot: Displays the prompt associated with the slot that comes after the slot that the user was working with just before asking the off-topic question. And your assistant makes no further attempts to fill the skipped slot.\n- Skip to response: Skips the prompts for all remaining empty slots including the slot the user was working with just before asking the off-topic question.\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07551-15747-17355", "score": 0.6967573165893555, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-14062-16080", "score": 0.6760825514793396, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10852-44214-45420", "score": 0.6756168603897095, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_04518-1426-3052", "score": 0.6558494567871094, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-1342-3184", "score": 0.6521733999252319, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-43319-44485", "score": 0.6402876377105713, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_00853-2658-4064", "score": 0.6028084754943848, "text": "\nFor instructions to configure the build job, see the [Configuring a Nexus npm build job in your pipeline](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-nexusconfig_nexus_npm) section.\n11. Optional: If you are using a toolchain on IBM Cloud Public and you want to build your app by using Nexus with Maven, configure your pipeline to add a Maven build job. For instructions to configure the build job, see the [Configuring a Nexus Maven build job in your pipeline](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-nexusconfig_nexus_maven) section.\n\n\n\n\n\n Configuring a Nexus npm build job in your pipeline \n\nBefore you configure an npm build job in your pipeline, you need a working pipeline that can use your build SCM repo as input, and you must configure Nexus for your toolchain. For instructions to configure Nexus, see the [Nexus](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-nexusnexus) section.\n\nConfigure the Delivery Pipeline to add an npm build job:\n\n\n\n1. Create a stage and set the input to the appropriate SCM repo.\n2. On the stage, add a build job.\n3. Configure the build job:\n\nZoom\n\n![npm build job](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/nexus_npm_job.png)\n\nFigure 1. npm build job\n\na. For the builder type, select npm (Artifactory or Nexus).\n\nb.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-nexus"}, {"document_id": "ibmcld_12952-2658-4091", "score": 0.599394679069519, "text": "\nFor instructions to configure the build job, see the [Configuring a Nexus npm build job in your pipeline](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-nexusconfig_nexus_npm) section.\n11. Optional: If you are using a toolchain on IBM Cloud Public and you want to build your app by using Nexus with Maven, configure your pipeline to add a Maven build job. For instructions to configure the build job, see the [Configuring a Nexus Maven build job in your pipeline](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-nexusconfig_nexus_maven) section.\n\n\n\n\n\n Configuring a Nexus npm build job in your pipeline \n\nBefore you configure an npm build job in your pipeline, you need a working pipeline that can use your build SCM repo as input, and you must configure Nexus for your toolchain. For instructions to configure Nexus, see the [Nexus](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-nexusnexus) section.\n\nConfigure the Delivery Pipeline to add an npm build job:\n\n\n\n1. Create a stage and set the input to the appropriate SCM repo.\n2. On the stage, add a build job.\n3. Configure the build job:\n\nZoom\n\n![npm build job](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/nexus_npm_job.png)\n\nFigure 1. npm build job\n\na. For the builder type, select npm (Artifactory or Nexus).\n\nb.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-nexus"}, {"document_id": "ibmcld_00679-2705-4183", "score": 0.5955770015716553, "text": "\nFor instructions to configure the build job, see the [Configuring an Artifactory npm build job in your pipeline](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-artifactoryconfig_artifactory_npm) section.\n10. Optional: If you are using a toolchain on IBM Cloud Public and you want to build your app by using Artifactory with Maven, configure your pipeline to add a Maven build job. For instructions to configure the build job, see the [Configuring an Artifactory Maven build job in your pipeline](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-artifactoryconfig_artifactory_maven) section.\n\n\n\n\n\n Configuring an Artifactory npm build job in your pipeline \n\nBefore you configure an npm build job in your pipeline, you must have a working pipeline that can use your build SCM repo as input. You must also configure Artifactory for your toolchain. For instructions to configure Artifactory, see the [Artifactory](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-artifactoryartifactory) section.\n\nConfigure Delivery Pipeline to add an npm build job:\n\n\n\n1. Create a stage and set the input to the appropriate SCM repo.\n2. On the stage, add a build job.\n3. Configure the build job:\n\nZoom\n\n![npm build job](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/artifactory_npm_job.png)\n\nFigure 1. npm build job\n\na. For the builder type, select NPM Build.\n\nb.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-artifactory"}, {"document_id": "ibmcld_12922-2705-4210", "score": 0.5883974432945251, "text": "\nFor instructions to configure the build job, see the [Configuring an Artifactory npm build job in your pipeline](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-artifactoryconfig_artifactory_npm) section.\n10. Optional: If you are using a toolchain on IBM Cloud Public and you want to build your app by using Artifactory with Maven, configure your pipeline to add a Maven build job. For instructions to configure the build job, see the [Configuring an Artifactory Maven build job in your pipeline](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-artifactoryconfig_artifactory_maven) section.\n\n\n\n\n\n Configuring an Artifactory npm build job in your pipeline \n\nBefore you configure an npm build job in your pipeline, you must have a working pipeline that can use your build SCM repo as input. You must also configure Artifactory for your toolchain. For instructions to configure Artifactory, see the [Artifactory](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-artifactoryartifactory) section.\n\nConfigure Delivery Pipeline to add an npm build job:\n\n\n\n1. Create a stage and set the input to the appropriate SCM repo.\n2. On the stage, add a build job.\n3. Configure the build job:\n\nZoom\n\n![npm build job](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/artifactory_npm_job.png)\n\nFigure 1. npm build job\n\na. For the builder type, select NPM Build.\n\nb.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-artifactory"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03036-7-2061", "score": 0.6755434274673462, "text": "\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_09791-7-1663", "score": 0.6685178279876709, "text": "\nManaging panels \n\nUse a panel to display a metric or group of metrics in a dashboard. You can copy, change the scope, duplicate, delete, export, and explore panels.\n\nYou can use any of the following panel types:\n\n\n\nTable 1. Panel types\n\n Type Description \n\n Line Use this panel to view trends over time for one or more metrics. \n Top list Use this panel to compare a metric across groups of entities. The bar chart is sorted in descending order. \n Histogram Use this panel to view the frequency distribution of a metric in buckets. \n Number Use this panel to view a single number that represents the value of an aggregated metric over time for one or more entities. \n Table Use this panel to display numerical data for your infrastructure based on metrics and segments. \n Text Use this panel to add text. Use markdown to add your text. \n\n\n\n\n\n Copy a panel into a dashboard \n\nComplete the following steps to copy a panel:\n\n\n\n1. Navigate to the Dashboards section (![dashboard section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/dashboards.png)) in the Web UI. Select a dashboard. Then, identify the panel that displays the metric that you want to copy.\n2. Click the Actions icon ![Three dots icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/actions.png) and select Copy to Dashboard![Copy to Dashboard icon](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/monitor/images/copy.png).\n3. Select one of the dashboards that are listed, or enter a name for a new dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-panels"}, {"document_id": "ibmcld_13406-8557-9604", "score": 0.666874349117279, "text": "\nprocessing_metrics_interval: 0.25,\ninterim_results: true,\nspeaker_labels: true\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n\nThe following example output shows the first few processing metrics results that the service returns for the request.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {\n\"received\": 7.04,\n\"seen_by_engine\": 1.59,\n\"transcription\": 0.49,\n\"speaker_labels\": 0.0\n},\n\"wall_clock_since_first_byte_received\": 0.32,\n\"periodic\": true\n}\n}\n{\n\"processing_metrics\": {\n\"processed_audio\": {\n\"received\": 7.04,\n\"seen_by_engine\": 1.59,\n\"transcription\": 0.49,\n\"speaker_labels\": 0.0\n},\n\"wall_clock_since_first_byte_received\": 0.51,\n\"periodic\": false\n},\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"timestamps\":\n\n\"hello\",\n0.43,\n0.76\n],\n\n\"world\",\n0.76,\n1.22\n]\n],\n\"transcript\": \"hello world \"\n}\n],\n\"final\": false\n}\n]\n}\n{\n\"processing_metrics\": {\n\"processed_audio\": {\n\"received\": 7.04,\n\"seen_by_engine\": 2.59,\n\"transcription\": 1.25,\n\"speaker_labels\": 0.0\n},\n\"wall_clock_since_first_byte_received\": 0.57,\n\"periodic\": true\n}", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_13406-1732-4088", "score": 0.6579732894897461, "text": "\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_00324-12617-14618", "score": 0.6539341807365417, "text": "\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https://cloud.ibm.com/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-about-content-delivery-networks-cdn-"}, {"document_id": "ibmcld_00331-35683-37392", "score": 0.647775411605835, "text": "\nReturns the real-time metrics for the current account, including the total data (bandwidth and hits) over the given period of time and the detailed data divided with the given time interval. For more details, [View the examples](https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-apiexample-code-for-getting-real-time-metrics).\n\n\n\n* Parameters:\n\n\n\n* vendorName - The name of the CDN provider. Currently, only akamai is supported.\n* startTime - The start time timestamp (UTC+0) for query. The start time must be later than 48 hours ago. For example, if it's 9:00 AM 08 March 2020 now, the start time should be later than 9:00 AM 06 March 2020 in the same time zone(The timestamp should be more than 1583485200).\n* endTime - The end time timestamp (UTC+0) for query must be later than the start time.\n* timeInterval - An optional parameter to provide the time interval in seconds. The time interval must be a multiple of 60 and should be less than the time range from start time to end time.\n\n\n\n* Return - A collection of objects of type SoftLayer_Container_Network_CdnMarketplace_Metrics.\n\n\n\n--------------------\n\n\n\n\n\n getMappingRealTimeMetrics \n\nReturns the real-time metrics for the given mapping, including the total data (bandwidth and hits) over the given period of time and the detailed data divided with the given time interval. For more details, [View the examples](https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-apiexample-code-for-getting-real-time-metrics).\n\n\n\n* Parameters:\n\n\n\n* mappingUniqueId - Unique ID of the mapping for which metrics are queried.\n* startTime - The start time timestamp (UTC+0) for query. The start time must be later than 48 hours ago.", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-cdn-api-reference"}, {"document_id": "ibmcld_13406-3429-5587", "score": 0.6459598541259766, "text": "\nThe service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics \n\nThe service returns processing metrics for transcription events in the processing_metrics field of the SpeechRecognitionResults object. For metrics generated at periodic intervals, not with transcription events, the object contains only the processing_metrics field, as shown in the following example.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {\n\"received\": float,\n\"seen_by_engine\": float,\n\"transcription\": float,\n\"speaker_labels\": float\n},\n\"wall_clock_since_first_byte_received\": float,\n\"periodic\": boolean\n}\n}\n\nThe processing_metrics field includes a ProcessingMetrics object that has the following fields:\n\n\n\n* wall_clock_since_first_byte_received is the amount of real time in seconds that has passed since the service received the first byte of input audio. Values in this field are generally multiples of the specified metrics interval, with two differences:\n\n\n\n* Values might not reflect exact intervals such as 0.25, 0.5, and so on. Actual values might, for example, be 0.27, 0.52, and so on, depending on when the service receives and processes audio.\n* Values for transcription events are not related to the processing interval. The service returns event-driven results as they occur.\n\n\n\n* periodic indicates whether the metrics apply to a periodic interval or to a transcription event:\n\n\n\n* true means that the response was triggered by a processing interval. The information contains processing metrics only.\n* false means that the response was triggered by a transcription event.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_00331-34386-36130", "score": 0.6428085565567017, "text": "\n* endDate - Provide the end date timestamp (UTC+0) for query.\n* frequency - Provide the data frequency for data format, the following options are available to configure frequency:\n\n\n\n* aggregate - Aggregated metrics data from startDate to endDatedefault.\n* day - Daily metrics data from startDate to endDate.\n\n\n\n\n\n* Return - A collection of objects of type SoftLayer_Container_Network_CdnMarketplace_Metrics.\n\n\n\n--------------------\n\n\n\n\n\n getMappingBandwidthByRegionMetrics \n\nReturns the total number of predetermined statistics for direct display (no graph) for a given mapping, over a given period of time. The value of frequency is aggregate by default.\n\n\n\n* Parameters:\n\n\n\n* mappingUniqueId - Provide a unique ID of the mapping for which metrics are queried.\n* startDate - Provide the start date timestamp (UTC+0) for query.\n* endDate - Provide the end date timestamp (UTC+0) for query.\n* frequency - Provide the data frequency for data format, the following options are available to configure frequency:\n\n\n\n* aggregate - Aggregated metrics data from startDate to endDatedefault.\n* day - Daily metrics data from startDate to endDate.\n\n\n\n\n\n* Return - A collection of objects of type SoftLayer_Container_Network_CdnMarketplace_Metrics.\n\n\n\n--------------------\n\n\n\n\n\n getCustomerRealTimeMetrics \n\nReturns the real-time metrics for the current account, including the total data (bandwidth and hits) over the given period of time and the detailed data divided with the given time interval. For more details, [View the examples](https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-apiexample-code-for-getting-real-time-metrics).\n\n\n\n* Parameters:\n\n\n\n* vendorName - The name of the CDN provider. Currently, only akamai is supported.", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-cdn-api-reference"}, {"document_id": "ibmcld_08592-8007-9409", "score": 0.6393123269081116, "text": "\nYou can scope down your metrics by using the following scope filters.\n\n\n\nTable 4. Describes the scope filters for Hyper Protect Crypto Services metrics.\n\n Attribute Name Description \n\n ibmResourceGroupName The name of the resource group associated with the Hyper Protect Crypto Services service instance. \n ibmScope The account, organization, or space GUID associated with the metric. \n ibmServiceInstanceName The service instance associated with the metric. \n ibmHpcsApi The Hyper Protect Crypto Services API calls associated with the metric. \n\n\n\nBecause of Monitoring limitations, you are able to see the values in the filters for up to 6 hours at a time. You can manually type in value into scope variables to use scope filters for given time periods.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics. To set up alerts, complete the following steps:\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert and select Metric as the alert type.\n3. Select the aggregation and the metric that you would like to be performed on.\n4. Select the scope if applicable.\n5. Set the metric and time requirements for the alert to trigger.\n6. Configure and set up the notification channel and notification interval.\n7. Click CREATE.\n\n\n\nFor more information about configuring metric alerts, see [Metric Alerts](https://docs.sysdig.com/en/metric-alerts.html).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metrics"}, {"document_id": "ibmcld_15746-8362-10414", "score": 0.6350595355033875, "text": "\nNavigate to the [metrics monitoring portal](https://cloud.ibm.com/observe/monitoring).\n2. Click Open Dashboard next to the service name of the monitoring instance you want to work with. The dashboard displays.\n3. On the left sidebar, select Dashboards. Then, click the green + sign in the panel.\n4. Select Blank dashboard, then select the type of visual representation you want.\n\nIBM Cloud Monitoring offers eight different visualizations for your dashboard. Read the description for each visualization, then choose the one that best meets your requirements.\n\nLine (\"View trends over time\") is the easiest and most basic option. It is also the most frequently selected option. The examples in this topic show a Line-based visualization.\n5. Configure your custom dashboard.\n\n\n\n* In the Metrics field, enter ibm_is to display the two load balancer metrics: ibm_is_load_balancer_active_connections and ibm_is_load_balancer_connection_rate.\n\nYou can monitor listener port traffic by enabling the ibm_is_load_balancer_listener_port metric.\n* You can choose a scope to display in your dashboard by clicking Override Dashboard Scope. For example, you can display the metrics for a particular load balancer.\n* You can also set a segment to compare metrics across the scope you have defined. For example, you can look at Active connections for a particular load balancer segmented by listener port.\n\n\n\n6. Click Save for your new custom dashboard to be accessible.\n\nBy default, the dashboard begins with the name \"blank dashboard\". You can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-nlb_monitoring-metrics"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09276-7-2089", "score": 0.6946117877960205, "text": "\nWorking with alerts \n\nYou can configure alerts to notify about the state of your infrastructure, applications, and IBM Cloud services.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-alerts"}, {"document_id": "ibmcld_13029-7-2115", "score": 0.6839160323143005, "text": "\nWorking with alerts \n\nYou can configure alerts to notify about the activity in your IBM Cloud account and changes in configuration in the account.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of events that show in a view is more than what you expect.\n\nFor example, you might have a view that shows events that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more events show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of events that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives events within the last 24 hours.\n\nFor example, you might have a view that does not get any events for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, events need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:", "title": "", "source": "https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-alerts"}, {"document_id": "ibmcld_04133-4-1701", "score": 0.6748807430267334, "text": "\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Creating alerts by type \n\nIBM Cloud\u00ae Internet Services has alerts that you can configure to warn you when events occur. Use email or webhooks to receive alerts.\n\nAlerts are available only to Enterprise plans.\n\nFor more information about each type of alert, see [Types of alerts](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies&interface=uinotification-types).\n\n\n\n Creating an email alert using the UI \n\nYou can create email alerts for each alert type by using the UI. For more information about creating email alerts using the console, see [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies&interface=uiui-configure-alert-policies).\n\n\n\n\n\n Creating an email alert using the CLI \n\nYou can create email alerts for each alert type by using the CLI.\n\n\n\n DDoS attack layer 7 command \n\nCreate an alert policy for DDoS attack layer 7 by running the following command:\n\nibmcloud cis alert-policy ddos-attack-l7-alert-create --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* --name is the name of the alert policy.\n* --description is the description for the alert policy.\n* --emails is the email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com\n* --webhooks is the webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2\n* --enabled sets whether or not the alert policy is enabled.\n* -i, --instance is the instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type"}, {"document_id": "ibmcld_09701-9031-10960", "score": 0.6621314287185669, "text": "\n400 The alert configuration is not valid. \n 401 Unauthorized access. \n 404 The alert ID is not recognized. \n 409 There is a version mismatch. \n 422 The alert name is not valid. The name is already used. \n\n\n\n\n\n\n\n Body parameters \n\n\n\n id (integer) \n\nID of an alert.\n\n\n\n\n\n condition (string) \n\nDefines the threshold that is configured for the alert. This parameter is required for MANUAL alerts only.\n\nFor example, you can defines a consition as follows: avg(timeAvg(uptime)) <= 0\n\n\n\n\n\n createdOn (integer) \n\nDefines the creation time of an alert in milliseconds.\n\nThis parameter returns the Unix-timestamp when the alert was created.\n\n\n\n\n\n description (string) \n\nThis parameter describes the alert.\n\nThe description is available when you view an alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n enabled (boolean) \n\nDefines the status of an alert.\n\nBy default, this parameter is set to true and the alert is enabled when it is created.\n\n\n\n\n\n filter (string) \n\nDefines the scope of the alert by configuring segments.\n\nWhen this field is empty, all the metric sources are included. The scope is set to Everything.\n\nFor example, you can define filters like the following ones:\n\nkubernetes.namespace.name='production'\n\ncontainer.image='nginx'.\n\nkubernetes.namespace.name='production' and container.image='nginx'.\n\n\n\n\n\n name (string) \n\nName of the alert. Must be unique.\n\nThe name is used to identify the alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n modifiedOn (integer) \n\nDefines when an alert was last modified in milliseconds.\n\nThis parameter defines the Unix-timestamp when the alert was last modified.\n\n\n\n\n\n notificationChannelIds (array) \n\nLists the notification channels that are configured to notify when an alert is triggered.\n\nValid options are EMAIL, PAGER_DUTY, WEBHOOK, VICTOROPS, and SLACK.\n\n\"notificationChannelIds\": [", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_09414-4424-6466", "score": 0.6588565111160278, "text": "\n* You can enable or disable the feature on alerts that allow a user to mute an alert for a period of time. This feature only applies to email notification channels.\n* You can [detach an alert](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-remove_alert_ui) from a view.\n* The timestamp that you see in a notification is set to UTC. For email notifications, you can set the Timezone to define a different timestamp value such as local time, for example.\n\n\n\n\n\n Presence alert \n\nConfigure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report the deletion of service instances in your account. You are not expecting the deletion of service instances. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nConsider the following information when you configure an absence alert:\n\n\n\n* An absence alert is enabled when the view receives at least 1 log line.\n* An absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\n\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following conditions for an alert:\n\n\n\n* Time frequency: You set this condition to specify how often to trigger an alert. Valid values are: 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 6 hours, 12 hours, 24 hours", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-monitor_logs"}, {"document_id": "ibmcld_09703-1640-3664", "score": 0.6530227661132812, "text": "\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts"}, {"document_id": "ibmcld_09702-2551-4426", "score": 0.6482945084571838, "text": "\nWhen you define a Slack channel, replace <SLACK_CHANNEL_NAME> with the name of your channel. You must include the symbol with the name of the channel, for example, my_monitoring_alert_channel.\n\n\n\nWhen you configure the alert, complete the following sections:\n\n\n\n* [name and description]: You must define a unique name for the alert name by replacing <ALERT_NAME>, and optionally, add a description by replacing <ALERT_DESCRIPTION>.\n* [severity]: You must define the severity of the alert by replacing <SEVERITY> with a number. Valid values are 0, 1, 2, 3, 4, 5, 6, and 7.\n* [for_atleast_s]: You must define the number of consecutive seconds that the condition is met before the alert is triggered. Replace <FOR_ATLEAST_S> with the number of seconds.\n* [condition]: You must define the condition that defines when the alert is triggered. For example, you can set this parameter to ['host.mac', 'proc.name'] to check a CPU alert for every process on every machine.\n\nFor more information, see [Multi-Condition Alerts](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n* [segmentby]: You can define the scope of an alert by configuring the segmentedby section. The default value is ANY.\n* [segment_condition]: When the parameter segmentby is specified, set this field to determine when the alert will be triggered. Valid values are ANY and ALL.\n* [user_filter]: You can define a filter that indicates when a notification is sent. For example, you could define this entry if you want to receive a notification only if the name of the process meets the condition.\n* [notify]: You can define the type of notifications that you want the alert to generate. Set this entry to the notification IDs of the channels that you have defined.\n* [enabled]: You can configure the status of the alert when it is created. By default, alerts are enabled and the entry is set to true.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_python"}, {"document_id": "ibmcld_04334-282023-283354", "score": 0.6370959877967834, "text": "\nRequired.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-opt-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-certificate-alert-examples\" \"> --> Examples Update a certificate alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy certificate-alert-update a2633e68-1a64-2512-a321-b64a17c7db7a --name test1 --emails test1@cn.ibm.com --webhooks b2633e68-9a64-4519-b361-a64a67c8db8e --enabled true -i \"cis-demo\"\n<-- </section \"id=\"section-update-certificate-alert-examples\" \"> --><-- </section \"id=\"section-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-glb-healthcheck-alert\" \"> --> ibmcloud cis alert-policy glb-healthcheck-alert-update Update an alert policy for changes in health status for global load balancer, pools, and origins.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-275510-276933", "score": 0.6368024349212646, "text": "\n<-- </section \"id=\"section-create-glb-healthcheck-alert-examples\" \"> --><-- </section \"id=\"section-create-glb-healthcheck-alert\" \"> --><-- <section \"id=\"section-update-ddos-attack-l7-alert\" \"> --> ibmcloud cis alert-policy ddos-attack-l7-alert-update Update an alert policy for DDos attack l7. ibmcloud cis alert-policy ddos-attack-l7-alert-update POLICY_ID --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-update-ddos-attack-l7-alert\" \"> --> Command options POLICY_ID: The ID of alert policy. Required.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-opt-update-ddos-attack-l7-alert\" \"> --><-- <section \"id=\"section-update-ddos-attack-l7-alert-examples\" \"> --> Examples Update a ddos attack alert policy a2633e68-1a64-2512-a321-b64a17c7db7a.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-284149-285531", "score": 0.6339863538742065, "text": "\nFor example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.--pools: The IDs of origin pool, if set to all, the all pool IDs will be used.--include-future-pools: Whether or not include the future pools. (default \"false\")--health-status-trigger: The trigger condition to fire the notification. Valid values: \"healthy\", \"unhealthy\", \"either\". (default \"either\")--event-source-trigger: The event source of trigger to fire the notification. Valid values: \"pool\", \"origin\", \"either\". (default \"either\")-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-opt-update-glb-healthcheck-alert\" \"> --><-- <section \"id=\"section-update-glb-healthcheck-alert-examples\" \"> --> Examples Update a certificate alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy glb-healthcheck-alert-update a2633e68-1a64-2512-a321-b64a17c7db7a --name test1 --emails test1@cn.ibm.com --enabled true --pools all --include-future-pools true -i \"cis-demo\"\n<-- </section \"id=\"section-update-glb-healthcheck-alert-examples\" \"> --><-- </section \"id=\"section-update-glb-healthcheck-alert\" \"> --><-- <section \"id=\"section-delete-alert-policy\" \"> --> ibmcloud cis alert-policy delete Delete an alert policy.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03036-4322-6185", "score": 0.6219258308410645, "text": "\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_13406-6795-8870", "score": 0.5910896062850952, "text": "\nThe metrics indicate the progress and complexity of the engine's processing:\n\n\n\n* seen_by_engine is audio that the service has read and passed to the engine at least once.\n* received - seen_by_engine is audio that has been buffered at the service but has not yet been seen or processed by the engine.\n* The relationship between the times is received >= seen_by_engine >= transcription >= speaker_labels.\n\n\n\nThe following relationships can also be helpful in understanding the results:\n\n\n\n* The values of the received and seen_by_engine fields are greater than the values of the transcription and speaker_labels fields during speech recognition processing. The service must receive the audio before it can begin to process results.\n* The values of the received and seen_by_engine fields are identical when the service has finished processing the audio. The final values of the fields can be greater than the values of the transcription and speaker_labels fields by a fractional number of seconds.\n* The value of the speaker_labels field typically trails the value of the transcription field during speech recognition processing. The values of the transcription and speaker_labels fields are identical when the service has finished processing the audio.\n\n\n\n\n\n\n\n Processing metrics example: WebSocket interface \n\nThe following example shows the start message that is passed for a request to the WebSocket interface. The request enables processing metrics and sets the processing metrics interval to 0.25 seconds. It also sets the interim_results and speaker_labels parameters to true. The audio contains the simple message \"hello world long pause stop.\"\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/flac',\nprocessing_metrics: true,\nprocessing_metrics_interval: 0.25,\ninterim_results: true,\nspeaker_labels: true\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n\nThe following example output shows the first few processing metrics results that the service returns for the request.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_13406-1732-4088", "score": 0.5860968232154846, "text": "\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_03363-4-2165", "score": 0.5858273506164551, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-2789-4951", "score": 0.5830173492431641, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03010-4285-6329", "score": 0.5714224576950073, "text": "\n* [Annotated mentions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n Important \n\n\n\n* Intent example data should be representative and typical of data that your users provide. Examples can be collected from actual user data, or from people who are experts in your specific field. The representative and accurate nature of the data is important.\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03334-5529-7605", "score": 0.5693853497505188, "text": "\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n How entity references are treated \n\nWhen you include an entity mention in a user example, the machine learning model uses the information in different ways in these scenarios:\n\n\n\n* [Referencing entity values and synonyms in intent examples](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-related-entities)\n* [Annotated mentions](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03363-1671-3630", "score": 0.5659565925598145, "text": "\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_13129-16717-17970", "score": 0.5621510744094849, "text": "\nTo understand the quality metrics, refer to [Quality metric overview](https://cloud.ibm.com/docs/ai-openscale?topic=ai-openscale-anlz_metrics)\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n1. Navigate to [IBM Cloud\u00ae Resource List](https://cloud.ibm.com/resources/).\n2. Under Name, enter tutorial in the search box.\n3. Delete the services which you created for this tutorial.\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https://cloud.ibm.com/docs/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Pak for Data Overview](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html?context=analytics)\n* [Automatic model creation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-overview.html?context=analytics)\n* [Machine learning & AI](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-ai.html?context=analytics)\n* [Watson OpenScale documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/model/getting-started.html?context=analytics)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"}, {"document_id": "ibmcld_13406-11936-13393", "score": 0.555138349533081, "text": "\n* With the HTTP interfaces, you specify a query parameter with a speech recognition request.\n\n\n\nThe service returns audio metrics with the final transcription results. It returns the metrics just once for the entire audio stream. Even if the service returns multiple transcription results (for different blocks of audio), it returns only a single instance of the metrics at the very end of the results.\n\nThe WebSocket interface accepts multiple audio streams (or files) with a single connection. You delimit different streams by sending stop messages or empty binary blobs to the service. In this case, the service returns separate metrics for each delimited audio stream.\n\n\n\n\n\n Understanding audio metrics \n\nThe service return the metrics in the audio_metrics field of the SpeechRecognitionResults object.\n\n{\n\"results\": [\n. . .\n],\n\"result_index\": integer,\n\"audio_metrics\": {\n\"sampling_interval\": float,\n\"accumulated\": {\n\"final\": boolean,\n\"end_time\": float,\n\"signal_to_noise_ratio\": float,\n\"speech_ratio\": float,\n\"high_frequency_loss\": float,\n\"direct_current_offset\": [\n{\"begin\": float, \"end\": float, \"count\": integer},\n. . .\n],\n\"clipping_rate\": [\n{\"begin\": float, \"end\": float, \"count\": integer},\n. . .\n],\n\"speech_level\": [\n{\"begin\": float, \"end\": float, \"count\": integer},\n. . .\n],\n\"non_speech_level\": [\n{\"begin\": float, \"end\": float, \"count\": integer},\n. . .\n]\n}\n}\n}\nShow more\n\nThe audio_metrics field includes an AudioMetrics object that has two fields:", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03036-4322-6185", "score": 0.6501445770263672, "text": "\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03363-1671-3630", "score": 0.646338939666748, "text": "\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_16258-2570-3569", "score": 0.6388815641403198, "text": "\n[Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-side.png)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-7-1952", "score": 0.6318697929382324, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-1324-3123", "score": 0.6292141675949097, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_03363-4413-6535", "score": 0.6206398010253906, "text": "\nFor more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-7103-8947", "score": 0.6094186305999756, "text": "\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter. See [Enabling user metrics](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resourceslogs-resources-user-id) for more information.\n\n\n\n\n\n\n\n Top Intents and Top Entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. For each entity you can select from the Values column to see a list of the most common values that were identified for this entity during the time period. You can also select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03036-2789-4951", "score": 0.6040769815444946, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_16261-10613-12744", "score": 0.5999175310134888, "text": "\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}, {"document_id": "ibmcld_03363-3084-5067", "score": 0.5970871448516846, "text": "\n[Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node. For more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-4413-6535", "score": 0.665198028087616, "text": "\nFor more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-2789-4951", "score": 0.6100077033042908, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_16261-10613-12744", "score": 0.5784225463867188, "text": "\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}, {"document_id": "ibmcld_02914-7-1833", "score": 0.5651529431343079, "text": "\nPersonalizing the dialog with context \n\nTo personalize the conversation, your assistant can collect information from the customer and then refer back to it later in the conversation.\n\n\n\n Anatomy of a dialog call \n\nEach user input is passed to the dialog as a /message API call. Replies that users make in response to prompts from the dialog that ask them for more information are included. A single /message API call is equivalent to a single dialog turn, which consists of an input from the customer and a corresponding response from the dialog.\n\nThe body of the /message API call request and response includes the following objects:\n\n\n\n* context: Contains variables that are meant to be persisted. For the dialog to subsequently reference information that is submitted by the user, you must store the information in the context object. For example, the dialog can collect the user's name and then refer to the user by name in subsequent nodes. The following example shows how the context object is represented in the dialog JSON editor:\n\n{\n\"context\" : {\n\"user_name\" : \"<? @name.literal ?>\"\n}\n\nSee [Retaining information across dialog turns](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context) for more information.\n* input: The string of text that was submitted by the user. The text string can contain up to 2,048 characters. The following example shows how the input object is represented in the dialog JSON editor:\n\n{\n\"input\" : {\n\"text\" : \"Where's your nearest store?\"\n}\n* output: The dialog response to return to the user. The following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-context"}, {"document_id": "ibmcld_07578-4297-6315", "score": 0.5636628866195679, "text": "\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-4297-6315", "score": 0.5636628866195679, "text": "\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03312-1841-4150", "score": 0.562808096408844, "text": "\nWatson Assistant analytics provide overview statistics on the number of interactions with users and containment rates. Analytics doesn't cumulate statistics across regions. With an active/passive topology, this approach to analytics should be sufficient. However, using an active/active topology likely requires using [webhooks](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Recommendations \n\nThe intent and user example recommendation features use production data to make the recommendations. The available recommendations may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Autolearning \n\nThe autolearning feature uses production data to train an improved intent recognizer. The autolearning results may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-failover"}, {"document_id": "ibmcld_16274-7091-8528", "score": 0.5586943626403809, "text": "\nstreaming_statistics Object Information and statistics related to the Speech to Text recognition. See [assistant_interaction_summaries.turns].request.streaming_statistics](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-request-streaming_statistics). \n\n\n\n\n\n assistant_interaction_summaries.turns[].request.streaming_statistics \n\nThe assistant_interaction_summaries.turns[].request.streaming_statistics object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].streaming_statistics object\n\n Property Type Description \n\n transaction_id String A unique identifier of the transaction. \n start_timestamp String The time when the transaction started, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n stop_timestamp String The time when the transaction ended, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n response_milliseconds Number The latency (in milliseconds) between when silence is detected in the caller's speech and a final result from the assistant is received. \n echo_detected Boolean Whether an echo was detected. \n confidence Number The confidence score of the final utterance. \n\n\n\n\n\n\n\n\n\n assistant_interaction_summaries.turns[].response \n\nThe assistant_interaction_summaries.turns[].response object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].response object\n\n Property Type Description", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-cdr-log-reference"}, {"document_id": "ibmcld_16306-7519-9097", "score": 0.557951807975769, "text": "\n\"voice_telephony\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\",\n\"sip_request_uri\":\"sips:+18885557777@public.voip.us-east.assistant.watson.cloud.ibm.com\",\n\"sip_from_uri\":\"sips:+18565558576@twilio.com\",\n\"sip_to_uri\":\"sips:+18885557777@public.voip.us-east.assistant.watson.cloud.ibm.com\"\n},\n\"sip_call_id\": \"Aob2-2743-5678-1234\",\n\"assistant_phone_number\":\"+18885556789\",\n\"sip_custom_invite_headers\": {\n\"custom-header1\": \"123\",\n\"custom-header2\": \"456\"\n}\n}\n\n\n\n\n\n Request properties (set by the assistant) \n\n\n\nRequest properties of the voice_telephony object\n\n Name Type Description \n\n final_utterance_timeout_count Integer The time (in milliseconds) to wait for a final utterance from the Speech to Text service. If no final utterance is received before the timeout occurs, the phone integration sends a message to the assistant with the final_utterance_timeout_occurred property set to true. \n post_response_timeout_count Integer The time (in milliseconds) to wait for a new utterance after the last response is played. If no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expression-integration-variables"}, {"document_id": "ibmcld_03373-2953-4766", "score": 0.5556788444519043, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11852-7577-8251", "score": 0.55378657579422, "text": "\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.565Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT04-wss://c-01-ws.us-south.link.satellite.cloud.ibm.com/ws\",\"msg\":\"Connecting to wss://c-01-ws.us-south.link.satellite.cloud.ibm.com/ws\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.922Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"DoTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.cloud.ibm.com to 169.61.31.178\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:22.294Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"TunnelCore\",\"msgid\":\"TC24\",\"msg\":\"Tunnel open\",\"connector_id\":\"U2F0ZWxsaXRlQ29ubmVjdG9yOiJjaThzdWd1ZDFwZ2RrZmUxa3UxZyI\"}", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-run-agent-locally"}, {"document_id": "ibmcld_12200-8846-9734", "score": 0.5502389669418335, "text": "\n\"workspace_status_msg\": {\n\"status_code\": \"200\",\n\"status_msg\": \"\"\n},\n\"workspace_status\": {\n\"frozen\": true,\n\"frozen_by\": \"test@in.ibm.com\",\n\"frozen_at\": \"2023-01-05T13:44:32.400019282Z\",\n\"locked\": false\n},\n\"template_repo\": {\n\"url\": \"https://github.com/Anil-CM/newrepo\",\n\"commit_id\": \"3dc60ea7fb30f236dbadfa817cf4beb5d337808d\",\n\"full_url\": \"https://github.com/Anil-CM/newrepo\",\n\"has_uploadedgitrepotar\": false\n},\n\"template_data\": [\n{\n\"id\": \"b44c147b-81fb-4e\",\n\"folder\": \".\",\n\"compact\": false,\n\"type\": \"terraform_v1.0\",\n\"values_url\": \"https://us.schematics.cloud.ibm.com/v1/workspaces/us-east.workspace.testwspace03jan.cf74cc48/template_data/b44c147b-81fb-4e/values\",\n\"values\": \"\",\n\"values_metadata\":\n{\n\"default\": \"testvpcone\",\n\"description\": \"\",\n\"name\": \"vpc_name\",\n\"type\": \"string\"\n},\n{\n\"default\": \"\"tag:test1\", \"tag:test2\"]\",\n\"description\": \"\",\n\"name\": \"vpc_tags\",\n\"type\": \"list(string)\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sch-update-wks"}, {"document_id": "ibmcld_03036-2789-4951", "score": 0.5424782037734985, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_11852-7002-7827", "score": 0.5403456687927246, "text": "\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.392Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"DoTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.cloud.ibm.com to 169.61.31.178\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.560Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"utilities\",\"msg\":\"MakeLinkAPICall GET /v1/connectors/U2F0ZWxsaXRlQ29ubmVjdG9yOiJjaThzdWd1ZDFwZ2RrZmUxa3UxZyI status code 200\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.563Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT03\",\"msg\":\"Got configuration\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.565Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT04-wss://c-01-ws.us-south.link.satellite.cloud.ibm.com/ws\",\"msg\":\"Connecting to wss://c-01-ws.us-south.link.satellite.cloud.ibm.com/ws\"}", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-run-agent-locally"}, {"document_id": "ibmcld_11929-726-1588", "score": 0.5338767170906067, "text": "\n{\"level\":30,\"time\":1685976939593,\"pid\":13,\"hostname\":\"2f07087dc304\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"doTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.test.cloud.ibm.com to 169.46.14.242\"}\n{\"level\":60,\"time\":1685977059299,\"pid\":13,\"hostname\":\"2f07087dc304\",\"name\":\"tOps\",\"msgid\":\"O03-703\",\"msg\":\"getToken error\",\"err\":{\"type\":\"TimeoutError\",\"message\":\"Timeout awaiting 'request' for 120000ms\",\"stack\":\"RequestError: Timeout awaiting 'request' for 120000msn at ClientRequest.<anonymous> (/connector_agent/node_modules/got/dist/source/core/index.js:970:65)n at Object.onceWrapper (node:events:628:26)n at ClientRequest.emit (node:events:525:35)n at origin.emit (/connector_agent/node_modules/@szmarczak/http-timer/dist/source/index.js:43:20)n at TLSSocket.socketErrorListener (node:_http_client:502:9)n at TLSSocket.emit (node:events:513:28)n at", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-ts-connector-tunnel"}, {"document_id": "ibmcld_11852-5893-6717", "score": 0.5326874852180481, "text": "\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.133Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_ID value from SATELLITE_CONNECTOR_ID environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.138Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A01\",\"msg\":\"Load SATELLITE_CONNECTOR_IAM_APIKEY value from file /agent-env-files/apikey.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.140Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_TAGS value from SATELLITE_CONNECTOR_TAGS environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.141Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_REGION value from SATELLITE_CONNECTOR_REGION environment variable.\"}", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-run-agent-locally"}, {"document_id": "ibmcld_05479-871-1495", "score": 0.5325026512145996, "text": "\n{\"level\":\"info\",\"ts\":1625217529.370393,\"logger\":\"git\",\"msg\":\"ssh\",\"path\":\"/usr/bin/ssh\",\"version\":\"OpenSSH_8.0p1, OpenSSL 1.1.1g FIPS 21 Apr 2020\"}\n{\"level\":\"info\",\"ts\":1625217529.3847454,\"logger\":\"git\",\"msg\":\"git\",\"path\":\"/usr/bin/git\",\"version\":\"git version 2.27.0\"}\n{\"level\":\"info\",\"ts\":1625217529.3940003,\"logger\":\"git\",\"msg\":\"git-lfs\",\"path\":\"/usr/bin/git-lfs\",\"version\":\"git-lfs/2.11.0 (GitHub; linux amd64; go 1.14.4)\"}\n{\"level\":\"debug\",\"ts\":1625217529.3940916,\"logger\":\"git\",\"msg\":\"/usr/bin/git clone --quiet --no-tags --branch main --depth 1 --single-branch -- https://github.com/IBM/CodeEngineX /workspace/source\"}", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-ts-build-gitsource-stepfail"}, {"document_id": "ibmcld_12430-2025-3161", "score": 0.5245712995529175, "text": "\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud/kv/data/mykvsecret:key1 token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Lookup User Credentials secret with token - full\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nansible.builtin.debug:\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud/username_password/secrets/{{ secret_id }} token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Parsing username_password\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nsecret_data: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud/username_password/secrets/{{ secret_id }}:secret_data token={{ vault_token }} url={{ hostname_vault }}') | to_json }} \"\nansible.builtin.debug:\nmsg: \"user is {{ secret_data.username }} and password is {{ secret_data.password }}\"\n\nwhen: login.status == 200\nShow more\n\nA successful request returns the following response.\n\nTASK [Lookup KV secret with token] \nok: [localhost] => {\n\"msg\": \"secret1\"\n}\n\nTASK [Lookup User Credentials secret with token - full] \nok: [localhost] => {\n\"msg\": {\n\"created_by\": \"xxxxxxxxxxxxx\",", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-integration-ansible"}, {"document_id": "ibmcld_05367-4252-6277", "score": 0.5187494158744812, "text": "\nstatusCode: 302\n}\n}\n\n\n\n\n\n Example 3: Generating a plain text response from a Function \n\nThe following example illustrates how to generate a plain text response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name !== \"\") {\nmsg = Hello, ${params.name}!\n}\nreturn {\nheaders: { 'Content-Type': 'text/plain;charset=utf-8' },\nbody: ${msg}\n}\n}\n\n\n\n\n\n\n\n Error handling and debugging \n\nFunction invocations can return system or application errors. For example, system errors indicate that the function code did not execute successfully, while application errors indicate a problem in the Function code itself.\n\nWhen a system error occurs, an HTTP response code similar to the following codes is returned.\n\n\n\nTable 1. HTTP response codes\n\n Code Description \n\n 409 The resources that are required by the Function could not be satisfied. \n 413 The request payload exceeds the defined maximum. \n 414 The invocation URI is too long. \n 416 The Function generated a response that exceeds the defined maximum. \n 422 The Function code could not be loaded from a specified source. \n 429 You exceeded your resource quota, could not schedule the Function. \n 431 The request headers exceed the defined maximum. \n 500 Internal server error. \n 502 Bad gateway. \n 503 Function currently unavailable, please try again later. \n 507 Insufficient storage to load the Function or Image. \n\n\n\nIf Code Engine can execute the Functions code, it responds to the invocation with one of the following status codes.\n\n\n\nTable 2. Status codes\n\n Code Description \n\n 200 Function invocation accepted, the Function will be executed delayed. \n 202 Function invocation accepted, the Function will be executed asynchronously. \n 299 The Function exceeded the specified or maximum runtime limit and was aborted. \n\n\n\nAs a developer of a Function, you can generate any arbitrary HTTP status code, even the ones listed previously. Therefore, a response header indicates that the status code was generated by the Function code.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-work"}, {"document_id": "ibmcld_15258-3011-4489", "score": 0.5140732526779175, "text": "\nlogSourceCRN string Where the log file is saved in the Log Analysis instance of the account indicated in the CRN. \n saveServiceCopy bool Indicates whether to save a log in the Log Analysis STS; the default value is false. \n\n\n\nThe following is an example of the JSON schema of a datapath log:\n\n{\n\"type\": \"object\",\n\"properties\": {\n\"PRIORITY\": {\n\"type\": \"string\"\n},\n\"MSG_timestamp\": {\n\"type\": \"string\"\n},\n\"SentByHost\": {\n\"type\": \"string\"\n},\n\"MESSAGE\": {\n\"type\": \"string\"\n},\n\"logSourceCRN\": {\n\"type\": \"string\"\n},\n\"saveServiceCopy\": {\n\"type\": \"boolean\"\n}\n}\n}\nShow more\n\nNote that:\n\n\n\n* PRIORITY is the log level that is associated with each message on the severity of the log. Currently, the only choice is info.\n* MSG_timestamp is the timestamp in Coordinated Universal Time.\n* SentByHost is the VIP of the appliance. For public load balancers, this is the floating IP; for private load balancers, this is a private IP.\n* MESSAGE is the content of the log message.\n* logSourceCRN indicates which Log Analysis instance to use to save the logs for the account.\n* saveServiceCopy is false (by default) and cannot be changed.\n\n\n\nThe format of the logs can be impacted by internal upgrades. It is recommended to use these messages only for debugging purposes, not for build automation.\n\n\n\n\n\n Related links \n\n\n\n* [IBM Log Analysis](https://cloud.ibm.com/observe/logging)\n* [Getting started with IBM Log Analysis](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-getting-started)", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-datapath-logging"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03049-2703-4536", "score": 0.7214316129684448, "text": "\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03369-66296-68553", "score": 0.7077649831771851, "text": "\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-103662-105841", "score": 0.6928079128265381, "text": "\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03329-1102-2607", "score": 0.6888249516487122, "text": "\n[Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_03353-1684-3127", "score": 0.6744363307952881, "text": "\nLanguage [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add) [Dialog skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add) [Search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA \n Chinese (Simplified) (zh-cn) GA GA GA \n Chinese (Traditional) (zh-tw) GA GA GA \n Czech (cs) GA GA GA \n Dutch (nl) GA GA GA \n French (fr) GA GA GA \n German (de) GA GA GA \n Italian (it) GA GA GA \n Japanese (ja) GA GA GA \n Korean (ko) GA GA GA \n Portuguese (Brazilian) (pt-br) GA GA GA \n Spanish (es) GA GA GA \n Universal (xx) GA GA GA \n\n\n\n\n\n\n\n Intent feature support details \n\n\n\nTable 3. Intent feature support details\n\n Language [Content Catalog](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog) [Algorithm version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version) \n\n English (en) GA GA \n Arabic (ar) GA (except Covid-19) GA \n Chinese (Simplified) (zh-cn) NA GA \n Chinese (Traditional) (zh-tw) NA GA \n Czech (cs) NA GA \n Dutch (nl) NA GA \n French (fr) GA GA \n German (de) GA (except Covid-19) GA \n Italian (it) GA (except Covid-19) GA \n Japanese (ja) GA (except Covid-19) GA \n Korean (ko) NA GA \n Portuguese (Brazilian) (pt-br) GA GA \n Spanish (es) GA GA \n Universal (xx) NA NA \n\n\n\n\n\n\n\n User input processing support details \n\n\n\nTable 4. User input processing support details", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_03126-3707-6008", "score": 0.6713741421699524, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03369-36856-39124", "score": 0.6687721014022827, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03043-7-2031", "score": 0.6678027510643005, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_16364-101992-104197", "score": 0.6658158898353577, "text": "\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16364-127333-129289", "score": 0.660668134689331, "text": "\n: Previously, if you included a response type of Search skill in a list of response types for a dialog node, the search results were displayed last despite its placement in the list. This behavior was changed to show the search results in the appropriate order, namely in the sequence in which the search skill response type is listed for the dialog node.\n\n\n\n\n\n 10 March 2020 \n\nContextual entity support is generally available\n: You can add contextual entities to English-language dialog skills. For more information about contextual entities, see [Creating entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFrench language support added for autocorrection\n: Autocorrection helps your assistant understand what your customers want. It corrects misspellings in the input that customers submit before the input is evaluated. With more precise input, your assistant can more easily recognize entity mentions and understand the customer's intent. See [Correcting user input](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime-spell-check) for more details.\n\nThe new system entities are used by new skills\n: For new English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills, the new system entities are enabled automatically. If you decide to turn on a system entity and add it to your dialog, it's the new and improved version of the system entity that is used. For more information, see [New system entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 6 March 2020 \n\nTransfer a web chat conversation to a human agent\n: Delight your customers with 360-degree support by integrating your web chat with a third-party service desk solution. When a customer asks to speak to a person, you can connect them to an agent through a service desk solution, such as Zendesk or Salesforce. Service desk support is a beta feature.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03353-4-2000", "score": 0.6953406929969788, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add) [Dialog skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add) [Search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_03027-7-1946", "score": 0.694773256778717, "text": "\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_03120-3469-5331", "score": 0.6907498240470886, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-3583-5403", "score": 0.6817029714584351, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_16364-103662-105841", "score": 0.6778832674026489, "text": "\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03120-4813-6717", "score": 0.6737635731697083, "text": "\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03126-3707-6008", "score": 0.6721152663230896, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_02839-1790-3940", "score": 0.6710423231124878, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03369-66296-68553", "score": 0.6614129543304443, "text": "\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03120-4-2233", "score": 0.6579098701477051, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03381-4347-6258", "score": 0.6852731704711914, "text": "\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add an actions or dialog skill.\n3. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions page instead.\n\n\n\n\n\n\n\n Sharing a dialog skill with team members \n\nAfter you create the service instance, you can give other people access to it. Together, you can define the training data and build the dialog.\n\nOnly one person can edit an intent, entity, or a dialog node at a time. If multiple people work on the same item at the same time, then the changes made by the person who saves their changes last are the only changes applied. Changes that are made during the same time frame by someone else and are saved first are not retained. Coordinate the updates that you plan to make with your team members to prevent anyone from losing their work.\n\nTo share a dialog skill with other people, you must give them access to the service instance that hosts the skill. Note that the person you invite will be able to access any skill or assistant in this service instance.\n\n\n\n1. Click the User ![User](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/user-icon2.png) icon in the page header.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03329-1102-2607", "score": 0.680912971496582, "text": "\n[Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_03120-3469-5331", "score": 0.6658260822296143, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03043-7-2031", "score": 0.664954662322998, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03411-4781-6488", "score": 0.664588212966919, "text": "\nTo achieve the same goal, you can use a saved version as the basis for a new version in which you incorporate any changes you want to make. To start development work from a saved version, overwrite the in-progress development version of the skill with the saved version.\n\n\n\n1. Save any changes you made to the skill since the last time you created a version.\n\nSave a version of the skill now. Otherwise, your work will be lost when you follow these steps.\n2. From the version you want to edit, click the Skill actions![Skill actions](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon, and then choose Revert to this version and confirm the action.\n\nThe page refreshes to revert to the state that the skill was in when the version was created.\n\n\n\nIf you want to save any changes that you make to this version, you must save the skill as a new version. You cannot apply changes to an already-saved version.\n\nWhen you open a skill by clicking the skill tile from the assistant page, the development version of the skill is displayed. Even if you associated a later version with the assistant, when you access the skill, its development version opens.\n\n\n\n\n\n Downloading a skill version \n\nYou can download a dialog skill version in JSON format. You might want to download a skill version if you want to use a specific version of a dialog skill in a different instance of the Watson Assistant service, for example. You can download the version from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill version, complete the following steps:\n\n\n\n1. From the skill menu, click Versions.\n2. Click the !", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-versions"}, {"document_id": "ibmcld_03381-2858-4802", "score": 0.658718466758728, "text": "\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03049-2703-4536", "score": 0.6573077440261841, "text": "\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_02839-1790-3940", "score": 0.6565650701522827, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_02998-1325-2715", "score": 0.6553269028663635, "text": "\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03369-36856-39124", "score": 0.6484348177909851, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09903-9624-10554", "score": 0.674035906791687, "text": "\nHebrew [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https://cloud.ibm.com/docs/natural-language-understanding/?topic=natural-language-understanding-entity-types-version-2)", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"}, {"document_id": "ibmcld_09913-7-1696", "score": 0.6230583190917969, "text": "\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_09226-18248-20249", "score": 0.6227647662162781, "text": "\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https://cloud.ibm.com/docs/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https://cloud.ibm.com/docs/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https://cloud.ibm.com/docs/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-release-notes"}, {"document_id": "ibmcld_09913-1307-2928", "score": 0.619520902633667, "text": "\n* [French](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)\n* [Hindi](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supporthindi)\n* [Italian](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportitalian)\n* [Japanese](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportjapanese)\n* [Korean](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportkorean)\n* [Norwegian](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian)\n* [Norwegian (Bokmal)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian-bokmal)\n* [Norwegian (Nyorsk)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian-nyorsk)\n* [Polish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportpolish)\n* [Portuguese](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportportuguese)", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_09229-6816-8417", "score": 0.6142167448997498, "text": "\n[French (Canadian)](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsfrench-canadian) fr [Sinhala](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelssinhala) si \n [German](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsgerman) de [Slovak](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsslovak) sk \n [Greek](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsgreek) el [Slovenian](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsslovenian) sl \n [Gujarati](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsgujarati) gu [Spanish](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsspanish) es \n [Hebrew](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelshebrew) he [Swedish](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelsswedish) sv \n [Hindi](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelshindi) hi [Tamil](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelstamil) ta \n [Hungarian](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelshungarian) hu [Telugu](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelstelugu) te", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-models"}, {"document_id": "ibmcld_02839-3583-5403", "score": 0.6107824444770813, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_09222-1220-2907", "score": 0.596800684928894, "text": "\n\"language\": \"ba\",\n\"name\": \"Bashkir\"\n}\n. . .\n]\n}\nShow more\n\n\n\n\n\n List of identifiable languages \n\nThe following table list the identifiable languages. The table is sorted by language name and provides the language code for each language.\n\nThe service uses ISO two-character codes for most languages. It uses an ISO three-character code (cnr) for Montenegrin. In some cases, it uses a two-character language code and a two-character country code separated by a hyphen, such as pa-PK for Punjabi spoken in Pakistan and zh-TW for traditional (Mandarin) Chinese spoken in Taiwan.\n\n\n\nTable 1. Identifiable languages\n\n Language name Language code Language name Language code \n\n Afrikaans af Kirghiz ky \n Albanian sq Korean ko \n Arabic ar Kurdish ku \n Armenian hy Lao lo \n Azerbaijani az Latvian lv \n Bashkir ba Lithuanian lt \n Basque eu Malay ms \n Belarusian be Malayalam ml \n Bengali bn Maltese mt \n Bulgarian bg Marathi mr \n Burmese my Mongolian mn \n Catalan ca Nepali ne \n Central Khmer km Norwegian Bokm\u00e5l nb \n Chinese (Simplified) zh Norwegian Nynorsk nn \n Chinese (Traditional) zh-TW Persian fa \n Chuvash cv Polish pl \n Croatian hr Portuguese pt \n Czech cs Punjabi (Indian) pa \n Danish da Punjabi (Pakistani) <br>(Shahmukhi script) pa-PK \n Dutch nl Pushto ps \n English en Romanian ro \n Esperanto eo Russian ru \n Estonian et Serbian sr \n Finnish fi Sinhala si \n French fr Slovakian sk \n Georgian ka Slovenian sl \n German de Somali so \n Greek el Spanish es \n Gujarati gu Swedish sv \n Haitian ht Tagalog tl \n Hebrew he Tamil ta \n Hindi hi Telugu te \n Hungarian hu Thai th \n Icelandic is Turkish tr \n Irish ga Ukrainian uk \n Italian it Urdu ur \n Japanese ja Vietnamese vi \n Kazakh kk Welsh cy", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-identifiable-languages"}, {"document_id": "ibmcld_09913-6894-8823", "score": 0.5943946838378906, "text": "\nClassifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Hebrew \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Hindi \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Italian \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Japanese \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_09229-17595-19748", "score": 0.5922368764877319, "text": "\nel-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general \n\n\n\n\n\n\n\n Hindi \n\nThe following Hindi translation model can be customized.\n\n\n\nTable 23. Hindi translation model\n\n Model ID Source Target Domain \n\n hi-en Hindi (hi) English (en) general \n\n\n\n\n\n\n\n Hungarian \n\nThe following Hungarian translation model can be customized.\n\n\n\nTable 24. Hungarian translation model\n\n Model ID Source Target Domain \n\n hu-en Hungarian (hu) English (en) general \n\n\n\n\n\n\n\n Indonesian \n\nThe following Indonesian translation model can be customized.\n\n\n\nTable 25. Indonesian translation model\n\n Model ID Source Target Domain \n\n id-en Indonesian (id) English (en) general \n\n\n\n\n\n\n\n Irish \n\nThe following Irish translation model can be customized.\n\n\n\nTable 26. Irish translation model\n\n Model ID Source Target Domain \n\n ga-en Irish (ga) English (en) general \n\n\n\n\n\n\n\n Italian \n\nThe following Italian translation models can be customized.\n\n\n\nTable 27. Italian translation models\n\n Model ID Source Target Domain \n\n it-de Italian (it) German (de) general \n it-en Italian (it) English (en) general \n\n\n\n\n\n\n\n Japanese \n\nThe following Japanese translation model can be customized.\n\n\n\nTable 28. Japanese translation model\n\n Model ID Source Target Domain \n\n ja-en Japanese (ja) English (en) general \n\n\n\n\n\n\n\n Kannada \n\nThe following Kannada translation model can be customized.\n\n\n\nTable 29. Kannada translation model\n\n Model ID Source Target Domain \n\n kn-en Kannada (kn) English (en) general \n\n\n\n\n\n\n\n Korean \n\nThe following Korean translation model can be customized.\n\n\n\nTable 30. Korean translation model\n\n Model ID Source Target Domain \n\n ko-en Korean (ko) English (en) general \n\n\n\n\n\n\n\n Latvian \n\nThe following Latvian translation model can be customized.\n\n\n\nTable 31. Latvian translation model\n\n Model ID Source Target Domain", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-models"}, {"document_id": "ibmcld_09218-1677-3252", "score": 0.5910922884941101, "text": "\n* The source and target languages must be among the [List of supported languages](https://cloud.ibm.com/docs/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n* The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\n\n\nThis tutorial walks you through translating documents from the command line with curl. You can also use the Watson SDKs to translate documents with a number of programming languages. For more information, see the methods in the [API & SDK reference](https://cloud.ibm.com/apidocs/language-translator).\n\n\n\n\n\n Step 1: Submit a document to translate \n\nThe following example request submits the file curriculum.html to the service and translates it from English to French. Replace {apikey} and {url} with your service credentials, and replace curriculum.html with a relative path to your file. The source and target parameters specify the languages for the translation.\n\ncurl -X POST --user \"apikey:{apikey}\" --form \"file=@curriculum.html\" --form \"source=en\" --form \"target=fr\" \"{url}/v3/documents?version=2018-05-01\"\n\nTo translate a document with a [custom model](https://cloud.ibm.com/docs/language-translator?topic=language-translator-customizing), use the model_id parameter. The following request translates the document with the custom model identified by the model ID 96221b69-8e46-42e4-a3c1-808e17c787ca. The custom model is defined for en-fr translation, so the source and target parameters are not needed.", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-document-translator-tutorial"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07085-3980-4899", "score": 0.6820346117019653, "text": "\n\"field\": \"STATE\",\n\"count\": 3,\n\"results\":\n{\n\"key\": \"CA\",\n\"matching_results\": 1210,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"CITY\",\n\"count\": 2,\n\"results\":\n{\n\"key\": \"LOS ANGELES\",\n\"matching_results\": 77\n},\n{\n\"key\": \"SAN DIEGO\",\n\"matching_results\": 66\n}\n]\n}\n]\n},\n{\n\"key\": \"NY\",\n\"matching_results\": 693,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"CITY\",\n\"count\": 2,\n\"results\":\n{\n\"key\": \"BROOKLYN\",\n\"matching_results\": 35\n},\n{\n\"key\": \"NEW YORK\",\n\"matching_results\": 21\n}\n]\n}\n]\n},\n{\n\"key\": \"FL\",\n\"matching_results\": 511,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"CITY\",\n\"count\": 2,\n\"results\":\n{\n\"key\": \"JACKSONVILLE\",\n\"matching_results\": 33\n},\n{\n\"key\": \"TAMPA\",\n\"matching_results\": 29\n}\n]\n}\n]\n}\n]\n}\n],\n\"results\": []\nShow more\n\nThe order in which you specify the aggregations matters. For example, if you reverse the order of the term aggregations from the previous example, you get different results.\n\n{\n\"query\":\"brake\",", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-aggregations"}, {"document_id": "ibmcld_16471-106006-108222", "score": 0.6683725118637085, "text": "\nAll other spans are left untouched.\n* LeftToRight\n\nThis policy processes the spans in order from left to right. When overlap occurs, it retains the leftmost, longest, non-overlapping span. This policy emulates the overlap-handling policy of most regular expression engines.\n\n\n\n* <priority_column>\n\nSpecifies a column of type Text, String, Integer, or Float. Can be specified only with the LeftToRight consolidation policy.\n* <priority_order>\n\nSpecifies either ascending or descending order. Can be specified only with the LeftToRight consolidation policy. The ascending order ensures that if a tuple T1 has priority 1 and a tuple T2 has priority 2, T1 has a higher priority than T2. By contrast, if the priority order is descending, T2 has a higher priority. The default value of the priority order is ascending.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* When the priority clause is present, the semantics of consolidation follow this order:\n\n\n\n* Process spans from left to right, and when spans overlap, retain the leftmost spans.\n* If you have multiple overlapping spans that start at the same offset, retain the ones with the highest priority according to the priority order.\n* Break remaining ties by retaining the longest spans among those spans with the same priority.\n\n\n\n* Consolidate treats nulls as identical. All inputs with a null <consolidate target> result in a single output tuple, which is chosen randomly among those inputs. This behavior is similar to how tuples are consolidated with an identical span in the target column. The exception to resulting in a single output tuple is if the policy is ContainsButNotEqual. In that case, the null <consolidate target> outputs all inputs with null consolidate target.\n\n\n\n\n\n\n\n Examples \n\nExample 1: Consolidate on single column\n\nThis example directs the system to examine the field Person.name of all output tuples and to use the ContainedWithin consolidation policy to resolve overlap.\n\nconsolidate on Person.name\nusing 'ContainedWithin'\n\nExample 2: Consolidate on expression, involving multiple columns\n\nThis example directs the system to examine the result of applying the CombineSpans scalar function to fields Person.firstname and Person.lastname in each output tuple.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_04161-8611-9846", "score": 0.6158698797225952, "text": "\n\"clientCountryName\": \"US\"\n}\n]\n}\n\n\n\n\n\n Query for the next page using filter \n\nTo get the next n results, specify a filter to exclude the last result from the previous query. Using the previous example, you can append the greater-than operator (_gt) to the clientCountryName field and the greater-or-equal operator to the datetime field. By making a specific order, you can get the most complete results.\n\nfirewallEventsAdaptive (limit: 2, orderBy: [datetime_ASC, clientCountryName_ASC], filter: {date_geq: \"2018-11-12T00:00:00Z\", clientCounterName_gt: \"US\"}) {\ndate\nclientCountryName\n}\n\nThe query response follows:\n\n{\n\"firewallEventsAdaptive\" : [\n{\n\"datetime\": \"2018-11-12T00:00:00Z\",\n\"clientCountryName\": \"UY\"\n},\n{\n\"datetime\": \"2018-11-12T00:00:00Z\",\n\"clientCountryName\": \"UZ\"\n}\n]\n}\n\n\n\n\n\n Query the previous page \n\nTo get the previous n results, reverse the filters and sort order.\n\nfirewallEventsAdaptive (limit: 2, orderBy: [datetime_DESC, clientCountryName_DESC, filter: {date_leq: \"2018-11-12T00:00:00Z\", clientCountryName_lt: \"UY\"}]) {\ndatetime\nclientCountryName\n}\n\nThe query response follows:\n\n{\n\"firewallEventsAdaptive\" : [\n{\n\"datetime\": \"2018-11-12T00:00:00Z\",\n\"clientCountryName\": \"US\"\n},\n{\n\"datetime\": \"2018-11-12T00:00:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-graphql"}, {"document_id": "ibmcld_02991-6314-8112", "score": 0.6151525974273682, "text": "\nThe message is labeled with the customer ID my_id. customer_id::my_id \n The message was sent to a specific assistant. assistant_id::dcd5c5ad-f3a1-4345-89c5-708b0b5ff4f7 \n The user input text contains the word \"order\" or a grammatical variant (for example, orders or ordering. request.input.text:order \n An intent name in the response exactly matches place_order. response.output.intents:intent::place_order \n An entity name in the response exactly matches beverage. response.output.entities:entity::beverage \n The user input text does not contain the word \"order\" or a grammatical variant. request.input.text:!order \n\n\n\n| The user input text contains the string !hello. | request.input.text:!hello | | The user input text contains the string IBM Watson. | request.input.text:\"IBM Watson\" | | The user input text contains a string that has no more than 2 single-character differences from Watson. | request.input.text:Watson2 | | The user input text contains a string consisting of comm, followed by zero or more additional characters, followed by s. | request.input.text:comms | | The user input text is not empty. | request.input.text::!\"\" | | An intent name in the response exactly matches either hello or goodbye. | response.output.intents:intent::(hellogoodbye) | | An intent name in the response exactly matches order, and an entity name in the response exactly matches beverage. | [response.output.intents:intent::order,response.output.entities:entity::beverage] |\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 /logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference"}, {"document_id": "ibmcld_00539-2548-4016", "score": 0.612094521522522, "text": "\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname/firstname/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00644-15701-17094", "score": 0.6114069223403931, "text": "\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL/$DATABASE/_design/$DDOC/_view/$VIEW_NAME?descending=true HTTP/1.1\nAccept: application/json\n\nSee the example of requesting the records in reverse sort order.\n\nClient libraries use POST method instead of GET because they have a similar behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL/users/_design/allusers/_view/getVerifiedEmails?descending=true\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nconst { CloudantV1 } = require('@ibm-cloud/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.postView({\ndb: 'users',\nddoc: 'allusers',\nview: 'getVerifiedEmails',\ndescending: true\n}).then(response => {\nconsole.log(response.result);\n});\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-views"}, {"document_id": "ibmcld_07085-4625-5922", "score": 0.6067709922790527, "text": "\n\"key\": \"TAMPA\",\n\"matching_results\": 29\n}\n]\n}\n]\n}\n]\n}\n],\n\"results\": []\nShow more\n\nThe order in which you specify the aggregations matters. For example, if you reverse the order of the term aggregations from the previous example, you get different results.\n\n{\n\"query\":\"brake\",\n\"aggregation\": \"term(field:CITY,count:3).term(field:STATE,count:1)\"\n}\n\nThe new order produces results that surface Chicago, a city that wasn't included in the previous set of results. When the request starts by grouping by state, Illinois, which has only one city with a high number of traffic incident reports, is not included in the results. New York and Florida, which both have more than one city with many incident reports, produce a higher number of statewide matches and therefore, were returned. When you group by city first, the results change.\n\n{\n\"matching_results\": 9064,\n\"retrieval_details\": {\n\"document_retrieval_strategy\": \"untrained\"\n},\n\"aggregations\": [\n{\n\"type\": \"term\",\n\"field\": \"CITY\",\n\"count\": 4,\n\"results\":\n{\n\"key\": \"LOS ANGELES\",\n\"matching_results\": 77,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"STATE\",\n\"count\": 1,\n\"results\":\n{\n\"key\": \"CA\",\n\"matching_results\": 77\n}\n]\n}\n]\n},\n{\n\"key\": \"SAN DIEGO\",\n\"matching_results\": 66,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"STATE\",\n\"count\": 1,\n\"results\":\n{", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-aggregations"}, {"document_id": "ibmcld_16310-6238-8054", "score": 0.6010874509811401, "text": "\nThe timestamp of the response is earlier than 2019-11-01T04:00:00.000Z. response_timestamp<2019-11-01T04:00:00.000Z \n The message is labeled with the customer ID my_id. customer_id::my_id \n The message was sent to a specific assistant. assistant_id::dcd5c5ad-f3a1-4345-89c5-708b0b5ff4f7 \n The user input text contains the word \"order\" or a grammatical variant (for example, orders or ordering. request.input.text:order \n An intent name in the response exactly matches place_order. response.output.intents:intent::place_order \n An entity name in the response exactly matches beverage. response.output.entities:entity::beverage \n No intent name in the response exactly matches order. response.intents:intent::!order \n The user input text does not contain the word \"order\" or a grammatical variant. request.input.text:!order \n The user input text contains the string !hello. request.input.text:!hello \n The user input text contains the string IBM Watson. request.input.text:\"IBM Watson\" \n The user input text contains a string that has no more than 2 single-character differences from Watson. request.input.text:Watson2 \n The user input text contains a string consisting of comm, followed by zero or more additional characters, followed by s. request.input.text:comms \n An intent name in the response exactly matches either hello or goodbye. response.output.intents:intent::(hello goodbye) \n An intent name in the response exactly matches order, and an entity name in the response exactly matches beverage. [response.output.intents:intent::order,response.output.entities:entity::beverage] \n\n\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 /logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-filter-reference"}, {"document_id": "ibmcld_16532-7-2100", "score": 0.5917725563049316, "text": "\nConfiguring support for Arabic \n\nRead these guidelines to understand how Knowledge Studio handles Arabic character shaping and numeric shaping in Arabic documents.\n\n\n\n About this task \n\nWith respect to character shaping, the Arabic alphabet does not have capital letters, but letters can change shape depending on their position in the text string and the surrounding letters. Different operating systems and code page conversion programs handle letter shaping in different ways. Unshaped storage is a standard for Windows systems, and Knowledge Studio presumes that Arabic text is stored unshaped. If you want to upload shaped text into Knowledge Studio, you must first convert the text to unshaped form by using standard tools, such as the International Components for Unicode (ICU) API (see the ArabicShaping Class at [http://icu-project.org/apiref/icu4j/com/ibm/icu/text/ArabicShaping.html](http://icu-project.org/apiref/icu4j/com/ibm/icu/text/ArabicShaping.html)).\n\n> Important: In some cases, lack of proper Arabic character shaping might cause content to be displayed incorrectly in the ground truth editor.\n\nWith respect to numeric shaping, Knowledge Studio treats numeric shaping as a storage-level property, similar to how Arabic content is handled on the iOS platform. Because a lot of Arabic content is created on platforms like Windows, which treat numeric shaping as a display-level property, you need to either convert content to make numeric shaping a storage-level property or use a Firefox browser when you use Knowledge Studio. Firefox supports the ability to set numeric shaping preferences explicitly at the browser level and enforce the appropriate display for all content shown in the browser.\n\n\n\n\n\n Procedure \n\nTo configure numeric shaping in the Firefox browser:\n\n\n\n1. In the browser URL field, enter about:config. If you are shown a warning from Firefox, click the action to disregard the warning and continue. For information about editing about:config properties, see [http://kb.mozillazine.org/About:config_entries](http://kb.mozillazine.org/About:config_entries).", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_langsupp_ar"}, {"document_id": "ibmcld_13429-14164-15905", "score": 0.5909243226051331, "text": "\n* [Improved language model customization for next-generation models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-customizationcustomLanguage-intro-ng)\n* [Upgrading custom models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-custom-upgrade)\n* [Using customization weight](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUseweight)\n* [Character insertion bias](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsinginsertion-bias)\n\n\n\nDefect fix: Grammar files now handle strings of digits correctly\n: Defect fix: When grammars are used, the service now handles longer strings of digits correctly. Previously, it was failing to complete recognition or returning incorrect results.\n\n\n\n\n\n 15 February 2023 \n\nImportant: All previous-generation models are deprecated and will reach end of service on 31 July 2023\n: Important: All previous-generation models are deprecated and will reach end of service effective 31 July 2023. On that date, all previous-generation models will be removed from the service and the documentation. The previous deprecation date was 3 March 2023. The new date allows users more time to migrate to the appropriate next-generation models. But users must migrate to the equivalent next-generation model by 31 July 2023.\n\nMost previous-generation models were deprecated on 15 March 2022. Previously, the Arabic and Japanese models were not deprecated. Deprecation now applies to all previous-generation models.\n\n\n\n* For more information about the next-generation models to which you can migrate from each of the deprecated models, see [Previous-generation languages and models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models)", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13942-13473-14921", "score": 0.6285938620567322, "text": "\nset system conntrack modules 'gre'\nset system conntrack modules h323 'disable'\nset system conntrack modules nfs 'disable'\nset system conntrack modules pptp 'disable'\nset system conntrack modules sip 'disable'\nset system conntrack modules sqlnet 'disable'\nset system conntrack modules tftp 'disable'\nset system conntrack table-size '3000000'\n\n\n\n\n\n\n\n Set system conntrack timeout \n\n\n\n Set system conntrack timeout issues \n\nset system conntrack timeout icmp '30'\nset system conntrack timeout other '600'\nset system conntrack timeout tcp close '10'\nset system conntrack timeout tcp close-wait '60'\nset system conntrack timeout tcp established '432000'\nset system conntrack timeout tcp fin-wait '120'\nset system conntrack timeout tcp last-ack '30'\nset system conntrack timeout tcp syn-recv '60'\nset system conntrack timeout tcp syn-sent '120'\nset system conntrack timeout tcp time-wait '60'\n\n\n\n\n\n\n\n Time based firewall \n\n\n\n Time based firewall issues \n\nset firewall name PRIV_SERVICE_IN rule 58 action 'accept'\nset firewall name PRIV_SERVICE_IN rule 58 description '586427 Acesso a base de dados ate 22-2-18'\nset firewall name PRIV_SERVICE_IN rule 58 destination address '10.150.156.57'\nset firewall name PRIV_SERVICE_IN rule 58 destination port '3306'\nset firewall name PRIV_SERVICE_IN rule 58 protocol 'tcp'\nset firewall name PRIV_SERVICE_IN rule 58 source address '10.150.156.104'\nset firewall name PRIV_SERVICE_IN rule 58 time startdate '2017-08-22'", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-vyatta-5400-common-migration-issues"}, {"document_id": "ibmcld_14690-4276-6282", "score": 0.6263992786407471, "text": "\nset security address-book global address-set SERVICE address SL19\nset security address-book global address-set SERVICE address SL20\nset security screen ids-option untrust-screen icmp ping-death\nset security screen ids-option untrust-screen ip source-route-option\nset security screen ids-option untrust-screen ip tear-drop\nset security screen ids-option untrust-screen tcp syn-flood alarm-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood attack-threshold 200\nset security screen ids-option untrust-screen tcp syn-flood source-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood destination-threshold 2048\nset security screen ids-option untrust-screen tcp syn-flood queue-size 2000\nset security screen ids-option untrust-screen tcp syn-flood timeout 20\nset security screen ids-option untrust-screen tcp land\nset security policies from-zone trust to-zone trust policy default-permit match source-address any\nset security policies from-zone trust to-zone trust policy default-permit match destination-address any\nset security policies from-zone trust to-zone trust policy default-permit match application any\nset security policies from-zone trust to-zone trust policy default-permit then permit\nset security policies from-zone trust to-zone untrust policy default-permit match source-address any\nset security policies from-zone trust to-zone untrust policy default-permit match destination-address any\nset security policies from-zone trust to-zone untrust policy default-permit match application any\nset security policies from-zone trust to-zone untrust policy default-permit then permit\nset security zones security-zone trust tcp-rst\nset security zones security-zone trust interfaces reth0.0 host-inbound-traffic system-services all\nset security zones security-zone untrust screen untrust-screen\nset security zones security-zone untrust interfaces reth1.0 host-inbound-traffic system-services all\nset interfaces ge-0/0/1 gigether-options redundant-parent reth0", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"}, {"document_id": "ibmcld_14690-2721-4678", "score": 0.6137877702713013, "text": "\nset security address-book global address SL17 10.2.48.0/20\nset security address-book global address SL18 10.2.176.0/20\nset security address-book global address SL19 10.3.64.0/20\nset security address-book global address SL20 10.3.80.0/20\nset security address-book global address SL_PRIV_MGMT 10.135.70.22/32\nset security address-book global address SL_PUB_MGMT 169.50.51.92/32\nset security address-book global address-set SERVICE address SL1\nset security address-book global address-set SERVICE address SL2\nset security address-book global address-set SERVICE address SL3\nset security address-book global address-set SERVICE address SL4\nset security address-book global address-set SERVICE address SL5\nset security address-book global address-set SERVICE address SL6\nset security address-book global address-set SERVICE address SL7\nset security address-book global address-set SERVICE address SL8\nset security address-book global address-set SERVICE address SL9\nset security address-book global address-set SERVICE address SL10\nset security address-book global address-set SERVICE address SL11\nset security address-book global address-set SERVICE address SL12\nset security address-book global address-set SERVICE address SL13\nset security address-book global address-set SERVICE address SL14\nset security address-book global address-set SERVICE address SL15\nset security address-book global address-set SERVICE address SL16\nset security address-book global address-set SERVICE address SL17\nset security address-book global address-set SERVICE address SL18\nset security address-book global address-set SERVICE address SL19\nset security address-book global address-set SERVICE address SL20\nset security screen ids-option untrust-screen icmp ping-death\nset security screen ids-option untrust-screen ip source-route-option\nset security screen ids-option untrust-screen ip tear-drop\nset security screen ids-option untrust-screen tcp syn-flood alarm-threshold 1024", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"}, {"document_id": "ibmcld_14688-1674-3523", "score": 0.6135357618331909, "text": "\nShow more\n\n\n\n Set commands \n\nset system login user pokeyjo uid 2000\n\nset system login user pokeyjo class super-user\n\nset system login user pokeyjo authentication encrypted-password\n\"removed for security\"\n\nset system root-authentication encrypted-password\n\"removed for security\"\n\nset system services ssh\n\nset system services web-management http interface fxp0.0\n\nset system services web-management http interface ge-0/0/0.0\n\nset system syslog user * any emergency\n\nset system syslog file messages any any\n\nset system syslog file messages authorization info\n\nset system syslog file interactive-commands interactive-commands any\n\nset security screen ids-option untrust-screen icmp ping-death\n\nset security screen ids-option untrust-screen ip source-route-option\n\nset security screen ids-option untrust-screen ip tear-drop\n\nset security screen ids-option untrust-screen tcp syn-flood\nalarm-threshold 1024\n\nset security screen ids-option untrust-screen tcp syn-flood\nattack-threshold 200\n\nset security screen ids-option untrust-screen tcp syn-flood\nsource-threshold 1024\n\nset security screen ids-option untrust-screen tcp syn-flood\ndestination-threshold 2048\n\nset security screen ids-option untrust-screen tcp syn-flood queue-size\n2000\n\nset security screen ids-option untrust-screen tcp syn-flood timeout 20\n\nset security screen ids-option untrust-screen tcp land\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match source-address any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match destination-address any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match application any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit then permit\n\nset security policies from-zone trust to-zone untrust policy\ndefault-permit match source-address any", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-default-config"}, {"document_id": "ibmcld_14287-15546-17269", "score": 0.6111637353897095, "text": "\nBind particular zones to interfaces on the Brocade vRouter (Vyatta).\n\nUse the following commands in configure mode:\n\nset zone-policy zone OUTSIDE description \u201cInternet Zone\u201d\nset zone-policy zone OUTSIDE default-action drop\nset zone-policy zone OUTSIDE interface bond1\nset zone-policy zone SLSERVICE description \u201cSoftLayer Services\u201d\nset zone-policy zone SLSERVICE default-action drop\nset zone-policy zone SLSERVICE interface bond0\nset zone-policy zone MGMT description \u201cManagement VMs & ESX Host Access\u201d\nset zone-policy zone MGMT default-action drop\nset zone-policy zone MGMT interface bond0.1101\nset zone-policy zone STORAGE description \u201cStorage\u201d\nset zone-policy zone STORAGE default-action drop\nset zone-policy zone STORAGE interface bond0.1102\nset zone-policy zone VMACCESS description \u201cVM Access\u201d\nset zone-policy zone VMACCESS default-action drop\nset zone-policy zone VMACCESS interface bond0.1103\ncommit\nsave\nShow more\n\n\n\n\n\n Applying firewall rules to zones \n\nApply the firewall rules to the communication between zones.\n\nUse the following commands in configure mode:\n\nset zone-policy zone OUTSIDE from MGMT firewall name INSIDE2OUTSIDE\nset zone-policy zone OUTSIDE from VMACCESS firewall name INSIDE2OUTSIDE\nset zone-policy zone VMACCESS from OUTSIDE firewall name OUTSIDE2INSIDE\nset zone-policy zone VMACCESS from SLSERVICE firewall name SLSERVICE2INSIDE\nset zone-policy zone MGMT from OUTSIDE firewall name OUTSIDE2INSIDE\nset zone-policy zone MGMT from SLSERVICE firewall name SLSERVICE2INSIDE\nset zone-policy zone SLSERVICE from MGMT firewall name INSIDE2SLSERVICE\nset zone-policy zone SLSERVICE from VMACCESS firewall name INSIDE2SLSERVICE\nset zone-policy zone SLSERVICE from STORAGE firewall name INSIDE2SLSERVICE", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-set-up-brocade"}, {"document_id": "ibmcld_14287-12756-14547", "score": 0.6063560247421265, "text": "\nset firewall name OUTSIDE2INSIDE rule 30 destination port 500\nset firewall name OUTSIDE2INSIDE rule 40 action accept\nset firewall name OUTSIDE2INSIDE rule 40 ipsec match-ipsec\nset firewall name OUTSIDE2INSIDE rule 50 action accept\nset firewall name OUTSIDE2INSIDE rule 50 protocol gre\nset firewall name OUTSIDE2INSIDE rule 60 action accept\nset firewall name OUTSIDE2INSIDE rule 60 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 60 destination port 1723\nset firewall name OUTSIDE2INSIDE rule 70 action accept\nset firewall name OUTSIDE2INSIDE rule 70 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 70 destination port 80\nset firewall name OUTSIDE2INSIDE rule 80 action accept\nset firewall name OUTSIDE2INSIDE rule 80 protocol tcp\nset firewall name OUTSIDE2INSIDE rule 80 destination port 443\nset firewall name OUTSIDE2INSIDE rule 90 action accept\nset firewall name OUTSIDE2INSIDE rule 90 state established enable\nset firewall name SLSERVICE2INSIDE\nset firewall name SLSERVICE2INSIDE default-action drop\nset firewall name SLSERVICE2INSIDE rule 10 action accept\nset firewall name SLSERVICE2INSIDE rule 10 protocol all\nset firewall name SLSERVICE2INSIDE rule 10 source group network-group SLSERVICES\nset firewall name INSIDE2SLSERVICE\nset firewall name INSIDE2SLSERVICE default-action drop\nset firewall name INSIDE2SLSERVICE rule 10 action accept\nset firewall name INSIDE2SLSERVICE rule 10 protocol all\nset firewall name INSIDE2SLSERVICE rule 10 destination group network-group SLSERVICES\nset firewall name VMACCESS2MGMT\nset firewall name VMACCESS2MGMT default-action drop\nset firewall name VMACCESS2MGMT rule 10 action drop\nset firewall name VMACCESS2MGMT rule 10 protocol all\nset firewall name VMACCESS2MGMT rule 10 source group network-group 1103VMACCESS\nset firewall name STORAGE2MGMT", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-set-up-brocade"}, {"document_id": "ibmcld_03542-6253-7944", "score": 0.6051068305969238, "text": "\nIf the update is successful, the current settings will be displayed.\n\n\n\n\n\n\n\n API settings and actions \n\nThe following table lists the actions that you can run to manage settings:\n\n\n\nTable 1. Settings actions by using the IBM Cloud Activity Tracker Event Routing REST API\n\n Action REST API Method API_URL \n\n Get settings information GET <ENDPOINT>/api/v2/settings \n Update settings PUT <ENDPOINT>/api/v2/settings \n\n\n\nYou can use private and public endpoints to manage settings. For more information about the list of ENDPOINTS that are available, see [Endpoints](https://cloud.ibm.com/docs/atracker?topic=atracker-endpoints).\n\n\n\n* By default, you can manage settings from the private network. You must use an API endpoint with the following format: https://private.<region>.atracker.cloud.ibm.com\n* You can also enable public endpoints in a region to manage settings. For more information, see [Managing endpoints](https://cloud.ibm.com/docs/atracker?topic=atracker-endpoints_manage).\n\n\n\nFor more information about the REST API, see [the settings API](https://cloud.ibm.com/apidocs/atracker/atracker-v2get-settings).\n\n\n\n\n\n API prerequsites \n\nTo make API calls to manage settings, complete the following steps:\n\n\n\n1. Get an IAM access token. For more information, see [Retrieving IAM access tokens](https://cloud.ibm.com/docs/atracker?topic=atracker-retrieve-iam-token).\n2. Identify the API endpoint in the region where you plan to configure or manage settings. For more information, see [Endpoints](https://cloud.ibm.com/docs/atracker?topic=atracker-endpointsendpoints_api).\n\n\n\n\n\n\n\n Getting settings using the API \n\nYou can use the following cURL command to get existing settings information:", "title": "", "source": "https://cloud.ibm.com/docs/atracker?topic=atracker-settings&interface=cli"}, {"document_id": "ibmcld_13942-14577-16111", "score": 0.600643515586853, "text": "\nset firewall name PRIV_SERVICE_IN rule 58 destination address '10.150.156.57'\nset firewall name PRIV_SERVICE_IN rule 58 destination port '3306'\nset firewall name PRIV_SERVICE_IN rule 58 protocol 'tcp'\nset firewall name PRIV_SERVICE_IN rule 58 source address '10.150.156.104'\nset firewall name PRIV_SERVICE_IN rule 58 time startdate '2017-08-22'\nset firewall name PRIV_SERVICE_IN rule 58 time stopdate '2018-02-22'\n\n\n\n\n\n\n\n TCP-MSS \n\n\n\n TCP-MSS issues \n\nset interfaces tunnel tun3 address '172.17.175.45/30'\nset interfaces tunnel tun3 encapsulation 'gre'\nset interfaces tunnel tun3 local-ip '169.55.223.76'\nset interfaces tunnel tun3 mtu '1476'\nset interfaces tunnel tun3 multicast 'disable'\nset interfaces tunnel tun3 policy route 'change-mss'(in 18.x unable to apply tcp-mss using PBR only option is to set on interface directly which i believe is not equivalent to pbr .\nset interfaces tunnel tun3 remote-ip '104.129.200.34'\n\nset policy route change-mss rule 1 protocol 'tcp'\nset policy route change-mss rule 1 set tcp-mss '1436'\nset policy route change-mss rule 1 tcp flags 'SYN\n\n\n\n\n\n\n\n Specific application or port broken in S-S IPsec VPN \n\n\n\n Specific application or port broken in S-S IPsec VPN issues \n\nvyatta@v5600dallas09 set security vpn ipsec site-to-site peer 12.0.0.1 tunnel 1 remote\nPossible Completions:\n<Enter> Execute the current command\nport Any TCP or UDP port\nprefix Remote IPv4 or IPv6 prefix set security vpn ipsec esp-group ESP lifetime '30000'\nset security vpn ipsec esp-group ESP proposal 1 encryption 'aes128'", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-vyatta-5400-common-migration-issues"}, {"document_id": "ibmcld_13891-10255-11746", "score": 0.5964893102645874, "text": "\nset system acm operational-ruleset rule 9993 action 'allow'\nset system acm operational-ruleset rule 9993 command '/reset/'\nset system acm operational-ruleset rule 9993 group 'vyattaop'\nset system acm operational-ruleset rule 9994 action 'allow'\nset system acm operational-ruleset rule 9994 command '/release/'\nset system acm operational-ruleset rule 9994 group 'vyattaop'\nset system acm operational-ruleset rule 9995 action 'allow'\nset system acm operational-ruleset rule 9995 command '/renew/'\nset system acm operational-ruleset rule 9995 group 'vyattaop'\nset system acm operational-ruleset rule 9996 action 'allow'\nset system acm operational-ruleset rule 9996 command '/telnet/'\nset system acm operational-ruleset rule 9996 group 'vyattaop'\nset system acm operational-ruleset rule 9997 action 'allow'\nset system acm operational-ruleset rule 9997 command '/traceroute/'\nset system acm operational-ruleset rule 9997 group 'vyattaop'\nset system acm operational-ruleset rule 9998 action 'allow'\nset system acm operational-ruleset rule 9998 command '/update/'\nset system acm operational-ruleset rule 9998 group 'vyattaop'\nset system acm operational-ruleset rule 9999 action 'deny'\nset system acm operational-ruleset rule 9999 command ''\nset system acm operational-ruleset rule 9999 group 'vyattaop'\nset system acm ruleset rule 9999 action 'allow'\nset system acm ruleset rule 9999 group 'vyattacfg'\nset system acm ruleset rule 9999 operation ''\nset system acm ruleset rule 9999 path ''\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-accessing-and-configuring-the-ibm-virtual-router-appliance"}, {"document_id": "ibmcld_14287-14248-15975", "score": 0.5957587957382202, "text": "\nset firewall name VMACCESS2MGMT\nset firewall name VMACCESS2MGMT default-action drop\nset firewall name VMACCESS2MGMT rule 10 action drop\nset firewall name VMACCESS2MGMT rule 10 protocol all\nset firewall name VMACCESS2MGMT rule 10 source group network-group 1103VMACCESS\nset firewall name STORAGE2MGMT\nset firewall name STORAGE2MGMT default-action drop\nset firewall name STORAGE2MGMT rule 10 action accept\nset firewall name STORAGE2MGMT rule 10 protocol all\nset firewall name STORAGE2MGMT rule 10 source group network-group 1102PRIMARY\nset firewall name STORAGE2MGMT rule 20 action accept\nset firewall name STORAGE2MGMT rule 20 protocol all\nset firewall name STORAGE2MGMT rule 20 source group network-group 1102STORAGEA\nset firewall name STORAGE2MGMT rule 30 action accept\nset firewall name STORAGE2MGMT rule 30 protocol all\nset firewall name STORAGE2MGMT rule 30 source group network-group 1102STORAGEB\nset firewall name MGMT2STORAGE\nset firewall name MGMT2STORAGE default-action drop\nset firewall name MGMT2STORAGE rule 10 action accept\nset firewall name MGMT2STORAGE rule 10 protocol all\nset firewall name MGMT2STORAGE rule 10 source group network-group 1101PRIMARY\nset firewall name MGMT2STORAGE rule 10 source group network-group 1101MGMT\ncommit\nsave\nShow more\n\n\n\n\n\n Configuring zone bindings \n\nBind particular zones to interfaces on the Brocade vRouter (Vyatta).\n\nUse the following commands in configure mode:\n\nset zone-policy zone OUTSIDE description \u201cInternet Zone\u201d\nset zone-policy zone OUTSIDE default-action drop\nset zone-policy zone OUTSIDE interface bond1\nset zone-policy zone SLSERVICE description \u201cSoftLayer Services\u201d\nset zone-policy zone SLSERVICE default-action drop\nset zone-policy zone SLSERVICE interface bond0", "title": "", "source": "https://cloud.ibm.com/docs/vmware?topic=vmware-set-up-brocade"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15918-37367-38469", "score": 0.7629776000976562, "text": "\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-manage"}, {"document_id": "ibmcld_15921-37405-38507", "score": 0.7629776000976562, "text": "\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-manage&interface=cli"}, {"document_id": "ibmcld_15922-37393-38495", "score": 0.7629776000976562, "text": "\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-manage&interface=ui"}, {"document_id": "ibmcld_15926-2839-5137", "score": 0.7415577173233032, "text": "\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore"}, {"document_id": "ibmcld_15934-2839-5137", "score": 0.7415577173233032, "text": "\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=api"}, {"document_id": "ibmcld_15937-2839-5137", "score": 0.7415577173233032, "text": "\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=cli"}, {"document_id": "ibmcld_15938-2839-5137", "score": 0.7415577173233032, "text": "\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=terraform"}, {"document_id": "ibmcld_15939-2839-5137", "score": 0.7415577173233032, "text": "\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=ui"}, {"document_id": "ibmcld_15111-10169-12034", "score": 0.7405931949615479, "text": "\nBy using the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n\n\n\n\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n\n\n\n\n\n\n\n Performance questions", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-vpc-faq"}, {"document_id": "ibmcld_07578-891912-893651", "score": 0.7340602874755859, "text": "\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09081-7-2309", "score": 0.6933509111404419, "text": "\nProtecting data with envelope encryption \n\nKey Protect uses envelope encryption to assist in protecting your Key Protect data. Envelope encryption involves encrypting your data with a Data Encryption Key, then encrypting the Data Encryption Key with a root key. This topic describes the process of envelope encryption and how to use Key Protect to encrypt and decrypt your data.\n\nWhen working with sensitive data, it is important to use advanced encryption techniques to prevent a data breach. If you have large amounts of confidential data, it is often helpful to use a Key Management System to assist in keeping your data secure. Key Protect uses the envelope encryption technique to keep your data resilient. Envelope encryption is the process of using encrypted keys, Data Encryption Keys and Root Keys, to protect your sensitive data.\n\nImagine that you plan to send a letter to a colleague. You want to discuss information that is highly sensitive, so you generate a secret code (Data Encryption Key) that is used to write (encrypt) the message in the letter. The letter is delivered to a mailbox (wrapped Data Encryption Key) that can only be opened by those with a copy of the mailbox key (Root key), including the colleague. Anyone who does not have an exact copy of the key will be unable to open the mailbox and see it's contents. When your colleague uses the key to unlock (unencrypt) the mailbox, they will need to know the secret code that the letter is written in to be able to understand the message. Everyone who is not aware of the secret code will conclude that the letter is a random mix of characters and will not be able to understand the letter's contents.\n\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption"}, {"document_id": "ibmcld_08739-8238-10173", "score": 0.6924368143081665, "text": "\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/hs-crypto//images/pkcs-database.svg)\n\nFigure 5. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications. Typically, database users do not need to be aware of default encryption and database client applications do not need to be adapted specifically.\n\nDb2 default encryption uses a two-tiered key hierarchy: Data is encrypted with a data encryption key (DEK). The DEK is encrypted with a master key and is stored in encrypted form with the database or the backup image. A unique DEK is generated by Db2 for each encrypted database and for each encrypted backup. A master key is used to encrypt a DEK. Each encrypted database is associated with one master key at one time.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-use-cases"}, {"document_id": "ibmcld_13494-7-1931", "score": 0.6833755373954773, "text": "\nSecuring your data in Data Engine \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Data Engine, it is important to know exactly [what data is stored and encrypted](https://cloud.ibm.com/docs/sql-query?topic=sql-query-keyprotectconsiderations) and how you can delete any stored data. Depending on your security requirements, you can encrypt data with customer-managed keys by integrating with IBM Cloud key management services such as Key Protect, which supports the Bring Your Own Key (BYOK) method.\n\n\n\n How your data is stored and encrypted in Data Engine \n\nAll data that is stored in Data Engine has by default service-managed encryption. You can also choose to encrypt with BYOK using IBM\u00ae Key Protect for IBM Cloud\u00ae. SQL query text and error messages can be encrypted by associating a IBM\u00ae Key Protect for IBM Cloud\u00ae during instance creation. Table metadata is encrypted by using the same mechanism for all tables or views that were created after August 23rd, 2022. All table metadata that was created before that date is encrypted by using service-managed encryption. You can re-create tables to convert the encryption method to BYOK by using IBM\u00ae Key Protect for IBM Cloud\u00ae.\n\n\n\n\n\n Protecting your sensitive data in Data Engine \n\nYou can add a higher level of encryption protection and control to your data at rest (when it is stored) by enabling integration with Key Protect. The data that you store in IBM Cloud is encrypted at rest by using a service-managed key. If you need to control the encryption keys, you can integrate Key Protect. This process is commonly referred to as Bring your own keys (BYOK). With Key Protect you can create, import, and manage encryption keys. You can assign access policies to the keys, assign users or service IDs to the keys, or give the key access only to a specific service. The first 20 keys are free.\n\n\n\n Enabling customer-managed keys for Data Engine", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-securing-data"}, {"document_id": "ibmcld_12655-1658-4229", "score": 0.6813061237335205, "text": "\nThe encryption process manages keys that are generated by a commercially available key management service such as IBM\u00ae Key Protect and Hyper Protect Crypto Services.\n\nApplication performance is minimally impacted allowing for enterprise workflows to continue to operate in a secure environment. The Data Security Broker Manager is the cloud-based management console providing scalability, fault tolerance, and manageability of the software.\n\n\n\n\n\n Encryption Technology Configuration Overview: \n\nData Security Broker supports data protection services that can be configured in four main modes.\n\n\n\n Data Encryption: \n\nData Security Broker functions as an application-level encryption (ALE) software in this mode for encrypting data on a field-level basis. This is performed using Data Security Broker Manager to enumerate the data schema and enable an encryption key mapping.\n\n\n\n\n\n Data Tokenization: \n\nData Security Broker supports length preserving and data type preserving tokenization method to anonymize data at the field level databases or in semi-structured data files.\n\n\n\n\n\n Record Level Encryption: \n\nData Security Broker can be configured for record level encryption to support multiple keys within a single column that are mapped to respective data owners or entities. This encryption mode can be used effectively in multi-tenant or shared data environments where segmenting of the data can be challenging. In this mode, data shredding can be enabled by deleting public keys and private keys for a respective entity.\n\n\n\n\n\n Data Masking: \n\nData Security Broker can enable simplified data masking to prevent decryption of data and sensitive file information based on configuration or deleted keys. This mode can minimize data exposure in public cloud environment and provides a better control of data exfiltration to external parties.\n\n\n\n\n\n\n\n Deployment Plans in IBM Cloud Data Data Security Broker: \n\nWhen you assign and customize default Data Protection Policies with Data Security Broker Manager, there are three options that you can choose to implement your data encryption policy:\n\n\n\n Save Policy: \n\nSave Policy option is selected by default. This option saves your selected data, but does not execute encryption or data protection on your database. Your policy remains saved with the application until a new policy is saved to overwrite it. You can use the saved policy to deploy or migrate it later.\n\n\n\n\n\n Deploy Policy: \n\nDeploy Policy option saves your policy and deploys your configured Data Security Broker Shield as a proxy for the configured database.", "title": "", "source": "https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_about"}, {"document_id": "ibmcld_13108-7-2001", "score": 0.6771624088287354, "text": "\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers", "title": "", "source": "https://cloud.ibm.com/docs/services/key-protect?topic=key-protect-about"}, {"document_id": "ibmcld_07545-1617-3641", "score": 0.6681296825408936, "text": "\n* Encryption of data at-rest controlled by your own key.\n* Explicit control of the lifecycle of data stored at rest.\n\n\n\nCustomer-managed keys is available on the Standard plan only.\n\nDeletion of the customer-managed key is non-recoverable and will result in the loss of any data stored in your Event Notifications instance.\n\n\n\n What is not covered by customer-managed encryption \n\nIf customer-managed encryption feature is selected, the user should be aware that only customer data is covered by this encryption. Event Notifications encrypts at-rest other data related to the use of the service.\n\nYou are not recommended to use confidential information in client metadata.\n\n\n\n\n\n How customer-managed encryption works \n\nEvent Notifications uses a concept called envelope encryption to implement customer-managed keys.\n\nEnvelope encryption is the practice of encrypting one encryption key with another encryption key. The key used to encrypt the actual data is known as a data encryption key (DEK). The DEK itself is never stored, but instead is wrapped by a second key known as the key encryption key (KEK) to create a wrapped DEK.\n\nTo decrypt data, the wrapped DEK must first be unwrapped to get the DEK. This process is possible only by accessing the KEK, which in this case is your root key stored in either [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-about) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-overview).\n\nYou own the KEK, which you create as a root key in the Hyper Protect Crypto Services or Key Protect service. The Event Notifications service never sees the root (KEK) key. Its storage, management, and use to wrap and unwrap the DEK is performed entirely within the key management service. If you disable or delete the key, the data can no longer be decrypted.\n\n\n\n\n\n Enabling a customer-managed key for Event Notifications \n\nComplete the following steps to provision your Event Notifications instance to use a customer-managed key:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-managing-encryption"}, {"document_id": "ibmcld_15710-3097-5054", "score": 0.6654270887374878, "text": "\nFor more information about envelope encryption, see [Protecting your sensitive data in VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end. Likewise, data elements that are related to your configuration are encrypted in transit and at rest. No personal or sensitive data is stored, processed, or transmitted. Data at rest is stored in an encrypted database.\n\nAfter the VPN for VPC is provisioned and the network connections are created, the encryption of data that you choose to transmit across the network is your responsibility.\n\n\n\n Instance storage data isolation and encryption \n\nThe instance storage disk or disks, which are attached to the virtual server instance, cannot be shared with any other virtual servers and cannot be accessed by any other virtual servers in the future. They are one-time use, single-attach, for the virtual server that requested the instance storage.\n\nInstance storage data is secured with on-disk encryption. The physical disks that are used for instance storage are self-encrypting with the strong AES-256 encryption standard. The data is automatically decrypted when your instance accesses the data. When your instance is shut down or deleted, the underlying storage space is erased and unrecoverable. At that point, the data is unrecoverable. For more information, see [Introduction to encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-basics).\n\nData is automatically encrypted on the physical media at the drive level. However, customer-managed keys are not supported for instance storage. For sensitive data, it is strongly recommended that users utilize software-based file system encryption such as LUKS for Linux\u00ae or BitLocker for Windows\u00ae.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-mng-data"}, {"document_id": "ibmcld_15710-4633-6509", "score": 0.6629752516746521, "text": "\nFor more information, see [Introduction to encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-basics).\n\nData is automatically encrypted on the physical media at the drive level. However, customer-managed keys are not supported for instance storage. For sensitive data, it is strongly recommended that users utilize software-based file system encryption such as LUKS for Linux\u00ae or BitLocker for Windows\u00ae. This technology allows end users to encrypt entirely within the instance, and can provide additional protection for sensitive data in-transit between the instances and the physical drive media. Some operating systems also provide FIPS certified encryption algorithms that may also be used. See [Encrypting block devices using LUKS](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/security_hardening/encrypting-block-devices-using-luks_security-hardening) for an example of how to encrypt on Red Hat Enterprise Linux\u00ae however, refer to the Operating System documentation or specific information on how to encrypt each device.\n\n\n\n\n\n\n\n Protecting your sensitive data in VPC \n\nKey Protect or Hyper Protect Crypto Services provide a higher level of protection called envelope encryption.\n\n[Envelope encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-ecryption-byok) encrypts one encryption key with another encryption key. A DEK encrypts your actual data. The DEK is never stored. Rather, it's encrypted by a key encryption key. The LUKS passphrase is then encrypted by a root key, which creates a WDEK. To decrypt data, the WDEK is unwrapped so you can access the data that's stored on the volume. This process is possible only by accessing the root key that is stored in your KMS instance. Root keys in HPCS service instances are also protected by a\n\nhardware security module (HSM)master key.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-mng-data"}, {"document_id": "ibmcld_02686-1611-3624", "score": 0.6608089208602905, "text": "\n* Encryption of data at-rest controlled by your own key.\n* Explicit control of the lifecycle of data stored at rest.\n\n\n\nCustomer-managed keys is available on the Enterprise plan only.\n\nDeletion of the customer-managed key is non-recoverable and will result in the loss of any data stored in your App Configuration instance.\n\n\n\n What is not covered by customer-managed encryption \n\nIf customer-managed encryption feature is selected, the user should be aware that only segment data is covered by this encryption. App Configuration encrypts at-rest other data related to the use of the service.\n\nYou are not recommended to use confidential information in client metadata.\n\n\n\n\n\n How customer-managed encryption works \n\nApp Configuration uses a concept called envelope encryption to implement customer-managed keys.\n\nEnvelope encryption is the practice of encrypting one encryption key with another encryption key. The key used to encrypt the actual data is known as a data encryption key (DEK). The DEK itself is never stored, but instead is wrapped by a second key known as the key encryption key (KEK) to create a wrapped DEK.\n\nTo decrypt data, the wrapped DEK must first be unwrapped to get the DEK. This process is possible only by accessing the KEK, which in this case is your root key stored in either [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-about) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-overview).\n\nYou own the KEK, which you create as a root key in the Hyper Protect Crypto Services or Key Protect service. The App Configuration service never sees the root (KEK) key. Its storage, management, and use to wrap and unwrap the DEK is performed entirely within the key management service. If you disable or delete the key, the data can no longer be decrypted.\n\n\n\n\n\n Enabling a customer-managed key for App Configuration \n\nComplete the following steps to provision your App Configuration instance to use a customer-managed key:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-managing-encryption"}, {"document_id": "ibmcld_15710-1620-3492", "score": 0.6554019451141357, "text": "\nYour key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.\n\nImages and volumes are often referred to as being encrypted with a root key when, in fact,\n\nenvelope encryptionis used. Internally, each image or volume is encrypted with adata encryption key (DEK), which is an open source QEMU technology that is used by the IBM Cloud VPC Generation 2 infrastructure. A LUKS passphrase, also called a key encryption key, encrypts the DEK. The LUKS passphrase is then encrypted with a root key, creating what is called a wrapped DEK (WDEK). For more information about IBM Cloud VPC key encryption technology, see [IBM Cloud VPC Generation 2 encryption technology](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\nFor example, if you provision two volumes by using the same root key, unique passphrases are generated for each volume, which are then encrypted with the root key. Envelope encryption provides more protection for your data, and ensures that the root key can be rotated without having to reencrypt the data. For more information about envelope encryption, see [Protecting your sensitive data in VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-mng-data"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03039-0-644", "score": 0.7034938335418701, "text": "\n\n\n\n\n\n\n  Disaster recovery \n\nRecovering from potential disasters requires planning and preparation.\n\nYou are responsible for understanding your configuration, customization, and usage of Watson Assistant. You are also responsible for being ready to re-create an instance of the service and to restore your data.\n\n\n\n  Disaster recovery \n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud\u00ae. See [Backing up and restoring data](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-backup) for information about how to back up your service instances.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-recovery"}, {"document_id": "ibmcld_12523-0-1829", "score": 0.6994560956954956, "text": "\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for projects \n\nDisaster recovery involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n  Responsibilities \n\nFor more information about your responsibilities when using projects, see [Shared responsibilities for projects](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-responsibilities-projects).\n\n\n\n  Disaster recovery strategy \n\nIBM Cloud has business continuity plans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data backup and associated recovery of your content.\n\nIBM Cloud performs regular electronic backups of project data with Recovery Time Objective (RTO) and Recovery Point Objective (RPO) of hours as documented in the [IBM Cloud Disaster Recovery Plan](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery). Projects don't replicate data outside of a region, except for backup data. When possible, backup data is kept within the data centers of a country but data is always kept within a geography. European data does not leave the EU.\n\n\n\nTable 1. RPO and RTO for projects\n\n Disaster recovery objective  Target Value \n\n RPO                          1 hour       \n RTO                          4 hours      \n\n\n\n\n\n\n\n\n\n  Locations \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-bc-dr"}, {"document_id": "ibmcld_00523-8515-10661", "score": 0.6845157146453857, "text": "\n[In-region automatic data redundancy](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backupin-region-automatic-data-redundancy) provides applications with high availability access to data. [Cross-region redundancy for disaster recovery](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backupcross-region-redundancy-for-disaster-recovery) provides applications with a means of recovering from a disaster. However, both of these capabilities focus on maintaining access only to the current copy of your data.\n\nPeople and applications can make mistakes and change data in unintended ways. The applications themselves can implement some protection, but sometimes undesirable changes get through. It's useful to be able to restore data from a previous point in time. Database backups support this requirement.\n\nIn addition to protecting your data with high availability and disaster recovery features, consider dumping your database data to a separate location at periodic, regular intervals. Ensure you check and test the backups for confidence that they're complete and correct.\n\nIBM Cloudant supports tools that help you dump the JSON content in databases to a file, and later restore databases from those files.\n\nSpecifically, IBM Cloudant supports tools that help you perform the following tasks:\n\n\n\n* Backup complete databases to a file that is suitable for further processing and off-site storage.\n* Restore complete databases from a previous state that is contained in your backup file.\n\n\n\nThe tools that are supported by IBM Cloudant have the following limitations:\n\n\n\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precisely accurate \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, the data in the database can change between the times when the first and last batches are read.\n* Index definitions held design documents are backed up, but when data is restored the indexes must be rebuilt.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backup"}, {"document_id": "ibmcld_14330-0-2649", "score": 0.6844201683998108, "text": "\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for VMware as a Service \n\nDisaster recoveryinvolves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n  Responsibilities \n\nFor more information about responsibility ownership for using IBM Cloud\u00ae products between IBM\u00ae and the customer, see [Shared responsibilities for IBM Cloud products](https://cloud.ibm.com/docs/overview?topic=overview-shared-responsibilities).\n\nFor more information about your responsibilities when using IBM Cloud\u00ae for VMware as a Service, see [Understanding your responsibilities when using VMware as a Service](https://cloud.ibm.com/docs/vmware-service?topic=vmware-service-vmaas-understand-responsib).\n\n\n\n\n\n  Disaster recovery strategy \n\nIBM Cloud has\n\nbusiness continuityplans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data backup and associated recovery of your content.\n\nVMware as a Service provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted\n\nrecovery point objective(RPO) andrecovery time objective(RTO) for the service. The following table outlines the targets for VMware as a Service.\n\n\n\nTable 1. RPO and RTO for VMware as a Service\n\n Disaster recovery objective  Target value      Method                                                                                                                                                             \n\n RPO                          24 h              Use a backup provider such as Veeam\u00ae Backup and Recovery to store periodic backups of your workload.                                                               \n RPO                          Minutes           Use a replication provider such as Veeam to replicate your workload to another location.                                                                           \n RTO                          Minutes to hours  The recovery time objective depends on the storage medium that is used for your backups and on how long it takes for your workload to be ready from a cold start.  \n\n\n\n\n\n\n\n  Locations \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-bc-dr"}, {"document_id": "ibmcld_16494-1892-3481", "score": 0.6640728712081909, "text": "\nThis stored data includes the training data for your models.\n\nRe-creating models from saved data takes time. You can maintain parallel service configurations in multiple locations to help eliminate the turnaround time associated with disaster recovery.\n\n\n\n Disaster recovery for models \n\nFor models, understand which data can be backed up, restore and re-create necessary artifacts, and then retrain and redeploy the models.\n\n\n\n Backing up data \n\nSome data can be backed up, and some must be re-created:\n\n\n\n1. [Understand which data can be backed up](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restoredata)\n2. [Prepare for backup](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restoreprepare)\n3. [Download artifacts from the current instance](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restoreexport)\n\n\n\n\n\n\n\n Restoring data, models, and tasks \n\nTo recover from a disaster:\n\n\n\n1. [Recreate workspaces on the new instance](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restorerecreateproj)\n2. [Restore the workspace data](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restorerestoredata)\n3. [Restore the models](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restorerestoremodels)\n4. [Restore any incomplete annotation tasks](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-backup-restorerestoretasks)", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-ha-dr"}, {"document_id": "ibmcld_01328-7-2398", "score": 0.6639025807380676, "text": "\nBusiness continuity and disaster recovery for Container Registry \n\nFind out about the business continuity and disaster recovery strategy for IBM Cloud\u00ae Container Registry.\n\nDisaster recoveryinvolves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n Your responsibilities when you're using Container Registry \n\nFor more information about your responsibilities when you're using IBM Cloud Container Registry, see [Shared responsibilities for IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_responsibilities).\n\n\n\n\n\n Disaster recovery strategy \n\nIBM Cloud has\n\nbusiness continuityplans in place to provide for the recovery of services within hours if a disaster occurs. You're responsible for your data backup and associated recovery of your content.\n\nContainer Registry provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted\n\nrecovery point objective(RPO) andrecovery time objective(RTO) for the service. The following table outlines the targets for Container Registry.\n\n\n\nTable 1. RPO and RTO for Container Registry\n\n Disaster recovery objective Target Value \n\n Recovery point objective (RPO) 48 hours \n Recovery time objective (RTO) 24 hours \n\n\n\n\n\n\n\n Locations for service availability \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\n\n\n Frequently asked questions about disaster recovery \n\nReview the following FAQs about disaster recovery.\n\n\n\n Does the service replicate the data? \n\nAll customer data in IBM Cloud Container Registry is replicated and backed up. Backups include service and policy settings and image data, but not vulnerability results, which can be reconstructed. All data, including vulnerability results, is replicated within each region so that the loss of a single availability zone is tolerated transparently. Regular point-in-time backups are used by IBM to restore the content if the data is corrupted.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-bc-dr"}, {"document_id": "ibmcld_00057-5736-7021", "score": 0.6609311103820801, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Restore or rebuild the provisioning environments in the affected regions.<br> * Restore existing Spark clusters, where possible.<br><br><br> <br><br> * Track instance state.<br> * Provision new Spark instances in alternatively available regions.<br> * Ensure that the Spark instance is stateless by making sure that all data, metadata and applications reside outside of the cluster. This activity must be completed before disaster recovery can be initiated.<br> * Provision a new service instance in an alternatively available region if the current instances can't be accessed.<br> * Track instance state.<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"}, {"document_id": "ibmcld_09756-3410-5722", "score": 0.6595399379730225, "text": "\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location.\n\nIBM Cloud Monitoring follows IBM Cloud requirements for [planning and recovering from disaster events](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery).\n\nIf a regional disaster occurs, consider the following information:\n\n\n\n* The estimated recovery time for rebuilding the regional site and restoring the service at another location is 24 hours.\n* You will have to update the endpoints of applications and monitoring agents to point to the ingestion endpoint in the new location.\n* You will have to restore the service instance's metadata, that is, dashboards and alerts definitions, from your backups.\n\n\n\nHistorical data may be lost during a disaster. If you require historical metrics for auditing purposes, backup the metrics regularly by querying the metrics from the service and storing them at a remote backup site.\n\n\n\n Manual recovery of the service \n\nIf a regional disaster occurs, the recovery time of the service depends on the recovery time for the region. To minimize the downtime of the service and impact to your business, you could implement a manual failover to switch to another region while the region is being restored. To reduce the time to get up and running in a new location, consider using access groups to manage permissions working with the service, and backup the monitoring metadata of each instance. You should backup your alerts, notifications, dashboards and team definitions on a regular basis.\n\nHow to continue working while a DR site is rebuilt?\n\nIf the applications and services that you are monitoring through a monitoring instance are all co-located in the same region, then you must wait for the region to be available again for business.\n\nIf you have deployed monitoring agents on your systems, and those systems are not impacted by the regional failure, you may choose to redirect metrics to other instances of monitoring in a different region. To redirect metric data, complete the following steps:\n\n\n\n1. [Provision a monitoring instance](https://cloud.ibm.com/docs/monitoring?topic=monitoring-provision)\n2. Reconfigure the monitoring agent of each system: Change the access key and ingestion endpoints in the agent configuration.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-ha-dr"}, {"document_id": "ibmcld_08117-7-2019", "score": 0.6590250730514526, "text": "\nIBM Cloud Disaster Recovery (DR) and Backup and Restore \n\nLocal service interruption can be caused by many things: hardware failures, bugs, power failures, planned and unplanned maintenance. To minimize a single point of failure, IBM Cloud\u00ae architects create resilient designs that have multiple virtual server instances to provide the highest availability.\n\nHowever, extreme failure events, such as data center wide failures due to network outages, natural disasters, or ransomware are harder to anticipate and plan for. Your Business Continuity and Disaster Recovery (BCDR) plan becomes a critical part of recovering from these types of events. Business continuity focuses on the processes and procedures that you implement to help your people minimize interruptions to business operations. Disaster recovery focuses on the IT components and restoring systems after a disaster.\n\n\n\n Disaster recovery components \n\nThe DR model has two main components that deal with what can be tolerated:\n\n\n\n* Recovery Time Objective (RTO) - the maximum time that the service can be down.\n* Recovery Point Objective (RPO) - the maximum amount of data loss.\n\n\n\nZoom\n\n![DR backup diagram.](https://cloud.ibm.com/docs-content/v1/content/df269b100c3499f1efcbb7d030dce8dec25c539b/ha-infrastructure/images/ha-DR-backup-diagram.svg)\n\nFigure 1. DR backup diagram\n\nThese values are directly correlated to both cost and complexity. A lower amount of time and data loss equates to higher cost and complexity.\n\n\n\n\n\n DR Strategies \n\nYou can implement your DR strategy in one of two ways:\n\n\n\n Strategy Description Benefits \n\n Cold (Active/Standby) With a Cold DR strategy, your solution is running in one environment and duplicate resources are available on standby. When an event occurs, you react and build up the standby site. A cold strategy is a reactive approach, where the upfront cost is minimal, other than storage costs for snapshots and backups. The cold approach typically entails higher RPO/RTO times and is simple to implement.", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-ha-dr-backup-restore"}, {"document_id": "ibmcld_01092-7-2034", "score": 0.658969521522522, "text": "\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https://www.ibm.com/support/knowledgecenter/SS6NHC/com.ibm.swg.im.dashdb.idrca.doc/overview/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-dr"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03470-12577-13864", "score": 0.6776981353759766, "text": "\nVPC gives you the security of a private cloud, with the agility and ease of a public cloud. See [IBM Cloud\u00ae Virtual Private Cloud Gen 2](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\nThe following table lists VPC infrastructure services that send auditing events:\n\n\n\nTable 13. List of VPC infrastructure services (generation 2)\n\n Service CRN service name Events \n\n [Storage resources](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-about) is.volume [Location-based events](https://cloud.ibm.com/docs/vpc?topic=vpc-at-eventsevents-storage) \n [Compute resources](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers) is.instance [Location-based events](https://cloud.ibm.com/docs/vpc?topic=vpc-at-eventsevents-compute) \n [Network resources](https://cloud.ibm.com/docs/vpc?topic=vpc-about-networking-for-vpc) is.subnet [Location-based events](https://cloud.ibm.com/docs/vpc?topic=vpc-at-eventsevents-network) \n [Load Balancer](https://cloud.ibm.com/docs/vpc?topic=vpc-load-balancers) is.load-balancer [Location-based events](https://cloud.ibm.com/docs/vpc?topic=vpc-at-eventsevents-load-balancers) \n [VPN](https://cloud.ibm.com/docs/vpc?topic=vpc-using-vpn) is.vpn [Location-based events](https://cloud.ibm.com/docs/vpc?topic=vpc-at-eventsat-events)", "title": "", "source": "https://cloud.ibm.com/docs/atracker?topic=atracker-cloud_services_atracker&interface=cli"}, {"document_id": "ibmcld_04543-88903-90180", "score": 0.6672765016555786, "text": "\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE1: ID or name of the VPC routing table.\n* ROUTING_TABLE2: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-routes \n\nList all the routes of a VPC routing table.\n\nibmcloud is vpc-routing-table-routes VPC ROUTING_TABLE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route \n\nView details of a VPC route.\n\nibmcloud is vpc-routing-table-route VPC ROUTING_TABLE ROUTE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* ROUTE: ID or name of the VPC route.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route-create \n\nCreate a VPC route.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-vpc-reference"}, {"document_id": "ibmcld_15545-89007-90284", "score": 0.6672765016555786, "text": "\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE1: ID or name of the VPC routing table.\n* ROUTING_TABLE2: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-routes \n\nList all the routes of a VPC routing table.\n\nibmcloud is vpc-routing-table-routes VPC ROUTING_TABLE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route \n\nView details of a VPC route.\n\nibmcloud is vpc-routing-table-route VPC ROUTING_TABLE ROUTE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* ROUTE: ID or name of the VPC route.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route-create \n\nCreate a VPC route.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"}, {"document_id": "ibmcld_15558-89059-90336", "score": 0.6672765016555786, "text": "\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE1: ID or name of the VPC routing table.\n* ROUTING_TABLE2: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-routes \n\nList all the routes of a VPC routing table.\n\nibmcloud is vpc-routing-table-routes VPC ROUTING_TABLE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route \n\nView details of a VPC route.\n\nibmcloud is vpc-routing-table-route VPC ROUTING_TABLE ROUTE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* ROUTE: ID or name of the VPC route.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route-create \n\nCreate a VPC route.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"}, {"document_id": "ibmcld_16082-88903-90180", "score": 0.6672765016555786, "text": "\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE1: ID or name of the VPC routing table.\n* ROUTING_TABLE2: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-routes \n\nList all the routes of a VPC routing table.\n\nibmcloud is vpc-routing-table-routes VPC ROUTING_TABLE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route \n\nView details of a VPC route.\n\nibmcloud is vpc-routing-table-route VPC ROUTING_TABLE ROUTE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* ROUTE: ID or name of the VPC route.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route-create \n\nCreate a VPC route.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-reference"}, {"document_id": "ibmcld_16092-88959-90236", "score": 0.6672765016555786, "text": "\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE1: ID or name of the VPC routing table.\n* ROUTING_TABLE2: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-routes \n\nList all the routes of a VPC routing table.\n\nibmcloud is vpc-routing-table-routes VPC ROUTING_TABLE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route \n\nView details of a VPC route.\n\nibmcloud is vpc-routing-table-route VPC ROUTING_TABLE ROUTE [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* VPC: ID or name of the VPC.\n* ROUTING_TABLE: ID or name of the VPC routing table.\n* ROUTE: ID or name of the VPC route.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is vpc-routing-table-route-create \n\nCreate a VPC route.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-reference&interface=cli"}, {"document_id": "ibmcld_15790-987-2174", "score": 0.6623046398162842, "text": "\n* For more information on creating a VPC, see [Getting started with Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started&interface=uicreate-and-configure-vpc).\n\n\n\n* security-group\n\n\n\n* For more information, see [About security groups](https://cloud.ibm.com/docs/vpc?topic=vpc-using-security-groups&interface=ui).\n\n\n\n* subnet\n\n\n\n* For more information on creating a subnet, see [Using the IBM Cloud console to create VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console), [Using the REST APIs to create VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-rest-apis), or [Using the CLI to create VPC resources](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-clicreate-a-subnet-cli).\n* For more information on deleting a subnet, see [Deleting VPC resources by using the UI](https://cloud.ibm.com/docs/vpc?topic=vpc-deleting-using-console), [Deleting VPC resources by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-deleting-using-cli), or [Deleting VPC resources by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-deleting-using-api).\n\n\n\n* floating-ip", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-quota-troubleshooting"}, {"document_id": "ibmcld_09715-14970-16572", "score": 0.6615695953369141, "text": "\n[Platform metrics](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared-monitorshared-monitor-metrics) \n\n\n\n\n\n\n\n VPC \n\nWith IBM Cloud\u00ae Virtual Private Cloud (VPC), you can provision a VPC in the IBM Cloud to run an isolated environment within the public cloud. VPC gives you the security of a private cloud, with the agility and ease of a public cloud. The VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. [Learn more](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\nYou can monitor various aspects of VPC services with IBM Cloud Monitoring dashboards. For more information, see [IBM Cloud VPC monitoring dashboards](https://cloud.ibm.com/docs/vpc?topic=vpc-ibm-monitoring).\n\nThe following table lists services that are enabled for IBM Cloud Monitoring:\n\n\n\nTable 14. List of VPC services (generation 2)\n\n Service Description Metrics \n\n [VPC virtual server instances](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui) With virtual server instances for VPC, you can quickly provision instances with high network performance. [Platform metrics](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-monitoring-metrics) \n [Flow Logs for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-flow-logs) Flow Logs for VPC enable the collection, storage, and presentation of information about the Internet Protocol (IP) traffic going to and from network interfaces within your Virtual Private Cloud (VPC). [Platform metrics](https://cloud.ibm.com/docs/vpc?topic=vpc-fl-monitoring-metrics)", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-cloud_services"}, {"document_id": "ibmcld_08007-2953-4885", "score": 0.65773606300354, "text": "\nAn alternative connectivity pattern requires use of the [VPN for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-using-vpn) service to securely connect from your private network to the management VPC. VPN for VPC can be used as a static, route-based VPN or a policy-based VPN to set up an IPsec site-to-site tunnel between your VPC and your on-premises private network, or another VPC. When using VPN for VPC, you need to place the gateway in a subnet (shown in the lower left subnet in the diagram).\n\n\n\n\n\n Bastion host \n\nRegardless of whether you are using Direct Link or VPN for VPC to connect to the management VPC, you need to ensure that all traffic is routed through a bastion host with session recording. The bastion host solution is depicted in the two rightmost lower subnets in the diagram.\n\n\n\n\n\n Connectivity between VPCs \n\nThe management VPC needs to connect to the workload VPC to deploy, configure, and operate the components and workloads that are found in the workload VPC. [Transit Gateway](https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-about) is designed specifically for this purpose, and is the means for connecting your management VPC to your workload VPC.\n\n\n\n\n\n\n\n Workload VPC \n\nThe workload VPC provides compute, storage, and network services to support hosted applications and operations that deliver services to the consumer. Let's take a closer look at the components within the VPC.\n\n\n\n Regions and zones \n\nJust like the management VPC, the workload VPC is spread across three zones. The workload VPC should be created in the same MZR as the management VPC.\n\n\n\n\n\n Connectivity to workload VPC \n\nIf the consumer is in the same organization as the application provider, then just like for the management VPC, Direct Link can provide access to the workload VPC. Alternatively, VPN for VPC can be used for site-to-site VPN connectivity.\n\n\n\n\n\n Storage and encryption \n\n\n\n Block Storage for VPC", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"}, {"document_id": "ibmcld_15261-3323-5267", "score": 0.6575547456741333, "text": "\n[Contact support](https://cloud.ibm.com/docs/vpc-on-classic?topic=vpc-on-classic-getting-help-and-support) if you are unable to delete a resource in failed status.\n\n\n\n\n\n Follow this order when you delete a VPC \n\nA VPC contains subnets and public gateways. A public gateway can be attached to one or more subnets in the VPC. A subnet also can contain virtual server instances, and one virtual server instance can have multiple network interfaces in different subnets within the VPC. Before a subnet can be deleted, any network interfaces in the subnet must first be deleted. A VPC contains security groups as well, but they are deleted automatically when the VPC is deleted. Address prefixes are attributes of a VPC, and they are deleted automatically, when the VPC is deleted.\n\nFollow this order when you delete a VPC:\n\n\n\n1. Delete all VPN gateways that are provisioned in any subnet of the VPC.\n2. Detach all load balancers that are provisioned in any subnet of the VPC.\n3. Delete all instances that have network interfaces in any subnet of the VPC. Any Floating IP associated with a network interface is automatically detached from the network interface when the instance is deleted.\n4. Delete all subnets in the VPC. Any public gateway attached to a subnet is automatically detached from the subnet when the subnet is deleted.\n5. Delete all public gateways in the VPC.\n6. When the VPC has no subnets and no public gateways, you can delete the VPC. All Address Prefixes in the VPC are automatically deleted when the VPC is deleted.\n\n\n\n\n\n\n\n VPC resource relationships \n\nSome VPC resources are contained within other VPC resources (as \"children\"), but other VPC resources are contained at the account level, outside of any specific VPC. All child VPC resources must be deleted before the parent resource can be deleted. For account-level VPC resources, all links to existing resources must be deleted before the account resource can be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-deleting"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12469-48144-49825", "score": 0.49960097670555115, "text": "\n--secret-type (string)\n: The secret type. Required.\n\nAllowable values are: public_cert, private_cert.\n\n--config-element (string)\n: The configuration element to define or manage. Required.\n\nAllowable values are: certificate_authorities, dns_providers, root_certificate_authorities, intermediate_certificate_authorities, certificate_templates.\n\n\n\n\n\n Examples \n\nibmcloud secrets-manager config-elements --secret-type=public_cert --config-element=certificate_authorities\n\n\n\n\n\n\n\n ibmcloud secrets-manager config-element \n\nGet the details of a specific configuration that is associated with a secret type.\n\nibmcloud secrets-manager config-element --secret-type SECRET-TYPE --config-element CONFIG-ELEMENT --config-name CONFIG-NAME\n\n\n\n Command options \n\n--secret-type (string)\n: The secret type. Required.\n\nAllowable values are: public_cert, private_cert.\n\n--config-element (string)\n: The configuration element to define or manage. Required.\n\nAllowable values are: certificate_authorities, dns_providers, root_certificate_authorities, intermediate_certificate_authorities, certificate_templates.\n\n--config-name (string)\n: The name of your configuration. Required.\n\n\n\n\n\n Examples \n\nibmcloud secrets-manager config-element --secret-type=public_cert --config-element=certificate_authorities --config-name=exampleString\n\n\n\n\n\n\n\n ibmcloud secrets-manager config-element-update \n\nUpdate a configuration element that is associated with the specified secret type.\n\nibmcloud secrets-manager config-element-update --secret-type SECRET-TYPE --config-element CONFIG-ELEMENT --config-name CONFIG-NAME --type TYPE --config CONFIG\n\n\n\n Command options \n\n--secret-type (string)\n: The secret type. Required.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1"}, {"document_id": "ibmcld_00708-30606-31461", "score": 0.4868299961090088, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-30606-31461", "score": 0.4868299961090088, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-30587-31442", "score": 0.4868299961090088, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_04513-6263-7086", "score": 0.4682578444480896, "text": "\n3]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire4\":{\"operates\":{\"qubits\":[4]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire5\":{\"operates\":{\"qubits\":[5]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire6\":{\"operates\":{\"qubits\":[6]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire7\":{\"operates\":{\"qubits\":[7]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire8\":{\"operates\":{\"qubits\":[8]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire9\":{\"operates\":{\"qubits\":[9]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"d0\":{\"operates\":{\"qubits\":[0]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d1\":{\"operates\":{\"qubits\":[1]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d10\":{\"operates\":{\"qubits\":[10]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d11\":{\"operates\":{\"qubits\":[11]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d12\":{\"operates\":{\"qubits\":[12]},\"purpose\":\"drive\",\"type", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-quantum-computing-cli"}, {"document_id": "ibmcld_11511-6291-7114", "score": 0.4682578444480896, "text": "\n3]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire4\":{\"operates\":{\"qubits\":[4]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire5\":{\"operates\":{\"qubits\":[5]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire6\":{\"operates\":{\"qubits\":[6]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire7\":{\"operates\":{\"qubits\":[7]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire8\":{\"operates\":{\"qubits\":[8]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"acquire9\":{\"operates\":{\"qubits\":[9]},\"purpose\":\"acquire\",\"type\":\"acquire\"},\"d0\":{\"operates\":{\"qubits\":[0]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d1\":{\"operates\":{\"qubits\":[1]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d10\":{\"operates\":{\"qubits\":[10]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d11\":{\"operates\":{\"qubits\":[11]},\"purpose\":\"drive\",\"type\":\"drive\"},\"d12\":{\"operates\":{\"qubits\":[12]},\"purpose\":\"drive\",\"type", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-quantum-computing-cli"}, {"document_id": "ibmcld_16527-1561-3838", "score": 0.46293866634368896, "text": "\nConsider referencing this type of resource to get an idea of the types of entities you might want to define in your own type system.\n\n\n\n Mentions \n\nA mention is any span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like airbag, Ford Explorer, and child restraint system might be relevant mentions.\n\n\n\n\n\n Entity types \n\nAn entity type is how you categorize a real-world thing. An entity mention is an example of a thing of that type. For example, the mention President Obama can be annotated as a PERSON entity type. The mention IBM can be annotated as an ORGANIZATION entity type. Entities are often nouns, but can also be verbs, as long as the verb is important to capture for the purposes of the application that will use the type system. For example, EVENT_CRASH might be a valid entity type for a type system about automotive vehicles, so that the word hit in the sentence, The car hit the barrier. can be annotated.\n\nThe goal of your annotation workspace is to annotate each mention in a document with the type of thing that it is. After a mention is classified by entity type, the labeled span of text is referred to as an entity.\n\nA type system that you build with Knowledge Studio can include the following entity type attributes. The attributes help qualify mentions in text, but they are not marked as entity types by a machine learning model. For example, if the entity type ORGANIZATION has an entity subtype called COMMERCIAL, COMMERCIAL is not marked as an entity type on its own.\n\n\n\n* Role\n\nQualifies the mention by the context in which the mention occurs. For example, the mention France in the statement, the students went to France, is marked with the entity type GPE because France is a geo-political entity. But, because France in this context is also a destination for the traveling students, the entity type is qualified by adding an attribute, in this case the role LOCATION. For another example, the mention Lawyers might be marked with the entity type PEOPLE and also by the role OCCUPATION.\n* Entity subtype\n\nFurther classifies the entity type. For example, the entity type ORGANIZATION might include the subtypes COMMERCIAL, GOVERNMENT, MILITARY, and EDUCATION.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"}, {"document_id": "ibmcld_09252-4848-5733", "score": 0.4627079665660858, "text": "\nNot all rule types support all comparison types. For example, if you are using FILE_TYPE, it is best to use comparison types REGEX and ENDS_WITH.\n\n\n\n\n\n Layer 7 rule properties \n\n\n\n Property Description \n\n Type Specifies the type of rule. Rule types can be HOST_NAME, FILE_TYPE, HEADER, COOKIE, or PATH. \n Comparison Type Comparison types are used in association with the rule type, key, and value to define a rule and classify traffic. Comparison types can be: REGEX, STARTS_WITH, ENDS_WITH, CONTAINS, and EQUAL_TO. \n Key The description key for the rule types HEADER and COOKIE. \n Value For the rule types HEADER and COOKIE, the value is compared against the key. \n Invert If you set the value to 1, the value of this L7 rule comparison is set to true whenever the specified rule is not matched. \n Layer 7 Policy ID The unique identifier of the policy to which the rules are attached.", "title": "", "source": "https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-layer-7-policy"}, {"document_id": "ibmcld_16527-11091-13443", "score": 0.46269404888153076, "text": "\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"}, {"document_id": "ibmcld_09254-1704-2604", "score": 0.46171391010284424, "text": "\nNot all rule types support all comparison types. For example, if you are using FILE_TYPE, it is best to use comparison types REGEX and ENDS_WITH.\n\n\n\n Layer 7 rule properties \n\n\n\nRule properties\n\n Property Description \n\n Type Specifies the type of rule. Rule types can be HOST_NAME, FILE_TYPE, HEADER, COOKIE, or PATH. \n Comparison Type Comparison types are used in association with the rule type, key, and value to define a rule and classify traffic. Comparison types can be: REGEX, STARTS_WITH, ENDS_WITH, CONTAINS, and EQUAL_TO. \n Key The description key for the rule types HEADER and COOKIE. \n Value For the rule types HEADER and COOKIE, the value is compared against the key. \n Invert If you set the value to 1, the value of this L7 rule comparison is set to true whenever the specified rule is not matched. \n Layer 7 Policy ID The unique identifier of the policy to which the rules are attached.", "title": "", "source": "https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-layer-7-rules"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11142-7-1829", "score": 0.6092201471328735, "text": "\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https://cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_16727-754871-756890", "score": 0.594291090965271, "text": "\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https://www.citrix.com/products/netscaler-adc/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-755905-757955", "score": 0.5839354991912842, "text": "\nYou can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https://cloud.ibm.com/docs/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07549-2080-3567", "score": 0.5793129801750183, "text": "\n(Author Vic Sh\u00f3stak) (https://proxy.golang.org/github.com/gofiber/fiber/v2/@v/v2.10.0.zip)<-- </section \"id=\"section-CC-BY-SA-4.0\" \"> --><-- <section \"id=\"section-GPL-V3\" \"> --> GNU GENERAL PUBLIC LICENSE, VERSION 3 The Program includes some or all of the following licensed to you as Separately Licensed Code under the GNU General Public License. For copies of the source code for this software, send an email to deepika.kothamasu@in.ibm.com]deepika_.kothamasu_in_.ibm_.com] identifying the IBM product and the GPL-licensed program for which you are requesting the source code.ACLOCAL Thrift], AX_LUA (GPL V3 WITH AUTOCONF EXCEPTION) Thrift] ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! Copyright \u00a9 2007 Free Software Foundation, Inc. <https://fsf.org/>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.PreambleThe GNU General Public License is a free, copyleft license for software and other kinds of works.The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_05374-1704-3601", "score": 0.5767378807067871, "text": "\n* Deploy an application from code on your local system with Code Engine.\n\n\n\n\n\n* Video transcript\n\nHi, my name is JJ Asghar and I'm a developer advocate for IBM Cloud. Recently, you might have heard about Heroku changing their policy on free - the free tier. It's causing a challenge for a lot of developers out there so I want to take a handful of moments here to show you how you can migrate from Heroku to Code Engine from IBM Cloud in just a handful of steps. So let's go ahead and start playing around with it and see how quickly you can actually make your system work.\n\nSo first thing first, if you haven't seen it this is the actual line inside the official blog from Heroku, starting on November 28, 2022, we plan to stop free - offering the free product plans and plan on shutting down the free dynos and data services. We'll be sending out a series of email communications to affected users. This is challenging for a lot of beginner beginner web applications. I know for a fact personally I used Heroku when I first started back in the day so this is a pretty large hit for a lot of people and I want to show you how easy it is to convert from Heroku to Code Engine.\n\nSo first thing first, let's actually see a nice little application I've created. If I go ahead and bring up my application here, we have a nice little flask app. If you don't know what python is or flask is, it's a it's a format for python to be able to run an application on a standard port. So let's say we have this application; it says \u201cHello World!\u201d. I've already deployed it and we can check out right here We have our amazing production app at heroku.com. It says \u201chello world\u201d and we want to go ahead and change it. We wanted to update it so I'm going to go ahead and quickly update it to \u201cHello Moving from Heroku to Code Engine\u201d.\n\nLet\u2019s go ahead and come out of it. git add .git commit -m \u201cupdate hello line\u201d.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-heroku-migrate"}, {"document_id": "ibmcld_04145-7-2180", "score": 0.5722378492355347, "text": "\nFAQs for IBM Cloud Internet Services \n\nHave a question about IBM Cloud\u00ae Internet Services? Review these frequently asked questions, which provide answers to provisioning concerns, application access, and other common inquiries.\n\n\n\n What do I get with a Free Trial Plan? \n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n\n\n\n\n\n How many Free Trial instances can I have? \n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n\n\n\n\n\n Can I downgrade from Standard to the Free Trial? \n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n\n\n\n\n\n My Free Trial has expired. What are my options? \n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n\n\n\n\n\n What happened to Enterprise Package plans? \n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https://cloud.ibm.com/docs/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-faq"}, {"document_id": "ibmcld_11142-1400-2265", "score": 0.5659842491149902, "text": "\nGo to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials \n\nCheck out our [tutorials for Lite plans](https://cloud.ibm.com/docs?tab=tutorials&filters=lite-account) for detailed steps about using IBM Cloud services that provide free Lite plans for you to implement common patterns based on best practices and proven technologies at no cost.\n\n\n\n\n\n Next steps \n\nBuild your apps! For more information, see the [Getting started tutorial](https://cloud.ibm.com/docs/apps?topic=apps-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_04557-1157-2639", "score": 0.5524638295173645, "text": "\n* Generate a map visualization of COVID-19 cases around the world.\n\n\n\nThis tutorial requires some basic knowledge of the Command Line Interface (CLI) and basic knowledge of Node.js.\n\nBecause the MongoDB instance you require is not free, this tutorial is not cost-free. However, if you deprovision your resources after completion, the cost should not be more than a few dollars.\n\n\n\n What you need \n\nBefore you begin, it's a good idea to have:\n\n\n\n* An [IBM Cloud](https://cloud.ibm.com/login) pay-as-you-go account, [logged in to your account](https://cloud.ibm.com/docs/cli?topic=cli-getting-startedstep4-configure-idt-env).\n* [Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli) - automates your resource provisioning.\n* Access to a Mac or Linux terminal.\n* [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n* [Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) - a free and open source-distributed version control system.\n* [MongoDB Compass](https://www.mongodb.com/try/download/compass) to look at your data (optional).\n* Tableau, to visualize your data. You need to set up a [30-day free trial](https://www.tableau.com/products/trial).\n\n\n\n\n\n\n\n Step-by-step instructions \n\n\n\n Step 1: Obtain an API key to deploy infrastructure to your account \n\nFollow the steps [here](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=uicreate_user_key) to create an API key. This key is used in Step 2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-bi-connector-tutorial-description"}, {"document_id": "ibmcld_04031-3311-5145", "score": 0.5518949031829834, "text": "\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.\n* Selecting a specific Kubernetes zone when deploying a node.\n* Overriding node configuration during or after deployment by using the console or APIs.\n* Adding or removing ordering nodes to an ordering service. The free offering only supports a single node Raft ordering service.\n\n\n\nHow to preview IBM Blockchain Platform for free\n\n\n\n1. Get an [IBM Cloud Account](https://cloud.ibm.com/registration?target=%2Fcatalog%2Fservices%2Fblockchain).\n2. Upgrade your IBM Cloud Account to \"Pay-as-you-go\" by adding in a credit card. You will not be charged.\n3. Launch IBM Blockchain Platform in the [IBM Cloud Catalog](https://cloud.ibm.com/catalog/services/blockchain-platform).\n4. Under Select a pricing plan, ensure that the Standard plan is selected and then click Create.\n5. On the Welcome and pre-requisites panel that opens, click I have a Cluster (Skip to Link a cluster).\n6.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricing"}, {"document_id": "ibmcld_07549-2803-4897", "score": 0.5475583076477051, "text": "\nCopyright \u00a9 2007 Free Software Foundation, Inc. <https://fsf.org/>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.PreambleThe GNU General Public License is a free, copyleft license for software and other kinds of works.The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.To protect your rights, we need to prevent others from denying you these rights, or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.For example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.Developers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it.For the developers' and authors' protection, the GPL clearly explains that there is no warranty for this free software.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": []}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10170-8677-11078", "score": 0.6134514808654785, "text": "\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10170-10609-12793", "score": 0.6119223833084106, "text": "\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_16233-3661-5046", "score": 0.5943764448165894, "text": "\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Building your assistant](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-build-actions-overview)\n* [Publishing and deploying your assistant](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overview)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see IBM Cloud [Prerequisites](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-browsers).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in [Supported languages](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-codes).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_05727-8804-11229", "score": 0.5934193134307861, "text": "\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nIBM Cloud Kubernetes Service provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_transport"}, {"document_id": "ibmcld_16278-7-2318", "score": 0.5853825211524963, "text": "\nComparing actions and dialog \n\nChoose the right type of conversation for your use case.\n\n\n\n Actions benefits \n\nUsing actions is the best choice when you want to approach the assistant with a focus on content. Actions offers the following benefits:\n\n\n\n* The process of creating a conversational flow is easier. People who have expertise with customer care can write the words that your assistant says. With a simplified process anyone can build a conversation. You don't need knowledge about machine learning or programming.\n* Actions provide better visibility into the customer's interaction and satisfaction with the assistant. Because each task is discrete and has a clear beginning and ending, you can track user progress through a task and identify snags.\n* The conversation designer doesn't need to manage data collected during the conversation. By default, your assistant collects and stores information for the duration of the current action. You don't need to take extra steps to delete saved data or reset the conversation. But if you want, you can store certain types of information, such as the customer's name, for the duration of a conversation.\n* Many people can work at the same time in separate, self-contained actions. The order of actions within a conversation doesn't matter. Only the order of steps within an action matters. And the action author can use drag and drop to reorganize steps in the action for optimal flow.\n\n\n\n\n\n\n\n Dialog benefits \n\nA dialog-based conversation is the best choice when you want greater control over the logic of the flow. The dialog editor exposes more of the underlying artifacts (such as intents and entities) used to build the AI models. The dialog flow uses an if-then-else style structure that might be familiar to developers, but not to content designers or customer-care experts.\n\n\n\n\n\n How actions are different from dialog \n\nIf you are already familiar with dialog-based conversations, learn more about how actions compares.\n\n\n\nConversational flow skill feature support\nThis table has row and column headers. The row headers identify features. The column headers identify the different skill types. To understand which features are supported by a skill, go to the row that describes the feature, and find the columns for the skill you are interested in.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-comparing-actions-dialog"}, {"document_id": "ibmcld_12128-4366-6437", "score": 0.5747554302215576, "text": "\nBenefits of using Schematics \n\nYou do not need to install the open source projects on your machine or learn their API and command-line. You need to simply point Schematics to your IaC code repository and let Schematics run the specified tasks.\n\n\n\nSchematics benefits\n\n Benefits Description \n\n The open source projects used by Schematics Terraform, Ansible, Helm provisioning engine, and execution platform are tested, maintained, and monitored by IBM. IBM automatically applies the latest security standards and patches to Schematics to ensure reliability and availability of the service. You do not need to manually apply updates to the Schematics platform. \n All versions are tested by IBM. As new versions of Terraform and Ansible become available, IBM begins with hardening and testing these versions, so that they can be supported in the Schematics platform. For more information, see [when are new Terraform and Ansible versions added to Schematics?](https://cloud.ibm.com/docs/schematics?topic=schematics-actions-faqnew-versions) \n Schematics is fully integrated with IAM You can use service access roles to control who can access and collaborate on your workspaces and actions, or roll out changes. You can invite IBM Cloud users to your account and leverage IAM access groups to streamline the access assignment process in your organization. As a multi-tenant solution, Schematics creates all resources in your personal account. Resources are not shared or reused by other IBM Cloud tenants. Because Schematics is built on Kubernetes, IAM service access roles are mapped to role-based access controls (RBAC) in Kubernetes to enforce resource isolation within your account. \n Full IBM support for the open-source tools and plug-ins related to IBM Cloud Schematics is fully integrated into the IBM Cloud support system. If you run into an issue by using the IBM Cloud Provider Plug-in for Terraform or the Ansible modules for IBM Cloud, you can [open an IBM Cloud support case](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatargetting-support).", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics"}, {"document_id": "ibmcld_07578-565403-567284", "score": 0.5745658874511719, "text": "\nFor more information, see the [End of Service announcement](https://cloud.ibm.com/docs/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https://www.hover.com/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https://opensrs.com/wp-content/uploads/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https://opensrs.com/resources/documentation/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-565357-567238", "score": 0.5745658874511719, "text": "\nFor more information, see the [End of Service announcement](https://cloud.ibm.com/docs/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https://www.hover.com/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https://opensrs.com/wp-content/uploads/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https://opensrs.com/resources/documentation/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_11518-1444-3611", "score": 0.5738078951835632, "text": "\nAfter identifying the appropriate primitive for your program, you can use Qiskit to prepare inputs, such as circuits, observables (for Estimator), and customizable options to optimize your job. For more information, see the [Primitives](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/primitives.html) topic.\n\n\n\n Benefits of using sessions \n\nThere are several benefits to using sessions:\n\n\n\n* Jobs that belong to a single algorithm run are run together without interruptions, increasing efficiency if your program submits multiple sequential jobs.\n\n\n\n* The queuing time does not decrease for the first job submitted within a session. Therefore, a session does not provide any benefits if you only need to run a single job.\n* Since data from the first session job is cached and used by subsequent jobs, if the first job is cancelled, subsequent session jobs will all fail.\n\n\n\n* When using sessions, the uncertainty around queuing time is significantly reduced. This allows better estimation of a workload's total runtime and better resource management.\n* In a device characterization context, being able to run experiments closely together helps prevent device drifts and provide more accurate results.\n* As long as the session is active, you can submit different jobs, inspect job results, and re-submit new jobs without opening a new session.\n* You maintain the flexibility to deploy your programs either remotely (cloud / on-premise) or locally (your laptop).\n\n\n\n\n\n\n\n The mechanics of sessions (queuing) \n\nFor each backend, the first job in the session waits its turn in the queue normally, but while the session is active, subsequent jobs within the same session take priority over any other queued jobs. If no jobs that are part of the active session are ready, the session is deactivated (paused), and the next job from the regular fair-share queue is run. See [Interactive timeout value](https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-sessionsttl) for more information.\n\nA quantum processor still executes one job at a time. Therefore, jobs that belong to a session still need to wait for their turn if one is already running.", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-sessions"}, {"document_id": "ibmcld_01447-1492-3786", "score": 0.5677506923675537, "text": "\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03185-6701-8694", "score": 0.7228567600250244, "text": "\n[A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build"}, {"document_id": "ibmcld_02873-5855-7814", "score": 0.7119747400283813, "text": "\nSee [Conditional responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03270-3352-5135", "score": 0.6873091459274292, "text": "\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-support"}, {"document_id": "ibmcld_03113-4-2033", "score": 0.6871038675308228, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the /dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the /dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03188-1732-3801", "score": 0.6864369511604309, "text": "\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https://www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https://www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations"}, {"document_id": "ibmcld_03114-9660-10499", "score": 0.6842008829116821, "text": "\n\"nodes_visited_details\":\n{\n\"dialog_node\": \"node_1_1547675028546\",\n\"title\": \"order drink\",\n\"user_label\": \"I'd like to order a drink.\",\n\"conditions\": \"order_drink\"\n}\n]\n},\n\"source_dialog_node\": \"root\"\n},\n{\n\"label\": \"I need a drink refill.\",\n\"value\": {\n\"intents\":\n{\n\"intent\": \"refill_drink\",\n\"confidence\": 0.2529746770858765\n}\n],\n\"entities\": ],\n\"input\": {\n\"suggestion_id\": \"6583b547-53ff-4e7b-97c6-4d062270abcd\",\n\"text\": \"I need a drink refill\"\n}\n},\n\"output\": {\n\"text\":\n\"I'll get you a refill.\"\n],\n\"generic\":\n{\n\"response_type\": \"text\",\n\"text\": \"I'll get you a refill.\"\n}\n],\n\"nodes_visited_details\":\n{\n\"dialog_node\": \"node_2_1547675097178\",\n\"title\": \"refill drink\",\n\"user_label\": \"I need a drink refill.\",\n\"conditions\": \"refill_drink\"\n}\n]\n},\n\"source_dialog_node\": \"root\"\n}\n]\n}\n],\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_02882-7-2075", "score": 0.6766592264175415, "text": "\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_02952-3289-5462", "score": 0.676464855670929, "text": "\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_02873-3029-4764", "score": 0.6742305755615234, "text": "\n[Shows that the first node in the dialog asks which type of cupcake the user wants, gluten-free or regular, and has two child nodes that provide a different response depending on the user's answer.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node1-children.png)\n\n\n\n\n\n Dialog flow \n\nThe dialog that you create is processed by your assistant from the first node in the tree to the last.\n\n![Arrow points down next to 3 nodes to show that dialog flows from the first node to the last](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node-flow-down.png)\n\nAs it travels down the tree, if your assistant finds a condition that is met, it triggers that node. It then moves along the triggered node to check the user input against any child node conditions. As it checks the child nodes it moves again from the first child node to the last.\n\nYour assistant continues to work its way through the dialog tree from first to last node, along each triggered node, then from first to last child node, and along each triggered child node until it reaches the last node in the branch it is following.\n\n![Shows arrow 1 pointing from the first root node to the last, arrow 2 pointing from along the length of a triggered node, and arrow 3 pointing from the first to the last child nodes of the triggered node.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/node-flow.png)\n\nWhen you start to build the dialog, you must determine the branches to include, and where to place them. The order of the branches is important because nodes are evaluated from first to last.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03196-24078-26023", "score": 0.6652221083641052, "text": "\n* [Search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill)![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png)\n\nThis response type is only visible to users of paid plans.\n* [Text](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text)\n\n\n\n2. To add another response type to the current response, click Add response type.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. This means that if you define three conditioned responses for a dialog node, each conditioned response can have no more than 5 response types added to it.\n\nYou cannot add more than one Connect to human agent or more than one Search skill response type to a single dialog node.\n\nDo not add more than one option response type to a single dialog node because both lists are displayed at once, but the customer can choose an option from only one of them.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n Adding a Connect to human agent response type \n\nIf your client application is able to transfer a conversation to a person, such as a customer support agent, then you can add a Connect to human agent response type to initiate the transfer.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03010-7-2157", "score": 0.7665954828262329, "text": "\nDefining intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03363-7585-9120", "score": 0.6938732266426086, "text": "\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Top intents and top entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. You can select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03403-1720-3144", "score": 0.6919212341308594, "text": "\nStep 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03334-5529-7605", "score": 0.6785238981246948, "text": "\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n How entity references are treated \n\nWhen you include an entity mention in a user example, the machine learning model uses the information in different ways in these scenarios:\n\n\n\n* [Referencing entity values and synonyms in intent examples](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-related-entities)\n* [Annotated mentions](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https://cloud.ibm.com/docs/assistant?topic=assistant-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03334-1458-3293", "score": 0.6761394143104553, "text": "\nThe user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) If you already have chat transcripts from a call center or customer inquiries that you collected from an online application, put that data to work for you. Share the real customer utterances with Watson and let Watson recommend the best intents and intent user examples for your needs. See [Get help defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-recommendations) for more details.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nKeep the name as short as possible. It's easier to read in the \"Try it out\" pane and conversation logs if you keep the intent name short and concise.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03145-1287-2166", "score": 0.6701847314834595, "text": "\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-catalog"}, {"document_id": "ibmcld_03010-4285-6329", "score": 0.6696455478668213, "text": "\n* [Annotated mentions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n Important \n\n\n\n* Intent example data should be representative and typical of data that your users provide. Examples can be collected from actual user data, or from people who are experts in your specific field. The representative and accurate nature of the data is important.\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_02970-18612-20135", "score": 0.6694248914718628, "text": "\nFor more information about language support, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\nUsing an intent's user examples to define contextual entities does not affect the classification of that intent. However, entity mentions that you label are also added to that entity as synonyms. And intent classification does use synonym mentions in intent user examples to establish a weak reference between an intent and an entity.\n\n\n\n1. From your dialog skill, click the Intents tab.\n2. Click an intent to open it.\n\nFor this example, the intent buy_supplies defines the order function for an online retailer.\n\n![Select the #buy_supplies intent](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oe-intent.png)\n3. Click Annotate entities, and then review the intent examples for potential entity mentions.\n\n![Shows the Annotate entities toggle](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oe-annotate.png)\n4. Click any word, words, or punctuation that is part of a single entity mention from the intent examples.\n\nIn this example, mobile phones is the entity mention.\n\n![Review intent examples](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oe-click-tokens.png)\n\nA Search box opens that you can use to search for the entity that the highlighted word or phrase is a mention of.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities"}, {"document_id": "ibmcld_03334-19597-21305", "score": 0.6594706177711487, "text": "\nIt provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_16360-1493-3354", "score": 0.6590515375137329, "text": "\nAll phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download). The format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nwhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\nWhere is your nearest location?,find_location\nDo you have a store in Raleigh?,find_location\n2. From the main actions page, click the Upload icon ![Upload icon](https://cloud.ibm.com/docs-content/v1/content/icons/upload.svg).\n3. Select the intents file that you downloaded.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\nThe intents in column 2 are created as new actions, and the phrases in column 1 are created as example phrases for the corresponding action. For example, if you upload the example from step 1, two new actions are created for the weather_conditions and find_location intents. The underscores (_) in the intent names are replaced with spaces, for example, the weather_conditions intent becomes the weather conditions action.\n\nIn this example, the weather_conditions action will have three example phrases: Tell me the current weather conditions., Is it raining?, and What's the temperature?. The find_location action will have two example phrases: Where is your nearest location? and Do you have a store in Raleigh?.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-upload-download-actions"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12297-56490-57784", "score": 0.5943528413772583, "text": "\n* [Defining a JSON config file](https://cloud.ibm.com/docs/schematics?topic=schematics-create-blueprint-filebp-create-configJSON)\n\n\n\n[Using environment variables with blueprints](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-env-varsbp-env-vars)\n\n\n\n* [Blueprints usage](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-env-varsusage)\n\n\n\n\n\n\n\n Managing Workspaces \n\n\n\n Creating workspace \n\n[Creating workspaces and importing your Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkssch-create-wks)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksprerequisites-create)\n* [Creating a workspace using the UI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-ui)\n\n\n\n* [Importing your Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksimport-template)\n* [Using Terraform templates in IBM Cloud](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksrun-template)\n\n\n\n* [Creating a workspace using the CLI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-cli)\n* [Creating a workspace using the API](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-api)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_11667-4046-5741", "score": 0.5918995141983032, "text": "\nIf you're manually creating the initial subnet, versus creating it when you created your VPC, the region (location) that you select is used as the region of the VPC. All additional resources that you in this VPC are created in the selected region.\n\nIf you created a subnet when you created your VPC, more subnets must be created in the same region. You can create multiple subnets within VPC zones.\n5. Click Create subnet.\n\n\n\n\n\n\n\n\n\n Provisioning your Intel virtual server \n\nBefore you can create a virtual server, you must create the VPC and you must create an SSH key that you add to the server instance during its creation - see more details on [SSH keys with virtual servers](https://cloud.ibm.com/docs/vpc?topic=vpc-ssh-keys).\n\nUse the following steps to order your virtual server and necessary components. For more information about creating a virtual server, see [Creating virtual server instances by using the IBM Cloud console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-virtual-servers).\n\n\n\n1. Log in to the [IBM Cloud console](https://cloud.ibm.com) with your unique credentials.\n2. Click Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) > VPC Infrastructure > Virtual server instances.\n3. Click Create.\n4. Enter a unique Name for the virtual server, which becomes the hostname. SAP hostnames must consist of a maximum of 13 alpha-numeric characters. For more information about SAP hostnames, see [SAP Notes 611361](https://launchpad.support.sap.com//notes/611361) and [129997](https://launchpad.support.sap.com//notes/129997).\n5. Choose a Resource group.\n\nThe resource group can't be changed after the virtual server is created.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-vs-set-up-infrastructure"}, {"document_id": "ibmcld_10727-7-1794", "score": 0.5873830318450928, "text": "\nCreating actions \n\nCreate an IBM Cloud\u00ae Functions action, which is a top-level function that returns a JSON object. You can combine actions into a package to simplify the management of your actions.\n\nBefore you begin\n\nTo create an action, your source code must meet certain requirements. For example, if you want to create an action from code that is contained in multiple files, package your code as a single .zip file before you create the action.\n\nSee [Preparing apps for actions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-prep) for details about the requirements for packaging code for each runtime.\n\n\n\n Creating actions from the CLI \n\n\n\n1. Create an action by running the [ibmcloud fn action create](https://cloud.ibm.com/docs/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_action_create) command.\n\nibmcloud fn action create <action_name> <file> --kind <runtime>\n\nExample\n\nibmcloud fn action create hello hello.js --kind nodejs:10\n\nExample output\n\nok: created action hello\n2. Verify that the action is in your actions list.\n\nibmcloud fn action list\n\nExample output\n\nactions\nhello private\n\n\n\nTips:\n\n\n\n* To save on cost, you can set limits.\n\n\n\n* To set a limit for memory usage, include --memory <value> with your create command, where the value is in megabytes.\n* To set a timeout, include --timeout <value> with your create command, where the value is in milliseconds.\n\n\n\n* If you packaged your code as a Docker image, include --docker <docker_hub_username>/<docker_hub_image>:<tag> with your create command instead of the local path to your app and the --kind flag. Manage your images well by not using the latest tag whenever possible. When the latest tag is used, the image with that tag is used, which might not always be the most recently created image.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions"}, {"document_id": "ibmcld_16471-134960-136979", "score": 0.5869235992431641, "text": "\ncreate external table create table \n\n <br><br> * Defines a placeholder for a table whose content is supplied at initialization time.<br><br><br> <br><br> * Requires that the content of the table is available at compile time.<br> * Serialized in the compiled representation (.tam) of a module.<br><br><br> \n\n\n\n\n\n\n\n Examples \n\nExample 1: Creating an external table that is populated at load time\n\nThe external table, PersonNegativeClues, expects to be populated at load-time because of the flag, allow_empty false.\n\nmodule PersonModuleFrench;\n\ncreate external table PersonNegativeClues (name Text)\nallow_empty false;\n\nexport table PersonNegativeClues;\n\nExample 2: Creating a dictionary with an external table\n\nDictionaries can also be created from external tables, similar to being created from inline tables that are declared with the create table statement.\n\ncreate external table Product (nickName Text, formalName Text)\nallow_empty false;\n\n/\n* Dictionary of product nicknames, from the nickName field\n* of the customizable external table Product.\n/\ncreate dictionary ProductDict\nfrom table Product\nwith entries from nickName;\n\n\n\n\n\n Documenting the create external table statement with AQL Doc \n\nThe AQL Doc comment for a create external table statement contains the following information:\n\n\n\n* General description about the table.\n* @field for every column name in the schema of this table.\n\n\n\n/ Create a table that maps company names to locations of corporate headquarters.\n* @field name name of the company\n* @field location location of corporate headquarters\n/\ncreate external table Company2Location\n(name Text, location Text)\nallow_empty false;\n\n\n\n\n\n\n\n The create external view statement \n\nThe create external view statement in AQL allows specification of more metadata about a document as a new view, in addition to the predefined Document view that holds the textual and label content.\n\n\n\n Syntax \n\ncreate external view <view_name> (\n<colname> <type> [, <colname> <type>]\n)\nexternal_name '<view_external_name>';", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_12297-57537-58864", "score": 0.5840907096862793, "text": "\n* [Creating a workspace using the CLI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-cli)\n* [Creating a workspace using the API](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-api)\n* [Creating a workspace using a Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-terraform)\n* [Next steps](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkssch-create-wks-nextsteps)\n\n\n\n[Creating Terraform templates](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configcreate-tf-config)\n\n\n\n* [Configuring the provider block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-provider)\n* [Adding IBM Cloud resources to the resource block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-resources)\n\n\n\n* [Referencing resources in other resource blocks](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configreference-resource-info)\n\n\n\n* [Managing resources in other account](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configmanage-resource-account)\n* [Using variable blocks to customize resources](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-variables)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_05444-86766-88182", "score": 0.5789797902107239, "text": "\n[Creating a job from images in a public registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job)\n\n\n\n* [Creating a job with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job-ui)\n* [Creating a job with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job-cli)\n* [Next steps](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobnextsteps-jobcreatepub)\n\n\n\n[Creating a job from images in IBM Cloud Container Registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage)\n\n\n\n* [Creating a job that references an image in Container Registry with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-console)\n* [Creating a job with an image in Container Registry with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-cli)\n* [Next steps](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagenextsteps-jobcreatecr)\n\n\n\n[Creating a job from images in a private registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-privatecreate-job-private)\n\n\n\n* [Creating a job that references an image in a private registry with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-privatecreate-job-private-console)", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-sitemap"}, {"document_id": "ibmcld_10534-124536-125809", "score": 0.5784344673156738, "text": "\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n[Creating Satellite clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatellite-clusters)\n\n\n\n* [Prerequisites](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-prereqs)\n* [Creating Red Hat OpenShift clusters on Satellite from the console](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-console)\n* [Creating Red Hat OpenShift clusters on Satellite from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-cli)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_03106-3091-5136", "score": 0.5773491859436035, "text": "\ncatalog_integration.create creates a custom extension \n catalog_integration.delete deletes a custom extension \n catalog_integration.update updates a custom extension \n counterexample.create marks test user input in the \"Try it out\" pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant \n counterexample.delete deletes a counterexample \n counterexample.update edits a counterexample \n data.delete deletes multiple training data items, such as multiple entities or intents \n data.update does a bulk action, such as importing a CSV file of intents or entities to the skill \n data_type.create creates a saved response \n data_type.delete deletes a saved response \n data_type.update updates a saved response \n entity.create creates an entity \n entity.delete deletes an entity \n entity.update edits an entity \n environment.create adds an environment \n environment.delete deletes an environment \n environment.updates updates an environment \n example.create adds a user input example to an intent \n example.delete deletes a user example from an intent \n example.update edits a user example that is associated with an intent \n integration_defintion.create creates an integration \n integration_defintion.delete deletes an integration \n integration_defintion.update updates an integration \n intent.create creates an intent \n intent.delete deletes an intent \n intent.update edits an intent \n log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page \n node.create creates a dialog node \n node.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-auditing"}, {"document_id": "ibmcld_16248-2956-5001", "score": 0.5773491859436035, "text": "\ncatalog_integration.create creates a custom extension \n catalog_integration.delete deletes a custom extension \n catalog_integration.update updates a custom extension \n counterexample.create marks test user input in the \"Try it out\" pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant \n counterexample.delete deletes a counterexample \n counterexample.update edits a counterexample \n data.delete deletes multiple training data items, such as multiple entities or intents \n data.update does a bulk action, such as importing a CSV file of intents or entities to the skill \n data_type.create creates a saved response \n data_type.delete deletes a saved response \n data_type.update updates a saved response \n entity.create creates an entity \n entity.delete deletes an entity \n entity.update edits an entity \n environment.create adds an environment \n environment.delete deletes an environment \n environment.updates updates an environment \n example.create adds a user input example to an intent \n example.delete deletes a user example from an intent \n example.update edits a user example that is associated with an intent \n integration_defintion.create creates an integration \n integration_defintion.delete deletes an integration \n integration_defintion.update updates an integration \n intent.create creates an intent \n intent.delete deletes an intent \n intent.update edits an intent \n log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page \n node.create creates a dialog node \n node.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-auditing"}, {"document_id": "ibmcld_15500-1707-3590", "score": 0.5735398530960083, "text": "\n* The volume must be in the region where you want to create the custom image.\n* The volume must be a primary boot volume with 100 GB capacity. Data volumes are not supported.\n* The volume must be attached to an instance. Unattached boot volumes are not supported.\n* The instance must be in an available state.\n* The available, running instance must be stopped before you create the custom image. Creating an image from a running instance is not allowed.\n\n\n\n\n\n\n\n\n\n Options for creating an image from a volume \n\nYou can create a custom image from a boot volume in several ways.\n\n\n\n* In the [UI](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-ui), you can create a custom image from any of the following places.\n\n\n\n* The Custom images for VPC page,\n* The list of instances on the Virtual server instances for VPC page,\n* The Instance details page,\n* The list of volumes on Block storage volumes for VPC page.\n* The Volume details page.\n\n\n\n* In the [API](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-api), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. With the regional API, you create an image by making a POST /images call and passing the boot volume ID.\n* From the [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-cli), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. Issue the ibmcloud is image-create command and specify the boot volume's ID.\n\n\n\n\n\n\n\n Image from volume encryption \n\nWhen you create an image from a volume, you have the following encryption choices.\n\n\n\n* If you want to create an instance and boot volume with default IBM-managed encryption, then the image from that boot volume inherits the IBM-managed encryption.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03049-2703-4536", "score": 0.6576868295669556, "text": "\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03373-4-1923", "score": 0.6522977352142334, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n* Search skill!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_03369-36856-39124", "score": 0.6504884958267212, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-163116-165172", "score": 0.6459758281707764, "text": "\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03329-1102-2607", "score": 0.6333798170089722, "text": "\n[Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_03049-7-1790", "score": 0.629564642906189, "text": "\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03381-2858-4802", "score": 0.6235243082046509, "text": "\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03369-74273-76338", "score": 0.6084108352661133, "text": "\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https://cloud.ibm.com/docs/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03381-4-1869", "score": 0.604698896408081, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=createworkspace).\n\nClick Upload.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_16364-74209-76251", "score": 0.6012438535690308, "text": "\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021 \n\nActions skill improvement\n: Actions now include a new choice, Go to a subaction, for what to do next in a step. This feature lets you can call one action from another action, to switch the conversation flow to another action to perform a certain task. If you have a portion of an action that can be applied across multiple use cases you can build it once and call to it from each action. This new option is available in the And then section of each step. For more information, see [Go to a subaction](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-step-what-nextgo-to-another-action).\n\n\n\n\n\n 21 April 2021 \n\nPreview button for testing your assistant\n: For testing your assistant, the new Preview button replaces the previous Preview tile in Integrations.\n\nNew checklist with steps to go live\n: Each assistant includes a checklist that you can use to ensure you're ready to go live.\n\nActions skill improvement\n: Actions now include currency and percentage response types.\n\nLearn what's new\n: The What's new choice on the help menu opens a list of highlighting recent features.\n\n\n\n\n\n 14 April 2021 \n\nActions skill improvement", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02953-12940-14393", "score": 0.7591158747673035, "text": "\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_03273-13172-14845", "score": 0.7535374760627747, "text": "\nPlan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID \n\nYou can search for a dialog node by its node ID. Enter the full node ID into the search field. You might want to find the dialog node that is associated with a known node ID for any of the following reasons:\n\n\n\n* You are reviewing logs, and the log refers to a section of the dialog by its node ID.\n* You want to map the node IDs listed in the nodes_visited property of the API message output to nodes that you can see in your dialog tree.\n* A dialog runtime error message informs you about a syntax error, and uses a node ID to identify the node you need to fix.\n\n\n\nAnother way to discover a node based on its node ID is by following these steps:\n\n\n\n1. From the Dialog page, select any node in your dialog tree.\n2. Close the edit view if it is open for the current node.\n3. In your web browser's location field, a URL should display that has syntax similar to the following:\n\nhttps://{location}.assistant.watson.cloud.ibm.com/{location}/{instance-id}/skills/{skill-id}/build/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}, {"document_id": "ibmcld_02882-32106-34249", "score": 0.7529745697975159, "text": "\nFor example, the response might ask the user a yes or no question. The dialog will not progress until the user provides more input.\n* Skip user input: Use this option when you want to bypass waiting for user input and go directly to the first child node of the current node instead.\n\nThe current node must have at least one child node for this option to be available.\n* Jump to another dialog node: Use this option when you want the conversation to go directly to an entirely different dialog node. You can use a Jump to action to route the flow to a common dialog node from multiple locations in the tree, for example.\n\nThe target node that you want to jump to must exist before you can configure the jump to action to use it.\n\n\n\n\n\n Configuring the Jump to action \n\nIf you choose to jump to another node, specify when the target node is processed by choosing one of the following options:\n\n\n\n* Condition: If the statement targets the condition section of the selected dialog node, your assistant checks first whether the condition of the targeted node evaluates to true.\n\n\n\n* If the condition evaluates to true, the system processes the target node immediately.\n* If the condition does not evaluate to true, the system moves to the next sibling node of the target node to evaluate its condition, and repeats this process until it finds a dialog node with a condition that evaluates to true.\n* If the system processes all the siblings and none of the conditions evaluate to true, the basic fallback strategy is used, and the dialog evaluates the nodes at the base level of the dialog tree.\n\n\n\nTargeting the condition is useful for chaining the conditions of dialog nodes. For example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated before the current node in the dialog tree. Otherwise, you can create an infinite loop.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_03196-53970-56256", "score": 0.7493953108787537, "text": "\n* Jump to another dialog node: Use this option when you want the conversation to go directly to an entirely different dialog node. You can use a Jump to action to route the flow to a common dialog node from multiple locations in the tree, for example.\n\nThe target node that you want to jump to must exist before you can configure the jump to action to use it.\n\n\n\n\n\n Configuring the Jump to action \n\nIf you choose to jump to another node, specify when the target node is processed by choosing one of the following options:\n\n\n\n* Condition: If the statement targets the condition section of the selected dialog node, your assistant checks first whether the condition of the targeted node evaluates to true.\n\n\n\n* If the condition evaluates to true, the system processes the target node immediately.\n* If the condition does not evaluate to true, the system moves to the next sibling node of the target node to evaluate its condition, and repeats this process until it finds a dialog node with a condition that evaluates to true.\n* If the system processes all the siblings and none of the conditions evaluate to true, the basic fallback strategy is used, and the dialog evaluates the nodes at the base level of the dialog tree.\n\n\n\nTargeting the condition is useful for chaining the conditions of dialog nodes. For example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated above the current node in the dialog tree. Otherwise, you can create an infinite loop. If your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_02873-5855-7814", "score": 0.7483304142951965, "text": "\nSee [Conditional responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-builddialog-overview-multiple) for more information.\n* By configuring digression settings for dialog nodes. Digressions can also impact how users move through the nodes at run time. If you enable digressions away from most nodes and configure returns, users can jump from one node to another and back again more easily. See [Digressions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions) for more information.\n\n\n\n\n\n\n\n Sample dialog \n\nThis diagram shows a mockup of a dialog tree that is built with the graphical user interface dialog editor.\n\n![A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build"}, {"document_id": "ibmcld_03113-6206-7586", "score": 0.7340251207351685, "text": "\n[Example dialog](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_1.png)\n\nWe can create a new node by making a POST request to /dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_3.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_02900-2946-5130", "score": 0.7337102890014648, "text": "\nHowever, the conversation cannot digress away from a node under the following circumstances:\n\n\n\n* If any of the child nodes of the current node contain the anything_else or true condition\n\n\n\nThese conditions are special in that they always evaluate to true. Because of their known behavior, they are often used in dialogs to force a parent node to evaluate a specific child node in succession. To prevent breaking existing dialog flow logic, digression are not allowed in this case. Before you can enable digressions away from such a node, you must change the child node's condition to something else.\n\n\n\n* If the node is configured to jump to another node or skip user input after it is processed\n\n\n\nThe final step section of a node specifies what should happen after the node is processed. When the dialog is configured to jump directly to another node, it is often to ensure that a specific sequence is followed. And when the node is configured to skip user input, it is equivalent to forcing the dialog to process the first child node after the current node in succession. To prevent breaking existing dialog flow logic, digressions are not allowed in either of these cases. Before you can enable digressions away from this node, you must change what is specified in the final step section.\n\n\n\n\n\n\n\n Customizing digressions \n\nYou do not define the start and end of a digression. The user is entirely in control of the digression flow at run time. You only specify how each node should or should not participate in a user-led digression. For each node, you configure whether:\n\n\n\n* a digression can start from and leave the node\n* a digression that starts elsewhere can target and enter the node\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime"}, {"document_id": "ibmcld_03113-4-2033", "score": 0.7332217693328857, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the /dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the /dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03269-3433-5472", "score": 0.7189269065856934, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog-start.png)\n\nThis design results in a dialog that works like this:\n\n\n\n* Whatever the integration type, the conversation_start node is processed, which means any context variables that you define in it are initialized.\n* In integrations where the assistant starts the dialog flow, the Welcome node is triggered and its text response is displayed.\n* In integrations where the user starts the dialog flow, the user's first input is evaluated and then processed by the node that can provide the best response.\n\n\n\n\n\n\n\n\n\n Ending the conversation gracefully \n\nThe Anything else node is designed to recognize the anything_else special condition, which understands when user input does not match any of the intents that are used as conditions in a dialog's nodes.\n\nDon't delete the Anything else node.\n\nYou might not recognize its value at first, but it serves some important functions. If you did delete it, don't panic. You can add it back. Just add a dialog node to the end of your dialog tree, and add the anything_else special condition to its If assistant recognizes field.\n\nThe Anything else node provides the following benefits:\n\n\n\n* It prevents your assistant from ever going silent and failing to respond at all to your customers. The Anything else node is what enables your assistant to (if nothing else) say, I'm sorry, I didn't understand. or I can't help you with that.\n* The skill's analytics feature uses this node to learn about the topics that your dialog can't address. The coverage metric looks for occurrences of nodes with the anything_else condition being processed in the user conversation logs. It uses this information to determine the frequency with which your dialog is able to match user requests to intents that can address them. The node is registered by the metric if it conditions on anything_else alone or when it's used in combination with another condition, such as anything_else && positive_feedback.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-start"}, {"document_id": "ibmcld_02882-33778-35796", "score": 0.7182802557945251, "text": "\nFor example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated before the current node in the dialog tree. Otherwise, you can create an infinite loop. If your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately. That is, the system does not evaluate the condition of the selected dialog node; it processes the response of the selected dialog node immediately.\n\nTargeting the response is useful for chaining several dialog nodes together. The response is processed as if the condition of this dialog node is true. If the selected dialog node has another Jump to action, that action is run immediately, too.\n* Wait for user input: Waits for new input from the user, and then begins to process it from the node that you jump to. This option is useful if the source node asks a question, for example, and you want to jump to a separate node to process the user's answer to the question.\n\n\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Be sure to test your dialog as you build it. For more information, see [Testing the dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks).\n* For more information about ways to address common use cases, see [Dialog building tips](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16527-11091-13443", "score": 0.6735600233078003, "text": "\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"}, {"document_id": "ibmcld_16454-9876-11996", "score": 0.6473743915557861, "text": "\nFor example, a PERSON entity can be an employee of an ORGANIZATION entity or a geo-political entity (GPE), such as MaryemployedByIBM, but organizations and geo-political entities cannot be employed by a person. When a human annotator clicks an entity in the ground truth editor , the list of available relation types is controlled by what is defined in the type system.\n\nDo not define relation attributes. They are not used by the machine learning model. The model uses only the relation type and order, and ignores the relation attributes.\n5. Use the Edit and Delete icons to modify entity types and their associated relation types, or to delete an entity type or relation type from the type system.\n\nIf you delete an entity that is used in a relation type definition, the relation type definition is also deleted.\n\n\n\n\n\n\n\nRelated tasks:\n\n[Modifying a type system without losing human annotations](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n Type system creation guidelines \n\nThe purpose of any type system in Knowledge Studio is to define how spans of text can be annotated. If you choose to create a type system from scratch, follow these guidelines.\n\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}, {"document_id": "ibmcld_16454-11402-13678", "score": 0.6266767978668213, "text": "\nFor example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"}, {"document_id": "ibmcld_07411-14782-16101", "score": 0.6221736669540405, "text": "\nName _sip._tcp.video.example.com\nType SRV\nCreated On 2020-04-10 09:15:56.940189115 +0000 UTC\nModified On 2020-04-10 09:15:56.940189115 +0000 UTC\nTTL 900\nData\nport 953\npriority 10\ntarget media.example.com\nweight 10\n\n\n\n\n\n Creating type 'TXT' resource record \n\nUse the ibmcloud dns resource-record-create command with --type TXT option to create a type TXT resource record. --name and --text are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type TXT --name text --text \"This is a text record.\"\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID TXT:92648285-c7e5-49ef-bf8b-a5be91d5c5d3\nName text.example.com\nType TXT\nCreated On 2020-04-10 09:16:50.169135062 +0000 UTC\nModified On 2020-04-10 09:16:50.169135062 +0000 UTC\nTTL 900\nData\ntext This is a text record.\n\n\n\n\n\n Creating type 'MX' resource record \n\nUse ibmcloud dns resource-record-create command with --type MX option to create a type MX resource record. --name and --exchange are the mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type MX --name mail --preference 10 --exchange exchange.example.com\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK", "title": "", "source": "https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-managing-dns-records"}, {"document_id": "ibmcld_05590-15026-16874", "score": 0.6022577881813049, "text": "\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=allow-client-ip\n\n\n\n\n\n Creating rules from the console \n\n\n\n1. [Review the available contexts](https://cloud.ibm.com/docs/containers?topic=containers-cbrcbr-overview) and determine the rules you want to create.\n2. Follow the steps to [create context-based restrictions in the console](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-create).\n\n\n\n\n\n\n\n\n\n Limitations \n\n\n\n* After you create a rule, it might take up to 10 minutes for the rule to take effect.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference network zones that contain IPv6 addresses. The APIs included in the cluster type don't support IPv6.\n* If you add IBM Cloud Kubernetes Service resources to private-only network zones, the APIs for getting and listing clusters are still accessible over the public network.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference other services like IBM Cloud Object Storage or Key Protect\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API type do not support Report-only enforcement for the cluster API type.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types are limited to no more than 20 IPs/subnets for private rules, and 200 IPs/subnets for public rules. These limits are expected to increase after the backend scalability of our implementation of Red Hat OpenShift on IBM Cloud CBR is updated.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr"}, {"document_id": "ibmcld_05593-15104-16965", "score": 0.6005288362503052, "text": "\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=allow-client-ip\n\n\n\n\n\n Creating rules from the console \n\n\n\n1. [Review the available contexts](https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=uicbr-overview) and determine the rules you want to create.\n2. Follow the steps to [create context-based restrictions in the console](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-create).\n\n\n\n\n\n\n\n\n\n Limitations \n\n\n\n* After you create a rule, it might take up to 10 minutes for the rule to take effect.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference network zones that contain IPv6 addresses. The APIs included in the cluster type don't support IPv6.\n* If you add IBM Cloud Kubernetes Service resources to private-only network zones, the APIs for getting and listing clusters are still accessible over the public network.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference other services like IBM Cloud Object Storage or Key Protect\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API type do not support Report-only enforcement for the cluster API type.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types are limited to no more than 20 IPs/subnets for private rules, and 200 IPs/subnets for public rules. These limits are expected to increase after the backend scalability of our implementation of Red Hat OpenShift on IBM Cloud CBR is updated.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=ui"}, {"document_id": "ibmcld_05592-15110-16972", "score": 0.5999894142150879, "text": "\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=allow-client-ip\n\n\n\n\n\n Creating rules from the console \n\n\n\n1. [Review the available contexts](https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=clicbr-overview) and determine the rules you want to create.\n2. Follow the steps to [create context-based restrictions in the console](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-create).\n\n\n\n\n\n\n\n\n\n Limitations \n\n\n\n* After you create a rule, it might take up to 10 minutes for the rule to take effect.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference network zones that contain IPv6 addresses. The APIs included in the cluster type don't support IPv6.\n* If you add IBM Cloud Kubernetes Service resources to private-only network zones, the APIs for getting and listing clusters are still accessible over the public network.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types must not reference other services like IBM Cloud Object Storage or Key Protect\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API type do not support Report-only enforcement for the cluster API type.\n* IBM Cloud Kubernetes Service CBR rules that apply to all API types or the cluster API types are limited to no more than 20 IPs/subnets for private rules, and 200 IPs/subnets for public rules. These limits are expected to increase after the backend scalability of our implementation of Red Hat OpenShift on IBM Cloud CBR is updated.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=cli"}, {"document_id": "ibmcld_10066-15642-17706", "score": 0.5987980365753174, "text": "\n[Review the available contexts](https://cloud.ibm.com/docs/openshift?topic=openshift-cbr&interface=uicbr-overview) and determine the rules you want to create.\n2. Follow the steps to [create context-based restrictions in the console](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-create).\n\n\n\n\n\n\n\n\n\n Limitations \n\n\n\n* After you create a rule, it might take up to 10 minutes for the rule to take effect.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types must not reference network zones that contain IPv6 addresses. The APIs included in the cluster type don't support IPv6.\n* If you add Red Hat OpenShift on IBM Cloud resources to private-only network zones, the APIs for getting and listing clusters are still accessible over the public network.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types must not reference other services like IBM Cloud Object Storage or Key Protect\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API type do not support Report-only enforcement for the cluster API type.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types are limited to no more than 20 IPs/subnets for private rules, and 200 IPs/subnets for public rules. These limits are expected to increase after the backend scalability of our implementation of Red Hat OpenShift on IBM Cloud CBR is updated.\n* Red Hat OpenShift on IBM Cloud public CBR rules that apply to the cluster API type do not effect clusters that are private service endpoint only. All public traffic to the cluster APIserver is blocked. To use public CBR rules to control access to your cluster, update your cluster to enable public service endpoint.\n* Due to a limitation with how Red Hat OpenShift on IBM Cloud fetches cluster details, the APIs for getting clusters and listing clusters are still accessible regardless of the CBR rules. This means clusters are still visible (read-only) in the console and CLI.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cbr&interface=ui"}, {"document_id": "ibmcld_07033-9327-11385", "score": 0.5954693555831909, "text": "\nLabeling tips \n\nReview these tips before you begin:\n\n\n\n* The document collection that you label must contain a representative set of documents. The documents must have many and varied examples of the entity types that you want the entity extractor to recognize. If the collection you selected when you started to create the entity extractor does not meet the requirement, stop now and start over with a different document collection.\n* Define entity types that are clearly distinct from one another.\n* Aim to label at least 40 examples of each entity type.\n* Label every valid example of an entity type. Do not skip any occurrences. To speed up the process, use the bulk label feature.\n\n\n\n\n\n\n\n Labeling entity examples \n\nLabel terms in the document that represent examples of the entity types you defined. When you are done with one document, switch the document status from In progress to Complete, and then move on to the next document.\n\nOnly the first 40,000 characters from each document are available for labeling. 40,000 characters is approximately 20 pages.\n\nTo label entity examples, complete the following steps:\n\n\n\n1. Review the text of the document. Look for entity examples to label.\n\nThe following table shows some examples.\n\n\n\nEntity types and examples\n\n Entity type Examples to label in the document \n\n color white, green, purple \n car convertible, SUV, sedan \n auto_model Explorer, Civic, Sorrento \n auto_manufacturer Ford, Honda, Kia \n clothing shirt, blouse, skort \n instruments bonds, stocks, ETFs, munis \n\n\n\nIf an entity type that you want to identify is not created yet, add the entity type. From the Entity types panel, click Create new. For more information about adding entity types, see [Defining entity types](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractorentity-extractor-add-entities).\n2. First, click the entity type from the Entity types panel.\n3. In the document body, select the word or phrase that represents the entity example.\n\nThe term is selected and a color label is applied to the term.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractor"}, {"document_id": "ibmcld_10065-15648-17713", "score": 0.5930008888244629, "text": "\n[Review the available contexts](https://cloud.ibm.com/docs/openshift?topic=openshift-cbr&interface=clicbr-overview) and determine the rules you want to create.\n2. Follow the steps to [create context-based restrictions in the console](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-create).\n\n\n\n\n\n\n\n\n\n Limitations \n\n\n\n* After you create a rule, it might take up to 10 minutes for the rule to take effect.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types must not reference network zones that contain IPv6 addresses. The APIs included in the cluster type don't support IPv6.\n* If you add Red Hat OpenShift on IBM Cloud resources to private-only network zones, the APIs for getting and listing clusters are still accessible over the public network.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types must not reference other services like IBM Cloud Object Storage or Key Protect\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API type do not support Report-only enforcement for the cluster API type.\n* Red Hat OpenShift on IBM Cloud CBR rules that apply to all API types or the cluster API types are limited to no more than 20 IPs/subnets for private rules, and 200 IPs/subnets for public rules. These limits are expected to increase after the backend scalability of our implementation of Red Hat OpenShift on IBM Cloud CBR is updated.\n* Red Hat OpenShift on IBM Cloud public CBR rules that apply to the cluster API type do not effect clusters that are private service endpoint only. All public traffic to the cluster APIserver is blocked. To use public CBR rules to control access to your cluster, update your cluster to enable public service endpoint.\n* Due to a limitation with how Red Hat OpenShift on IBM Cloud fetches cluster details, the APIs for getting clusters and listing clusters are still accessible regardless of the CBR rules. This means clusters are still visible (read-only) in the console and CLI.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cbr&interface=cli"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03381-4347-6258", "score": 0.7337836027145386, "text": "\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add an actions or dialog skill.\n3. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions page instead.\n\n\n\n\n\n\n\n Sharing a dialog skill with team members \n\nAfter you create the service instance, you can give other people access to it. Together, you can define the training data and build the dialog.\n\nOnly one person can edit an intent, entity, or a dialog node at a time. If multiple people work on the same item at the same time, then the changes made by the person who saves their changes last are the only changes applied. Changes that are made during the same time frame by someone else and are saved first are not retained. Coordinate the updates that you plan to make with your team members to prevent anyone from losing their work.\n\nTo share a dialog skill with other people, you must give them access to the service instance that hosts the skill. Note that the person you invite will be able to access any skill or assistant in this service instance.\n\n\n\n1. Click the User ![User](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/user-icon2.png) icon in the page header.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03043-7-2031", "score": 0.7269470691680908, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03049-3966-5647", "score": 0.7041901350021362, "text": "\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03126-5596-6966", "score": 0.7013754844665527, "text": "\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03381-2858-4802", "score": 0.6950842142105103, "text": "\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03119-7-1688", "score": 0.6943322420120239, "text": "\nCreating an assistant \n\nCreate an assistant with the skills it needs to address the business goals of your customers.\n\nTo learn more about what an assistant is first, see [Assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants).\n\nFollow these steps to create an assistant:\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/nav-ass-icon.png).\n2. Click Create assistant.\n3. Add details about the new assistant:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n4. Click Create assistant.\n5. Add a skill to the assistant.\n\nNote: You can choose to add an existing skill or create a new one.\n\nSee [Adding a skill to an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add).\n\n\n\n\n\n Assistant limits \n\nThe number of assistants you can create depends on your Watson Assistant [plan type](https://www.ibm.com/products/watson-assistant/pricing/). There is also a limit of 100 assistants per service instance.\n\nAfter 30 days of inactivity, an unused assistant in a Lite plan service instance might be deleted to free up space. See [Changing the inactivity timeout setting](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-settings) for more information on the subject.\n\nYou can connect one skill of each type to your assistant. The number of skills you can build differs depending on the plan you have. See [Skill limits](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-limits) for more details.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add"}, {"document_id": "ibmcld_03049-2703-4536", "score": 0.6899533271789551, "text": "\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_03329-2181-3852", "score": 0.68829345703125, "text": "\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3. Find General in the list, and then click Add to skill.\n\n![Shows the Content Catalog and highlights the Add to skill button for the General catalog.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-content-catalog.png)\n4. Open the Intents tab to review the intents and associated example utterances that were added to your training data. You can recognize them because each intent name begins with the prefix General_. You will add the General_Greetings and General_Ending intents to your dialog in the next step.\n\n![Shows the intents that are displayed in the Intents tab after the General catalog is added.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-general-content-added.png)\n\n\n\nYou successfully started to build your training data by adding prebuilt content from IBM.\n\n\n\n\n\n Step 4: Build a dialog \n\nA [dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview) defines the flow of your conversation in the form of a logic tree. It matches intents (what users say) to responses (what your virtual assistant says back). Each node of the tree has a condition that triggers it, based on user input.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_03054-18427-20301", "score": 0.6880865097045898, "text": "\nFor details about how to add a search skill response type, see [Adding rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03373-4-1923", "score": 0.6874096393585205, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n* Search skill!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03054-28651-29202", "score": 0.7391384840011597, "text": "\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search Skill page, and then click to switch the toggle to Disabled.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03383-23830-24369", "score": 0.73708176612854, "text": "\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search skill page, and then set the switch to Disabled.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_13042-23866-24405", "score": 0.73708176612854, "text": "\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search skill page, and then set the switch to Disabled.", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03383-20671-22804", "score": 0.7348501682281494, "text": "\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_13042-20707-22840", "score": 0.7348501682281494, "text": "\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03373-7076-8670", "score": 0.7289320230484009, "text": "\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_03383-17365-19519", "score": 0.7222949266433716, "text": "\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_13042-17392-19546", "score": 0.7222949266433716, "text": "\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03054-19820-21851", "score": 0.7214237451553345, "text": "\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03196-46002-48092", "score": 0.7180259227752686, "text": "\nYou can trigger a search of the existing material in real time to get the latest and most up-to-date answer for your customers.\n\nTo use the search skill response type, you must create a search skill and add it to the same assistant that uses this dialog skill. For more information, see [Creating a search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add).\n\nTo add a Search skill response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Search skill.\n\nIndicates that you want to search an external data source for a relevant response.\n2. To edit the search query to pass to the Discovery service, click Customize, and then fill in the following fields:\n\n\n\n* Query: Optional. You can specify a specific query in natural language to pass to Discovery. If you do not add a query, then the customer's exact input text is passed as the query.\n\nFor example, you can specify What cities do you fly to?. This query value is passed to Discovery as a search query. Discovery uses natural language understanding to understand the query and to find an answer or relevant information about the subject in the data collection that is configured for the search skill.\n\nYou can include specific information provided by the user by referencing entities that were detected in the user's input as part of the query. For example, Tell me about @product. Or you can reference a context variable, such as Do you have flights to $destination?. Just be sure to design your dialog such that the search is not triggered unless any entities or context variables that you reference in the query have been set to valid values.\n\nThis field is equivalent to the Discovery natural_language_query parameter. For more information, see [Query parameters](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametersnlq).\n\n\n\n* Filter: Optional. Specify a text string that defines information that must be present in any of the search results that are returned.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 0.7143416404724121, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-7-1802", "score": 0.658353328704834, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-2884-4620", "score": 0.6575931310653687, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_02772-4213-5899", "score": 0.6181905269622803, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_06004-29614-31438", "score": 0.6109517812728882, "text": "\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_10852-43319-44485", "score": 0.6068794131278992, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10645-7-1995", "score": 0.6049734950065613, "text": "\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/openshift?topic=openshift-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/openshift?topic=openshift-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update_app"}, {"document_id": "ibmcld_06225-7-1999", "score": 0.5973528623580933, "text": "\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https://cloud.ibm.com/docs/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update_app"}, {"document_id": "ibmcld_00959-2830-5215", "score": 0.5929330587387085, "text": "\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}, {"document_id": "ibmcld_00962-3246-5702", "score": 0.5870978832244873, "text": "\nThe Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds. Over time, the traffic that is sent to the new version is increased until all of the traffic is sent there, at which point you can stop the old production environment. For rapid rollback while deployment is in progress, you can route all of the traffic to the original production environment. Since this strategy requires two full production environments only during deployment, the overall resource usage is lower than for the Blue-Green deployment. The Canary release deployment strategy is the slowest to move from a previous release to a current release of the software that is being deployed. Canary deployments allow organizations to test two different software versions side by side in production.\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https://cloud.ibm.com/registration), with a Standard plan.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-vpc"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07551-15747-17355", "score": 0.5593017935752869, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-14062-16080", "score": 0.5342127680778503, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_04518-1426-3052", "score": 0.5059549808502197, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-44214-45420", "score": 0.5040551424026489, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10852-43319-44485", "score": 0.5007123947143555, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 0.4979390501976013, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_12332-1034-2510", "score": 0.46315905451774597, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_04518-7-1743", "score": 0.407850056886673, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 0.39300480484962463, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05367-1325-3446", "score": 0.6013831496238708, "text": "\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides a streamlined way for you to run your code as a Function.\n\n\n\n* If you are starting with source code that is located in a Git repository, you can choose to point to the location of your source, and Code Engine takes care of building the code bundle from your source and creating the Function with a single operation. In this scenario, Code Engine uploads your code to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a Function from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-repo).\n* If you are starting with source code on a local workstation, you can choose to point to the location of your source, and Code Engine takes care of building the image from your source and creating the Function with a single CLI command. In this scenario, Code Engine uploads your code to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your Function from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-local).\n* If you are starting with source code, you can also run your source code inline. In this scenario, you paste in your source code when you create your Function. For more information, see [Creating your Function with inline code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-create-inlinecode).\n\n\n\nAfter you create and run your Function, you can also update your Function by using any of the preceding ways, independent of how you created or previously updated your Function.\n\n\n\n\n\n Requests and responses \n\nFunctions are invoked with the HTTP protocol. When you invoke your Function, you can specify the custom request parameters, custom request body and headers, as well as the HTTP method. The request parameters are made available to the Function code as input parameters. The Function code can set the response body, response headers, and response code, which are returned to the caller from the Functions endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-work"}, {"document_id": "ibmcld_07549-15470-17876", "score": 0.5779937505722046, "text": "\nConveying Non-Source Forms You may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:a) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.b) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.c) Convey individual copies of the object code with a copy of the written offer to provide the corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.d) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_02569-2974-5046", "score": 0.567922830581665, "text": "\n\"more_info\": \"https://docs.api.example.com/v2/users/create_userusername\",\n\"target\": {\n\"type\": \"field\",\n\"name\": \"username\"\n}\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n Codes and messages \n\nError code values SHOULD specify the problem that caused an error; message values SHOULD describe the problem and MAY also provide suggestions or solutions.\n\n\n\n Codes \n\nError code values MUST be snake case strings, descriptive of the problem encountered, as succinct as possible, and absent of any non-standard or proprietary terms, brands, codenames, abbreviations, or acronyms.\n\ncode values SHOULD NOT prescribe solutions to problems. For example, color_must_be_red_or_blue is not a good code. A better code would be invalid_color, leaving solutions to message values. This allows code values to remain constant even if a field becomes more permissive in the future.\n\nA code value, along with any other machine-readable fields included in an error, SHOULD be specific enough for client code to take any required action. Client code should not be forced to parse a human-readable message value in order to take action on a specific error condition.\n\nThe documentation for specific requests SHOULD enumerate possible error code values. Adding a possible error code for a request SHOULD be considered a breaking change. For this reason, the documentation MAY include possible error code values which are not yet used.\n\n\n\n\n\n Messages \n\nError message values SHOULD describe the problems identified by code values in complete, well-formed sentences and MAY provide suggestions or solutions. It is expected for message values to duplicate information from code, target, and custom extensions to the error model.\n\nImportantly, message values are still meant for developers and for this reason SHOULD NOT be localized or written for use in a user interface. Fields mentioned within a message SHOULD be mentioned by exact field name (e.g., first_name, not \"first name\").\n\nConsider the example above of an error code with value invalid_color. A poor message would be:\n\n\"The color provided for paint was invalid.\"", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-errors"}, {"document_id": "ibmcld_05345-8896-10818", "score": 0.5628101229667664, "text": "\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples?", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimage"}, {"document_id": "ibmcld_05381-10648-12570", "score": 0.5628101229667664, "text": "\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples?", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code"}, {"document_id": "ibmcld_05344-6440-8274", "score": 0.5588485598564148, "text": "\nFor example, run ibmcloud ce job update -n JOB_NAME --build-clear. After you remove the association of the build from your job, you can update the job to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job"}, {"document_id": "ibmcld_05434-9714-11548", "score": 0.5588485598564148, "text": "\nFor example, run ibmcloud ce job update -n JOB_NAME --build-clear. After you remove the association of the build from your job, you can update the job to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-tutorial"}, {"document_id": "ibmcld_05276-5947-7734", "score": 0.5552754402160645, "text": "\nWhen a job instance completes with a nonzero return code, Code Engine restarts the job instance. With Code Engine, you can specify to limit the number of retries to avoid restarting failed job instances.\n\n\n\n\n\n Running batch jobs \n\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides a streamlined way for you to run your code as a job.\n\nYou can create and run batch jobs in Code Engine in the following ways:\n\n\n\n* Run an existing container image. Create a job and provide a reference to your image to use when you submit the job. For an example, see [Create and run a job](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-startedfirst-job).\n* Start with source code. If you are starting with source code that is located in a Git repository or on your local workstation, you can point to the location of your source and Code Engine takes care of building the image for you. See [Create a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code) and [Create a job from local source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code).\n\n\n\nFor more information, see [Working with jobs](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-plan).\n\n\n\n\n\n Scaling \n\nA job in Code Engine (batch job) consists of one or more job instances. While job instances run independent of each other, they run the same code. Suppose you have a database with 100 records to analyze. You can run your job such that each job instance analyzes 10 records each. For example, the first job instance analyzes records 0 - 9, the second job instance can analyze records 10 - 19, and so on.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cebatchjobs"}, {"document_id": "ibmcld_05272-7-1877", "score": 0.5516607761383057, "text": "\nBuilding a container image with stand-alone build commands (CLI) \n\nWhen your code exists as source in a local file or in a Git repository, Code Engine provides options for you to build your code as a container image, per the [Open Container Initiative (OCI) standard](https://opencontainers.org/). With the Code Engine CLI, you can build a container image with a single command.\n\nCode Engine offers the flexibility to handle the build process for you whenever you are [deploying your app from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-app-source-code), [deploying your app from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-app-local-source-code), or you are [creating a job from repository source code](https://cloud.ibm.com/docs/codeengine?topic=codeengine-run-job-source-code) or [creating your job from local source code with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-job-local-source-code).\n\nHowever, if you want more control over the build of your container image, Code Engine gives you the flexibility to build your container image by using one of the following options:\n\n\n\n* Use a single CLI command, buildrun submit, to run one build run. The benefit of this option is that you can obtain your build with a single CLI command; however, the configuration for the build is not preserved.\n* Define a build configuration from which you can run multiple build runs. See [Building a container image by using a build configuration](https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-image).\n\n\n\nAfter your build is complete and your image exists, you can deploy the container image as an application or create a job that references your image.\n\nLet's learn about how to build your container image with a single command and not reference a build configuration.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-build-standalone"}, {"document_id": "ibmcld_02586-5749-7864", "score": 0.5493351221084595, "text": "\nResponses with a 304 status MUST NOT have a response body. \n 307 [Temporary Redirect](https://datatracker.ietf.org/doc/html/rfc7231section-6.4.7) This code MAY be returned to indicate that the request should be resubmitted to the URI provided in the Location header, which MUST be included when this code is returned, and that future requests should use the original URI. This code indicates that the request method should not change when using the temporary URI. \n\n\n\n\n\n URI ambiguity \n\nURI ambiguity requiring the use of a 300 status code SHOULD be avoided by following the below principles:\n\n\n\n1. URI schemes SHOULD be inherently unambiguous with respect to what resource is meant.\n2. If multiple representations of a particular resource are offered, the desired version SHOULD be specified with an Accept header rather than distinct URIs, and a default representation SHOULD be served liberally.[5]\n\n\n\nHowever, in such cases where it is deemed important that an occasionally-ambiguous URI scheme be used or where different representations of a resource require differing URIs (e.g., for media files where a file extension is considered significant), a 300 status code MAY be returned where a particular URI is ambiguous.\n\n\n\n\n\n 303 and 307 temporary redirects \n\nA 303 in response to a POST, PUT, or DELETE indicates that the operation has succeeded but that the response entity-body is not being sent along with this request. If the client wants the response entity-body, it needs to make a GET request to the URI provided in the Location header.\n\nA 307 in response to a POST, PUT, or DELETE indicates that the server has not even tried to perform the operation and the client needs to resubmit the entire request, with the original method, to the URI in the Location header.\n\n\n\n\n\n\n\n Client errors: 4xx \n\n\n\nClient error status codes\n\n Code Meaning Description \n\n 400 [Bad Request](https://datatracker.ietf.org/doc/html/rfc7231section-6.5.1) This code MUST be returned when a request cannot be processed due to client error (e.g., the request is malformed or too large) when a more specific code is not applicable.", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-status-codes"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08474-1435-3113", "score": 0.6040781736373901, "text": "\nOperational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n 22 internal keystores $3795 (5x0+15x225+2x210) \n 15 external keystores $980 (1x0+14x70) \n Unified Key Orchestrator connection $3600 (30x24x5.00) \n Total charge $11442.2", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_07578-1183252-1185036", "score": 0.5920128226280212, "text": "\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1185885-1187669", "score": 0.5920128226280212, "text": "\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_08474-7-1664", "score": 0.589690089225769, "text": "\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_09915-2815-3708", "score": 0.5877423286437988, "text": "\nThe first 250,000 NLU items are charged at $0.003 per item\nAdditional NLU items until the 5,000,000th NLU item are charged at $0.001 per item\nEstimated price = (250,000 NLU items \u00d7 $0.003) + (50,000 NLU items \u00d7 $0.001)\nEstimated price = $750 + $50\n\n\n\nTotal cost = $800\n\n\n\n\n\n How do I calculate the Standard Plan price for 15,000 NLU items? \n\n\n\n* Since the first 250,000 NLU items are priced at $0.003/item - your 15,000 NLU items are charged at $0.003 per item (Tier 1). Your estimated price would be $45.\n\n\n\n\n\n\n\n How do I calculate the Standard Plan price for 6,000,000 NLU items? \n\n\n\n* Since you have more than 5,000,000 NLU items, your first 250,000 NLU items are charged at $0.003 per item (Tier 1), your next 4,750,000 NLU items are charged at $0.001 per item (Tier 2), and your remaining 1,000,000 NLU items are charged at $0.0002 per item (Tier 3). Your estimated price would be $5,700.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-pricing"}, {"document_id": "ibmcld_07532-3613-6012", "score": 0.5870815515518188, "text": "\nThe IBM Cloud push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nConsumption: Only 500 devices or 5000 outbound digital messages is permitted per pre-production destination. If either the number of devices or the number of outbound digital messages exceeds the permitted limit, the permitted number of devices is moved by additional 500 devices or by additional 5000 messages and charged.\n\nFor example, if you tried to send 5001th message, the message cap automatically is raised to 10000 (another 5000 messages are added) for the month and the device cap is raised to 1000 (another 500 devices are added) per month. Notice that both limits are always raised even if only one cap has been exceeded.\n\n\n\n\n\n Push charges for changing from pre-production destination to production destination \n\nYou can change a pre-production destination to a production destination at any particular time and the charges are calculated accordingly.\n\nThe push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nA production destination instance fee is also charged monthly and allows unlimited devices and outbound messages.\n\nIf you change a pre-production destination to a production destination, the charges for the transition month would be the pre-producdtion fee + pro-rated charge for the production instance.\n\nFor example, assume the pre-production instance fee is $15 per month and the production instance fee is $50 per month.\n\nThese prices are assumed for this example only. Current pricing may be different from the amounts shown in the example. See the Event Notifications catalog page for current pricing.\n\n\n\n* As of 31 July, you create a pre-production destination and does not register any devices or send messages, the charges for July will be $15.\n* As of 1 August, you register 500 devices and 5001 messages sent. The charges for August will be $30 (This is due to the message threshold exceeds the permitted limit.)\n* As of 5 August, you change from pre-production destination to production destination.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-push"}, {"document_id": "ibmcld_03798-0-2240", "score": 0.5870614051818848, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_07456-1475-3845", "score": 0.5863840579986572, "text": "\nIf for any reason IBM Cloud is unable to charge Your payment method for the full amount owed, or if IBM Cloud is charged a penalty for any fee it previously charged to Your payment method, You agree that IBM Cloud may pursue all available remedies in order to obtain payment, including immediate cancellation, without notice, of any domain names registered or renewed by You or on Your behalf. IBM Cloud reserves the right to charge a reasonable service fee for administrative tasks outside the scope of its regular Services, including customer service issues that cannot be handled over email but require personal service, and disputes that require legal services. These charges will be billed to the payment method on file for You.\n\n\n\n\n\n Domain Name Renewals \n\nYou have the option to elect automatic renewal of the domain names You register, in which case IBM Cloud will automatically renew Your domain(s) for a period equivalent to the length of Your original registration, and will take payment from the payment method You have on file, at IBM Cloud's then-current rates. Domain name renewals are non-refundable. If IBM Cloud is not able to process payment for an automatic renewal, and You fail to respond to our notices, Your domain name registration will expire. It is Your responsibility to keep Your payment information current. If You do not elect automatic renewal, You have the responsibility of manually renewing Your domain by the expiration date. If You fail to manually renew in a timely fashion the domain name will be cancelled and You will no longer have use of that name. You agree that IBM Cloud will not be responsible for cancelled domain names that You fail to renew, either automatically or manually. If You do fail to renew Your domain name in a timely fashion, additional charges may apply. (Current fees for post-expiration renewal can be found here: [https://www.ibm.com/cloud/dns](https://www.ibm.com/cloud/dns)). If You signed up for any other services in conjunction with Your domain registration, these services may be automatically renewed when Your domain registration is renewed, and You may incur additional renewal fees unless You cancel in advance. IBM Cloud sends domain renewal reminders via email to the registered owner contact in accordance with the ICANN Expired Registration Recovery Policy. The notices are sent as follows:", "title": "", "source": "https://cloud.ibm.com/docs/dns?topic=dns-domain-registration-agreement"}, {"document_id": "ibmcld_02775-4830-5961", "score": 0.5844154357910156, "text": "\nFor a complete list of the options and setup information, see [Advanced password management](https://cloud.ibm.com/docs/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-pricing"}, {"document_id": "ibmcld_03729-4932-7001", "score": 0.5832916498184204, "text": "\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09064-11577-12953", "score": 0.6199166774749756, "text": "\n<br> <br>For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID). \n return_preference Optional. A header that alters server behavior for POST and DELETE operations. <br> <br>When you set the return_preference variable to return=minimal, the service returns a successful deletion response. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n\n\n\nIf the return_preference variable is set to return=representation, the details of the DELETE request are returned in the response entity-body.\n\nAfter you delete a key, it transitions to the Deactivated key state. After 24 hours, if a key is not reinstated, the key transitions to the Destroyed state. Deleted keys can be recovered after up to 30 days or their expiration date, whichever is sooner. After this the key contents are permanently shredded and its metadata is no longer accessible.\n\nThe following JSON object shows an example returned value.\n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"id\": \"2291e4ae-a14c-4af9-88f0-27c0cb2739e2\",\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"name\": \"test-root-key\",\n\"description\": \"...\",\n\"state\": 5,\n\"expirationDate\": \"2020-03-15T20:41:27Z\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys"}, {"document_id": "ibmcld_08442-4913-6121", "score": 0.6179852485656738, "text": "\nFor more information, see [Managing key rings](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-managing-key-rings). \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns a successful deletion response. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n\n\n\nIf the return_preference variable is set to return=representation, the details of the DELETE request are returned in the response entity-body.\n\nThe following JSON object shows a sample returned value.\n\n{\n\"metadata\": {\n\"collectionType\": \"application/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-root-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"state\": 5,\n\"extractable\": false,\n\"crn\": \"crn:v1:bluemix:public:hs-crypto:us-south:a/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-10T20:41:27Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"AES\",", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys"}, {"document_id": "ibmcld_09419-9246-10565", "score": 0.6016913652420044, "text": "\n-d '{ \"name\": \"My preset\", \"channels\": [\"<CHANNEL>\"] }'\n\nWhere <PRESET_ID> is the presetid value returned when [running the GET method to return all presets.](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-preset-apipreset-api-get-all)\n\nA response similar to the following is returned:\n\n{\"name\":\"Send by email\",\"channels\":[{\"integration\":\"email\",\"immediate\":false,\"terminal\":true,\"triggerlimit\":1,\"triggerinterval\":30,\"operator\":\"presence\",\"emails\":\"AnotherUser@mycompany.com\",\"alertid\":\"6043b60788\"}],\"presetid\":\"291a4100b0\"}\n\nIf the <PRESET_ID> does not exist, the following is returned:\n\n{\"error\":\"Resource Not Found\",\"code\":\"NotFound\",\"status\":\"error\"}\n\n\n\n\n\n Deleting a preset \n\nThe following sample deletes a preset.\n\ncurl --request DELETE https://api.us-south.logging.cloud.ibm.com/v1/config/presetalert/<PRESET_ID> \n-H \"Accept: application/json\" \n-H \"servicekey: <SERVICE_KEY>\" \n\nWhere <PRESET_ID> is the presetid value returned when [running the GET method to return all presets.](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-preset-apipreset-api-get-all)\n\nThe following response will be returned when the preset is successfully deleted:\n\n{\"deleted\":true}\n\nIf the <PRESET_ID> does not exist, the following is returned:\n\n{\"error\":\"Resource Not Found\",\"code\":\"NotFound\",\"status\":\"error\"}", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-preset-api"}, {"document_id": "ibmcld_03218-31027-32769", "score": 0.6002102494239807, "text": "\nIf you do not take action, the same text response is displayed a second time to let users know they have returned to the node they digressed away from. You can make it clearer to users that they have returned to the original conversation thread by specifying a unique message to be displayed when they return.\n\nFor example, if the original text response for the node is, What's the order number?, then you might want to display a message like, Now let's get back to where we left off. What is the order number? when users return to the node.\n\nTo do so, use the following syntax to specify the node text response:\n\n<? (returning_from_digression)? \"post-digression message\" : \"first-time message\" ?>\n\nFor example:\n\n<? (returning_from_digression)? \"Now, let's get back to where we left off.\nWhat is the order number?\" : \"What's the order number?\" ?>\n\nYou cannot include SpEL expressions or shorthand syntax in the text responses that you add. In fact, you cannot use shorthand syntax at all. Instead, you must build the message by concatenating the text strings and full SpEL expression syntax together to form the full response.\n\nFor example, use the following syntax to include a context variable in a text response that you would normally specify as, What can I do for you, $username?:\n\n<? (returning_from_digression)? \"Where were we, \" +\ncontext\"username\"] + \"? Oh right, I was asking what can I do\nfor you today.\" : \"What can I do for you today, \" +\ncontext\"username\"] + \"?\" ?>\n\nFor full SpEL expression syntax details, see Expression for accessing objects]] ! ! ! ! ! .\n* Preventing returns: In some cases, you might want to prevent a return to the interrupted conversation flow based on a choice the user makes in the current dialog flow.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime"}, {"document_id": "ibmcld_07098-12237-14153", "score": 0.5939153432846069, "text": "\nFilter search results are not returned in order of relevance.When you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter, the filter parameter runs first, and then any aggregation, query, or natural_language_query parameters run in parallel.With a simple query, especially on a small data set, the filter and query parameters often return the exact same (or similar) results. If the filter and query calls return similar results, and you don't need the responses to be returned in order of relevance, use the filter parameter. Filter calls are faster and are cached. Caching means that the next time you make the same call, you get a much quicker response, particularly in a big data set.<-- </section \"id=\"section-filter\" \"> --><-- <section \"id=\"section-query-parameters-structure\" \"> --> Structure parameters Structure parameters define the content and organization of the documents in the returned JSON. Structure parameters don't affect which documents are part of the entire results set.<-- </section \"id=\"section-query-parameters-structure\" \"> --><-- <section \"id=\"section-return\" \"> --> return A comma-separated list of the portion of the document hierarchy to return. Any of the document hierarchies are valid values. If this parameter is an empty list, then all fields are returned.<-- </section \"id=\"section-return\" \"> --><-- <section \"id=\"section-count\" \"> --> count The number of documents that you want to return in the response. The default is 10. The maximum for the count and offset values together in any one query is 10000.<-- </section \"id=\"section-count\" \"> --><-- <section \"id=\"section-offset\" \"> --> offset Index value of the position of the search result where the set of results to return begins. For example, if the total number of results that are returned is 10, and the offset is 8, it returns the last two results. The default is 0.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_00348-10050-11511", "score": 0.592544674873352, "text": "\n\"type\": \"INTEGRATED\",\n\"names\": [\n\"TotalHits\",\n\"TotalBandwidth\",\n\"0XX\",\n\"200\",\n\"206\",\n\"2XX\",\n\"302\",\n\"304\",\n\"3XX\",\n\"404\",\n\"4XX\",\n\"5XX\",\n\"Other\",\n\"Australasia\",\n\"EMEA\",\n\"India\",\n\"Japan\",\n\"North America\",\n\"Rest Of APAC\",\n\"South America\"\n],\n\"descriptions\": [\n\"All hits to the Edge servers from the end-users.\",\n\"Total number of megabytes transferred between the Edge to the end user.\",\n\"Number of hits that returned response code - 0XX\",\n\"Number of hits that returned response code - 200\",\n\"Number of hits that returned response code - 206\",\n\"Number of hits that returned response code - 2XX\",\n\"Number of hits that returned response code - 302\",\n\"Number of hits that returned response code - 304\",\n\"Number of hits that returned response code - 3XX\",\n\"Number of hits that returned response code - 404\",\n\"Number of hits that returned response code - 4XX\",\n\"Number of hits that returned response code - 5XX\",\n\"Number of hits that returned response code not within 2XX to 5XX\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-api"}, {"document_id": "ibmcld_02505-9300-10635", "score": 0.5920542478561401, "text": "\n-d '{ \"name\": \"My preset\", \"channels\": [\"<CHANNEL>\"] }'\n\nWhere <PRESET_ID> is the presetid value returned when [running the GET method to return all presets.](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-preset-apipreset-api-get-all)\n\nA response similar to the following is returned:\n\n{\"name\":\"Send by email\",\"channels\":[{\"integration\":\"email\",\"immediate\":false,\"terminal\":true,\"triggerlimit\":1,\"triggerinterval\":30,\"operator\":\"presence\",\"emails\":\"AnotherUser@mycompany.com\",\"alertid\":\"6043b60788\"}],\"presetid\":\"291a4100b0\"}\n\nIf the <PRESET_ID> does not exist, the following is returned:\n\n{\"error\":\"Resource Not Found\",\"code\":\"NotFound\",\"status\":\"error\"}\n\n\n\n\n\n Deleting a preset \n\nThe following sample deletes a preset.\n\ncurl --request DELETE https://api.us-south.logging.cloud.ibm.com/v1/config/presetalert/<PRESET_ID> \n-H \"Accept: application/json\" \n-H \"servicekey: <SERVICE_KEY>\" \n\nWhere <PRESET_ID> is the presetid value returned when [running the GET method to return all presets.](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-preset-apipreset-api-get-all)\n\nThe following response will be returned when the preset is successfully deleted:\n\n{\"deleted\":true}\n\nIf the <PRESET_ID> does not exist, the following is returned:\n\n{\"error\":\"Resource Not Found\",\"code\":\"NotFound\",\"status\":\"error\"}", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-preset-api"}, {"document_id": "ibmcld_04334-116993-118903", "score": 0.5888341665267944, "text": "\nRequired.--available-fields: List of all available fields.--ray-id value: Lookup logs by specific Ray ID.--fields value: Define field set in return. This must be specified as a comma separated list without any spaces, and all fields must exist. The order in which fields are specified doesn't matter, and the order of fields in the response is not specified. Note that fields are expected to be case sensitive.--start value: The (inclusive) beginning of the requested time frame. This can be a unix timestamp (in seconds or nanoseconds), or an absolute timestamp that conforms to RFC 3339. At this point in time, it cannot exceed a time in the past greater than 7 days. Default is 65 minutes earlier.--end value: The (exclusive) end of the requested time frame. This can be a unix timestamp (in seconds or nanoseconds), or an absolute timestamp that conforms to RFC 3339. The end must be at least 5 minutes earlier than now and must be later than start. Difference between start and end must be not greater than 1h. Default is 5 minutes earlier.--count value: Number of logs to retrieve. The default value is -1.--sample value: Percentage of sampling. When sample is provided, a sample of matching records is returned. If sample=0.1 then 10% of records will be returned. Sampling is random: repeated calls will not only return different records, but likely will also vary slightly in number of returned records. When count is also specified, count is applied to the number of returned records, not the sampled records. So, with sample=0.05 and count=7, when there is a total of 100 records available, approximately 5 will be returned. When there are 1000 records, 7 will be returned. When there are 10,000 records, 7 will be returned. The default value is 1.--timestamps value: Set the format in which response timestamps are returned. Valid values: unix, unixnano, rfc3339.-i, --instance: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_07120-22745-24224", "score": 0.5833156108856201, "text": "\n[Shows that multiple responses are returned for the query.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-rule-response.png)\n\nFigure 26. Multiple responses are returned for the query\n\nOur updates only improved the quality of the accurate responses that were returned before.\n3. Now, let's ask a question that returned poor results previously. Enter What are PTFs? as the search query.\n\nThe same response that was returned as the only response last time is returned again. However, this time we get more than one response. And we can see that the second response that is returned defines the acronym for us.\n\n(\u201cprincipal trading firms\u201d or \u201cPTFs\u201d)\n\nZoom\n\n![Shows responses that are returned to answer the question about PTFs.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-ptf-responses.png)\n\nFigure 27. Responses that answer the question about PTFs\n4. Let's try the other problematic search query. Enter Where do muni bond trades get reported to? as the search query.\n\nThis time it's the third response that provides an answer to the question. You must view the full passage to see the entire definition.\n\nZoom\n\n![Shows responses that are returned to answer the question about muni bonds.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-muni-responses.png)\n\nFigure 28.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-sdu"}, {"document_id": "ibmcld_04142-4286-5812", "score": 0.5832606554031372, "text": "\n// Hosts don't match. This is a hotlink. Redirect the\n// user to our homepage.\nreturn new Response('', {\nstatus: 302,\nheaders: {\n'Location': '/'\n}\n})\n}\n}\n\n// Everything is fine, return the response normally.\nreturn response\n}\nShow more\n\n\n\n\n\n Originless responses \n\nYou can return responses directly from the edge. No need to hit your origin.\n\n\n\n Ignore POST and PUT HTTP requests \n\nIgnore POST and PUT HTTP requests. This snippet allows all other requests to pass through to the origin.\n\naddEventListener('fetch', event => {\nevent.respondWith(fetchAndApply(event.request))\n})\n\nasync function fetchAndApply(request) {\nif (request.method === 'POST' || request.method === 'PUT') {\nreturn new Response('Sorry, this page is not available.',\n{ status: 403, statusText: 'Forbidden' })\n}\n\nreturn fetch(request)\n}\n\n\n\n\n\n Deny a spider or crawler \n\nProtect your origin from unwanted spiders or crawlers. In this case, if the user-agent is \u201cannoying-robot\u201d, the Edge function returns the response instead of sending the request to the origin.\n\naddEventListener('fetch', event => {\nevent.respondWith(fetchAndApply(event.request))\n})\n\nasync function fetchAndApply(request) {\nif (request.headers.get('user-agent').includes('annoying_robot')) {\nreturn new Response('Sorry, this page is not available.',\n{ status: 403, statusText: 'Forbidden' })\n}\n\nreturn fetch(request)\n}\n\n\n\n\n\n Prevent a specific IP from connecting \n\nBlocklist IP addresses. This snippet of code prevents a specific IP, in this case \u2018225.0.0.1\u2019 from connecting to the origin.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-edge-functions-use-cases"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10762-1269-2843", "score": 0.6963881254196167, "text": "\ndefault a8a12accd63b437bbd6d58fb8b462ca7 true ACTIVE\ntest a8a12abbbd63b437cca6d58fb8b462ca7 false ACTIVE\n6. Target a resource group by running the following command.\n\nibmcloud target -g <resource_group>\n\nExample output\n\nTargeted resource group default\n\n\n\n\n\n\n\n Setting up the Cloud Functions CLI plug-in \n\nTo work with Cloud Functions, download and install the CLI plug-in.\n\nYou can use the Cloud Functions CLI plug-in to perform the following tasks.\n\n\n\n* Run your code snippets, or actions, on Cloud Functions. See [Creating and invoking actions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions).\n* Create triggers and rules to enable your actions to respond to events. See [Creating triggers and rules](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-triggers).\n* Bundle actions and configure external events sources. See [Create and use packages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_ov).\n* Explore the catalog of packages and enhance your applications with external services. See [Adding IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-services).\n\n\n\nComplete the following steps to install the Cloud Functions CLI plug-in\n\n\n\n1. Install the Cloud Functions plug-in.\n\nibmcloud plugin install cloud-functions\n2. Verify that the plug-in is installed.\n\nibmcloud plugin list\n\nExample Output\n\nPlugin Name Version\ncloud-functions/wsk/functions/fn 1.0.32\n3. All Cloud Functions commands begin with ibmcloud fn. To see everything that you can do with the Cloud Functions plug-in, run ibmcloud fn with no arguments.\n\nibmcloud fn", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-cli_install"}, {"document_id": "ibmcld_10820-7-1769", "score": 0.6807835102081299, "text": "\nObject Storage \n\nYou can extend the functionality of your IBM Cloud\u00ae Functions app by integrating with an IBM Cloud\u00ae Object Storage instance.\n\nBefore you begin\n\n\n\n* To learn about IBM Cloud Object Storage, see the [Getting started tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n* For more information about setting up the IBM Cloud Object Storage instance, see [Provision an instance IBM Cloud Object Storage](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-gs-devgs-dev-provision).\n\n\n\n\n\n Packages for Object Storage \n\nReview the following table for a list of Cloud Functions packages that you can use to work with your IBM Cloud Object Storage entities.\n\n\n\nTable 1. Cloud functions packages that you can use to work with your Object storage entities\n\n Package Availability Description \n\n [IBM Cloud Object Storage trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev) Pre-installed The IBM Cloud Object Storage trigger [listens for changes](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev) to an IBM Cloud Object Storage bucket. \n [IBM Cloud Object Storage package](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_install) Installable You can use the installable cloud-object-storage package to [read, write, and delete](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_install) from an IBM Cloud Object Storage bucket. \n\n\n\n\n\n\n\n Setting up the IBM Cloud Object Storage trigger \n\nWith the IBM Cloud Object Storage trigger, you can listen for changes to GPS street data stored in an IBM Cloud Object Storage bucket.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstorage"}, {"document_id": "ibmcld_05054-3754-5497", "score": 0.649488091468811, "text": "\nBut don't forget that there are many CLI and GUI tools readily available for use as part of your migration.\n\n\n\n* [COS CLI](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-cli-plugin-ic-cos-cli) can be used for many operations. For example, you may wish to use the CLI to configure your IBM Cloud Object Storage instances, and to create and configure buckets.\n* [AWS CLI](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-aws-cli) can be used to list your current bucket's contents to prepare for migrating from AWS, among other operations:\n\n\n\naws s3 ls --recursive s3://<BUCKET_NAME> --summarize > bucket-contents-source.txt\n\n\n\n* [rclone](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-rclone) has many uses, and we'll look at it specifically, next.\n\n\n\n\n\n Migrate your data \n\nBased on the process and tools you've chosen, you will want to choose a strategy for migrating your data. We can take a look at a simplified process using the command line and the Go-based rclone executable as an example.\n\n\n\n1. Install rclone from [either a package manager or precompiled binary](https://rclone.org/install/). There are more configuration options available with explanations at the IBM Cloud Object Storage [documentation](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-rclone).\n\ncurl https://rclone.org/install.sh | sudo bash\n\n\n\n\n\n Configure rclone with your AWS credentials \n\nYou may start by creating 'profiles' for your source and destination of the migration in rclone. A profile contains the configuration and credentials needed for working with your date. You will be migrating from AWS, so you will need those credentials to continue.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-migrate"}, {"document_id": "ibmcld_08849-2524-4430", "score": 0.6268612742424011, "text": "\nos_reference_code = \"DEBIAN_8_64\"\ndatacenter = \"dal09\"\nnetwork_speed = 10\nhourly_billing = true\nprivate_network_only = false\ncores = 1\nmemory = 1024\ndisks = [25]\nlocal_disk = false\n}\n2. Initialize Terraform on IBM Cloud.\n\nterraform init\n\nExample output:\n\nInitializing provider plugins...\n\nThe following providers do not have any version constraints in configuration, so the latest version was installed.\n\nTo prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested.\n\nTerraform on IBM Cloud has been successfully initialized!\n\nYou may now begin working with Terraform on IBM Cloud. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform on IBM Cloud commands should now work.\n\nIf you ever set or change modules or backend configuration for Terraform on IBM Cloud, rerun this command to reinitialize your working directory. If you forget, other commands detects it and remind you to do so if necessary.\n3. Generate an Terraform on IBM Cloud execution plan. When you execute this command, Terraform on IBM Cloud validates the syntax of your configuration file and resource definitions against the specifications that are provided by the IBM Cloud Provider plug-in.\n\nterraform plan\n\nExample output:\n\nRefreshing Terraform on IBM Cloud state in-memory prior to plan...\nThe refreshed state be used to calculate this plan, but not be persisted to local or remote state storage.\n\nAn execution plan has been generated and is shown here.\nResource actions are indicated with the following symbols:\n+ create\n\nTerraform on IBM Cloud perform the following actions:\n\n+ ibm_compute_vm_instance.vm1\nid: <computed>\nblock_storage_ids.: <computed>\ncores: \"1\"\ndatacenter: \"dal09\"\ndisks.: \"1\"\ndisks.0: \"25\"", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-manage_resources"}, {"document_id": "ibmcld_00580-33278-35323", "score": 0.6208773255348206, "text": "\nSo far, our API interactions were triggered by the dashboard or by using curl from the command line. In the following section, we see how IBM Cloudant is accessed programmatically.\n\nThe examples use Node.js, so if you want to try the code yourself, you need to install node and npm from nodejs.org.\n\nWe can then install the official IBM Cloudant Node.js library with npm install @cloudant/cloudant. (Npm is the package manager that comes with Node.js - allowing you to access thousands of open source projects and build them into your application for free).\n\nOnce the IBM Cloudant library is installed, we can build some source code. Let's go through this code snippet line-by line:\n\nThe IBM Cloudant service URL is gleaned from the environment variable that we created earlier.\n\nThe @cloudant/cloudant library is loaded into your Node.js app with the built-in required functions. We then create an instance of the library that is configured with the credentials we stored in the first line. We use the IBM Cloudant object to get a reference to the books database and store it in a variable database. We haven't made any API calls - only created data structures that store credentials and which database that we are working on. The main function calls db.list, which maps 1-1 with the _all_docs endpoint we saw earlier. The parameters passed to db.list must be familiar as the options that _all_docs expects to limit the result set and to return document bodies for each ID.\n\nSee another code snippet that writes a document.\n\nYou can see from the first line that standard JavaScript objects can be used in your code and sent to IBM Cloudant with no conversion, as they turn into JSON natively in JavaScript.\n\nWriting a document is simply a matter of calling db.insert, which maps to a PUT/POST API call or to _bulk_docs.\n\nTo summarize, the official libraries for IBM Cloudant are Java\u2122, Python, and Nodejs. They are thin wrappers around the IBM Cloudant HTTP API - so it's worth understanding the underlying API to understand all the parameters.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00500-13090-15172", "score": 0.6187577247619629, "text": "\nDue to sharding, IBM Cloudant offers no guarantees that the output of any two specific map functions passes to the same instance of a reduce call. You must not rely on any ordering. The reduce function that you use must consider all the values that are passed to it and return the correct answer irrespective of ordering. IBM Cloudant is also guaranteed to call your reduce function with rereduce=true at query time even if it didn't need to do so when it built the index. It's essential that your functions work correctly in that case (rereduce=true means that the keys parameter is null and the values array is filled with results from previous reduce function calls).\n\n\n\n\n\n Reduced value size \n\nIBM Cloudant computes view indexes and the corresponding reduce values then caches these values inside each of the B-tree node pointers. Now, IBM Cloudant can reuse reduced values when it updates the B-tree. You must pay attention to the amount of data that is returned from reduce functions.\n\nIt's best that the size of your returned data set stays small and grows no faster than log(num_rows_processed). If you ignore this restriction, IBM Cloudant does not automatically throw an error, but B-tree performance degrades dramatically. If your view works correctly with small data sets but quits working when more data is added, your view might violate the growth rate characteristic restriction.\n\n\n\n\n\n Execution environment \n\nYour indexing functions work in a memory-constrained environment where the document forms part of the memory used in the environment. Your code's stack and document must fit within the memory. We limit documents to a maximum size of 64 MB.\n\n\n\n\n\n No JavaScript reducers when options.partitioned is true \n\nDesign documents with options.partitioned set to true can't contain JavaScript reduce functions, only built-ins Erlang reducers such as _stats.\n\n\n\n\n\n\n\n Storing the view definition \n\nEach view is a JavaScript function. Views are stored in design documents. So, to store a view, IBM Cloudant simply stores the function definition within a design document.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-views-mapreduce"}, {"document_id": "ibmcld_12093-6301-8557", "score": 0.6181401610374451, "text": "\nThe support to use custom providers is not available in the shared multi-tenant Schematics service. It is only available with Agents. Agents does not include a local or private provider registry. The registry must be provided and configured by the user on the users private network accessible to the agents.\n\nBy default, Schematics jobs running the Terraform CLI will download Terraform provider plug-ins or Terraform modules from the public Terraform registry via the Internet or public network. When an Agent is deployed on a private network, security policies may dictate that a proxy or mirror site must be used for downloading and caching provider plug-ins. Additionally it may be desired to use custom developed Terraform providers to configure environment specific resources using Terraform.\n\nFor these usecases, Terraform allows configuration of provider download from alternate provider registries via the use of a provider_installation block in the Terraform CLI configuration. This allows customization of the Terraform default installation behavior. Review the Terraform documentation for [provider installation](https://developer.hashicorp.com/terraform/cli/config/config-fileprovider-installation) for more detail on configuring provider download.\n\nWhen using Agents, the following two workspace environment variables, can be used to configure the Terraform CLI to refer to an alternate repository and select providers by name and namespace from this registry.\n\n\n\n* The TF_NETWORK_MIRROR_URL Terraform private repository, website or Artifactory instance where custom Terraform providers are hosted.\n* The TF_NETWORK_MIRROR_PROVIDER_NAME name and namespace of provider that is to be downloaded from the custom location. Refer to the Terraform documentation for [provider naming and namespaces](https://developer.hashicorp.com/terraform/language/providers/requirementsnames-and-addresses). This is an optional variable. If not specified it is defaulted to all providers in all namespaces \"/\".\n\n\n\nSchematics auto generates the following Terraform CLI configuration file parameters which tell Terraform during job execution to use an alternate registry for some or all of the providers you intend to use.\n\nprovider_installation {\nnetwork_mirror {", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-faqs-agent&interface=ui"}, {"document_id": "ibmcld_05337-7-1416", "score": 0.608502984046936, "text": "\nCLI version history \n\nFind a summary of changes for each version of IBM Cloud\u00ae Code Engine CLI plug-in. Be sure to keep your CLI up-to-date so that you can use all the available commands and their options.\n\n\n\nChanges in the IBM Cloud Code Engine CLI\n\n Version Release date Changes \n\n 1.45.1 06 July 2023 <br><br> * Fixed various bugs.<br><br><br> \n 1.45.0 29 June 2023 <br><br> * Added support for the Functions command group. Use these commands to create and work with functions on Code Engine. See [Working with Functions](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-work) and [Code Engine CLI reference (domainmapping command)](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-function).<br> * Fixed various bugs.<br><br><br> \n 1.44.0 22 June 2023 <br><br> * Added support for the --scale-down-delay option on the [app create](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-application-create) and [app update](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-application-update) commands.<br> * Fixed various bugs.<br><br><br> \n 1.43.7 08 June 2023 <br><br> * Fixed various bugs.<br><br><br> \n 1.43.5 16 May 2023 <br><br> * Fixed various bugs.<br> * Updated translations for the CLI.<br><br><br> \n 1.43.4 27 April 2023 <br><br> * Fixed various bugs.<br><br><br> \n 1.43.3 14 April 2023 <br><br> * Fixed configuration error (Windows only).<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli_versions"}, {"document_id": "ibmcld_05125-1346-2681", "score": 0.6057628393173218, "text": "\nThe official s3fs documentation suggests using libcurl4-gnutls-dev instead of libcurl4-openssl-dev. Either work, but the OpenSSL version may result in better performance.\n\nFor macOS, you will need to build s3fs from source:\n\nEnsure you have the following packages installed (all are available via [Homebrew](https://brew.sh)):\n\n\n\n* macfuse\n* automake\n* gcc\n* curl\n* libxml2\n* pkg-config\n* openssl\n\n\n\nAnd as noted in the output of the openssl install, you'll need to set these environment variables:\n\nexport LDFLAGS=\"-L/usr/local/opt/openssl@3/lib\"\nexport CPPFLAGS=\"-I/usr/local/opt/openssl@3/include\"\nexport PKG_CONFIG_PATH=\"/usr/local/opt/openssl@3/lib/pkgconfig\"\n\nBe aware that [macFUSE is closed-source software](https://osxfuse.github.io) containing a kernel extension, and may require a license for commercial use.\n\nFirst clone the Github repository:\n\ngit clone https://github.com/s3fs-fuse/s3fs-fuse.git\u00a0\n\nThen build s3fs:\n\ncd s3fs-fuse\n./autogen.sh\n./configure\nmake\n\nAnd install the binary:\n\nsudo make install\n\n\n\n\n\n Configuration \n\nStore your credentials in a file containing either <access_key>:<secret_key> or :<api_key>. This file needs to have limited access so run:\n\nchmod 0600 <credentials_file>\n\n\n\nNow you can mount a bucket using:\n\ns3fs <bucket> <mountpoint> -o url=http{s}://<endpoint> \u2013o passwd_file=<credentials_file>", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-s3fs"}, {"document_id": "ibmcld_13182-23364-24927", "score": 0.5953592658042908, "text": "\nFor example:\n\n% terraform init\n\nInitializing the backend...\n\nInitializing provider plugins...\n- Finding latest version of hashicorp/random...\n- Finding latest version of vmware/vcd...\n- Installing hashicorp/random v3.4.3...\n- Installed hashicorp/random v3.4.3 (signed by HashiCorp)\n- Installing vmware/vcd v3.8.2...\n- Installed vmware/vcd v3.8.2 (signed by a HashiCorp partner, key ID 8BF53DB49CDB70B0)\n\nPartner and community providers are signed by their developers.\nIf you'd like to know more about provider signing, you can read about it here:\nhttps://www.terraform.io/docs/cli/plugins/signing.html\n\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\nShow more\n2. Next, you can run terraform plan to see what will be deployed.\n\n% terraform plan\ndata.vcd_resource_list.list_of_vdcs: Reading...\ndata.vcd_resource_list.list_of_vdc_edges: Reading...\ndata.vcd_resource_list.list_of_catalog_items: Reading...", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vmware-as-a-service-tf"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16324-3229-5312", "score": 0.6958609819412231, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_16233-7-2298", "score": 0.6924446821212769, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_03330-4-2191", "score": 0.6900911331176758, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_07080-6045-7467", "score": 0.6899363398551941, "text": "\n[checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Deploy your solution. [Deploying your project](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Create a Conversational Search project. [Creating projects](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projects) \n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-product-overview"}, {"document_id": "ibmcld_09228-1610-2667", "score": 0.666124701499939, "text": "\n* [View on GitHub](https://github.com/with-watson/multilingual-chatbot)\n* [Try the demo](https://multilingual-chatbot.mybluemix.net/)\n* [Read more](https://medium.com/ibm-watson/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https://developer.ibm.com/components/watson-apis/patterns/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https://github.com/ibm/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https://github.com/IBM/tensorflow-hangul-recognition)", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-sample-apps"}, {"document_id": "ibmcld_16261-17057-18537", "score": 0.6535062789916992, "text": "\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant. Of course, a real-world application would use a more sophisticated user interface, and it might integrate with other applications such as a customer database or other business systems. It would also need to send additional data to the assistant, such as a user ID to identify each unique user. But the basic principles of how the application interacts with the Watson Assistant service would remain the same.\n\n\n\n\n\n Using the v1 runtime API \n\nUsing the v2 API is the recommended way to build a runtime client application that communicates with the Watson Assistant service. However, some older applications might still be using the v1 runtime API, which includes a similar method for sending messages to the workspace within a dialog skill. Note that if your app uses the v1 runtime API, it communicates directly with the workspace, bypassing the skill orchestration and state-management capabilities of the assistant.\n\nFor more information about the v1 /message method and context, see the [v1 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1message).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}, {"document_id": "ibmcld_03118-4-2208", "score": 0.6496058702468872, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy /message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-overview"}, {"document_id": "ibmcld_16365-6859-8897", "score": 0.6462358236312866, "text": "\n[This link](https://www.ibm.com/products/watson-assistant/demos/lendyr/demo.html){{target=\"_self\" rel=\"noopener noreferrer\"}} opens in the same tab.\n\n\n\nFor detailed information about the Markdown format, see the [CommonMark specification](https://spec.commonmark.org/).\n\n\n\n\n\n\n\n Live agent transfer \n\nThe web chat supports transferring the customer to a human in situations the assistant can't handle. If you configure one of the supported contact center integrations, the web chat can open a separate chat window in which the customer can communicate with a live agent.\n\nYour assistant can then initiate a transfer in situations when the assistant is unable to handle a customer's requests. (For more information about initiating a transfer, see [Connecting to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent).)\n\nFor information about how to add a contact center integration to the web chat, see [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa).\n\n\n\n\n\n Technical details \n\nThe web chat is displayed on your web site by a short JavaScript code snippet, which calls additional JavaScript code that is hosted by IBM Cloud. The hosted code is automatically updated with new features and fixes, so by default you will always have the latest version. (You can optionally [lock to a specific version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-versions) if you prefer to control upgrades yourself.)\n\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_07082-6438-8544", "score": 0.6443424224853516, "text": "\nThe built-in synchronization capabilities mean that your assistant can share the most up-to-date information available. Use the integrations that are provided with Watson Assistant to deploy an assistant that connects to this project to various platforms, including your company website, in minutes.\n\nThe documents that you add to this type of project are not enriched automatically.\n\nIf you need to perform more complex searches from your virtual assistant, you might want to create a Document Retrieval project instead of Conversational Search project. For more information, see [Choosing the right project type for a chatbot](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project).\n\nIBM Cloud\n\nAnother feature to consider enabling is the Emphasize the answer feature. When enabled, the answers that are returned to customers who interact with the assistant show the exact answer highlighted in bold font within the search response. For more information about how the exact answer is determined, see [Answer finding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\nFor more information about building a Watson Assistant search skill, see the appropriate documentation for your deployment:\n\n\n\nIBM Cloud Pak for Data\n\n[Adding a search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add).\nIBM Cloud\n\n[Embedding existing help content](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add)\n\nFrom the classic Watson Assistant experience, see [Creating a search skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n\n\n Content Mining \n\nUse this project type to discover hidden insights, trends, and relationships in your data.\n\nOnly users of installed deployments (IBM Cloud Pak for Data) or Premium or Enterprise plan managed deployments can create this type of project.\n\nThis project type is especially useful for analyzing structured data, such as data that you add by uploading a CSV file or by connecting to a database data source.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projects"}, {"document_id": "ibmcld_03330-3253-5192", "score": 0.6409139037132263, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09921-1508-2973", "score": 0.5653197169303894, "text": "\nsatisfied An affective response to perceived service quality \n sympathetic An affective mode of understanding that involves emotional resonance \n\n\n\n\n\n* Example response:\n\n{\n\"usage\": {\n\"text_units\": 1,\n\"text_characters\": 60,\n\"features\": 1\n},\n\"language\": \"en\",\n\"classifications\": [\n{\n\"confidence\": 0.564849,\n\"class_name\": \"excited\"\n},\n{\n\"confidence\": 0.355816,\n\"class_name\": \"satisfied\"\n},\n{\n\"confidence\": 0.126127,\n\"class_name\": \"polite\"\n},\n{\n\"confidence\": 0.026995,\n\"class_name\": \"sympathetic\"\n},\n{\n\"confidence\": 0.012211,\n\"class_name\": \"frustrated\"\n},\n{\n\"confidence\": 0.011065,\n\"class_name\": \"sad\"\n},\n{\n\"confidence\": 0.000872,\n\"class_name\": \"impolite\"\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n Migrating from Watson Tone Analyzer Customer Engagement endpoint to Natural Language Understanding \n\nYou can migrate your [Watson Tone Analyzer customer-engagement](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-utco) analysis requests to Natural Language Understanding. This can help you better understand your interactions with customers and improve your communications generally, or for specific customers.\n\n\n\n Reformatting your input data \n\nIn Watson Tone Analyzer, you pass the /v3/tone_chat method a JSON ToneChatInput object consisting of utterances, text, and an optional user string fields. For Natural Language Understanding, you pass a JSON object that contains text to be analyzed, and a language-specific model classification ID, to the /v1/analyze method.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics"}, {"document_id": "ibmcld_13761-1826-3662", "score": 0.5496118664741516, "text": "\nIn such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice. The second sample speaks the same text with the same voice but with the indicated style. A request that uses the <express-as> element fails if the style is not one of the supported values or is omitted from the element.\n\n\n\nTable 1. Speaking styles\n\n Style Example input text Audio sample \n\n cheerful \"Oh, that's good news. I am very happy for you!\" Your browser does not support the audio tag. \n \"<express-as style='cheerful'>Oh, that's good news. I am very happy for you!</express-as>\" Your browser does not support the audio tag. \n empathetic \"Oh, I'm sorry to hear that. I know how difficult that can be.\" Your browser does not support the audio tag. \n \"<express-as style='empathetic'>Oh, I'm sorry to hear that. I know how difficult that can be.</express-as>\" Your browser does not support the audio tag. \n neutral \"A five-alarm fire early this morning claimed the lives of more than a dozen residents.\" Your browser does not support the audio tag. \n \"<express-as style='neutral'>A five-alarm fire early this morning claimed the lives of more than a dozen residents.</express-as>\" Your browser does not support the audio tag. \n uncertain \"That's strange. Hmm, I don't know if I've seen this before.\" Your browser does not support the audio tag. \n \"<express-as style='uncertain'>That's strange.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_13074-16820-18514", "score": 0.5310004949569702, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_09913-2509-4265", "score": 0.5246835947036743, "text": "\n* [Norwegian (Nyorsk)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian-nyorsk)\n* [Polish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportpolish)\n* [Portuguese](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportportuguese)\n* [Romanian](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportromanian)\n* [Russian](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportrussian)\n* [Slovak](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportslovak)\n* [Spanish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportspanish)\n* [Swedish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportswedish)\n* [Turkish](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-supportturkish)\n\n\n\nLanguage support might be different if you are a IBM Cloud\u00ae Dedicated customer. If you are using IBM Cloud\u00ae Dedicated, check with your IBM salesperson to confirm which languages are supported in your environment.\n\n\n\n Arabic \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_09892-7-1976", "score": 0.5243473052978516, "text": "\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> /news\n> /art and entertainment\n> /movies and tv/television\n> /news\n> /international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about"}, {"document_id": "ibmcld_09913-6894-8823", "score": 0.5065609216690063, "text": "\nClassifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Hebrew \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Hindi \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Italian \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Japanese \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_09919-9389-11561", "score": 0.5012882947921753, "text": "\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics\n: [Tone analytics](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics) is now available, for English and French languages only. The tone analytics feature detects excited, frustrated, impolite, polite, sad, satisfied, and sympathetic tones from text.\n\n\n\n\n\n 12 October 2021 \n\nKeyword and syntax support for additional languages\n: Support for keywords and syntax is now available, for all public and premium service instances, for the following languages: Hindi, Romanian, and Turkish. In addition, syntax is available for all supported languages. For details, see [Language support](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support).\n\n\n\n\n\n 15 August 2021 \n\nCustom classification feature\n: The [custom classifications](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-classifications) feature is now generally available (GA).\n\nCategories stock model updated\n: The [categories stock model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy) has been updated to use the [IAB Tech Lab 2.0 taxonomy](https://iabtechlab.com/standards/content-taxonomy/).\n\n\n\n\n\n 5 May 2021 \n\nAdvanced Rules beta feature deprecated\n: The advanced rules beta feature is deprecated. As of June 10, 2021, you will not be able to deploy advanced rules models to Natural Language Understanding; existing models will keep running. After June 24, 2021, no advanced rules models will run in Natural Language Understanding.\n\n\n\n\n\n 25 March 2021 \n\nCustom classifications beta feature", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-release-notes"}, {"document_id": "ibmcld_09913-5372-7266", "score": 0.4964398145675659, "text": "\n* Relevance ranking is not supported.\n\n\n\n\n\n Dutch \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n English \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X X (Beta) \n Classifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n Finnish \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n French \n\n\n\n Feature Standard Support [Custom model](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support"}, {"document_id": "ibmcld_13074-15255-17243", "score": 0.4911974370479584, "text": "\nSee [Entity extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_09919-7713-9881", "score": 0.48498356342315674, "text": "\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-release-notes"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08197-0-402", "score": 0.6784919500350952, "text": "\n\n\n\n\n\n\n  Supported browsers \n\nFor a list of supported browsers, see [Required Browsers for IBM Cloud\u00ae](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor Safari, clear the options Prevent cross-site tracking and Block all cookies under Safari > Preferences > Privacy.\n\nIf you encounter problems when you use these browsers, disable your browser plug-ins.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-help-support-browsers"}, {"document_id": "ibmcld_16270-0-505", "score": 0.6646897792816162, "text": "\n\n\n\n\n\n\n  Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see [IBM Cloud prerequisites](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overviewweb-chat-architecture-browsers).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-browser-support"}, {"document_id": "ibmcld_04083-11129-13211", "score": 0.6269863247871399, "text": "\nWhy are my console actions failing in my Chrome browser Version 77.0.3865.90 (Official Build) (64-bit)? \n\n What\u2019s happening \n\nThe console has been working successfully, but requests have started to fail. For example, after I create an ordering service and open it I see the error: Unable to get system channel. If you associated an identity without administrative privilege on the ordering service node, you will not be able to view or manage ordering service details.\n\n Why it\u2019s happening \n\nThis problem can be caused by a [bug](https://bugs.chromium.org/p/chromium/issues/detail?id=1006243) introduced by the Chrome browser Version 77.0.3865.90 (Official Build) (64-bit) that causes actions from the browser to fail.\n\n How to fix it \n\nTo resolve this problem, open the console in a new browser tab in Chrome. Any identities that you saved in your console wallet will persist in the new browser tab. To avoid this problem you can upgrade your Chrome browser version. Ensure you have downloaded all of your wallet identities to your local machine before closing your browser.\n\n\n\n\n\n When I hover over my node, the status is Status unavailable or Status unknown, what does this mean? \n\n What\u2019s happening \n\nA CA, peer, or ordering node has a gray status box, meaning the status of the node is not available. Ideally, when you hover over any node, the node status should be Running.\n\n Why it\u2019s happening \n\nThis problem can occur if the node is newly created and the deployment process has not completed. If the node is a CA and the status has been gray for more than a few minutes, then it is likely that the deployment process has failed. Peers and ordering nodes take longer to deploy, but this condition can also occur when the health checker that runs against the peer or ordering nodes cannot contact the node. The request for status can fail with a timeout error because the node did not respond within a specific time period, the node could be down, or network connectivity is down.\n\n How to fix it \n\nIf this is a new node, wait a few more minutes for the deployment to complete.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-v2-troubleshooting"}, {"document_id": "ibmcld_11112-0-1295", "score": 0.6231699585914612, "text": "\n\n\n\n\n\n\n  What are the IBM Cloud prerequisites? \n\nThe prerequisites for using the IBM Cloud\u00ae platform are limited, but we do have a few.\n\n\n\n  Browsers \n\nThe following table specifies the minimum required browser software for IBM Cloud.\n\n\n\nTable 1. Minimum required browser software for IBM Cloud\n\n Browser  Minimum Required Browser Software                                                                                                \n\n Chrome   Latest version -1 for your operating system                                                                                      \n Firefox  Latest regular -1 and ESR versions for your operating system, see [Mozilla Firefox Extended Support Release](https://www.mozilla.org/en-US/firefox/organizations/) for more details  \n Edge     Latest version -1 for Windows                                                                                                    \n Safari   Latest version -1 for Mac                                                                                                        \n\n\n\n\n\n\n\n  Command-line interface \n\nThe IBM Cloud command-line interface (CLI) is constantly changing. To see the latest CLI version, go to [Getting started with the IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platform"}, {"document_id": "ibmcld_08822-0-509", "score": 0.6226208209991455, "text": "\n\n\n\n\n\n\n  Why do I get redirected by the browser to install MotionPro client when it's already installed on my Mac? \n\nThis is a known issue with the combination of the OSX Operating System (macOS BigSur 11.4) and the Firefox browser (89.0.2 64-bits).\n\n  What\u2019s happening \n\nThis might occur when you visit the URL site for the VPN directly and log in.\n\n  How to fix it \n\nTo avoid this issue, launch the MotionPro client from your local system rather than accessing one of the VPN endpoints from a browser.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-troubleshoot-browser-redirect"}, {"document_id": "ibmcld_07578-7341-9464", "score": 0.6147360801696777, "text": "\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-7341-9464", "score": 0.6147360801696777, "text": "\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13761-5201-6996", "score": 0.6105309724807739, "text": "\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application/json\" --header \"Accept: audio/wav\" --output partial-cheerful-style.wav --data \"{\"text\":\"<express-as style='cheerful'>Oh, that's good news!</express-as> Do you need any further help?\"}\" \"{url}/v1/synthesize?voice=en-US_EmmaExpressive\"\n\n\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a number of common interjections based on context. In the resulting audio, it gives them the natural emphasis that a human would use in normal conversation.\n\nTable 2 lists the interjections that the service recognizes and provides examples of how they are pronounced in synthesized speech. The samples use the en-US_AllisonExpressive voice. The table shows the primary spelling of each interjection. The service recognizes alternative spellings for some of the interjections. For example, oh and ohh produce the same sound, as do hmm and hmmm. However, the service produces slightly different pronunciations for other alternative spellings, such as ooh and uhm,\n\n\n\nTable 2. Interjections that are emphasized\n\n Interjection Example sentence Audio sample \n\n aha \"Aha. So that's the secret.\" Your browser does not support the audio tag. \n hmm \"Hmm. I'm not sure I understand.\" Your browser does not support the audio tag. \n huh \"Huh, I hadn't noticed that.\" Your browser does not support the audio tag. \n oh \"Oh, let me get that for you.\" Your browser does not support the audio tag. \n uh \"Uh, let me check.\" Your browser does not support the audio tag. \n uh-huh \"Uh-huh, that's right.\" Your browser does not support the audio tag. \n um \"That's, um, not quite right.\" Your browser does not support the audio tag. \n\n\n\n\n\n Enabling or disabling interjections with SSML", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_06942-4977-6807", "score": 0.6085454225540161, "text": "\n[Help icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/help.svg) from the header of any page in the product user interface to open the Discovery documentation.\n\n\n\n\n\n Browser support \n\nIBM Cloud Pak for Data\n\n\n\n* The minimum required browser software for the product user interface includes the following browsers:\n\nGoogle Chrome\n: Latest version -1 for your operating system\n\nMozilla Firefox\n: Latest regular -1 and Extended Support Release (ESR) version for your operating system\n\nMicrosoft Edge\n: Latest version -1 for Windows\n\nApple Safari\n: Latest version -1 for Mac\n* The IBM Cloud Pak for Data web client where you create service instances supports the IBM Cloud Pak for Data requirements. For more information, see [Supported web browsers](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=requirements-softwaresoftware-reqs__web)\n\n\n\nIBM Cloud\n\n\n\n* Deployments of Discovery that are managed by IBM Cloud follow the IBM Cloud requirements. For more information, see [Prerequisites](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platform)\n* For more information about browser support for deployments that are provisioned with Cloud Pak for Data as a Service, see [Which web browsers are supported for Cloud Pak for Data as a Service](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/browser-support.html).\n\n\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support) topic.\n\n\n\n\n\n Beta features \n\nIBM releases services, features, and language support for your evaluation that are classified as beta. These features might be unstable, might change frequently, and might be discontinued with short notice.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-about"}, {"document_id": "ibmcld_00362-3997-6008", "score": 0.6008042097091675, "text": "\n* The browser checks those CORS response headers to make sure that the CORS request is allowed.\n* If the browser sees that the intended resource request should be allowed by the server, it makes a second request to the browser with the intended HTTP method, whether GET, POST, PUT and so on, with the same CORS request headers.\n\n\n\nAfterward, the communication between the browser and CORS origin (different than that of the web page) proceeds as if it was a simple CORS request. Similar to a simple CORS request, content and resources are accessible and can be loaded if this second CORS request is allowed.\n\n\n\n\n\n\n\n Setting up CORS at your origin \n\nAs shown in the previous diagrams, CORS is initiated by the requesting HTTP client. However, the effects depend on the requested origin. For your content to be ready for CORS requests, your origin must be configured correctly to respond with the correct CORS response headers and the correct access permissions.\n\nThe following example shows a basic CORS configuration for a Nginx server:\n\nhttp {\n some http context configs\n\nserver {\n some server context configs\n\n URI path to some content\nlocation /my-static-content {\n\n some location context configs\n\n Handle simple requests\n\n Consider only \"HTTP GET\" requests (content fetching)\nif ($request_method = 'GET') {\n\n Allows the browser to access data from this server during CORS,\n only if the request comes from a web page from the following origin\nadd_header 'Access-Control-Allow-Origin' 'https://www.example.com';\n}\n\n Handle preflight requests\nif ($request_method = 'OPTIONS') {\n\n Allows the browser to access data from this server during CORS,\n only if the request comes from a web page from the following origin\nadd_header 'Access-Control-Allow-Origin' 'https://www.example.com';\n\n Allows only GET requests\nadd_header 'Access-Control-Allow-Methods' 'GET';\n\n Allows the following headers in the browser's request headers\n that may have been added by anything other than what the browser had added automatically", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-cors-and-cors-requests-through-your-cdn"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13074-16820-18514", "score": 0.6544462442398071, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_13074-15255-17243", "score": 0.598246693611145, "text": "\nSee [Entity extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_16356-7-2036", "score": 0.5978853106498718, "text": "\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases"}, {"document_id": "ibmcld_16313-10077-11045", "score": 0.596278965473175, "text": "\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}, {"document_id": "ibmcld_03027-8135-10108", "score": 0.5873667597770691, "text": "\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_13333-1778-4047", "score": 0.5872489213943481, "text": "\nYou can set a threshold below which such events are ignored.\n\n\n\nBy default, speech activity detection is configured to provide optimal performance for the general case for each model. For specific cases, the default settings might not be optimal and can lead either to slow transcription or to word insertions and deletions. You are encouraged to experiment with different settings to determine which values work best for your audio.\n\n\n\n\n\n Speech detector sensitivity \n\nUse the speech_detector_sensitivity parameter to adjust the sensitivity of speech activity detection. Use the parameter to suppress word insertions from music, coughing, and other non-speech events. The service biases the audio it passes for speech recognition by evaluating chunks of the input audio against prior models of speech and non-speech activity.\n\nSpecify a float value between 0.0 and 1.0. The default value is 0.5, which provides a reasonable compromise for the level of sensitivity. A value of 0.0 suppresses all audio (no speech is transcribed). A value of 1.0 suppresses no audio (speech detection sensitivity is disabled). The values increase on a monotonic curve of sensitivity versus speech. Specifying one or two decimal places of precision (for example, 0.55) is typically more than sufficient.\n\nThis parameter can affect both the quality and the latency of speech recognition:\n\n\n\n* Lower values can decrease latency because less audio is potentially passed for speech recognition. However, a low setting might discard chunks of audio that contain actual speech, losing viable content from the transcript.\n* Higher values can increase latency because more audio is potentially passed for speech recognition. However, a high setting might pass chunks of audio that contain non-speech events, adding spurious content to the transcript.\n\n\n\n\n\n Speech detector sensitivity example \n\nThe following example request specifies a value of 0.6 for the speech_detector_sensitivity parameter with the synchronous HTTP interface. The service recognizes slightly more potential non-speech events than it would by default.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @{path}audio-file1.flac \"{url}/v1/recognize?speech_detector_sensitivity=0.6\"", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-detection"}, {"document_id": "ibmcld_13761-1826-3662", "score": 0.5848225355148315, "text": "\nIn such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice. The second sample speaks the same text with the same voice but with the indicated style. A request that uses the <express-as> element fails if the style is not one of the supported values or is omitted from the element.\n\n\n\nTable 1. Speaking styles\n\n Style Example input text Audio sample \n\n cheerful \"Oh, that's good news. I am very happy for you!\" Your browser does not support the audio tag. \n \"<express-as style='cheerful'>Oh, that's good news. I am very happy for you!</express-as>\" Your browser does not support the audio tag. \n empathetic \"Oh, I'm sorry to hear that. I know how difficult that can be.\" Your browser does not support the audio tag. \n \"<express-as style='empathetic'>Oh, I'm sorry to hear that. I know how difficult that can be.</express-as>\" Your browser does not support the audio tag. \n neutral \"A five-alarm fire early this morning claimed the lives of more than a dozen residents.\" Your browser does not support the audio tag. \n \"<express-as style='neutral'>A five-alarm fire early this morning claimed the lives of more than a dozen residents.</express-as>\" Your browser does not support the audio tag. \n uncertain \"That's strange. Hmm, I don't know if I've seen this before.\" Your browser does not support the audio tag. \n \"<express-as style='uncertain'>That's strange.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_16364-21733-23882", "score": 0.5800756812095642, "text": "\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases).\n\nChanges to unrecognized requests algorithm\n: In Analyze, the Recognition page lets you view groups of similar unrecognized requests. You can use the requests as example phrases in new or existing actions to address questions and issues that aren't being answered by your assistant. With this release, the criteria for grouping the requests is relaxed for customers with lesser amounts of data. Also, the group names have been improved with better grammar and to be more representative of the requests. For more information, see [Use unrecognized requests to get action recommendations](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 1 February 2023 \n\nActions templates updated with new design and new choices\n: The actions template catalog has a new design that lets you select multiple templates at the same time. It also has new and updated templates, including starter kits you can use with external services such as Google and HubSpot. For more information, see [Building actions from a template](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-templates).\n\n\n\n\n\n 26 January 2023 \n\nDisplay formats for variables\n: In Global settings for actions, Display formats lets you specify the display formats for variables that use date, time, numbers, currency, or percentages. You can also choose a default locale to use if one isn't provided by the client application.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_13443-7-2262", "score": 0.5799782872200012, "text": "\nKeyword spotting and word alternatives \n\nThe IBM Watson\u00ae Speech to Text service can identify user-specified keywords in its transcription results. It can also suggest alternative words that are acoustically similar to the words of a transcript. In both cases, the keywords and word alternatives must meet a user-specified level of confidence.\n\n\n\n Keyword spotting \n\nThe keywords and keywords_threshold parameters are supported only with previous-generation models, not with next-generation models.\n\nThe keyword spotting feature detects specified strings in a transcript. The service can spot the same keyword multiple times and report each occurrence. The service spots keywords only in the final results, not in interim results. By default, the service does no keyword spotting.\n\nTo use keyword spotting, you must specify both of the following parameters:\n\n\n\n* Use the keywords parameter to specify an array of strings to be spotted. The service spots no keywords if you omit the parameter or specify an empty array. A keyword string can include more than one token. For example, the keyword Speech to Text has three tokens. Keyword matching is case-insensitive, so Speech to Text is effectively equivalent to speech to text.\n\nFor US English, the service normalizes each keyword to match spoken versus written strings. For example, it normalizes numbers to match how they are spoken as opposed to written. For other languages, keywords must be specified as they are spoken.\n* Use the keywords_threshold parameter to specify a probability between 0.0 and 1.0 for a keyword match. The threshold indicates the lower bound for the level of confidence the service must have for a word to match the keyword. A keyword is spotted in the transcript only if its confidence is greater than or equal to the specified threshold.\n\nSpecifying a small threshold can potentially produce many matches. If you specify a threshold, you must also specify one or more keywords. Omit the parameter to return no matches.\n\n\n\nThe following limits apply to keyword spotting:\n\n\n\n* You can spot a maximum of 1000 keywords with a single request.\n* A single keyword can have a maximum length of 1024 characters. The maximum effective length for double-byte languages might be shorter.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spotting"}, {"document_id": "ibmcld_13741-6046-8162", "score": 0.5794650912284851, "text": "\nYou can use the parameter to direct the service to spell out individual characters more slowly, in groups of one, two, or three characters. Use the parameter with the SSML <say-as> element to control how the characters of a string are synthesized. For more information, see [Specifying how strings are spelled out](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-paramsparams-spell-out-mode).\n\nThe spell_out_mode parameter is beta functionality that is supported only for German voices.\n\n\n\n\n\n Word timings \n\nWith the WebSocket interface, you can obtain timing information about the location of words in the audio that the service returns. Timing information is useful for synchronizing the input text and the audio.\n\nYou can use the SSML <mark> element to identify specific locations, such as word boundaries, in the audio. For languages other than Japanese, you can also request word timing information for all words of the input text. For more information, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n\n\n\n\n\n\n\n Using speech synthesis features with expressive neural voice \n\nWith expressive neural voices, the service supports additional features that modify how the text that you pass is synthesized into audio.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. You can embellish the voices' natural tendencies by indicating that all or some of the text is to emphasize a specific style: cheerful, empathetic, neutral, or uncertain. You use SSML to indicate the style and the text to which it is to be applied. For more information, see [Using speaking styles](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressivesyntheses-expressive-styles).\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a collection of common interjections based on context.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-features"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03655-0-1101", "score": 0.5425167083740234, "text": "\n\n\n\n\n\n\n  FAQs for custom image templates \n\n\n\n  Why don\u2019t I see some of my disks as choices on the 'Create image template' page? \n\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n\n\n\n\n\n  Why did my capture fail? \n\nWhen a capture fails, an error occurred. If the error can be resolved, you might be contacted by our support personnel. Until the error is resolved, a completed image isn't in the portal. If you want to know why the capture failed, you can [contact support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n  Why don't I see my captured images? \n\nIf you don\u2019t see a captured image in your portal, the capture experienced an unrecoverable error. For more information, [contact support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-faqs-image-templates"}, {"document_id": "ibmcld_03707-0-719", "score": 0.5218536257743835, "text": "\n\n\n\n\n\n\n  Why can\u2019t I access details about my commitments? \n\nYou are unable to view your account's commitments and subscriptions in the IBM Cloud\u00ae console.\n\n  What\u2019s happening \n\nYou try to view the Commitments and Subscriptions page, but a message is displayed that says Looks like you don't have access to view this page.\n\n  Why it\u2019s happening \n\nYou don't have the correct access to view this information. To access this information, you need an access policy with the Viewer role or higher on the Billing account management service.\n\n  How to fix it \n\nContact your administrator for access. For more information, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles) for more information.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-access-commit-page"}, {"document_id": "ibmcld_12754-0-705", "score": 0.5035204887390137, "text": "\n\n\n\n\n\n\n  Why don't I see any results? \n\nYou've created a profile or a rule but don't see any results.\n\n  What\u2019s happening \n\nYou can't find the results for your new profile or rule in your account.\n\n  Why it\u2019s happening \n\nYou might not be able to view results for the following reasons:\n\n\n\n*  Your rule isn't associated with a specification or profile.\n*  Your attachment hasn't been evaluated yet.\n*  An error occurred during the scan.\n\n\n\n  How to fix it \n\nDepending on the reason, you might try one or more of the following options to resolve the issue.\n\n\n\n*  Verify that the attachment is created.\n*  Wait for the scan to run.\n*  Wait 24 hours for the next scan to run, or open a support ticket.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-ts-results"}, {"document_id": "ibmcld_13041-1336-3131", "score": 0.48760271072387695, "text": "\nCheck to be sure that you have the [IBM Cloud prerequisites](https://cloud.ibm.com/docs/overview?topic=overview-prereqs-platform).\n2. In the IBM Cloud catalog, select App ID. The service configuration screen opens.\n3. Give your service instance a name, or use the preset name.\n4. Select your pricing plan and click Create.\n\n\n\nThat's it! You're ready to start configuring your application settings.\n\n\n\n\n\n Step 2: Configure a sample app \n\nYou can use one of the preconfigured sample apps to get familiar with working with the service.\n\nOut of the box, the sample apps are configured with two identity providers and the ability to review authentication. Sample apps are offered in iOS Swift, Android, Node.js, Java and Single-page application. If you don't see a language in which you feel comfortable working, don't worry! You can integrate App ID into your own application by using the provided APIs.\n\nTo build a sample app:\n\n\n\n1. Click Download Sample.\n2. Click on the language of your choice to download the sample. Don't see the language you're looking for? Don't worry! You can take advantage of App ID through the APIs.\n3. Be sure that you have the prerequisites installed or completed.\n4. Follow the Build & Run steps to set up your sample with App ID.\n5. Click Review Activity to see any authentication events that occurred. Any type of sign in creates an event that is visible on this page.\n6. Customize the sign in widget.\n\n\n\n1. Add an image such as a brand logo by clicking Select and browsing your local system for an image to upload.\n2. Choose a color scheme by either selecting one of the color options or specifying in a hex value.\n3. Change between web and mobile to see how the color scheme looks on each type of device.\n4. When you're happy with your choices, click Save Changes.", "title": "", "source": "https://cloud.ibm.com/docs/services/appid?topic=appid-getting-started"}, {"document_id": "ibmcld_11913-34045-35103", "score": 0.4868878722190857, "text": "\nDo not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-endpoint - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-location - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n\n\n\n\n\n1. Create the storage configuration and specify the updated values. In this example, the osd-device-path parameter is updated to include the device IDs of the disks that you want to use and the num-of-osd value is increased to 2. Do not specify the Object Storage parameters when you create your configuration if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-storage-odf-local"}, {"document_id": "ibmcld_11914-34110-35168", "score": 0.4868878722190857, "text": "\nDo not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-endpoint - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n* ibm-cos-location - Optional: Use the same parameter value as in your existing configuration. Do not specify this parameter if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.\n\n\n\n\n\n1. Create the storage configuration and specify the updated values. In this example, the osd-device-path parameter is updated to include the device IDs of the disks that you want to use and the num-of-osd value is increased to 2. Do not specify the Object Storage parameters when you create your configuration if you don't use an IBM Cloud Object Storage service instance as your backing store in your existing configuration.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-storage-odf-local&interface=ui"}, {"document_id": "ibmcld_02259-0-1260", "score": 0.48166757822036743, "text": "\n\n\n\n\n\n\n  Why can't I manage a service ID that I created and previously had access to? \n\nIn the case that you aren't able to manage a service ID that you created in another user's account, you might need to check your assigned access.\n\n  What\u2019s happening \n\nYou don't have access to manage a service ID that you created in an account that you're not the owner of. You received an error message about not having the required access, but you used to be able to manage it.\n\n  Why it\u2019s happening \n\nIf you create a service ID in an account that you don't own, an administrator policy for that specific service ID is automatically generated for you only if you don't already have access to manage service IDs in the account. For example, if you are already assigned the Administrator role on the IAM Identity service, then a new policy is not automatically generated because you already have access. However, if the account administrator later revokes your access as an administrator on the IAM Identity service, then you can no longer manage the service IDs that you created in the account.\n\n  How to fix it \n\nRequest the correct level of access from the account administrator to manage all service IDs in the account or just the specific ones that you created.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-troubleshoot-serviceid-access"}, {"document_id": "ibmcld_12601-0-1026", "score": 0.4783327281475067, "text": "\n\n\n\n\n\n\n  Why can't I see the enterprise subscriptions? \n\n  What\u2019s happening \n\nWhen you go to view the Subscriptions page in the IBM Cloud\u00ae console from a child account, the following message is displayed:\n\n> Looks like you don't have permission to view subscription data for this account. Contact your account owner or administrator to request access.\n\nThe following message is displayed in the Billing section on your enterprise dashboard:\n\n> Looks like you don't have permission to view this information. Learn more about IAM access.\n\n  Why it\u2019s happening \n\nAccess to billing and payment information for future billing periods is restricted to users in the enterprise account. Users in a child account can't access billing and payment information, such as subscriptions, even if they previously had access in the account.\n\n  How to fix it \n\nTo view or manage billing, you need to be invited to the enterprise account and given access to the Billing service in that account. Contact the account owner to request access.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-viewsub-enterprise"}, {"document_id": "ibmcld_00533-1561-3443", "score": 0.4617079496383667, "text": "\nAt those times, IBM Cloudant returns the document normally, as though no conflict exists. However, the version that is returned isn't necessarily the most current version. Instead, the version is selected based on an internal algorithm that considers multiple factors. You must not assume that when documents are returned they're always the most current.\n\n\n\n\n\n How do I identify a document with a conflict? \n\nIf a conflict with a document exists and you try to update it, IBM Cloudant returns a 409 response. If you try to update a document while you're offline, IBM Cloudant can't check for potential conflicts, and you don't receive a 409 response.\n\nWhen this situation happens, it's best to check for document conflicts when you're back online. If you need to find document conflicts, use the following example map function:\n\nfunction (doc) {\nif (doc._conflicts) {\nemit(null, [doc._rev].concat(doc._conflicts));\n}\n}\n\nIf you want to find conflicts within multiple documents in a database, write a [view](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-views-mapreduce).\n\n\n\n\n\n What happens if I ignore conflicts? \n\nIf you don't check for conflicts, or don't fix them, your IBM Cloudant database has the following problems:\n\n\n\n* Document inconsistency increases because conflicting documents continue to multiply.\n* Database size increases because documents with conflicts must be kept until the conflict is resolved.\n* Performance degrades because it takes more work for IBM Cloudant to respond to each request since it has to go through all the conflicted documents to find the \"best possible\" version.\n\n\n\n\n\n\n\n How do I resolve conflicts? \n\nAfter you find a conflict, follow these four steps to resolve it.\n\n\n\n1. [Get](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccget-conflicting-revisions-mvcc) the conflicting revisions.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-document-versioning-conflicts"}, {"document_id": "ibmcld_01602-3776-5022", "score": 0.45585209131240845, "text": "\n[View more](https://cloud.ibm.com/docs/overview?topic=overview-whatsnew)03 April 2023 | Customize your private catalog and private products\n\nYou can enhance the appearance of your private catalog to match your brand by adding a custom banner image to your private catalogs. You can also make it easier for users to search for your products added to a private catalog by specifying a custom provider name. Adding a custom provider name for your private products can help users find them quickly by using the Provider filter in the catalog.\n\n29 March 2023 | Generate a report on the MFA status of account users\n\nUsers that don't meet MFA requirements leave your account vulnerable. You can now identify the users in your account that don't satisfy your MFA requirements.\n\n29 March 2023 | An extra layer of security for users that don't use MFA\n\nIBM recommends enabling multifactor authentication (MFA) for all users in your account, but some automation scenarios might require you to exclude specific users from your MFA requirement. For users that are excluded from MFA, you can make access more secure by disabling CLI logins with only a username and password. This way, you require an API key to log in to the CLI or users can log in with --sso.", "title": "", "source": "https://cloud.ibm.com/docs/account/eu_hipaa_supported.html"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02998-8791-9815", "score": 0.7394675612449646, "text": "\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-custom-app).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03184-3236-4998", "score": 0.6762639880180359, "text": "\nThe client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable. This node responds with text output that includes the weather forecast, which the client application displays to the user. (If the $weather_forecast variable is not set, another child node can handle this case and report an error.)\n\n\n\nIt is also possible to call an external Web service directly from a dialog node, without involving the client application, by defining a webhook. For more information about how to call an external service using a webhook, see [Making a programmatic call from a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-webhooks).\n\n\n\n Procedure \n\nTo request a client action from a dialog node, complete the following steps:\n\n\n\n1. In the dialog node from which you want to request the client action, open the JSON editor for the node response.\n\n![Shows how to access the JSON editor associated with a standard noderesponse.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/contextvar-json-response.png)\n2. Use the following syntax to define the client action you want to request.\n\n{\n\"context\": {\n\"variable_name\" : \"variable_value\"\n},\n\"actions\": [\n{\n\"name\":\"<actionName>\",\n\"type\":\"client\",\n\"parameters\": {\n\"<parameter_name>\":\"<parameter_value>\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_03184-1586-3749", "score": 0.6737442016601562, "text": "\nIt is the responsibility of the client application to carry out the requested action, store the result in the context, and send it back to the dialog with the next message.\n\nYou might call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nThe following diagram illustrates how client actions work, using the example of an action to get a weather forecast.\n\n![Shows someone asking for a weather forecast and the dialog sending a request to a client app, which sends it to the external service and returns the result](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/forecast.png)\n\nThe flow of requests and responses follows this pattern:\n\n\n\n1. The client application sends a message containing user input that asks for a weather forecast (using the message or message_stateless method).\n2. The user input triggers a dialog node conditioned on a #weather intent. In its response to the client, this node specifies the get_weather client action, which is a name that the client application recognizes. (This is in addition to any text response, such as Checking the weather forecast....)\n3. When it receives this response, the client application recognizes that the get_weather action is being requested. It calls an external web service (/weather) to get the actual forecast information, passing any specified parameters (such as the user's location). The client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_02953-3805-5544", "score": 0.6724016666412354, "text": "\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_02998-7662-9256", "score": 0.6677803993225098, "text": "\n[An ending node was added to the dialog also.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03114-4-1709", "score": 0.6575214862823486, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Implementing responses \n\nA dialog node can respond to users with a response that includes text, images, or interactive elements such as clickable options. If you are building your own client application, you must implement the correct display of all response types returned by your dialog. (For more information about dialog responses, see [Responses](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-responses)).\n\n\n\n Response output format \n\nBy default, responses from a dialog node are specified in the output.generic object in the response JSON returned from the /message API. The generic object contains an array of up to 5 response elements that are intended for any channel. The following JSON example shows a response that includes text and an image:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"OK, here's a picture of a dog.\"\n},\n{\n\"response_type\": \"image\",\n\"source\": \"http://example.com/dog.jpg\"\n}\n],\n\"text\" : [\"OK, here's a picture of a dog.\"]\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more\n\nAs this example shows, the text response (OK, here's a picture of a dog.) is also returned in the output.text array. This is included for backward compatibility for older applications that do not support the output.generic format.\n\nIt is the reponsibility of your client application to handle all response types appropriately. In this case, your application would need to display the specified text and image to the user.\n\n\n\n\n\n Response types", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_03184-4-2189", "score": 0.6560741662979126, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Requesting client actions ![BETA](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/beta.png) \n\nAdd a client action to your dialog node to request that a client-side process run and return a result to the dialog.\n\nIf your assistant is integrated with a custom client using the API, you can use client actions to invoke functions that the client application completes. A client action defines a request for a client-side process, in a standardized format that your external client application can understand. Your external client application must use the provided information to carry out the requested action, which can be a local programmatic function, a call to an external service, or any other action the client can perform. The client then returns the result from the action to the dialog, which can process it further, display it to the user, or use it as a condition to determine subsequent flow.\n\nUnlike other action types, a client action does not make a direct call itself. Instead, it simply makes a request for the client application to do something, in the form of an action object that is included in a response from the dialog (along with any output text). This object includes a name identifying the requested action, along with any required parameters and the name of a context variable where the result should be stored. It is the responsibility of the client application to carry out the requested action, store the result in the context, and send it back to the dialog with the next message.\n\nYou might call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nThe following diagram illustrates how client actions work, using the example of an action to get a weather forecast.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_03114-14238-16113", "score": 0.6547032594680786, "text": "\n\"object_1\": {\n\"property_1\": \"Another string value\"\n}\n}\n}\n]\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more\n\nYour application can parse and display the data in any way you choose.\n\n\n\n\n\n\n\n Example: Implementing option responses \n\nTo show how a client application might handle option responses, which prompt the user to select from a list of choices, we can extend the client example described in [Building a client application](https://cloud.ibm.com/docs/assistant?topic=assistant-api-client). This is a simplified client app that uses standard input and output to handle three intents (sending a greeting, showing the current time, and exiting from the app):\n\nWelcome to the Watson Assistant example!\n>> hello\nGood day to you.\n>> what time is it?\nThe current time is 12:40:42 PM.\n>> goodbye\nOK! See you later.\n\nIf you want to try the example code shown in this topic, you should first set up the required workspace and obtain the API details you will need. For more information, see [Building a client application](https://cloud.ibm.com/docs/assistant?topic=assistant-api-client).\n\n\n\n Receiving an option response \n\nThe option response can be used when you want to present the user with a finite list of choices, rather than interpreting natural language input. This can be used in any situation where you want to enable the user to quickly select from a set of unambiguous options.\n\nIn our simplified client app, we will use this capability to select from a list of the actions the assistant supports (greetings, displaying the time, and exiting). In addition to the three intents previously shown (hello, time, and goodbye), the example workspace supports a fourth intent: menu, which is matched when the use asks to see a list of available actions.\n\nWhen the workspace recognizes the menu intent, the dialog responds with an option response:\n\n{\n\"output\": {", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_02872-1338-3179", "score": 0.6544042229652405, "text": "\n* Get data from another application or service.\n\n\n\nFor information about how to call an external service, such as a Cloud Functions web action, see [Making a programmatic call from a dialog node](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks).\n\nThe following diagram illustrates how you can use a client call to get weather forecast information, and return it to the user.\n\n![Shows someone asking for a weather forecast, the dialog sending a request to a client app, which sends it to the external service](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/forecast.png)\n\nNote that the client action calls the MyWeatherFunction program, which is a program that the client application runs. The client application makes the call to the external web service (/weather) to get the actual forecast information. The client application then returns the response to the dialog. When you add a client action to a dialog, a client application must exist that either does the processing itself or that passes information between your dialog and any external back-end services that you want to use.\n\n\n\n Procedure \n\nTo make a programmatic call to a client application from a dialog node, complete the following steps:\n\n\n\n1. In the dialog node from which you want to make the programmatic call, open the JSON editor.\n\n\n\n* To make a programmatic call that runs after the response for a node is evaluated, open the JSON editor for the node response.\n\n![Shows how to access the JSON editor associated with a standard node response.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/contextvar-json-response.png)\n\nIf the Multiple responses setting is On for the node, then you must click the Edit response!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-actions-client"}, {"document_id": "ibmcld_16261-17057-18537", "score": 0.648389458656311, "text": "\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant. Of course, a real-world application would use a more sophisticated user interface, and it might integrate with other applications such as a customer database or other business systems. It would also need to send additional data to the assistant, such as a user ID to identify each unique user. But the basic principles of how the application interacts with the Watson Assistant service would remain the same.\n\n\n\n\n\n Using the v1 runtime API \n\nUsing the v2 API is the recommended way to build a runtime client application that communicates with the Watson Assistant service. However, some older applications might still be using the v1 runtime API, which includes a similar method for sending messages to the workspace within a dialog skill. Note that if your app uses the v1 runtime API, it communicates directly with the workspace, bypassing the skill orchestration and state-management capabilities of the assistant.\n\nFor more information about the v1 /message method and context, see the [v1 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1message).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10596-7-2100", "score": 0.7144704461097717, "text": "\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud oc worker commands, and as NotReady in the Red Hat OpenShift dashboards and when you run oc get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-7-2098", "score": 0.7088484168052673, "text": "\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud ks worker commands, and as NotReady in the Kubernetes dashboards and when you run kubectl get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_05558-7-2091", "score": 0.7061171531677246, "text": "\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https://cloud.ibm.com/docs/containers?topic=containers-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-add_workers"}, {"document_id": "ibmcld_10710-7-1992", "score": 0.7022709846496582, "text": "\nWorker node states \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\n\n\n Critical state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA worker node can go into a Critical state for many reasons. See [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready) for more information and troubleshooting steps.\n\n\n\n\n\n Deleting state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleting state means that you requested to delete the worker node, possibly as part of resizing a worker pool or autoscaling the cluster. Other operations can't be issued against the worker node while the worker node deletes. You can't reverse the deletion process. When the deletion process completes, you are no longer billed for the worker nodes.\n\n\n\n\n\n Deleted state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleted state means that your worker node is deleted, and no longer is listed in the cluster or billed. This state can't be undone. Any data that was stored only on the worker node, such as container images, are also deleted.\n\n\n\n\n\n Deployed state \n\nYou can view the current worker node state by running the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nUpdates are successfully deployed to your worker node. After updates are deployed, Red Hat OpenShift on IBM Cloud starts a health check on the worker node. After the health check is successful, the worker node goes into a Normal state.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-worker-node-state-reference"}, {"document_id": "ibmcld_10035-7-2089", "score": 0.697919487953186, "text": "\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-add_workers"}, {"document_id": "ibmcld_06302-7-1990", "score": 0.6974327564239502, "text": "\nWorker node states \n\nYou can view the current worker node state by running the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\n\n\n Critical state \n\nYou can view the current worker node state by running the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA worker node can go into a Critical state for many reasons. See [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready) for more information and troubleshooting steps.\n\n\n\n\n\n Deleting state \n\nYou can view the current worker node state by running the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleting state means that you requested to delete the worker node, possibly as part of resizing a worker pool or autoscaling the cluster. Other operations can't be issued against the worker node while the worker node deletes. You can't reverse the deletion process. When the deletion process completes, you are no longer billed for the worker nodes.\n\n\n\n\n\n Deleted state \n\nYou can view the current worker node state by running the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nA Deleted state means that your worker node is deleted, and no longer is listed in the cluster or billed. This state can't be undone. Any data that was stored only on the worker node, such as container images, are also deleted.\n\n\n\n\n\n Deployed state \n\nYou can view the current worker node state by running the ibmcloud ks worker ls --cluster <cluster_name_or_ID> command and locating the State and Status fields.\n\nUpdates are successfully deployed to your worker node. After updates are deployed, IBM Cloud Kubernetes Service starts a health check on the worker node. After the health check is successful, the worker node goes into a Normal state.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference"}, {"document_id": "ibmcld_06128-11467-13651", "score": 0.6821417808532715, "text": "\nHow many worker nodes do I need to handle my workload? \n\nNow that you have a good idea of what your workload looks like, let's map the estimated usage onto your available cluster configurations.\n\n\n\n1. Estimate the max worker node capacity, which depends on what type of cluster you have. You don't want to max out worker node capacity in case a surge or other temporary event happens.\n\n\n\n* Single zone clusters: Plan to have at least three worker nodes in your cluster. Further, you want one extra node's worth of CPU and memory capacity available within the cluster.\n* Multizone clusters: Plan to have at least two worker nodes per zone, so six nodes across three zones in total. Additionally, plan for the total capacity of your cluster to be at least 150% of your total workload's required capacity, so that if one zone goes down, you have resources available to maintain the workload.\n\n\n\n2. Align the app size and worker node capacity with one of the [available worker node flavors](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesplanning_worker_nodes). To see available flavors in a zone, run ibmcloud ks flavors --zone <zone>.\n\n\n\n* Don't overload worker nodes: To avoid your pods competing for CPU or running inefficiently, you must know what resources your apps require so that you can plan the number of worker nodes that you need. For example, if your apps require less resources than the resources that are available on the worker node, you can limit the number of pods that you deploy to one worker node. Keep your worker node at around 75% capacity to leave space for other pods that might need to be scheduled. If your apps require more resources than you have available on your worker node, use a different worker node flavor that can fulfill these requirements. You know that your worker nodes are overloaded when they frequently report back a status of NotReady or evict pods due to the lack of memory or other resources.\n* Larger versus smaller worker node flavors: Larger nodes can be more cost efficient than smaller nodes, particularly for workloads that are designed to gain efficiency when they process on a high-performance machine.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-strategy"}, {"document_id": "ibmcld_06056-1578-4012", "score": 0.6796162724494934, "text": "\nReservation: The reservation contains details such as the container platform, worker node flavor, location, and infrastructure provider.\n\nContract: The example reservation has two contracts for different terms. One contract is for 10 worker nodes across 3 years. The other contract is for 5 worker nodes across 1 year. Therefore, the total capacity of the reservation is 15 worker nodes.\n\nClusters: Each cluster is in the same multizone region as the reservation, but can be in a different resource group. Reserved worker nodes from different reservations can be used in different clusters. A cluster can have a mix of reserved and regular, as-needed worker pools.\n\nWorker pools: You can create multiple worker pools in multiple clusters with your reserved worker nodes. Reserved worker nodes are used for the entire worker pool; you can't mix and match between regular and reserved worker nodes in the same worker pool. Reserved worker nodes are used on a first-available basis, which means if you provision a worker pool that uses all your reserved worker nodes, you have no more reserved worker nodes remaining for other worker pools. Therefore, you might create separate reservations for each team that owns a worker pool or cluster.\n\nZones: Because the reservation is created in an IBM Cloud multizone region, the reserved worker nodes can be used for clusters in any of the zones. For example, reservations in Washington, DC (US East region) can be used to create classic worker nodes in wdc04, wdc06, or wdc07.\n\nReserved worker nodes that are used in the worker pools: In this scenario, the development and production environments share a reservation that has a mix of contracts that are used for a mix of worker pools and teams. The reservation still has one unused, 3-year term reserved worker node that can be used for other worker pools or to scale up the existing worker pools. If the production environment needs more than one more worker node, you might resize down some worker pools in development, create a worker pool that uses on demand worker nodes, or add more contracts to the reservation. If you are concerned about a development environment using up your production environment resources, consider creating separate reservations for the different environments.\n\n\n\n Reservation usage and lifecycle \n\nHow can I use my reservation?\n: You can use your reservation to create worker pools in new or existing clusters.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-reservations"}, {"document_id": "ibmcld_10487-1581-4015", "score": 0.6796162724494934, "text": "\nReservation: The reservation contains details such as the container platform, worker node flavor, location, and infrastructure provider.\n\nContract: The example reservation has two contracts for different terms. One contract is for 10 worker nodes across 3 years. The other contract is for 5 worker nodes across 1 year. Therefore, the total capacity of the reservation is 15 worker nodes.\n\nClusters: Each cluster is in the same multizone region as the reservation, but can be in a different resource group. Reserved worker nodes from different reservations can be used in different clusters. A cluster can have a mix of reserved and regular, as-needed worker pools.\n\nWorker pools: You can create multiple worker pools in multiple clusters with your reserved worker nodes. Reserved worker nodes are used for the entire worker pool; you can't mix and match between regular and reserved worker nodes in the same worker pool. Reserved worker nodes are used on a first-available basis, which means if you provision a worker pool that uses all your reserved worker nodes, you have no more reserved worker nodes remaining for other worker pools. Therefore, you might create separate reservations for each team that owns a worker pool or cluster.\n\nZones: Because the reservation is created in an IBM Cloud multizone region, the reserved worker nodes can be used for clusters in any of the zones. For example, reservations in Washington, DC (US East region) can be used to create classic worker nodes in wdc04, wdc06, or wdc07.\n\nReserved worker nodes that are used in the worker pools: In this scenario, the development and production environments share a reservation that has a mix of contracts that are used for a mix of worker pools and teams. The reservation still has one unused, 3-year term reserved worker node that can be used for other worker pools or to scale up the existing worker pools. If the production environment needs more than one more worker node, you might resize down some worker pools in development, create a worker pool that uses on demand worker nodes, or add more contracts to the reservation. If you are concerned about a development environment using up your production environment resources, consider creating separate reservations for the different environments.\n\n\n\n Reservation usage and lifecycle \n\nHow can I use my reservation?\n: You can use your reservation to create worker pools in new or existing clusters.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-reservations"}, {"document_id": "ibmcld_05746-7-2024", "score": 0.6755249500274658, "text": "\nWhy does strongSwan VPN connectivity fail after I add or delete worker nodes? \n\nClassic infrastructure\n\n What\u2019s happening \n\nYou previously established a working VPN connection by using the strongSwan IPSec VPN service. However, after you added or deleted a worker node on your cluster, you experience one or more of the following symptoms:\n\n\n\n* You don't have a VPN status of ESTABLISHED\n* You can't access new worker nodes from your on-prem network\n* You can't access the remote network from pods that are running on new worker nodes\n\n\n\n Why it\u2019s happening \n\nIf you added a worker node to a worker pool:\n\n\n\n* The worker node was provisioned on a new private subnet that is not exposed over the VPN connection by your existing localSubnetNAT or local.subnet settings.\n* VPN routes can't be added to the worker node because the worker has taints or labels that are not included in your existing tolerations or nodeSelector settings.\n* The VPN pod is running on the new worker node, but the public IP address of that worker node is not allowed through the on-premises firewall.\n\n\n\nIf you deleted a worker node:\n\n\n\n* That worker node was the only node where a VPN pod was running, due to restrictions on certain taints or labels in your existing tolerations or nodeSelector settings.\n\n\n\n How to fix it \n\nUpdate the Helm chart values to reflect the worker node changes.\n\n\n\n1. Delete the existing Helm chart.\n\nhelm uninstall <release_name> -n <namespace>\n2. Open the configuration file for your strongSwan VPN service.\n\nhelm show values iks-charts/strongswan > config.yaml\n3. Check the following settings and change the settings to reflect the deleted or added worker nodes as necessary.\n\nIf you added a worker node:localSubnetNAT : The added worker might be deployed on a new, different private subnet than the other existing subnets that other worker nodes are on. If you use subnet NAT to remap your cluster's private local IP addresses and the worker was added on a new subnet, add the new subnet CIDR to this setting.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_vpn_fails_worker_add"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06294-2598-4239", "score": 0.715647280216217, "text": "\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}, {"document_id": "ibmcld_16098-2598-4239", "score": 0.715647280216217, "text": "\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc_ks_tutorial"}, {"document_id": "ibmcld_10290-40997-42763", "score": 0.712364137172699, "text": "\n--vpc-id VPC_ID\n: Required: The ID of the VPC in which to create the cluster and worker nodes. To list available IDs, run ibmcloud oc vpcs.\n\n--subnet-id VPC_SUBNET_ID\n: Required: The VPC subnet to assign the cluster. To list available VPC subnets, run ibmcloud oc subnets --provider vpc-gen2.\n\n--version 4.11_openshift\n: VPC clusters are supported for Red Hat OpenShift version 4 only.\n\n--flavor FLAVOR\n: Choose a flavor for your worker nodes. You can deploy your worker nodes as virtual machines on shared or dedicated hardware. To see flavors that are available in a zone, run ibmcloud oc flavors --zone <vpc_zone> --provider vpc-gen2.\n\n--cluster-security-group GROUP_ID\n: Optional. Specify additional security group IDs to apply to all workers on the cluster. You must include a separate --cluster-security-group option for each individual security group you want to add. To apply the IBM-created kube-clusterID, use --cluster-security-group cluster. If no value is specified, only the kube-clusterID and the default VPC security group are applied. A maximum of five security groups can be applied to workers, including the default security groups. Note that the VPC security group is only applied if no other security groups are specified. For more information, see [Adding VPC security groups to clusters and worker pools during create time](https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-groupvpc-sg-cluster). The security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_06294-3784-5599", "score": 0.7088637948036194, "text": "\nCreate a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2. Create a subnet for your VPC, and note its ID. Consider the following information when you create the VPC subnet:\n\n\n\n* Zones: You must have one VPC subnet for each zone in your cluster. The available zones depend on the metro location that you created the VPC in. To list available zones in the region, run ibmcloud is zones.\n* IP addresses: VPC subnets provide private IP addresses for your worker nodes and load balancer services in your cluster, so make sure to [create a subnet with enough IP addresses](https://cloud.ibm.com/docs/containers?topic=containers-vpc-subnetsvpc_basics_subnets), such as 256. You can't change the number of IP addresses that a VPC subnet has later.\n* Public gateways: You don't need to attach a public gateway to complete this tutorial. Instead, you can keep your worker nodes isolated from public access by using VPC load balancers to expose workloads securely. You might attach a public gateway if your worker nodes need to access a public URL. For more information, see [Planning your cluster network setup](https://cloud.ibm.com/docs/containers?topic=containers-plan_clusters).\n\n\n\nibmcloud is subnet-create mysubnet1 <vpc_ID> --zone us-south-1 --ipv4-address-count 256\n\n\n\n3. Create a cluster in your VPC in the same zone as the subnet. By default, your cluster is created with a public and a private cloud service endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}, {"document_id": "ibmcld_05713-132600-134017", "score": 0.7031855583190918, "text": "\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n\n\n\n\n Accessing clusters \n\n[Accessing clusters](https://cloud.ibm.com/docs/containers?topic=containers-access_clusteraccess_cluster)\n\n\n\n* [Prerequisites](https://cloud.ibm.com/docs/containers?topic=containers-access_clusterprereqs)\n* [Accessing clusters through the public cloud service endpoint](https://cloud.ibm.com/docs/containers?topic=containers-access_clusteraccess_public_se)\n* [Accessing clusters through the private cloud service endpoint](https://cloud.ibm.com/docs/containers?topic=containers-access_clusteraccess_private_se)\n\n\n\n* [Accessing VPC clusters through the private cloud service endpoint](https://cloud.ibm.com/docs/containers?topic=containers-access_clustervpc_private_se)", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_10041-7462-8947", "score": 0.6939208507537842, "text": "\nGET/v2/getFlavors List available flavors types for a VPC zone (data center). N/A N/A \n GET/v2/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N/A \n GET/v2/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET/v2/getOperatingSystems Get a list of available worker node operating systems. N/A cluster-worker-pool-supported-operating-systems.get \n GET/v2/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET/v2/vpc/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getVPC View details of a VPC. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N/A \n PATCH/v1/clusters/{idOrName}/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH/v1/clusters/{idOrName}/subnets/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST/v1/clusters Create a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-api-at-iam"}, {"document_id": "ibmcld_05567-7444-8929", "score": 0.6939208507537842, "text": "\nGET/v2/getFlavors List available flavors types for a VPC zone (data center). N/A N/A \n GET/v2/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N/A \n GET/v2/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET/v2/getOperatingSystems Get a list of available worker node operating systems. N/A cluster-worker-pool-supported-operating-systems.get \n GET/v2/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET/v2/vpc/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getVPC View details of a VPC. containers-kubernetes.cluster.read N/A \n GET/v2/vpc/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N/A \n PATCH/v1/clusters/{idOrName}/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH/v1/clusters/{idOrName}/subnets/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST/v1/clusters Create a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-api-at-iam"}, {"document_id": "ibmcld_10689-2901-4781", "score": 0.691540002822876, "text": "\nAutomatically attached to each worker node in a cluster created in the VPC.<br> * Allows all outbound traffic by default.<br><br><br> \n VPC cluster security group kube-<cluster-ID> <br><br> * Automatically created when the VPC cluster is created. Automatically attached to each worker node in a cluster created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n Security groups applied to VPE gateways and VPC ALBs \n\nDo not modify the rules in the kube-<vpc-id> security group as doing so might cause disruptions in network connectivity between the workers of the cluster and the control cluster. However, you can [remove the default security group from the VPC ALB](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-remove) and [replace it with a security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-add) that you create and manage.\n\n\n\nTable 1. VPC security groups\nThe table shows the three types of security groups that are automatically created for VPCs. The first column includes the type of security group. The second column includes the naming format of the security group. The third column includes details on when and where the security group is created and what type of traffic it allows.\n\n Security group type Name Details \n\n Red Hat OpenShift on IBM Cloud security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-group"}, {"document_id": "ibmcld_10442-1449-3496", "score": 0.6886487007141113, "text": "\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https://cloud.ibm.com/vpc/provision/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-plan_vpc_basics"}, {"document_id": "ibmcld_06282-2925-4793", "score": 0.6878979206085205, "text": "\nAutomatically attached to each worker node in a cluster created in the VPC.<br> * Allows all outbound traffic by default.<br><br><br> \n VPC cluster security group kube-<cluster-ID> <br><br> * Automatically created when the VPC cluster is created. Automatically attached to each worker node in a cluster created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n Security groups applied to VPE gateways and VPC ALBs \n\nDo not modify the rules in the kube-<vpc-id> security group as doing so might cause disruptions in network connectivity between the workers of the cluster and the control cluster. However, you can [remove the default security group from the VPC ALB](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-remove) and [replace it with a security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-add) that you create and manage.\n\n\n\nTable 1. VPC security groups\nThe table shows the three types of security groups that are automatically created for VPCs. The first column includes the type of security group. The second column includes the naming format of the security group. The third column includes details on when and where the security group is created and what type of traffic it allows.\n\n Security group type Name Details \n\n Kubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05713-131400-132874", "score": 0.7008188962936401, "text": "\n* [Deciding on your cluster setup](https://cloud.ibm.com/docs/containers?topic=containers-clustersprepare_cluster_level)\n* [Next steps](https://cloud.ibm.com/docs/containers?topic=containers-clustersnext_steps)\n\n\n\n[Creating classic clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/containers?topic=containers-cluster-create-vpc-gen2cluster_vpcg2_cli)", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_10534-123564-124806", "score": 0.6848771572113037, "text": "\n[Creating classic clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10534-124536-125809", "score": 0.6739416718482971, "text": "\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n[Creating Satellite clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatellite-clusters)\n\n\n\n* [Prerequisites](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-prereqs)\n* [Creating Red Hat OpenShift clusters on Satellite from the console](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-console)\n* [Creating Red Hat OpenShift clusters on Satellite from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-cli)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10253-8931-10558", "score": 0.6304606795310974, "text": "\nnamespaces get, list, watch get, list, watch get, list, watch <br>cluster-admin only: create, delete \n namespaces/status get, list, watch get, list, watch get, list, watch \n networkpolicies get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n networkpolicies.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n node None None admin scoped to a namespace: None<br><br>cluster-admin for all namespaces: All verbs \n persistentvolume None None create, delete, deletecollection, get, list, patch, update, watch \n persistentvolumeclaims get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n poddisruptionbudgets.policy get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, top, patch, update, watch \n pods/attach <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods/exec <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods/log get, list, watch get, list, watch get, list, watch", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-iam-service-access-roles"}, {"document_id": "ibmcld_05846-9014-10641", "score": 0.6304606795310974, "text": "\nnamespaces get, list, watch get, list, watch get, list, watch <br>cluster-admin only: create, delete \n namespaces/status get, list, watch get, list, watch get, list, watch \n networkpolicies get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n networkpolicies.extensions get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n node None None admin scoped to a namespace: None<br><br>cluster-admin for all namespaces: All verbs \n persistentvolume None None create, delete, deletecollection, get, list, patch, update, watch \n persistentvolumeclaims get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n poddisruptionbudgets.policy get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods get, list, watch create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, top, patch, update, watch \n pods/attach <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods/exec <br><br> * <br><br><br> create, delete, deletecollection, get, list, patch, update, watch create, delete, deletecollection, get, list, patch, update, watch \n pods/log get, list, watch get, list, watch get, list, watch", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-iam-service-access-roles"}, {"document_id": "ibmcld_01393-2937-4518", "score": 0.6219786405563354, "text": "\n* IBM Cloud Kubernetes Service or Red Hat OpenShift on IBM Cloud clusters. When you create IBM Cloud Kubernetes Service and Red Hat OpenShift on IBM Cloud clusters, one service ID is automatically created for each cluster. If you want more than one service ID, you can create them manually.\n* Kubernetes and Red Hat\u00ae OpenShift\u00ae clusters that aren't on IBM Cloud. You must create your own service ID, API key, and pull secret.\n* Docker CLI and other clients. You must create your own service ID and API key.\n\n\n\n\n\n Creating a service ID API key manually \n\nCreate a service ID API key that you can use to log in to the registry.\n\nTo create a service ID API key, complete the following steps:\n\n\n\n1. Create a service ID, see [ibmcloud iam service-id-create](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_iamibmcloud_iam_service_id_create).\n2. Assign service policies to the service ID to control the level of access that is allowed when the service ID is used to authenticate with IBM Cloud Container Registry, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n3. Create a service ID API key, see [Managing service ID API keys](https://cloud.ibm.com/docs/account?topic=account-serviceidapikeys) and [ibmcloud iam service-api-key-create](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_iamibmcloud_iam_service_api_key_create).\n\n\n\n\n\n\n\n Creating a user API key manually \n\nCreate a user API key that you can use to log in to the registry.\n\nIf you create a user API key, the user's access policies are used.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_access"}, {"document_id": "ibmcld_12297-57537-58864", "score": 0.6216832399368286, "text": "\n* [Creating a workspace using the CLI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-cli)\n* [Creating a workspace using the API](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-api)\n* [Creating a workspace using a Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-terraform)\n* [Next steps](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkssch-create-wks-nextsteps)\n\n\n\n[Creating Terraform templates](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configcreate-tf-config)\n\n\n\n* [Configuring the provider block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-provider)\n* [Adding IBM Cloud resources to the resource block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-resources)\n\n\n\n* [Referencing resources in other resource blocks](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configreference-resource-info)\n\n\n\n* [Managing resources in other account](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configmanage-resource-account)\n* [Using variable blocks to customize resources](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-variables)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_11667-4046-5741", "score": 0.6180746555328369, "text": "\nIf you're manually creating the initial subnet, versus creating it when you created your VPC, the region (location) that you select is used as the region of the VPC. All additional resources that you in this VPC are created in the selected region.\n\nIf you created a subnet when you created your VPC, more subnets must be created in the same region. You can create multiple subnets within VPC zones.\n5. Click Create subnet.\n\n\n\n\n\n\n\n\n\n Provisioning your Intel virtual server \n\nBefore you can create a virtual server, you must create the VPC and you must create an SSH key that you add to the server instance during its creation - see more details on [SSH keys with virtual servers](https://cloud.ibm.com/docs/vpc?topic=vpc-ssh-keys).\n\nUse the following steps to order your virtual server and necessary components. For more information about creating a virtual server, see [Creating virtual server instances by using the IBM Cloud console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-virtual-servers).\n\n\n\n1. Log in to the [IBM Cloud console](https://cloud.ibm.com) with your unique credentials.\n2. Click Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/icons/icon_hamburger.svg) > VPC Infrastructure > Virtual server instances.\n3. Click Create.\n4. Enter a unique Name for the virtual server, which becomes the hostname. SAP hostnames must consist of a maximum of 13 alpha-numeric characters. For more information about SAP hostnames, see [SAP Notes 611361](https://launchpad.support.sap.com//notes/611361) and [129997](https://launchpad.support.sap.com//notes/129997).\n5. Choose a Resource group.\n\nThe resource group can't be changed after the virtual server is created.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-vs-set-up-infrastructure"}, {"document_id": "ibmcld_16094-7010-8824", "score": 0.6112696528434753, "text": "\nHTTP requests are on port 80 and 443.\n6. Click Create security group to create it.\n7. Navigate to Security Groups, then select vpc-secure-bastion-sg.\n8. Finally, edit the security group and add the following outbound rule.\n\n\n\nBastion: Outbound rules\n\n Protocol Destination type Destination Port / Value \n\n TCP Security group vpc-secure-maintenance-sg Ports 22-22 \n\n\n\n\n\n\n\n\n\n Step 3: Use the bastion host to access other instances in the VPC \n\nIn this section, you will create a subnet with virtual server instance and a security group.\n\nIf you already have virtual server instances in your VPC that you want to connect to, you can skip the next three sections and start at [Add virtual server instance(s) to the maintenance security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-secure-management-bastion-servervpc-secure-management-bastion-server-add-vsi-to-maintenance).\n\n\n\n Create a subnet \n\nTo create a new subnet,\n\n\n\n1. Click Subnets under Network on the left pane, then click Create.\n\n\n\n* Enter vpc-secure-private-subnet as name, then select the VPC you created.\n* Select a resource group same as your VPC.\n* Select a Location and zone.\n* Enter the IP range for the subnet in CIDR notation, i.e., 10.xxx.1.0/24. Leave the Address prefix as it is and select the Number of addresses as 256.\n\n\n\n2. Switch the Public gateway to Attached.\n3. Click Create subnet to provision it.\n\n\n\n\n\n\n\n Create a security group \n\nTo create a new security group:\n\n\n\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-secure-management-bastion-server"}, {"document_id": "ibmcld_15500-1707-3590", "score": 0.6051455140113831, "text": "\n* The volume must be in the region where you want to create the custom image.\n* The volume must be a primary boot volume with 100 GB capacity. Data volumes are not supported.\n* The volume must be attached to an instance. Unattached boot volumes are not supported.\n* The instance must be in an available state.\n* The available, running instance must be stopped before you create the custom image. Creating an image from a running instance is not allowed.\n\n\n\n\n\n\n\n\n\n Options for creating an image from a volume \n\nYou can create a custom image from a boot volume in several ways.\n\n\n\n* In the [UI](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-ui), you can create a custom image from any of the following places.\n\n\n\n* The Custom images for VPC page,\n* The list of instances on the Virtual server instances for VPC page,\n* The Instance details page,\n* The list of volumes on Block storage volumes for VPC page.\n* The Volume details page.\n\n\n\n* In the [API](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-api), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. With the regional API, you create an image by making a POST /images call and passing the boot volume ID.\n* From the [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifvimage-from-volume-vpc-cli), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. Issue the ibmcloud is image-create command and specify the boot volume's ID.\n\n\n\n\n\n\n\n Image from volume encryption \n\nWhen you create an image from a volume, you have the following encryption choices.\n\n\n\n* If you want to create an instance and boot volume with default IBM-managed encryption, then the image from that boot volume inherits the IBM-managed encryption.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-623552-625809", "score": 0.7943283319473267, "text": "\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-623510-625767", "score": 0.7943283319473267, "text": "\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_12095-1659-3450", "score": 0.790550708770752, "text": "\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated. Use schematics or sch in your command.\n\n\n\n\n\n Does IBM Cloud Schematics support multiple Terraform provider versions? \n\nYes, IBM Cloud Schematics supports multiple Terraform provider versions. You need to add Terraform provider block with the right provider version. By default the provider run current version 1.21.0, and previous four versions such as 1.20.1, 1.20.0, 1.19.0, 1.18.0 are supported.\n\nExample for a multiple provider configuration:\n\nterraform{\nrequired_providers{\nibm = \">= 1.21.0\" // Error !! version unavailable.\nibm = \">= 1.20.0\" // Execute against latest version.\nibm = \"== 1.20.1\" // Executes version v1.20.1.\n}\n}\n\nCurrently, version 1.21.0 is released. For more information, see [provider version](https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-setup_cliinstall_provider).\n\n\n\n\n\n How do I generate IAM access token, if client ID bx is used? \n\nTo create IAM access token, use export IBMCLOUD_API_KEY=<ibmcloud_api_key> and run the command.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-general-faq"}, {"document_id": "ibmcld_12098-7-1814", "score": 0.7765210270881653, "text": "\nSoftware deployment in IBM Cloud Schematics \n\nTry out one of the IBM\u00ae provided software templates to quickly spin up a classic Virtual Server Instance (VSI), and automatically configure the instance to connect to an IBM Cloud\u00ae Databases for PostgreSQL instance.\n\nWith IBM Cloud Schematics, you can choose from a wide variety of [software and infrastructure templates](https://cloud.ibm.com/catalogsoftware) that you can use to set up IBM Cloud services, and to install IBM and Third party software. The templates are applied by using the built-in Terraform, Ansible, Helm, CloudPak, and Operator capabilities in Schematics.\n\nAs part of this getting started tutorial, you create a Schematics Workspaces that points to the [VSI database](https://cloud.ibm.com/catalogabout) template. Then, you run this template and watch Schematics provision your VSI and your IBM Cloud Databases for PostgreSQL instance. IBM Cloud Databases for PostgreSQL is a fully managed database offering in IBM Cloud that supports storing of non-relational and relational data types. For more information about this offering, see [What is PostgreSQL?](https://www.ibm.com/cloud/databases-for-postgresql).\n\nThis getting started tutorial incurs costs. You must have an [IBM Cloud Pay-As-You-Go or Subscription](https://cloud.ibm.com/registration) account to proceed. Make sure that you review pricing information for [classic VSIs](https://cloud.ibm.com/gen1/infrastructure/provision/vs) and [PostgreSQL](https://cloud.ibm.com/databases/databases-for-postgresql/create).\n\n\n\n Before you begin \n\nBefore you can use this template, you must complete the following tasks.\n\n\n\n* Make sure that you have the permissions to [create classic virtual servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-managing-device-access).", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-get-started-software"}, {"document_id": "ibmcld_12321-7-1946", "score": 0.7749478816986084, "text": "\nSetting up continuous deployment with Schematics and DevOps toolchain \n\n\n\n Description \n\nIn this tutorial, you can learn to use your credentials and an API key to use a Terraform template of IBM Cloud\u00ae Object Storage in the Schematics Workspace. Then, you also learn to automate the continuous deployment by using DevOps delivery pipeline. As part of the tutorial, you use ibm_cos_bucket Terraform template example.\n\nThe ibm_cos_bucket example creates an instance of IBM Cloud Object Storage, IBM Cloud\u00ae Activity Tracker, and IBM Cloud\u00ae Monitoring.\n\nCosts are incurred based on your resource usage. For more information about the pricing, see [Pricing](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges). About the support and help, see [Schematics help](https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-help).\n\n\n\n\n\n Objectives \n\nIn this tutorial, you can:\n\n\n\n* Explore an IBM provided Terraform template to create an IBM Cloud Object Storage instance that binds with the IBM resource instance, and IBM resource group.\n* Learn how to create an IBM Cloud Schematics Workspace.\n* Learn to automate continuous deployment of a resource by using IBM Cloud Schematics and DevOps toolchain.\n* Review the IBM Cloud resources that you create.\n\n\n\n\n\n\n\n Time needed \n\n1 hour\n\n\n\n\n\n Audience \n\nThis tutorial is intended for the developer and system administrators who want to learn how to use Terraform templates to create. And automate the continuous deployment of resource by using IBM Cloud Schematics and DevOps toolchain.\n\n\n\n\n\n Prerequisites \n\nAbout IBM Cloud Schematics\n\n[IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-getting-started) is an IBM Cloud automation tool. It provides simplified provisioning, orchestrating Infrastructure as Code (IaC), templates, and managing IBM Cloud resources in your IBM Cloud environment by using various resources tools such as Terraform, Helm.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-workspace-continuous-deployment"}, {"document_id": "ibmcld_12095-7-2147", "score": 0.7713136672973633, "text": "\nGeneral \n\nAnswers to common questions about the IBM Cloud Schematics are classified into following section.\n\n\n\n What is IBM Cloud Schematics and how does it work? \n\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-learn-about-schematics).\n\n\n\n\n\n What is Infrastructure as Code? \n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n\n\n\n\n\n What am I charged for when I use Schematics? \n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-general-faq"}, {"document_id": "ibmcld_12581-17606-19704", "score": 0.7596385478973389, "text": "\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom"}, {"document_id": "ibmcld_12064-1122-2723", "score": 0.7501671314239502, "text": "\n* Install the [Schematics command-line](https://cloud.ibm.com/docs/schematics?topic=schematics-setup-cliinstall-schematics-plugin) plug-in, or [update the command line plug-in](https://cloud.ibm.com/docs/schematics?topic=schematics-setup-clischematics-cli-update) to access the Schematics blueprints commands.\n* Check that you have the right [permissions](https://cloud.ibm.com/docs/schematics?topic=schematics-accessblueprint-permissions) to create blueprints.\n\n\n\n\n\n Step 1: Select a blueprint template \n\nThis tutorial uses a [sample blueprint](https://github.com/Cloud-Schematics/blueprint-basic-example) to create two blueprint modules referencing a resource group and creating an IBM Cloud\u00ae Object Storage instance and bucket. No costs are incurred deploying this example.\n\n\n\n\n\n Step 2: Create the blueprint configuration \n\nCreate your blueprint environment by using CLI command [ibmcloud schematics blueprint config create](https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-cli-referenceschematics-blueprint-create). Use the following parameters to create a blueprint.\n\nFor Schematics blueprints, the [Schematics plug-in](https://cloud.ibm.com/docs/schematics?topic=schematics-setup-cliinstall-schematics-plugin) version must be greater than the 1.12.3.\n\n\n\n* The Name of the blueprint: Blueprint_basic\n* The Schematics management resource group: <default-resource-group-name>\n* The blueprint URL: https://github.com/Cloud-Schematics/blueprint-basic-example\n* The blueprint file: basic-blueprint.yaml\n* An Input file URL: https://github.com/Cloud-Schematics/blueprint-basic-example", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-deploy-schematics-blueprint-cli"}, {"document_id": "ibmcld_12258-118201-119517", "score": 0.7331272959709167, "text": "\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias 'terraform' will be deprecated. Use 'schematics' or 'sch' in your commands.\n\n\n\n Create file template in JSON format \n\nSchematics supports to download the Terraform modules template from the private repository. For more information, see [Supporting to download modules from private remote host](https://cloud.ibm.com/docs/schematics?topic=schematics-download-modules-pvt-git).\n\nYou can create the JSON file as shared in the example.json file for workspace creation and pass the file path along with the file name in --file flag. The description of all the parameters of example.json as described in the table.\n\nYou need to replace the <...> placeholders with the actual values. For example, \"<workspace_name>\" as \"testworkspace\".\n\nexample.json:\n\n{\n\"name\": \"<workspace_name>\",\n\"type\": [\n\"<terraform_version>\"\n],\n\"location\": \"<location>\",\n\"description\": \"<workspace_description>\",\n\"tags\": [],\n\"template_repo\": {\n\"url\": \"<github_source_repo_url>\"\n},\n\"template_data\": [\n{\n\"folder\": \".\",\n\"type\": \"<terraform_version>\",\n\"env_values\":\n{\n\"VAR1\":\"<val1>\"\n},\n{\n\"VAR2\":\"<val2>\"\n}\n],\n\"variablestore\":\n{\n\"name\": \"<variable_name_x>\",\n\"value\": \"<variable_value_x>\",\n\"type\": \"string\",\n\"secure\": true,\n\"description\":\"<description>\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-cli-reference&interface=cli"}, {"document_id": "ibmcld_12093-4-1896", "score": 0.7297142744064331, "text": "\nIBM Cloud Schematics Agent beta-1 delivers a simplified agent installation process and policy for agent assignment.. You can review the [beta-1 release](https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-relnotes&interface=clischematics-mar2223) documentation and explore.\n\nSchematics Agent are a [beta-1 feature](https://cloud.ibm.com/docs/schematics?topic=schematics-agent-beta1-limitations) that are available for evaluation and testing purposes. It is not intended for production usage.\n\n\n\n Agent \n\nAnswers to common questions about the Agent for IBM Cloud Schematics.\n\n\n\n What are the updates in the agent beta-1 release? \n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n\n\n\n\n What are the costs of installing and using Agents? \n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service\n\n\n\n* There is no cost involved in running the agent service.\n* Post beta, the agent feature may be a priced service.\n\n\n\n\n\n\n\n Can I install more than one Agent on a cluster? \n\nYou can install only one agent on a Kubernetes cluster on IBM Cloud Kubernetes Service. You can install additional agents on different clusters.\n\nYou cannot install more than one agent in a single Kubernetes cluster. You will get a failure with namespace conflict error.\n\n\n\n\n\n What type of Schematics jobs can I run in my Agent? \n\nYou can run Schematics Workspace Terraform jobs on an Agent. You can also run Schematics Action jobs, Ansible playbooks on an Agent.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-faqs-agent&interface=ui"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10116-16035-17814", "score": 0.7354156970977783, "text": "\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_07578-985053-986983", "score": 0.7213623523712158, "text": "\n* What metrics am I charged for if I am using VPN gateway for VPC?\n\nThe following metrics are collected for VPN gateway billing on a monthly basis:\n\n\n\n* VPN Gateway Instance Hour: How much time your VPN gateway instance is up and running.\n* VPN Connection Hour: How much time each of your VPN connections is established and maintained on the VPN gateway.\n* Floating IP: The number of active floating IP addresses being used by the VPN gateway instance.\n\n\n\nSee the IBM Cloud VPN tab on the [Pricing](https://www.ibm.com/cloud/vpc/pricing) page for the unit pricing per hour in each region for VPN gateway.\n\nWhile using a VPN gateway, you are also charged for all outbound public internet traffic billed at VPC data rates. See the Data Transfer tab on the [Pricing](https://www.ibm.com/cloud/vpc/pricing) page for details about the unit pricing for outbound data transfer.\n* Why doesn't the route-based VPN gateway route the traffic?\n\nIf you configured a VPC route and its next hop is a VPN connection, the following use cases block the traffic forwarded through the VPN connection.\n\n\n\n* The security groups associated with the VPC instance do not permit the traffic; the network ACLs associated with the subnet of the VPC instance and VPN gateway blocked the traffic. For more information about configuring security groups and network ACLs, see [Configuring ACLs and security groups for use with VPN](https://cloud.ibm.com/docs/vpc?topic=vpc-acls-security-groups-vpn).\n* The traffic source IP is not in any subnet associated with the VPC routing table. For example, the VPC routing table is associated with subnet A and includes a route whose next hop is a VPN connection. However, when the traffic reaches the VPN gateway, the source IP is not in subnet A or any other subnets that are associated with the routing table. Therefore, the VPN gateway drops the traffic.\n\n\n\n\n\nVirtual Private Networks (VPN)\n\n\n\n* What is IBM Cloud VPN?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-984929-986859", "score": 0.7213623523712158, "text": "\n* What metrics am I charged for if I am using VPN gateway for VPC?\n\nThe following metrics are collected for VPN gateway billing on a monthly basis:\n\n\n\n* VPN Gateway Instance Hour: How much time your VPN gateway instance is up and running.\n* VPN Connection Hour: How much time each of your VPN connections is established and maintained on the VPN gateway.\n* Floating IP: The number of active floating IP addresses being used by the VPN gateway instance.\n\n\n\nSee the IBM Cloud VPN tab on the [Pricing](https://www.ibm.com/cloud/vpc/pricing) page for the unit pricing per hour in each region for VPN gateway.\n\nWhile using a VPN gateway, you are also charged for all outbound public internet traffic billed at VPC data rates. See the Data Transfer tab on the [Pricing](https://www.ibm.com/cloud/vpc/pricing) page for details about the unit pricing for outbound data transfer.\n* Why doesn't the route-based VPN gateway route the traffic?\n\nIf you configured a VPC route and its next hop is a VPN connection, the following use cases block the traffic forwarded through the VPN connection.\n\n\n\n* The security groups associated with the VPC instance do not permit the traffic; the network ACLs associated with the subnet of the VPC instance and VPN gateway blocked the traffic. For more information about configuring security groups and network ACLs, see [Configuring ACLs and security groups for use with VPN](https://cloud.ibm.com/docs/vpc?topic=vpc-acls-security-groups-vpn).\n* The traffic source IP is not in any subnet associated with the VPC routing table. For example, the VPC routing table is associated with subnet A and includes a route whose next hop is a VPN connection. However, when the traffic reaches the VPN gateway, the source IP is not in subnet A or any other subnets that are associated with the routing table. Therefore, the VPN gateway drops the traffic.\n\n\n\n\n\nVirtual Private Networks (VPN)\n\n\n\n* What is IBM Cloud VPN?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_14886-1801-3922", "score": 0.7205280065536499, "text": "\nBenefits \n\n\n\n BYOL \n\nRenting licenses can get expensive. Bringing your own license is an option for IBM Cloud Bare Metal Servers for VPC.\n\n\n\n\n\n Rapid scaling \n\nScale your dedicated, bare metal server environment for your needs quickly. Often, in 10 minutes or less when resources are available.\n\n\n\n\n\n Network orchestration \n\nA network orchestration layer handles the networking for all bare metal servers that are within an IBM Cloud VPC across regions and zones. Create multiple, virtual private clouds in multizone regions. Network orchestration also helps improve security, reduce latency, and increase high availability.\n\nYou are responsible for security on your bare metal server. That means upgrading or patching the operating system as needed to make sure that vulnerabilities are addressed in a timely manner. Bare metal servers with associated floating IP addresses are internet-facing and you need to take appropriate precautions. For more information, see [Understanding your responsibilities](https://cloud.ibm.com/docs/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n\n\n\n\n\n\n\n Pricing options \n\nPay-as-you-go bandwidth is per gigabyte. Your billing charges accrue from provision to cancellation, and are billed in arrears. Total pricing includes bare metal server instance profiles and software, internet data transfers, and optional VPC services. Each additional component is priced separately and included as part of your total IBM Cloud VPC charge. Service tiers are bound to your account, not to any specific VPC.\n\nFor more information about pricing, see [Pricing](https://www.ibm.com/cloud/vpc/pricingtab_2651670).\n\n\n\n\n\n Bare Metal Servers for VPC versus bare metal server on classic infrastructure \n\nWith Bare Metal Servers for VPC, you can enjoy the security and performance of the private cloud with the flexibility and scalability of the public cloud. Compared to the classic bare metal infrastructures, Bare Metal Servers for VPC provides better connectivity and networking throughput by using VPC concepts.\n\nBare Metal Servers for VPC has local NVMe, which you can use to create VMWare vSAN.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-bare-metal-servers"}, {"document_id": "ibmcld_05666-8826-10757", "score": 0.7197930216789246, "text": "\nReview each product documentation and use the IBM Cloud console to [estimate costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https://cloud.ibm.com/docs/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https://cloud.ibm.com/kubernetes/catalog/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_10116-14646-16447", "score": 0.7077642679214478, "text": "\n* [File Storage for Classic](https://www.ibm.com/products/file-storage)\n* [Block Storage for Classic](https://www.ibm.com/products/block-storage)\n* [File Storage for VPC](https://www.ibm.com/products/file-storage)\n* [Block Storage for VPC](https://www.ibm.com/products/block-storage)\n* [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage)\n* [Portworx Enterprise pricing](https://cloud.ibm.com/catalog/services/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\n[Operators](https://cloud.ibm.com/docs/openshift?topic=openshift-operators) and other [third-party integrations](https://cloud.ibm.com/docs/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_11408-11687-13539", "score": 0.7020624876022339, "text": "\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_10116-10237-12114", "score": 0.6987779140472412, "text": "\n[Menu icon](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/icons/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https://www.ibm.com/cloud/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for Red Hat OpenShift on IBM Cloud clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https://cloud.ibm.com/docs/subnets) documentation or estimate your costs in the [classic subnets console)](https://cloud.ibm.com/classic/network/subnet/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_07578-882118-884014", "score": 0.6938036680221558, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-881995-883891", "score": 0.6938036680221558, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05666-7536-9272", "score": 0.7416171431541443, "text": "\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https://www.ibm.com/products/file-storage)\n* [Block Storage for Classic](https://www.ibm.com/products/block-storage)\n* [File Storage for VPC](https://www.ibm.com/products/file-storage)\n* [Block Storage for VPC](https://www.ibm.com/products/block-storage)\n* [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage)\n* [Portworx Enterprise pricing](https://cloud.ibm.com/catalog/services/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https://cloud.ibm.com/docs/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_07578-871859-873660", "score": 0.7304331064224243, "text": "\nFor more information, see [About restoring from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-871736-873537", "score": 0.7304331064224243, "text": "\nFor more information, see [About restoring from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10116-14646-16447", "score": 0.7279045581817627, "text": "\n* [File Storage for Classic](https://www.ibm.com/products/file-storage)\n* [Block Storage for Classic](https://www.ibm.com/products/block-storage)\n* [File Storage for VPC](https://www.ibm.com/products/file-storage)\n* [Block Storage for VPC](https://www.ibm.com/products/block-storage)\n* [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage)\n* [Portworx Enterprise pricing](https://cloud.ibm.com/catalog/services/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\n[Operators](https://cloud.ibm.com/docs/openshift?topic=openshift-operators) and other [third-party integrations](https://cloud.ibm.com/docs/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_07578-966486-968340", "score": 0.7253826260566711, "text": "\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\nWhen you use the [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-966362-968216", "score": 0.7253826260566711, "text": "\nSnapshots have their own lifecycle, independent of the Block Storage for VPC volume. You can separately manage the source volume. However, when you take a snapshot, you must wait for the snapshot creation process to complete before you detach or delete the volume.\n* How am I charged for usage?\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary. Deleting snapshots reduces cost, so the fewer snapshots you retain the lower the cost becomes.\n\nPricing for snapshots is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\nWhen you use the [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) feature, your existing regional plan is adjusted. Billing for fast restore is based on instance hours. For more information about the cost of fast restore, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n\n\n\n Can I add tags to a Block Storage for VPC snapshot? \n\nDepending on the action that you're performing, you can add user tags and access management tags to your snapshots. User tags are used by the backup service to periodically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC snapshots. For more information, see [Tags for Block Storage for VPC snapshots](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-about-tags).\n\n\n\n\n\n Can I use volume snapshot for disaster recovery? \n\nYou can use your snapshots and backups to create volumes in case of an emergency. You can also create copies of your snapshot in other regions and use them to create volumes there.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13995-0-1665", "score": 0.7229354977607727, "text": "\n\n\n\n\n\n\n  Dedicated host pricing \n\nPricing for dedicated hosts is offered in an hourly and monthly model.\n\nDedicated host pricing is inclusive of all vCPU, RAM, local storage, and uplink port speed components as instances are provisioned onto dedicated hosts. For more information about pricing, see the [Virtual servers pricing and configuration tool](https://www.ibm.com/cloud/virtual-servers/calculator/).\n\nWith dedicated hosts, extra local storage disks are available on first, second, third, fourth, and fifth disks. Extra capacity up to 400 GB on each secondary disk is also available.\n\nHourly instances can be provisioned on hourly and monthly hosts. Monthly instances can be provisioned on only monthly hosts.\n\n\n\nTable 1. Dedicated host configurations\n\n Host configuration  vCPU  RAM (GB)  Local storage (TB SSD) \n\n 56x242x1.2          56    242       1.2                    \n 56x484x1.2          56    484       1.2                    \n\n\n\nPricing varies by region.\n\nSAN (network attached), premium OSs, and add-ons are charged hourly or monthly, by the instance, depending on the instance provisioned on the dedicated host. Pricing for these components is consistent with the existing offering on public instances and dedicated instances.\n\nFor example, a dedicated instance that is provisioned on a dedicated host with the following configuration isn't charged by the instance. vCPU, RAM, local storage, and uplink port speeds are included in dedicated host charges.\n\n\n\n*  8 vCPU\n*  16 GB RAM\n*  100 GB Local SSD first disk\n*  400 GB Local SSD second disk\n*  400 GB Local SSD third disk\n*  1 Gbps public and private network uplinks (dedicated host)\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-dedicated-virtual-server-pricing"}, {"document_id": "ibmcld_07578-882118-884014", "score": 0.7207346558570862, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-881995-883891", "score": 0.7207346558570862, "text": "\nYou can also [create stand-alone volumes](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https://cloud.ibm.com/docs/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https://cloud.ibm.com/docs/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS/GB tier to a 3-IOPS/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https://www.ibm.com/cloud/vpc/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10116-13064-14929", "score": 0.720108687877655, "text": "\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\n\n\n\n\n\n\n Default storage for images \n\nTo store images in the internal registry, Red Hat OpenShift on IBM Cloud creates a storage instance that varies by infrastructure provider.\n\n\n\n* Classic clusters: A classic IBM Cloud File Storage for Classic volume is automatically created for you. Your file storage volume is provisioned with an ibmc-file-gold storage class of 100 GB capacity at 10 IOPS/GB, and billed at an hourly rate. If you need more image storage capacity, you can [update the volume size](https://cloud.ibm.com/docs/openshift?topic=openshift-registryopenshift_internal_registry), which modifies the cost.\n* VPC clusters: A bucket in an existing IBM Cloud Object Storage instance is created for you. For more information, see [Billing and pricing in the Object Storage documentation](https://www.ibm.com/cloud/object-storage).\n\n\n\n\n\n\n\n Storage for apps \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https://www.ibm.com/products/file-storage)\n* [Block Storage for Classic](https://www.ibm.com/products/block-storage)\n* [File Storage for VPC](https://www.ibm.com/products/file-storage)\n* [Block Storage for VPC](https://www.ibm.com/products/block-storage)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01660-8584-10307", "score": 0.8360737562179565, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_07578-1076793-1078629", "score": 0.8287746906280518, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 0.828774631023407, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01705-7-1620", "score": 0.7905172109603882, "text": "\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https://cloud.ibm.com/catalog/?search=label:lite) ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) ![Feature available](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/icon_enabled.svg) !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_11142-1400-2265", "score": 0.7819393873214722, "text": "\nGo to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials \n\nCheck out our [tutorials for Lite plans](https://cloud.ibm.com/docs?tab=tutorials&filters=lite-account) for detailed steps about using IBM Cloud services that provide free Lite plans for you to implement common patterns based on best practices and proven technologies at no cost.\n\n\n\n\n\n Next steps \n\nBuild your apps! For more information, see the [Getting started tutorial](https://cloud.ibm.com/docs/apps?topic=apps-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_07578-1320438-1322384", "score": 0.7810606956481934, "text": "\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https://cloud.ibm.com/objectstorage/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https://cloud.ibm.com/objectstorage/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https://cloud.ibm.com/docs/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1323103-1325049", "score": 0.7810606956481934, "text": "\nNo, Lite Plan instances can only be upgraded to the Cloud Object Storage Standard plan.\n* Are there any minimum object size or minimum duration requirements for objects stored with the One-Rate plan?\n\nThere are no minimum object size or minimum duration requirements for the One-Rate plan.\n* What is the cost of data retrieval from One Rate Active buckets?\n\nThere is no data retrieval charge for the One Rate Active buckets.\n* What happens if I exceed my monthly allowance for Outbound bandwidth and Operational requests?\n\nFor any usage (Outbound bandwidth or Operational requests) that exceeds the allowance determined by aggregated monthly capacity, a small overage fee applies based on the One Rate pricing regions. See [One Rate pricing plan details](https://cloud.ibm.com/objectstorage/createpricing).\n* Is the overage pricing tiered for Outbound bandwidth and Operational requests?\n\nNo, the overage pricing for the One Rate plan has flat rates regardless of excess usage. See [One Rate pricing plan details](https://cloud.ibm.com/objectstorage/createpricing).\n* I already have a Cloud Object Storage Standard plan in my IBM Cloud account. Can I add a One Rate plan for my new workloads?\n\nYes, you can add a One Rate plan to your existing account in addition to the Standard plan. If you are a new to Cloud Object Storage, you can add either Standard or One Rate plan (or both) based on your workload requirements.\n* Why can I not create or delete a service instance?\n\nA user is required to have have at a minimum the platform role of editor for all IAM enabled services, or at least for Cloud Object Service. For more information, see the [IAM documentation on roles](https://cloud.ibm.com/docs/account?topic=account-iam-service-roles-actions).\n* Which one of my instances uses a Lite plan?\n\nAn account is limited to a single instance of IBM Cloud Object Storage that uses a Lite plan. You can find this instance three different ways:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02660-1509-3609", "score": 0.7781554460525513, "text": "\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-create-an-instance"}, {"document_id": "ibmcld_11142-7-1829", "score": 0.7697694301605225, "text": "\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https://cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free"}, {"document_id": "ibmcld_13336-7-1965", "score": 0.7636781930923462, "text": "\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": []}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00696-1740-4173", "score": 0.6609973907470703, "text": "\nWhen you log in, any of the following types of accounts might be associated with your user credentials:\n\n\n\n* Personal account\n* Corporate account\n* Corporate individual account\n\n\n\n\n\n Personal accounts \n\nTypically, each user has their own account that is their personal account. You can easily identify your personal account because it usually contains your name, for example, John Smith's Account.\n\nYou have full rights over all objects that are created in your personal account. You can invite other users to join your account, assign them rights over objects that you create, and assign them rights to create objects in your account. Because of these rights, the personal data of other users might be in your account, and your personal data might be in other user's accounts.\n\nIf you have permission to create an object in an account, you also have the right to modify and delete it, regardless of which account the object is stored in. When two users collaborate, they often share a personal account.\n\n\n\n\n\n Corporate accounts \n\nA corporate account is set up by your company. Typically, you are added automatically to the account, rather than being invited. Although corporate accounts provide users with a place to work, communicate, and share resources and charging, this set up is just a convention. A corporate account is really no different than a personal account. Objects that are created in a corporate account are associated with the account and users can be invited to the account.\n\nTeams of people who work for a corporation often collaborate by using a corporate account.\n\n\n\n\n\n Corporate individual accounts \n\nWhen you work for a corporation, the work in your account might be legally owned by the corporation. Many users who work for a corporation have a corporate individual account. If you log in to your account by using credentials that contain your corporation's name and also have what appears to be a personal account, the work within your personal account might belong to the corporation.\n\nA corporate individual account is no different from any other account. You can invite users to a corporate individual account and objects that are created in a corporate individual account are owned by the account.\n\nIf you work for a corporation that owns your work, a personal account that usually contains your name is considered a corporate individual account.\n\n\n\n\n\n\n\n Modifying, exporting, and deleting personal data", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd_personal_data"}, {"document_id": "ibmcld_12546-4-2108", "score": 0.6253697872161865, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Adding accounts to an enterprise \n\nYou can build out your enterprise by adding more IBM Cloud\u00ae accounts to it. To add accounts, you can import existing accounts that aren't in another enterprise, or you can create new accounts within your enterprise.\n\nAfter your enterprise has multiple accounts, you can organize related accounts by using account groups. For more information, see in [Organizing accounts in an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-organize).\n\n\n\n Importing existing accounts \n\nYou can import existing accounts into an enterprise. After you import an account, it can't be removed, and each account can be a part of only one enterprise. If you import a Lite or trial account, it's automatically upgraded to a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\nImporting an account to the enterprise has the following impacts:\n\n\n\n* Billing for the account transitions to being managed by the enterprise. After the transition, users in the account can't access billing and payment information, such as invoices, payments, or subscriptions, for future billing periods. To view or manage billing, users need to be invited to the enterprise account and be given access to the Billing service in that account. See [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise) for more information.\n* Users and access permissions within the account are not changed. Access within the account is separate from the enterprise, and users don't automatically get access within the enterprise when the account is imported.\n* Resources within the account are not changed. Users with the correct access permissions can continue to view usage information for resources in the account.\n\n\n\nTo import existing accounts into an enterprise, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Billing service within the account.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_12623-3561-5622", "score": 0.619625985622406, "text": "\n* Account groups, which you can use to organize related accounts. Account groups can't contain resources themselves, but you can view costs for resource usage from the accounts that they contain.\n* Accounts, which are just like stand-alone IBM Cloud accounts in that they contain resources and resource groups, Cloud Foundry orgs and spaces, and independent access permissions. However, one major difference is that each account in an enterprise doesn't manage its own billing or payments because these are handled at the enterprise account level.\n\n\n\nYou create tiers in your enterprise by nesting an account group within an account group.\n\nZoom\n\n![A diagram that shows four enterprise tiers. The first tier is the enterprise, which contains two tiers of account groups. Then, the account group contains accounts.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-hierarchy.svg)\n\nFigure 1. A four-tier enterprise hierarchy\n\nAn enterprise can contain up to five tiers of accounts and account groups. In its most basic form, an enterprise has two tiers: The enterprise account, and a single child account. A maximum of 300 accounts can be added to an enterprise.\n\nYour enterprise structure is flexible and can grow and change as your needs do. You can add and remove account groups and move accounts between account groups. If the purpose of an account group changes, you can rename it to better reflect the accounts it contains.\n\n\n\n\n\n Consolidated billing \n\nIn an enterprise, all billing is managed through the enterprise account. Enterprises require [subscription billing](https://cloud.ibm.com/docs/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use). Subscription billing means that you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_12546-1569-3760", "score": 0.611162543296814, "text": "\nAccess within the account is separate from the enterprise, and users don't automatically get access within the enterprise when the account is imported.\n* Resources within the account are not changed. Users with the correct access permissions can continue to view usage information for resources in the account.\n\n\n\nTo import existing accounts into an enterprise, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Billing service within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\n\n\n Importing an account in the console \n\nTo import an existing account, complete the following steps:\n\n\n\n1. Log in to your enterprise account, and go to Manage > Enterprise in the IBM Cloud console.\n2. Click Accounts to view the accounts and account groups in the enterprise. In the Accounts section, select Add > Import account.\n3. Select the account that you want to import.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. If you want to add the account to an account group, select the account group to be its parent. The parent that you select determines where in the enterprise hierarchy the account exists.\n5. Review the information about impacts to your account, and select I understand the impact to my account. Then, click Import.\n\nAfter the account is imported to the enterprise, it can't be removed. Be sure you want to permanently move the account to the enterprise.\n\n\n\n\n\n\n\n Importing accounts by using the CLI \n\n\n\n1. Find the ID of the account that you want to import to the enterprise.\n\nibmcloud account list\n2. If you want to add the account to an account group, find the names and IDs of existing account groups in the enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. Import the account into the enterprise, specifying the account ID for the --account ID parameter. If you don't specify a parent account group, the account is added directly under the enterprise.\n\nibmcloud enterprise account-import --account-id ID", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_07578-1082408-1084289", "score": 0.6055909991264343, "text": "\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs/images/account-faq.svg)\n\nFigure 1. Account selector\n\nYou can view your role in each account on the [Users page](https://cloud.ibm.com/iam/users). The 'owner' tag next to a user name indicates the account owner. If you are the owner of the account, the 'self' tag is also listed next to your name. If you see only your name that is listed and you are not the account owner, the account owner has restricted the user list. For more information, see [Controlling user visibility](https://cloud.ibm.com/docs/account?topic=account-iam-user-setting).Contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) to determine the account owner.\n\nYou can also find your accounts from the CLI by running the ibmcloud account list command. This command lists the account that you own and any other accounts that are affiliated with your IBMid.\n* Can I view my account ID, account type, and account number?\n\nGo to the [Account settings](https://cloud.ibm.com/account/settings) page in the console to view your account ID and type. The account ID is a 32 character, unique account identifier. The IBM Cloud console menu bar lists all of the accounts that are affiliated with your IBMid, including the accounts that you own. The account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_01660-16615-18504", "score": 0.6006360650062561, "text": "\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/account/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_12559-4953-7138", "score": 0.6000842452049255, "text": "\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_02292-0-758", "score": 0.5990172028541565, "text": "\n\n\n\n\n\n\n  How do I get access to upgrade my IBM Cloud account? \n\nYou can't upgrade to a Pay-As-You-Go account.\n\n  What\u2019s happening \n\nWhen you try to upgrade your account from the [Account settings](https://cloud.ibm.com/account/settings) page in the IBM Cloud console, the following message is displayed:\n\n> Looks like you don't have access to view this page. Contact the account owner for access.\n\n  Why it\u2019s happening \n\nTo upgrade your account, you must have an access policy with the Editor role or higher on all account management services.\n\n  How to fix it \n\nContact the account owner to request access to upgrade your account. For more information, see [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-ts_upgrade_cc"}, {"document_id": "ibmcld_07578-1083825-1085863", "score": 0.598469614982605, "text": "\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07500-7-2180", "score": 0.5975170135498047, "text": "\nPlanning your account structure \n\nA large organization needs to register for two IBM Cloud enterprise accounts and then set them up following this pattern.\n\nZoom\n\n![Diagram of a typical enterprise account structure. All of the information is conveyed in the surrounding text.](https://cloud.ibm.com/docs-content/v1/content/f18e964848e0337fedc42d43e246fa446f4b9646/enterprise-account-architecture/images/account-structure.svg)\n\nFigure 1. Enterprise account structure\n\nEach enterprise has a central account group to store administrative tools and enterprise wide shared services. It also has a set of account groups for each business unit.\n\nThe following shows each type of account and its purpose:\n\n\n\nTable 1. Account purpose\n\n Account type Quantity Location Purpose \n\n [Security and Compliance Center](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-scc-account-structure) 2 Development and production enterprise root Hosts Security and Compliance Center and its dependencies \n [Central administration](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-admin-hub-account) 1 Production administration account group Hosts infrastructure as code to manage development and production enterprise configuration \n [Network and service hub](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-hub-account) 2 Development and production administration account group Hosts centralized network resources, shared cloud tools, and any account wide shared custom services \n [Business unit administration](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-bu-admin-account) 1-25 Production BU account groups Hosts infrastructure as code to manage workload accounts and the workload account's applications and infrastructure \n [Workload](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-infra-account) 2-500 Development and production BU account groups Hosts shared infrastructure for hosting application workloads. Used in development - production pairs", "title": "", "source": "https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-account-structure"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12297-56490-57784", "score": 0.6316754817962646, "text": "\n* [Defining a JSON config file](https://cloud.ibm.com/docs/schematics?topic=schematics-create-blueprint-filebp-create-configJSON)\n\n\n\n[Using environment variables with blueprints](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-env-varsbp-env-vars)\n\n\n\n* [Blueprints usage](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-env-varsusage)\n\n\n\n\n\n\n\n Managing Workspaces \n\n\n\n Creating workspace \n\n[Creating workspaces and importing your Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkssch-create-wks)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksprerequisites-create)\n* [Creating a workspace using the UI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-ui)\n\n\n\n* [Importing your Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksimport-template)\n* [Using Terraform templates in IBM Cloud](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wksrun-template)\n\n\n\n* [Creating a workspace using the CLI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-cli)\n* [Creating a workspace using the API](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-api)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_08423-6549-8265", "score": 0.6226850748062134, "text": "\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the SO user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, SO user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the SO user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 2. Create service IDs and API keys for the normal user \n\nTo create a service ID for the normal user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the normal user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Normal user and description for the normal user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Normal user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Normal user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the normal user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"}, {"document_id": "ibmcld_12297-57537-58864", "score": 0.6091850399971008, "text": "\n* [Creating a workspace using the CLI](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-cli)\n* [Creating a workspace using the API](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-api)\n* [Creating a workspace using a Terraform template](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkscreate-wks-terraform)\n* [Next steps](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-create-wkssch-create-wks-nextsteps)\n\n\n\n[Creating Terraform templates](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configcreate-tf-config)\n\n\n\n* [Configuring the provider block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-provider)\n* [Adding IBM Cloud resources to the resource block](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-resources)\n\n\n\n* [Referencing resources in other resource blocks](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configreference-resource-info)\n\n\n\n* [Managing resources in other account](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configmanage-resource-account)\n* [Using variable blocks to customize resources](https://cloud.ibm.com/docs/schematics?topic=schematics-create-tf-configconfigure-variables)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_05444-86766-88182", "score": 0.6066516637802124, "text": "\n[Creating a job from images in a public registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job)\n\n\n\n* [Creating a job with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job-ui)\n* [Creating a job with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobcreate-job-cli)\n* [Next steps](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-jobnextsteps-jobcreatepub)\n\n\n\n[Creating a job from images in IBM Cloud Container Registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage)\n\n\n\n* [Creating a job that references an image in Container Registry with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-console)\n* [Creating a job with an image in Container Registry with the CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagecreate-job-crimage-cli)\n* [Next steps](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-crimagenextsteps-jobcreatecr)\n\n\n\n[Creating a job from images in a private registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-privatecreate-job-private)\n\n\n\n* [Creating a job that references an image in a private registry with the console](https://cloud.ibm.com/docs/codeengine?topic=codeengine-create-job-privatecreate-job-private-console)", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-sitemap"}, {"document_id": "ibmcld_08295-27628-29026", "score": 0.59894859790802, "text": "\nibmcloud schematics blueprint create \n\nCreate a blueprint config from the command line using the ibmcloud schematics blueprint create command. Creating a blueprint config is the first step to deploy a blueprint environment. The blueprint config is created from user provided parameters via the command line that specifies the source of the blueprint template in a Git repository, and input values sourced from Git hosted input files and locally sourced input values.\n\nThe create command supports passing all required parameters via options on the CLI and passing input values from local files.\n\nA experimental file option is provided to create a blueprint config from a configuration provided as a JSON file from the local file system. Refer to the [ibmcloud schematics blueprint create - file option](https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-cli-referenceschematics-blueprint-create) section. These two usage modes are mutually exclusive.\n\nFor Schematics Blueprints, the [Schematics plug-in](https://cloud.ibm.com/docs/schematics?topic=schematics-setup-cliinstall-schematics-plugin) version must be greater than the 1.12.5 version.\n\nRefer to the section on [Creating Blueprints](https://cloud.ibm.com/docs/schematics?topic=schematics-create-blueprint-config&interface=cli) for examples of command syntax and output.\n\nSyntax to create blueprint config using CLI parameters:", "title": "", "source": "https://cloud.ibm.com/docs/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"}, {"document_id": "ibmcld_10534-123564-124806", "score": 0.5964365005493164, "text": "\n[Creating classic clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster-create-classic)\n\n\n\n* [Creating a classic cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classicclusters_ui)\n* [Creating a standard classic cluster in the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classicclusters_cli_steps)\n* [Example commands to create classic clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster_create_classic)\n* [Creating a single-zone classic cluster with Terraform](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-classiccluster_classic_tf)\n\n\n\n[Creating VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-gen2)\n\n\n\n* [Prerequisites and notes](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster-create-vpc-prereq)\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10534-124536-125809", "score": 0.594862699508667, "text": "\n* [Creating a VPC cluster in the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2clusters_vpcg2_ui)\n* [Creating VPC clusters from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_cli)\n* [Example commands to create VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_create_vpc)\n* [Creating a VPC cluster with Terraform](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2cluster_vpcg2_tf)\n\n\n\n[Creating clusters on dedicated hosts for VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-dedicated-hostscluster-create-dedicated-hosts)\n\n[Creating Satellite clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatellite-clusters)\n\n\n\n* [Prerequisites](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-prereqs)\n* [Creating Red Hat OpenShift clusters on Satellite from the console](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-console)\n* [Creating Red Hat OpenShift clusters on Satellite from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-satellite-clusterssatcluster-create-cli)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_05348-5259-6697", "score": 0.5890640020370483, "text": "\nTo create an IBM Cloud IAM API key with the CLI, run the [iam api-key-create](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_iamibmcloud_iam_api_key_create) command. For example, to create an API key called cliapikey with a description of \"My CLI API key\" and save it to a file called key_file, run the following command:\n\nibmcloud iam api-key-create cliapikey -d \"My CLI API key\" --file key_file\n\nIf you choose to not save your key to a file, you must record the API key that is displayed when you create it. You cannot retrieve it later.\n2. After you create your API key, add registry access to Code Engine. To add access to Container Registry with the CLI, use the [ibmcloud ce secret create --format registry](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-secret-create) command to create a registry secret. For example, the following command creates registry access to a Container Registry instance called myregistry. Note, even though the --server and --username options are specified in the example command, the default value for the --server option is us.icr.io and the --username option defaults to iamapikey when the server is us.icr.io.\n\nibmcloud ce secret create --format registry --name myregistry --server us.icr.io --username iamapikey --password APIKEY\n\nExample output\n\nCreating registry secret 'myregistry'...\nOK\n3. Create your app and reference the hello_repo image in Container Registry.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-deploy-app-crimage"}, {"document_id": "ibmcld_12297-159404-160750", "score": 0.5829019546508789, "text": "\n[Blueprint create fails](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails)\n\n\n\n* [Blueprint create fails with an invalid blueprint template: failed to clone Git repository error](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails1)\n* [Blueprint create fails with an invalid blueprint template: unable to find file error](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails2)\n* [Blueprint create fails with the requested resource group as invalid](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails3)\n* [Blueprint create fails with the error blueprint JSON validation failed: field missing or invalid in config](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails4)\n* [Blueprint create fails with the error blueprint JSON validation failed - field missing or invalid](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failsbp-create-fails5)\n* [Why is Schematics not able to clone the private GitHub repository?](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failstsg-privategithub)\n* [Why is Schematics not able to clone the public GitHub repository?](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-create-failstsg-publicgithub)", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-sitemap"}, {"document_id": "ibmcld_05256-25086-26909", "score": 0.5815774202346802, "text": "\nBe sure to give the service ID a description that helps you retrieve the service ID later, such as including the project name. For a complete listing of the iam service-id-create command and its options, see the [ibmcloud iam service-id-create](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_iamibmcloud_iam_service_id_create) command.\n\nFor example, the following command creates a service ID called codeengine-myproject-id with the description Service ID for IBM Cloud Container Registry in Code Engine project myproject:\n\nibmcloud iam service-id-create codeengine-myproject-id --description \"Service ID for IBM Cloud Container Registry in Code Engine project my proj\"\n2. Create a custom IBM Cloud IAM policy for your service ID that grants access to IBM Cloud Container Registry with the iam service-policy-create command. For a complete listing of the iam service-policy-create command and its options, see the [ibmcloud iam service-policy-create](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_iamibmcloud_iam_service_policy_create) command.\n\nFor example, the following command creates a policy for codeengine-myproject-id service ID with the role of Reader:\n\nibmcloud iam service-policy-create codeengine-myproject-id --roles Reader --service-name container-registry\n\nThe following table summarizes the options that are used with the iam service-policy-create command in this example. For more information about the command and its options, see the [ibmcloud iam service-policy-create](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_iamibmcloud_iam_service_policy_create) command.\n\n\n\nTable 4. iam service-policy-create command components\n\n Option Description \n\n <service_ID> Required. Replace with the codeengine-<project_name>-id service ID that you previously created.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08111-8353-9763", "score": 0.6997116804122925, "text": "\n<br><br> * rate_limit_mb_per_member - Auto scaling rate limit in megabytes per member.-> [Scale up by rate_increase_percent<br><br><br> \n <br><br> * rate_period_seconds - Auto scaling rate period in seconds. -> [Scale up by rate_increase_percent every rate_period_seconds]<br><br><br> \n <br><br> * rate_units - Auto scaling rate in units<br><br><br> \n Nested scheme for memory: \n <br><br> * io_above_percent - Auto scaling scalar I/O utilization above percent. -> [Average IO utilization]<br><br><br> \n <br><br> * io_enabled- Auto scaling scalar I/O utilization enabled.<br><br><br> \n <br><br> * io_over_period - Auto scaling scalar I/O utilization over period. ->[Average IO utilization for this period]<br><br><br> \n <br><br> * rate_increase_percent - Auto scaling rate in increase percent. -> [Scale up by rate_increase_percent]<br><br><br> \n <br><br> * rate_limit_mb_per_member - Auto scaling rate limit in megabytes per member. [Scale up by rate_increase_percent every rate_period_seconds up to rate_limit_mb_per_member]<br><br><br> \n <br><br> * rate_period_seconds - Auto scaling rate period in seconds. -> [Scale up by rate_increase_percent every<br><br><br> \n <br><br> * rate_units - Auto scaling rate in units.<br><br><br> \n tags A list of tags that you want to add to your instance. \n whitelist A list of allowed IP addresses for the database. Multiple blocks are allowed.Nested scheme for whitelist:", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-create-three-tier-resilient-vpc-mzr-modular"}, {"document_id": "ibmcld_03781-1481-2683", "score": 0.6821850538253784, "text": "\nThe number of GB used per month is 4 x 256 = 1024 MB or 1 GB per month. Assume that there are 24 x 30 = 720 hours in a month, so the application is charged for 1 x 720 = 720 GB-hours.\n\nIBM Cloud offers a free tier of [Cloud Foundry application usage](https://cloud.ibm.com/docs/account?topic=account-accounts) that affects the overall cost for an application that's running, by reducing your costs.\n\nTwo Auto-Scaling policies (processor and memory)\n: The Auto-Scaling policies are free of charge.\n\n150 GB per month IBM Cloudant\n: The IBM Cloudant for IBM Cloud service charges are based on data storage and the ability to access that data by provisioned throughput capacity denoted by lookups, writes, and queries per second.\n\nAdd up the number of GB and deduct the 20-GB free allowance. 130 GB is charged per month. The total storage price includes the following parts:\n\n130 x 1 = $130\n(1,000 / 100) x 0.25 = $2.50\n(500 / 50) x 0.50 = $5.00\n(50 / 5) x 5.00 = $50.00\n\nThe total price is 130 + 2.50 + 5.00 + 50.00 = $187.50.\n\n20 GB inbound or outbound network traffic\n: Inbound and outbound network traffic is free of charge.\n\nWhen all the items are added, the total price of the application is $211.65.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-sample"}, {"document_id": "ibmcld_07578-474233-476319", "score": 0.6692018508911133, "text": "\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-474215-476301", "score": 0.6692018508911133, "text": "\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00348-11019-12529", "score": 0.6620515584945679, "text": "\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Rest Of APAC\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - South America\"\n],\n\"totals\": [\n15, // Total Hits from start time to end time.\n4.9301e-5, // Total Bandwidth from start time to end time.\n0, // Hits by type 0XX\n0, // Hits by type 200\n0, // Hits by type 206\n0, // Hits by type 2XX\n0, // Hits by type 302\n0, // Hits by type 304\n0, // Hits by type 3XX\n0, // Hits by type 404\n13, // Hits by type 4XX\n2, // Hits by type 5XX\n0, // Hits by type Other\n0, // Bandwidth by region Australasia\n3.6554e-5, // Bandwidth by region EMEA\n0, // Bandwidth by region India\n0, // Bandwidth by region Japan\n1.1524e-5, // Bandwidth by region North America\n1.223e-6, // Bandwidth by region Rest Of APAC\n0 // Bandwidth by region South America\n],\n\"percentage\": [ // The percentage of the bandwidth by regions\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\n0, // Australasia", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-api"}, {"document_id": "ibmcld_01447-7714-9749", "score": 0.6471830606460571, "text": "\nContainer Registry determines the size of all new layers and adds the amount of storage to your monthly usage.\n\n\n\n Billing for storage and pull traffic \n\nDepending on the service plan that you choose, you are charged for the storage and pull traffic that you use per month in each region.\n\n\n\n Storage charges \n\nEvery IBM Cloud Container Registry service plan comes with a certain amount of storage that you can use to store your Docker images in the namespaces of your IBM Cloud account. If you're on the standard plan, you are charged by GB-Months of usage. The first 0.5 GB-Months are free. If you're on the free plan, you can store your images in Container Registry for free until you reach the quota limits for the free plan. A GB-Month is an average of 1 GB of storage for a month (730 hours).\n\nThe following example is for the standard plan:\n: You use 5 GB for exactly half the month and then you push several images to your namespace and use 10 GB for the rest of the month. Your monthly usage is calculated as shown in the following example:\n\n(5 GB x 0.5 (months)) + (10 GB x 0.5 (months)) = 2.5 + 5 = 7.5 GB-Months\n\nIn the standard plan, the first 0.5 GB-Months are free, so you get charged for 7 GB-Months (7.5 GB-Months - 0.5 GB-Months).\n\n\n\n\n\n Pull traffic charges \n\nEvery IBM Cloud Container Registry service plan includes a certain amount of free pull traffic to your private images that are stored in your namespace. Pull traffic is the bandwidth that you use when you pull a layer of an image from your namespace to your local computer. If you're on the standard plan, you're charged by GB of usage per month. The first 5 GB each month is free. If you're on the free plan, you can pull images from your namespace until you reach the quota limit for the free plan.\n\nPull traffic across public connections counts toward usage and quota. Pull traffic across private connections doesn't count.\n\nThe following example is for the standard plan:\n: In the month, you pulled images that contain layers with a total size of 14 GB.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview"}, {"document_id": "ibmcld_08112-7997-9381", "score": 0.6462112069129944, "text": "\n<br><br> * io_over_period - Auto scaling scalar I/O utilization over period. -> [Average Disk IO utilization for this period]<br><br><br> \n <br><br> * io_enabled - Auto scaling scalar I/O utilization enabled.<br><br><br> \n <br><br> * rate_increase_percent - Auto scaling rate increase percent. -> [Scale up by rate_increase_percent]<br><br><br> \n <br><br> * rate_limit_mb_per_member - Auto scaling rate limit in megabytes per member.-> [Scale up by rate_increase_percent<br><br><br> \n <br><br> * rate_period_seconds - Auto scaling rate period in seconds. -> [Scale up by rate_increase_percent every rate_period_seconds]<br><br><br> \n <br><br> * rate_units - Auto scaling rate in units<br><br><br> \n Nested scheme for memory: \n <br><br> * io_above_percent - Auto scaling scalar I/O utilization above percent. -> [Average IO utilization]<br><br><br> \n <br><br> * io_enabled- Auto scaling scalar I/O utilization enabled.<br><br><br> \n <br><br> * io_over_period - Auto scaling scalar I/O utilization over period. ->[Average IO utilization for this period]<br><br><br> \n <br><br> * rate_increase_percent - Auto scaling rate in increase percent. -> [Scale up by rate_increase_percent]<br><br><br> \n <br><br> * rate_limit_mb_per_member - Auto scaling rate limit in megabytes per member. [Scale up by rate_increase_percent every rate_period_seconds up to rate_limit_mb_per_member]<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-create-three-tier-resilient-vpc-saz-modular"}, {"document_id": "ibmcld_01468-1672-3502", "score": 0.6441466808319092, "text": "\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_list) command.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quota"}, {"document_id": "ibmcld_06520-1690-3879", "score": 0.6374945640563965, "text": "\nFor example, in a given month, if you have a Databases for MongoDB deployment that has 20 GB of disk per member, and has three data members, you receive 60 GB of backup storage free for that month. If your backup storage utilization is greater than 60 GB for the month (in this scenario), you are charged an overage of $0.03/ month per gigabyte.\n\nBy default, Cloud Databases provides a daily backup that is stored for 30 days. These backups, and any on-demand backups you make, all count toward the allocation.\n\nIn the example, if your database contains 2 GB of data and you have not taken any on-demand backups, then your total backup size is 2 GB x 30 = 60 GB. Your backup costs are nil.\n\nIf your database contains 15 GB of data and you have not taken any on-demand backups, then your total backup size is 15 GB x 30 = 450 GB. In this scenario, your backup costs are (450 GB - 60 GB) * 0.03 = $11.7 per month.\n\nMost deployments will not ever go over the allotted credit.\n\n\n\n\n\n Dedicated Cores Pricing \n\nYou have the option of selecting the CPU allocation for your for Databases for MongoDB Standard Edition deployment, while dedicated cores are required for Databases for MongoDB Enterprise Edition deployments. With dedicated cores, your resource group is given a single-tenant host with a guaranteed minimum reserve of cpu shares. Your deployments are then allocated the number of CPUs you specify. The cost of dedicated cores is $45 per core per month for the Standard plan, and $60 per core per month for the Enterprise plan. Each member gets the selected number of cores. For example, if you provision a deployment with three dedicated cores per member on the Standard plan, that is a total of 9 cores, and billed at $405 per month.\n\nThe default Shared CPU setting provisions for your Databases for MongoDB Standard Edition deployment hosts with shared compute resources and incurs no additional charge.\n\nDedicated cores are an optional feature for Databases for MongoDB Standard Edition and required for Databases for MongoDB Enterprise Edition deployments.\n\n\n\n\n\n Scaling per Member \n\nDatabases for MongoDB deployments have minimum and maximum allocation for disk and RAM as shown.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-pricing"}, {"document_id": "ibmcld_05405-2462-3494", "score": 0.6343501806259155, "text": "\n10 vCPU <br>20 GB 10 vCPU <br>40 GB \n 12 vCPU <br>24 GB 12 vCPU <br>48 GB \n\n\n\nYour existing apps and jobs might be using other memory and CPU combinations, and those will remain unaffected. However, these other combinations are not valid and only the valid combinations are supported. Therefore, any new apps or jobs as well as any changes to existing apps or jobs must comply with the list of valid choices.\n\n\n\n\n\n Units of measurement \n\nDecimal units such as kilobyte (KB), megabyte (MB), and gigabyte (GB) are commonly used to express the size of data. Binary units of measurement include kibibyte (KiB), mebibyte (MiB), and gibibyte (GiB). The following table compares the names, symbols, and values of decimal and binary units.\n\n\n\nTable 2. Comparison of binary and decimal units and values\n\n Binary name Binary value (base 2) Decimal name Decimal value (base 10) \n\n kibibyte (KiB) 2^10 kilobyte (KB) 10^3 \n mebibyte (MiB) 2^20 megabyte (MB) 10^6 \n gibibyte (GiB) 2^30 gigabyte (GB) 10^9 \n tebibyte (TiB) 2^40 terabyte (TB) 10^12", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-mem-cpu-combo"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02294-7-2292", "score": 0.5934654474258423, "text": "\nTypes of multifactor authentication \n\nMultifactor authentication (MFA) adds an extra layer of security to your account by requiring all users to authenticate by using another authentication factor beyond an ID and password. MFA is also commonly known as two-factor authentication (2FA).\n\nThe following two types of MFA options might be enabled for your account:\n\nID-based MFA\n: ID-based MFA is the preferred method for requiring MFA in an account. This type of MFA is associated with each users' ID and authenticates them across all accounts that they are a member of, so they authenticate only one time. This type of MFA overrides the legacy account-based MFA options.\n: ID-based MFA applies to all resources in any type of account. When ID-based MFA is enabled, a user is prompted to provide a unique identifier (such as a username or email) and a one-time password (OTP) generated by an authenticator app or a hardware token. After the correct OTP is entered, access is granted to the requested resource. This type of MFA is much more secure than account-based MFA because it is not limited to classic infrastructure resources and applies to all resources within the account. It also reduces the risk of a breach because of a weak password or the use of the same password across multiple accounts.\n\nAccount-based MFA\n:\nClassic infrastructure\n\nAccount-based MFA applies only to classic infrastructure and not to other resources in your account. Unlike with ID-based MFA, legacy MFA options, such as security questions, are enforced only on the specific account where the MFA is enabled. If you have a different legacy MFA option set up for each account that you are a member of, you must authenticate in a different way each time that you switch accounts.\n\nLegacy account-based MFA was available to accounts with classic infrastructure prior to the release of ID-based MFA. This legacy offering continues to work for accounts with classic infrastructure and requires the user to provide a secondary authentication input when logging in or switching to accounts with classic infrastructure. Non-classic resources are not secured by this legacy offering. ID-based MFA is for customers that want to implement MFA to secure the full range of IBM Cloud offerings.\n\n\n\n ID-based MFA options", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-types"}, {"document_id": "ibmcld_14009-7-1986", "score": 0.5859807729721069, "text": "\nFAQs: Virtual servers \n\n\n\n What types of virtual servers are available for use? \n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure. The standard offering is a public-based virtual server, which is a multi-tenant environment that is suitable for various needs. If you're looking for a single-tenant environment, consider the dedicated virtual server offering. The dedicated virtual server option is ideal for applications with more stringent resource requirements. For more information about the current virtual server offerings, see [Getting started with virtual servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial).\n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud (VPC) is the next generation of virtual servers. You create your own space in the IBM Cloud to run an isolated environment within the public cloud by using VPC. IBM Cloud VPC provides the security of a private cloud with the agility and ease of a public cloud. For more information, see [About virtual server instances for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers).\n\n\n\n\n\n Where can I find pricing information for public instance types? \n\nFor more information, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n\n\n\n\n\n Where can I find pricing information for virtual public instances? \n\nEstimating your cost for an IBM Cloud server to support your workload begins in the [IBM Cloud catalog](https://cloud.ibm.com/catalog). From the catalog, select Compute and choose the server type - Bare Metal Server, Virtual Server, or Virtual Server for VPC (Virtual Private Cloud). For more information, see the [Virtual servers provisioning calculator](https://www.ibm.com/cloud/virtual-servers/calculator/).\n\n\n\n\n\n Can I change the configuration of a virtual server? \n\nAfter you provision a virtual server, you can upgrade or downgrade your server configuration at any time.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-faqs-virtual-servers"}, {"document_id": "ibmcld_08063-4144-5315", "score": 0.5675595998764038, "text": "\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},\n\"resources\": [\n{\n\"crn\": \"crn:v1:staging:public:cloud-object-storage:global:a/2dded3de4a4d4a098ebd0998be5cc845:723a59c4-9338-43fe-9dc4-e4a87cc78c8e::\",\n\"note\": \"Resource note\"\n}\n]\n}'\n\nOfferingType offeringType = new OfferingType.Builder()\n.group(OfferingType.Group.CRN_SERVICE_NAME)\n.key(\"cloud-object-storage\")\n.build();\nOffering offeringPayload = new Offering.Builder()\n.name(\"Cloud Object Storage\")\n.type(offeringType)\n.build();\nCreateCaseOptions createCaseOptions = new CreateCaseOptions.Builder()\n.type(\"technical\")\n.subject(\"Example technical case\")\n.description(\"This is an example case description. This is where the problem would be described.\")\n.offering(offeringPayload)\n.severity(4)\n.build();\n\nResponse<Case> response = service.createCase(createCaseOptions).execute();\nCase xCase = response.getResult();\n\nSystem.out.println(xCase);\n\noffering_type = OfferingType(\ngroup='crn_service_name',\nkey='cloud-object-storage'\n)\noffering_payload = Offering(\nname='Cloud Object Storage',", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-open-case&interface=ui"}, {"document_id": "ibmcld_07578-337406-339520", "score": 0.5615425109863281, "text": "\nMore network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure. The standard offering is a public-based virtual server, which is a multi-tenant environment that is suitable for various needs. If you're looking for a single-tenant environment, consider the dedicated virtual server offering. The dedicated virtual server option is ideal for applications with more stringent resource requirements. For more information about the current virtual server offerings, see [Getting started with virtual servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial).\n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud (VPC) is the next generation of virtual servers. You create your own space in the IBM Cloud to run an isolated environment within the public cloud by using VPC. IBM Cloud VPC provides the security of a private cloud with the agility and ease of a public cloud. For more information, see [About virtual server instances for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers).\n* Where can I find pricing information for public instance types?\n\nFor more information, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* Where can I find pricing information for virtual public instances?\n\nEstimating your cost for an IBM Cloud server to support your workload begins in the [IBM Cloud catalog](https://cloud.ibm.com/catalog). From the catalog, select Compute and choose the server type - Bare Metal Server, Virtual Server, or Virtual Server for VPC (Virtual Private Cloud). For more information, see the [Virtual servers provisioning calculator](https://www.ibm.com/cloud/virtual-servers/calculator/).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-337380-339494", "score": 0.5615425109863281, "text": "\nMore network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure. The standard offering is a public-based virtual server, which is a multi-tenant environment that is suitable for various needs. If you're looking for a single-tenant environment, consider the dedicated virtual server offering. The dedicated virtual server option is ideal for applications with more stringent resource requirements. For more information about the current virtual server offerings, see [Getting started with virtual servers](https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-getting-started-tutorial).\n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud (VPC) is the next generation of virtual servers. You create your own space in the IBM Cloud to run an isolated environment within the public cloud by using VPC. IBM Cloud VPC provides the security of a private cloud with the agility and ease of a public cloud. For more information, see [About virtual server instances for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-advanced-virtual-servers).\n* Where can I find pricing information for public instance types?\n\nFor more information, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* Where can I find pricing information for virtual public instances?\n\nEstimating your cost for an IBM Cloud server to support your workload begins in the [IBM Cloud catalog](https://cloud.ibm.com/catalog). From the catalog, select Compute and choose the server type - Bare Metal Server, Virtual Server, or Virtual Server for VPC (Virtual Private Cloud). For more information, see the [Virtual servers provisioning calculator](https://www.ibm.com/cloud/virtual-servers/calculator/).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02855-12369-14489", "score": 0.5613565444946289, "text": "\nThe text in the Option label field has two functions:\n\n\n\n* The text is shown in the suggestions list as an option for customers to select.\n* When selected by a customer, the text is sent to your assistant as a new message. The label must be able to function as input that your dialog understands and knows how to handle.\n\n\n\nBy default, the option label Connect with agent is used. Change the option label to a message that helps your customers reach whatever form of support you do offer. If you offer a toll-free support line, you might add Get the support line phone number. Or if you offer an online support request form, you might add Open a support ticket.\n\nWhether you use the default option label or add your own, make sure your dialog is designed to recognize the message and respond to it appropriately. For more information, see [Connecting customers with support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support).\n\n\n\n\n\n\n\n Dialog considerations \n\nThe rich responses that you add to a dialog are displayed in the web chat as expected, with the following exceptions:\n\n\n\n* Connect to human agent: This response type is ignored.\n* Option: If your option list contains up to four choices, they are displayed as buttons. If your list contains five or more options, then they are displayed in a drop-down list.\n* Pause: This response type pauses the assistant's activity in the chat. However, activity does not resume after the pause until another response is triggered. Whenever you include a pause response type, add another, different response type, such as text, after it.\n\n\n\nFor more information about rich response types, see [Rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_13741-7-1934", "score": 0.5556520819664001, "text": "\nService features \n\nYou can access the speech synthesis capabilities of the IBM Watson\u00ae Text to Speech service via an HTTP or WebSocket interface. Both interfaces provide features that let you submit and receive different information from the service. And as with all Watson services, SDKs are available to simplify application development in many programming languages.\n\n\n\n Using languages and voices \n\nThe service supports speech synthesis with voices for the languages listed in [Language support](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-aboutabout-languages). For different languages, the service offers female voices, male voices, or both. Some languages and voices might be supported for IBM Cloud\u00ae only.\n\nAll of the service's voices use neural voice technology, which produces more natural-sounding speech. The service offers two types of voices, expressive neural and enhanced neural, which have different qualities and features. For information about the types of voices and about the supported languages and voices for each type, see [Languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n Using audio formats \n\nThe service can return synthesized audio in the many formats listed in [Audio support](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-aboutabout-formats). For information about the supported audio formats, see [Using audio formats](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-audio-formats).\n\n\n\n\n\n Synthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's /v1/synthesize method. The two versions of the method offer generally equivalent functionality.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-features"}, {"document_id": "ibmcld_11564-6349-8231", "score": 0.5549952983856201, "text": "\nMore information that compares different infrastructure types is in [Comparing the different SAP-certified IaaS offerings](https://cloud.ibm.com/docs/sap?topic=sap-overviewiaas-offerings-compare-summary) with more detail under [Infrastructure certified for SAP](https://cloud.ibm.com/docs/sap?topic=sap-iaas-offerings). All SAPS benchmarks are listed for each profile under each infrastructure type that is offered in the IBM Cloud\u00ae for SAP portfolio.\n\n\n\n\n\n SAP HANA considerations \n\nThe SAP BW/4HANA business application is an analytical processing (OLAP) workload and is affected by multiple [SAP HANA Database Server design considerations](https://cloud.ibm.com/docs/sap?topic=sap-hana-design-considerations).\n\nDuring SAP sizing, decision making, and infrastructure selection for the SAP HANA infrastructure to support OLAP workloads, the sizing is most often determined by the memory (DRAM) capacity size.\n\n\n\n Scale-up and Scale-out \n\nSAP BW/4HANA is built to take advantage of the analytical capabilities of SAP HANA and is regularly used in scale-out scenarios to analyze huge volumes of data (including data beyond ERP transactional data, such as Hadoop data lakes).\n\nIt is important to understand SAP BW/4HANA certifications to ensure your infrastructure selection meets business requirements, particularly for business decisions on lead times of analytics and reporting or quantity of data to be analyzed.\n\nAll SAP-certified infrastructure on Cloud for OLAP (i.e. SAP BW/4HANA) is listed in [SAP HANA Directory - Certified IaaS Platforms - OLAP application type](https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN//solutions?filters=iaas;v:105). For performance benchmarks of the SAP-certified infrastructure for SAP BW/4HANA, these are listed in the [SAP BW edition for SAP HANA benchmark directory (BWH)](https://www.sap.com/dmc/exp/2018-benchmark-directory//bwh).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-bw4hana"}, {"document_id": "ibmcld_08063-5034-6357", "score": 0.5547571778297424, "text": "\nResponse<Case> response = service.createCase(createCaseOptions).execute();\nCase xCase = response.getResult();\n\nSystem.out.println(xCase);\n\noffering_type = OfferingType(\ngroup='crn_service_name',\nkey='cloud-object-storage'\n)\noffering_payload = Offering(\nname='Cloud Object Storage',\ntype=offering_type\n)\n\ncase = case_management_service.create_case(\ntype='technical',\nsubject='Example technical case',\ndescription='This is an example case description. This is where the problem would be described.',\noffering=offering_payload,\nseverity=4,\n).get_result()\n\nprint(json.dumps(case, indent=2))\n\nofferingType, _ := caseManagementService.NewOfferingType(\ncasemanagementv1.OfferingTypeGroupCRNServiceNameConst,\n\"cloud-object-storage\",\n)\nofferingPayload, _ := caseManagementService.NewOffering(\n\"Cloud Object Storage\",\nofferingType,\n)\n\ncreateCaseOptions := caseManagementService.NewCreateCaseOptions(\n\"technical\",\n\"Example technical case\",\n\"This is an example case description. This is where the problem would be described.\",\n)\ncreateCaseOptions.SetSeverity(4)\ncreateCaseOptions.SetOffering(offeringPayload)\n\ncaseVar, response, err := caseManagementService.CreateCase(createCaseOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(caseVar, \"\", \" \")\nfmt.Println(string(b))\n\nconst offeringType = {\ngroup: 'crn_service_name',", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-open-case&interface=ui"}, {"document_id": "ibmcld_15545-232015-233745", "score": 0.5413224697113037, "text": "\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https://cloud.ibm.com/docs/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https://cloud.ibm.com/docs/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https://cloud.ibm.com/apidocs/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https://cloud.ibm.com/apidocs/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys. SSH keys can either be of type RSA or Ed25519. Ed25519 can be used only if the operating system supports this key type. Ed25519 can't be used with Windows or VMware images.\n* --dedicated-host: ID or name of the host destination where the instance is placed.\n* --dedicated-host-group: ID or name of the host group destination where the instance is placed.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12559-1521-3753", "score": 0.6374543905258179, "text": "\nTo create an enterprise, you must be the account owner or have the Administrator role on the Billing account management service.\n\nCreating an enterprise from an account and importing existing accounts cannot be undone. This tutorial is provided as an example of the steps you can follow to set up an enterprise by department, but you should carefully plan your enterprise structure around your organization's needs.\n\n\n\n\n\n Step 1: Create the enterprise \n\nEnterprises are created from an existing Subscription account. When you create the enterprise, the account is added to the enterprise hierarchy. Billing transitions to being managed by the enterprise, but its users and resources remain the same and are completely unaffected. For a complete description of account impacts, see [Creating an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-create-enterprise).\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Enterprise, and click Create.\n2. Enter the name of your company, such as Example Corp, to identify your enterprise.\n3. Enter your company's domain, such as examplecorp.com.\n4. Review the information about the impact to your account, and select I understand the impact to my account. Then, click Create. The account is now permanently part of the enterprise and can't be removed.\n\n\n\nAfter your enterprise is created, you are directed to the enterprise dashboard. From here, you can view the enterprise details, accounts, users, and billing information. Go to the Accounts page to view your enterprise structure, where you see the following accounts:\n\n\n\n* An enterprise account with the same name as your enterprise. This account is used for enterprise management.\n* The account that you created the enterprise from. Users can continue working with resources in the account unaffected.\n\n\n\n\n\n\n\n Step 2: Create an enterprise structure with account groups \n\nUse account groups to [organize related accounts](https://cloud.ibm.com/docs/account?topic=account-enterprise-organize). The second and third tier of the Example Corp. enterprise hierarchy contain the Marketing, Development, Sales, Design, and Engineering account groups. Complete the following steps to create the account groups:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_12559-7-2119", "score": 0.6279783248901367, "text": "\nSetting up an enterprise \n\nThis tutorial walks you through how to set up an enterprise by department so you can manage and track usage costs for multiple IBM Cloud\u00ae accounts. By completing this tutorial, you learn how to create an enterprise, add accounts and organize them in account groups, invite users, and explore subscriptions.\n\nThe tutorial uses a fictitious company that is called Example Corp that wants to create an enterprise with the following structure. As you complete the tutorial, adapt each step to match your organization's accounts and desired structure.\n\nZoom\n\n![A four-tier enterprise that groups accounts according to department in an organization. For example, account groups are named Marketing, Development, and Sales. The account groups contain accounts for teams within those departments. For example, the Sales account group contains accounts for Direct, Online, and Enablement.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-by-dept.svg)\n\nFigure 1. An enterprise that is organized by department\n\n\n\n Before you begin \n\nRead [What is an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise) to learn the basic principles of how account management, billing, resources, and user and access management work in an enterprise.\n\nVerify that you have the required access in a Subscription account, which serves as the base account from which you create the enterprise. To create an enterprise, you must be the account owner or have the Administrator role on the Billing account management service.\n\nCreating an enterprise from an account and importing existing accounts cannot be undone. This tutorial is provided as an example of the steps you can follow to set up an enterprise by department, but you should carefully plan your enterprise structure around your organization's needs.\n\n\n\n\n\n Step 1: Create the enterprise \n\nEnterprises are created from an existing Subscription account. When you create the enterprise, the account is added to the enterprise hierarchy.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_12540-4-2205", "score": 0.6227278709411621, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating an enterprise \n\nYou create an IBM Cloud\u00ae enterprise from an existing Subscription account. When an existing subscription account is used, an enterprise and an enterprise account are created. The account that you use to create the enterprise and the new enterprise account are permanently added to the enterprise, but this account does not become the parent account.\n\n\n\n Before you begin \n\nTo create an [IBM Cloud enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise), you must be the account owner or have the Administrator role on the Billing account management service in a Subscription account.\n\nThe Subscription account that you use to create the enterprise is permanently moved into the enterprise. Moving the account into the enterprise has the following impacts:\n\n\n\n* Billing for the account transitions to being [managed by the enterprise](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise). After the transition, users in the account can't access billing and payment information, such as invoices, payments, or subscriptions, for future billing periods. To view or manage billing, users need to be invited to the enterprise account and be given access to the Billing service in that account.\n* Users and access permissions within the account are not changed. Access within the account is separate from the enterprise, and users don't automatically get access within the enterprise when the account is added. However, billing information is no longer available within the account regardless of access permissions.\n* Resources within the account are not changed. Users with the correct access permissions can continue to view usage information for resources in the account.\n\n\n\nBefore you can create an enterprise by using Terraform, make sure that you have completed the following:\n\n\n\n* Install the Terraform CLI and configure the IBM Cloud Provider plug-in for Terraform. For more information, see the tutorial for [Getting started with Terraform on IBM Cloud\u00ae](https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-create-enterprise"}, {"document_id": "ibmcld_12540-7265-8679", "score": 0.6177321672439575, "text": "\nname='Example Enterprise',\nprimary_contact_iam_id=contact_iam_id,\n).get_result()\n\nprint(json.dumps(create_enterprise_response, indent=2))\n\ncreateEnterpriseOptions := enterpriseManagementService.NewCreateEnterpriseOptions(\nsrcAccountID,\n\"Example Enterprise\",\ncontactIamID,\n)\n\ncreateEnterpriseResponse, response, err := enterpriseManagementService.CreateEnterprise(createEnterpriseOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createEnterpriseResponse, \"\", \" \")\nfmt.Println(string(b))\n\nconst params = {\nsourceAccountId: srcAccountId,\nname: 'Example Enterprise',\nprimaryContactIamId: contactIamId,\n};\n\nenterpriseManagementService.createEnterprise(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})\n.catch(err => {\nconsole.warn(err)\n});\n\n\n\n\n\n Creating an enterprise by using Terraform \n\nUse the following steps to create an enterprise:\n\n\n\n1. Create an argument in your main.tf file. The following example creates an enterprise by using the ibm_enterprise resource, where name is a unique name to identify the enterprise. You must have an existing IAM ID of an enterprise primary contact in order to complete the task.\n\nresource \"ibm_enterprise\" \"enterprise\" {\nsource_account_id = <source_account_id>\nname = <name>\nprimary_contact_iam_id = <primary_contact_iam_id>\n}\n\nYou can specify the ID of an account that is used to create the enterprise on the source_account_id option.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-create-enterprise"}, {"document_id": "ibmcld_12546-4-2108", "score": 0.6168609857559204, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Adding accounts to an enterprise \n\nYou can build out your enterprise by adding more IBM Cloud\u00ae accounts to it. To add accounts, you can import existing accounts that aren't in another enterprise, or you can create new accounts within your enterprise.\n\nAfter your enterprise has multiple accounts, you can organize related accounts by using account groups. For more information, see in [Organizing accounts in an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-organize).\n\n\n\n Importing existing accounts \n\nYou can import existing accounts into an enterprise. After you import an account, it can't be removed, and each account can be a part of only one enterprise. If you import a Lite or trial account, it's automatically upgraded to a [Pay-As-You-Go account](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\nImporting an account to the enterprise has the following impacts:\n\n\n\n* Billing for the account transitions to being managed by the enterprise. After the transition, users in the account can't access billing and payment information, such as invoices, payments, or subscriptions, for future billing periods. To view or manage billing, users need to be invited to the enterprise account and be given access to the Billing service in that account. See [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise) for more information.\n* Users and access permissions within the account are not changed. Access within the account is separate from the enterprise, and users don't automatically get access within the enterprise when the account is imported.\n* Resources within the account are not changed. Users with the correct access permissions can continue to view usage information for resources in the account.\n\n\n\nTo import existing accounts into an enterprise, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Billing service within the account.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_12545-7-2359", "score": 0.6121267080307007, "text": "\nUser management for enterprises \n\nIBM Cloud\u00ae enterprises are valuable for large companies or organizations that need to group a set of accounts while still maintaining a separation and isolation between the accounts for different departments or teams. The management of users and their access to resources in each account remains entirely separate even when the accounts are added and organized in an enterprise.\n\nSee [What is an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information about enterprises.\n\nThe user list for each child account in an enterprise is accessible only to users in that child account. This means the users who are invited to the enterprise and the users who are invited to the accounts within the enterprise remain entirely separate. This is beneficial because you can add multiple accounts to an enterprise and organize them as needed into account groups, but keep the user lists restricted from other accounts.\n\nIn most cases, you want to add only the users to your enterprise account that need the ability to manage the enterprise. Depending on the role the user is assigned on the [Enterprise account management service](https://cloud.ibm.com/docs/account?topic=account-account-servicesenterprise-account-management), they have varying levels of access for managing the enterprise. For example, a user assigned the Administrator role on the Enterprise service can rename the enterprise, update the domain, view usage, create accounts, and more. However, a user with the viewer or operator role is limited to viewing the accounts and account groups hierarchy for the enterprise.\n\nInviting users to the enterprise account doesn't provide access to manage any of the child accounts within the enterprise or their resources. If you add a user to an enterprise account that contains a number of accounts, those users do not automatically have access to manage those accounts as far as user management, billing, and more. The enterprise account users also don't have access to any resources in other accounts within the enterprise.\n\nIf you want a user to manage the enterprise and have access to resources within child accounts, you must invite them to both accounts. Assigning access policies in the enterprise account allows the user to manage the enterprise.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-access-management"}, {"document_id": "ibmcld_12552-7-1847", "score": 0.6112815141677856, "text": "\nFAQs about enterprises \n\nFAQs for your IBM Cloud\u00ae enterprise might include questions about importing accounts, moving accounts and account groups, and inviting users to your enterprise. To find all FAQs for IBM Cloud, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n How do I set up an enterprise account? \n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n\n\n\n\n\n When I create an enterprise, does my IBM Cloud account become the enterprise account? \n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n\n\n\n\n\n Can I use my IBM Cloud account to create multiple enterprise accounts? \n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\n\n\n\n\n Can an existing enterprise be a child of another enterprise? \n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n\n\n\n\n\n How do I add child accounts to my enterprise? \n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-faqs"}, {"document_id": "ibmcld_03749-10273-12577", "score": 0.6067993640899658, "text": "\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice. If all of the credit in the credit pool is used, the invoice contains a line item for any overage charges.\n\nBecause all usage is invoiced through the enterprise account, child accounts within the enterprise don't receive separate invoices.\n\nYou can analyze usage costs for each account or account group on the Usage page in the enterprise account. For details, see [Viewing usage in an enterprise](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Access management for enterprise billing and usage \n\nAs with other enterprise management roles, access to enterprise billing and usage is managed through the enterprise account. Users must be invited to the enterprise account and assigned an access policy with a role on the relevant service.\n\nIn an enterprise, billing access and usage access are assigned separately.\n\n\n\n* Billing access is provided by assigning enterprise users a role on the Billing account management service. For example, you can assign the Viewer role to an enterprise user so that they can view the amount of available subscription credit in the credit pool. If you would like an enterprise user to be able to add new subscriptions or manage payment methods, you can assign the Editor or Administrator role to them.\n* Usage access is provided by assigning enterprise users the Usage Reports Viewer, Editor, or Administrator role on the Enterprise account management service. You can assign this access for the entire enterprise or for specific account groups and accounts.\n\n\n\nIf you want your billing administrator to be able to view costs by account or account group, assign them the appropriate access on both the Enterprise service and Billing service.\n\nFor more information, see [Assigning access for enterprise management](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-assign-access-enterprise).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise&interface=ui"}, {"document_id": "ibmcld_16727-1133881-1135817", "score": 0.5996232628822327, "text": "\nYour account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy. See [What is an enterprise?](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n* Can an existing enterprise be a child of another enterprise?\n\nNo, an existing IBM Cloud enterprise account can't be imported into another enterprise.\n* How do I add child accounts to my enterprise?\n\nYou can use the enterprise dashboard to import an existing account to your enterprise or create a new account within your enterprise. For more information, see [Import existing accounts](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uiexisting_accounts_tutorial) and [Create new accounts](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=uicreate-accounts_tutorial).\n* Can I import a Lite account into an enterprise?\n\nYes, but your Lite account is automatically upgraded to a Pay-As-You-Go account. Billing for the account is then managed at the enterprise level. For more information, see [Centrally managing billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise).\n* Can I remove my account from an enterprise?\n\nAfter you import your account into an enterprise, you can't remove it.\n* Can I move an account within an enterprise?\n\nYes, you can move your account anywhere within an enterprise. For example, you can move your account directly under the enterprise or from one account group to another.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07964-6983-8940", "score": 0.5995118618011475, "text": "\nSee [Enterprise account architecture](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-about) for recommendations on how to address these concerns across accounts so that a robust, compliant, and scalable solution can be achieved.\n\n\n\n\n\n Organizing your enterprise \n\nWithin an enterprise, you can create multiple accounts and account groups. With this structure, you can easily manage many accounts and many deployments.\n\n\n\n VPC reference architecture \n\nThe following diagram shows a single enterprise with one account group that contains separate accounts for each deployment of the VPC reference architecture.\n\nZoom\n\n![Enterprise account organization with VPC reference architecture](https://cloud.ibm.com/docs-content/v1/content/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221/framework-financial-services/vpc/images/resource-organization/vpc-enterprise-account-organization-beta2.drawio.svg)\n\nFigure 7. Enterprise account organization with VPC reference architecture\n\nWhen using enterprise accounts, it is recommended that you use one enterprise account for production and another enterprise account for development. See [Planning your enterprise account structure](https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-account-structure) for more information.\n\n\n\n\n\n Satellite reference architecture \n\nThe following diagram shows an enterprise with one account group that contains separate accounts for each deployment of the Satellite reference architecture.\n\nZoom\n\n![Enterprise account organization with Satellite reference architecture](https://cloud.ibm.com/docs-content/v1/content/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221/framework-financial-services/satellite/images/resource-organization/satellite-enterprise-account-organization-beta2.drawio.svg)\n\nFigure 8. Enterprise account organization\n\n\n\n\n\n\n\n\n\n Related controls in IBM Cloud Framework for Financial Services", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-account-organization"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11601-1712-3717", "score": 0.6993206143379211, "text": "\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.\n\n\n\n\n\n Requesting support for SAP-certified IBM Power Virtual Servers \n\nAll performance-related issues need to be checked by IBM Power Systems and IBM Cloud support first, to establish whether any infrastructure-related issues exist, before a case of the software stack (SAP Workloads) can be opened.\n\nIf the issue is operating system (OS) related, go the support portal of the distribution (AIX or Linux\u00ae) to open a case.\n\nYou can check whether the infrastructure is set up correctly by running a python script on Linux\u00ae: python chk_numa_lpm.py. For more information, see [SAP Note 2923962 - - Check SAP HANA NUMA Layout on IBM Power Systems Virtual Servers](https://launchpad.support.sap.com//notes/2923962).\n\n\n\n\n\n Requesting support for resources in the European Union \n\nEuropean Union (EU) support is available to customers who choose to enable the EU supported setting. EU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe.\n\nGlobal teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the primary user or account owner. For more information, see [Enabling the EU Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* Your resources are in the appropriate European data center.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_09646-0-364", "score": 0.6958411931991577, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nFor information about opening an IBM support cases, or about support levels and case severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\nIf you need to open a support case, collect as much information as possible to help Support analyze and diagnose your problem.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/microsoft?topic=microsoft-microsoft-help-support"}, {"document_id": "ibmcld_08056-6550-8417", "score": 0.6851725578308105, "text": "\nFor support for these products, go to [IBM Support](https://www.ibm.com/support/home/).\n\nSupport for third-party services is provided by the service provider.\n\n\n\n\n\n Does IBM Cloud provide support for resources available through the IBM SkillsBuild Software Downloads? \n\nThe [IBM SkillsBuild Software Downloads](https://www.ibm.com/academic/home) is an IBM corporate program that provides access to the IBM Cloud Platform for faculty, students, and researchers at accredited academic institutions. Acceptance decisions, length of participation, awarding of credits, and any possible extensions are made by the IBM SkillsBuild Software Downloads Team and not IBM Cloud Support. IBM Cloud Support also does not provide technical support for accounts that are part of the IBM SkillsBuild Software Downloads Program. For more information about the program, see the [IBM SkillsBuild Software Downloads FAQ](https://www.ibm.com/academic/faqs/faqs).\n\n\n\n\n\n How do I ensure that users in my account get updates for a support case? \n\nAs the account owner or as an administrator or editor on the Support Center service, you can add users in the account to the watchlist. Users on the watchlist can view and follow the support case's progress. For more information, see [Updating your support case's watchlist](https://cloud.ibm.com/docs/get-support?topic=get-support-contact-watchlist).\n\n\n\n\n\n Can I find support cases that are created by specific users? \n\nYou can download a list of created support cases and view the cases that are created by each user.\n\nTo download a list of created support cases, use the following steps:\n\n\n\n1. From the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/9147bc2ffd9bafd03e4559b378e714fac17a4977/icons/help.svg) > Support center.\n2. Click View all from the Recent support cases tile.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-get-supportfaq"}, {"document_id": "ibmcld_04249-0-808", "score": 0.6832199692726135, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions when using Citrix DaaS for IBM Cloud\u00ae, you can contact Citrix support. See [Contact support](https://www.citrix.com/support/open-a-support-case/).\n\nIf you have problems or questions when using the underlying IBM Cloud infrastructure, you can get help by searching for information or by asking questions through one of the forums. You can also create a case in the [IBM Cloud console](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nSee [Getting help](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatarusing-avatar) for more details about using the forums.\n\nFor information about opening an IBM support ticket, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/citrix-daas?topic=citrix-daas-gettinghelp"}, {"document_id": "ibmcld_12857-6706-7812", "score": 0.6821523904800415, "text": "\nSelect your product's support provider and complete the support statement field. For the support statement, describe the provided support for your product and add any additional support information that isn't provided in the other fields.\n\n\n\n1. If you select Community for your support provider, provide the URL for the support community.\n2. If you select Third-party for your support provider, use the following steps to complete the necessary fields.\n\n\n\n3. Click Add support details and complete the necessary fields, then click Save to add each detail. You must add at least 1 support detail for your product.\n4. After you add all of your product's support details, provide the required URLs for your product.\n5. Add all locations where you provide support for your product.\n6. Add your escalation information. Do not use a personal phone number or email.\n7. Provide your support contact information. This information is for internal use only and is not displayed on the product details page.\n\n\n\n\n\n\n\n Next steps \n\nYou can now [add your broker](https://cloud.ibm.com/docs/sell?topic=sell-broker-onboard).", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-svc-define"}, {"document_id": "ibmcld_08091-2715-4739", "score": 0.6757533550262451, "text": "\nFor more information, see [Assigning user access for working with support center](https://cloud.ibm.com/docs/get-support?topic=get-support-access&interface=ui).\n\n\n\n Asking a question \n\nThe Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new question. Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about developing apps with the IBM Cloud platform and services.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and follow the questions that are tagged with ibm-cloud. When you create a question, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n\n\n Getting support for IBM Cloud Dedicated or Bluemix Local \n\nIf your account is either IBM Cloud Dedicated or Bluemix Local, support is provided by the IBM Cloud support team.\n\n\n\n* Open a new case by using the [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) page and click Create a case. Mention that your account is either IBM Cloud Dedicated or Bluemix Local in the Subject and Description of the support case.\n* If you don't have an IBMid, contact someone in your organization that does, or work with your IBM representative.\n\n\n\n\n\n\n\n Requesting support for resources in the European Union \n\nEuropean Union (EU) support is available to customers who choose to enable the EU supported setting. EU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe. Global teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the master user or account owner.", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_12805-5016-6513", "score": 0.6755611300468445, "text": "\nProvide details that help users understand how to get support if they encounter issues when they use the Operator bundle. For more information about providing support information, see [Defining your support experience](https://cloud.ibm.com/docs/sell?topic=sell-sw-support-details).\n\nTo define your product's support experience, use the following steps:\n\n\n\n1. Click Support.\n2. Select your product's support provider and complete the support statement field. For the support statement, describe the provided support for your product and add any additional support information that isn't provided in the other fields.\n\n\n\n1. If you select Community for your support provider, provide the URL for the support community.\n2. If you select Third-party for your support provider, use the following steps to complete the necessary fields.\n\n\n\n3. Click Add support details and complete the necessary fields, then click Save to add each detail. You must add at least 1 support detail for your product.\n4. After you add all of your product's support details, provide the required URLs for your product.\n5. Add all locations where you provide support for your product.\n6. Add your escalation information. Do not use a personal phone number or email.\n7. Provide your support contact information. This information is for internal use only and is not displayed on the product details page.\n\n\n\n\n\n\n\n Next steps \n\n[Onboard and validate your Operator bundle](https://cloud.ibm.com/docs/sell?topic=sell-bundle-onboard)", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-bundle-define"}, {"document_id": "ibmcld_12867-6005-7591", "score": 0.6726860404014587, "text": "\n\"support_type\": \"third-party\"\n}'\n\nThe details that you provide are displayed on your product details page in the catalog.\n\n\n\n\n\n Providing your product's support information by using the API \n\nYou can programmatically provide the support information of your product by calling the [Partner Center Sell API](https://cloud.ibm.com/apidocs/partner-center-sellupdate-support) as shown in the following sample request. You can provide your support site URL, support contacts, or the support escalation process. The example adds the https://my-company.com/support support site URL to your product:\n\ncurl --request PATCH --url https://product-\nlifecycle.api.cloud.ibm.com/openapi/v1/products/9fab83da-98cb-4f18-\na7ba-b6f0435c9673/support --header 'Authorization: Bearer TOKEN' --header 'Content-Type:\napplication/json' --data '{\n\"url\": \"https://my-company.com/support\",\n\"case\": \"case\",\n\"contacts\": \"JohnSupport@my-company.com\",\n\"country\": \"us\",\n\"escalationProcess\": \"Customers can escalate support cases via email.\",\n}'\n\nThe details that you provide are displayed on your product details page in the catalog.\n\n\n\n\n\n Updating your product's support information by using the API \n\nYou can programmatically update the support information of your product by calling the [Partner Center Sell API](https://cloud.ibm.com/apidocs/partner-center-sellupdate-support) as shown in the following sample request. The example updates the support site URL to https://my-updated-company.com/support:\n\ncurl --request PATCH --url https://product-\nlifecycle.api.cloud.ibm.com/openapi/v1/products/9fab83da-98cb-4f18-", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-sw-support-details"}, {"document_id": "ibmcld_11601-7-2113", "score": 0.6693599224090576, "text": "\nGetting help and support from IBM Cloud or SAP \n\nIf you experience problems with IBM Cloud, you have several options to get help with determining the cause of the problem and finding a solution.\n\nWhich support option depends on the level of support (and urgency), and whether the problem is with the Offering or running SAP Workloads using the Offering.\n\nOptions include:\n\n\n\n* IBM Cloud Support Case, using the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter)\n* SAP support incident, using the [SAP ONE Support Launchpad](https://launchpad.support.sap.com/)\n* IBM Cloud Docs\n\n\n\nFor previous users of IBM Cloud Classic Infrastructure (formerly Softlayer), please be aware these Support Cases were previously termed Support Tickets.\n\n\n\n IBM Cloud Support \n\nIBM Cloud Support handles any support questions and issues that might arise - available through live web chat, phone, and case-based support.\n\nEach IBM Cloud account automatically comes with customer support at no cost and covers most cases which are placed each day; this is the Basic level of support.\n\nThe types of available and response time of support, depends on the support level of the account. Your support plan also determines the severity level that you can assign to support cases. For more information, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nYou can change your current support plan at any time by contacting IBM Cloud sales expert.\n\nFor full information about opening an IBM Cloud Support case, or about support levels and ticket severities, see [IBM Cloud Support documentation](https://cloud.ibm.com/docs/get-support).\n\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_08040-3-1534", "score": 0.6635850667953491, "text": "\nGetting support docs \n\nUse the docs and API and SDK reference to learn about support plan options, how to use the Support Center for self-guided resolutions to your issues, and how to open and manage support cases when needed.\n\n Developer tools \n\n[API & SDK reference](https://cloud.ibm.com/apidocs/support-center/case-management)\n\n Recommended content \n\n[Using the Support Center Discover the best way to get the support that you need by utilizing the Support Center.](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar)[Basic, Advanced, and Premium Support plans IBM Cloud offers different support plans to fit your business needs.](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans)[Creating support cases Create a support case to have a support engineer review your issue and help you resolve the problem you're experiencing.](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case)\n\n Learn more \n\n[IBM Developer<br><br>Visit IBM Developer for technical articles, code patterns, tutorials, and more.<br><br>![112-Developer-tools.svg](https://cloud.ibm.com/media/docs/images/homepage/112-Developer-tools.svg)](https://developer.ibm.com/depmodels/cloud/)[Architecture Center<br><br>Discover the architecture references available for this product.<br><br>![190-Application-Platform.svg](https://cloud.ibm.com/media/docs/images/homepage/190-Application-Platform.svg)](https://www.ibm.com/cloud/architecture)[IBM Training<br><br>Build your skills with IBM Cloud training.<br><br>!", "title": "", "source": "https://cloud.ibm.com/docs/get-support"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-7-2136", "score": 0.6829505562782288, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 0.6829505562782288, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05138-7979-9034", "score": 0.6437026858329773, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_14704-7-1976", "score": 0.6368503570556641, "text": "\nImmutable backup solution architecture \n\nThe immutable backup solution architecture is suitable for clients who want to extend their VMware vCenter Server\u00ae instance with the Veeam\u00ae service to use immutable storage and minimize costs. The immutable backup solution architecture does not preclude any of the vCenter Server options such as Caveonix, Entrust, and VMware Aria\u00ae Operations\u2122.\n\nThe solution architecture is enabled by the following key technologies:\n\n\n\n* The immutable storage is provided by a Veeam Linux\u00ae hardened repository that is hosted on an IBM Cloud\u00ae bare metal server. For more information, see [Veeam Linux hardened repository](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr).\n* Optionally, if a sandbox is required, the following technologies are used:\n\n\n\n* Veeam vPower NFS service enables a virtual machine (VM) to be started and run directly from the backup file that is hosted in the backup repository.\n* Veeam Instant Restore enables a VM to be started directly from the backup files. Veeam vPower NFS service is used to access the backup files.\n* The Veeam VM Recovery with the restore to new location option, enables a copy of the VM to be started and connected to an isolated network. The backup file is converted to VMDK files and placed in the designated data store.\n* Veeam Secure Restore is only available for Microsoft\u00ae Windows\u00ae VMs. It is an extra option in the VM Recovery workflow that enables the VM to be scanned by antivirus software before you restore the VM. The VMs disks are connected to a mount server and then the antivirus software on the mount server that is used to scan files from the mounted disks.\n* VMware NSX-T\u2122 overlay segments allow the creation of isolated segments onto which copies of the VMs can be attached and isolated from the production VMs.\n* NSX-T distributed firewall provides the required isolation so that only required cybertoolsets can access the copies of the VMs.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"}, {"document_id": "ibmcld_02361-24500-26305", "score": 0.6338261365890503, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_14704-5996-7720", "score": 0.6297717094421387, "text": "\nThe immutable backup solution architecture consists of:\n\n\n\n* Linux hardened repository - The hardened repository is one or more IBM Cloud bare metal servers that run a supported Linux OS. The hardened repository is configured as an immutable storage repository. The IBM Cloud bare metal servers are ordered with internal disks and a RAID card to present this directly attached storage to the OS to be used as a backup repository.\n* Optionally, the immutable backup solution architecture can include one or more sandboxes. For more information, see [Veeam technologies used in the sandbox](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sandboxveeam).\n\n\n\nThe solution architecture does not show the components to adhere to the 3-2-1 backup rule. The 3-2-1 rule describes a backup architecture that:\n\n\n\n* 3 - At least three copies of data: production, primary backup, and backup copy\n* 2 - Use of two different types of media\n* 1 - Keep one backup copy offsite\n\n\n\nTo adhere to this rule, consider:\n\n\n\n* Use a Scale-Out-Repository capacity tier to copy data to Cloud Object Storage. Currently, IBM Cloud Object Storage cannot be used by Veeam as an immutable capacity tier.\n* Set up a Veeam backup copy job to transfer the backup to another backup repository hosted in another IBM Cloud data center.\n\n\n\n\n\n Related links \n\n\n\n* [Overview of VMware Solutions](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-solution_overview)\n* [Veeam on bare metal server introduction](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-bms-archi-intro)\n* [Veeam Backup and Replication 12 overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"}, {"document_id": "ibmcld_00589-9560-11733", "score": 0.6252488493919373, "text": "\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_05075-8514-10699", "score": 0.6202200651168823, "text": "\nDeleting a versioned object creates a delete marker. The object may appear to be deleted, but if the object is protected it is not possible to delete the protected version. Delete markers themselves are not protected.\n\n\n\n\n\n Replication \n\nObject Lock cannot be used on the source bucket for replication, only on the destination. Objects will be assigned the default retention period.\n\n\n\n\n\n Key Management Systems \n\nProtected objects will be encrypted using the root key of the bucket. When Object Lock is enabled on a bucket, the root key hosted by Key Protect or Hyper Protect Crypto Services is protected from deletion as long as an associated bucket has Object Lock enabled. This prevents crypto shredding of protected objects.\n\n\n\n\n\n Lifecycle configurations \n\nIt is possible to enable lifecycle policies that [archive locked objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive), but naturally not those that [expire objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) under retention or legal hold (unprotected objects in the bucket can still be expired).\n\n\n\n\n\n Immutable Object Storage \n\nObject Lock is an alternative to the retention policies available when using Immutable Object Storage. As Object Lock requires versioning to be enabled, and Immutable Object Storage is not compatible with versioning, it is not possible to have both WORM solutions enabled on the same bucket. It is possible to have a mix of buckets in a Service Instance, each using either Immutable Object Storage or Object Lock.\n\n\n\n\n\n Object Tagging \n\nThere are no restrictions on adding or modifying tags on a protected object.\n\n\n\n\n\n Other interactions \n\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_07578-459850-462081", "score": 0.6167443990707397, "text": "\nThis fact is a price of scalability and data resilience.\n\nIt is best to structure your data so that resolving conflicts is quick and does not involve operator assistance. This practice helps your databases to hum along smoothly. The ability to automatically resolve conflicts without user involvement significantly improves their experience and reduces the support burden on your organization.\n\nHow you resolve conflicts is application-specific. See the following tips for more ways to improve the process:\n\n\n\n* Avoid invariants across document fields if possible. Avoiding invariants makes it more likely that a simple merge operation, if you take the changed field from each conflicted document revision, is suitable. This practice makes simpler and more robust application code.\n* Allow documents to be independent. If you have to retrieve other documents to work out the correct resolution, it increases latency in conflict resolution. There's also a chance you get a version of the other documents that aren't consistent with the document you're resolving, making correct resolution difficult.\n\n\n\n\n\n\n\nHeavily conflicted documents exert a heavy toll on the database. Building in the capability to resolve conflicts from the beginning is a great help in avoiding pathologically conflicted documents.\n\n\n\n\n\nThese tips demonstrate how modeling data affects your application\u2019s performance. IBM Cloudant\u2019s data store has some specific characteristics, both to watch out for and to take advantage of, that ensure the database performance scales as your application grows. IBM Cloudant support understands the shift can be confusing, so they are always available to give advice.\n\nFor more information, see the [data model for Foundbite](https://cloudant.com/blog/foundbites-data-model-relational-db-vs-nosql-on-cloudant/), or the [example from our friends at Twilio](https://www.twilio.com/blog/2013/01/building-a-real-time-sms-voting-app-part-3-scaling-node-js-and-couchdb.html).\n\n\n\n* When must I make my documents immutable?\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-459832-462063", "score": 0.6167443990707397, "text": "\nThis fact is a price of scalability and data resilience.\n\nIt is best to structure your data so that resolving conflicts is quick and does not involve operator assistance. This practice helps your databases to hum along smoothly. The ability to automatically resolve conflicts without user involvement significantly improves their experience and reduces the support burden on your organization.\n\nHow you resolve conflicts is application-specific. See the following tips for more ways to improve the process:\n\n\n\n* Avoid invariants across document fields if possible. Avoiding invariants makes it more likely that a simple merge operation, if you take the changed field from each conflicted document revision, is suitable. This practice makes simpler and more robust application code.\n* Allow documents to be independent. If you have to retrieve other documents to work out the correct resolution, it increases latency in conflict resolution. There's also a chance you get a version of the other documents that aren't consistent with the document you're resolving, making correct resolution difficult.\n\n\n\n\n\n\n\nHeavily conflicted documents exert a heavy toll on the database. Building in the capability to resolve conflicts from the beginning is a great help in avoiding pathologically conflicted documents.\n\n\n\n\n\nThese tips demonstrate how modeling data affects your application\u2019s performance. IBM Cloudant\u2019s data store has some specific characteristics, both to watch out for and to take advantage of, that ensure the database performance scales as your application grows. IBM Cloudant support understands the shift can be confusing, so they are always available to give advice.\n\nFor more information, see the [data model for Foundbite](https://cloudant.com/blog/foundbites-data-model-relational-db-vs-nosql-on-cloudant/), or the [example from our friends at Twilio](https://www.twilio.com/blog/2013/01/building-a-real-time-sms-voting-app-part-3-scaling-node-js-and-couchdb.html).\n\n\n\n* When must I make my documents immutable?\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05032-6428-8442", "score": 0.5293999910354614, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-6428-8391", "score": 0.5231152772903442, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_03618-1804-3397", "score": 0.467790812253952, "text": "\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https://www.ibm.com/cloud/bare-metal-servers/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"}, {"document_id": "ibmcld_14708-3638-5837", "score": 0.46166855096817017, "text": "\nThe [Compliance assessment report (by Cohasset)](https://www.veeam.com/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"}, {"document_id": "ibmcld_04939-64122-65726", "score": 0.44245293736457825, "text": "\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https://ibm.github.io/ibm-cos-sdk-java/).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-64102-65706", "score": 0.44245293736457825, "text": "\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https://ibm.github.io/ibm-cos-sdk-java/).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-61129-62904", "score": 0.43617597222328186, "text": "\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe presence of a retention period header is required, otherwise a 400 error is returned.\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\npublic static void addLegalHoldToObject(String bucketName, String objectName, String legalHoldId) {\nSystem.out.printf(\"Adding legal hold %s to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n\ncos.addLegalHold(\nbucketName,\nobjectName,\nlegalHoldId\n);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %s!n\", legalHoldId, objectName, bucketName);\n}\n\npublic static void deleteLegalHoldFromObject(String bucketName, String objectName, String legalHoldId) {\nSystem.out.printf(\"Deleting legal hold %s from object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n\ncos.deleteLegalHold(\nbucketName,\nobjectName,\nlegalHoldId\n);\n\nSystem.out.printf(\"Legal hold %s deleted from object %s in bucket %s!n\", legalHoldId, objectName, bucketName);\n}\nShow more\n\n\n\n\n\n Extend the retention period of a protected object \n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_04939-61149-62924", "score": 0.4361759424209595, "text": "\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe presence of a retention period header is required, otherwise a 400 error is returned.\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\npublic static void addLegalHoldToObject(String bucketName, String objectName, String legalHoldId) {\nSystem.out.printf(\"Adding legal hold %s to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n\ncos.addLegalHold(\nbucketName,\nobjectName,\nlegalHoldId\n);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %s!n\", legalHoldId, objectName, bucketName);\n}\n\npublic static void deleteLegalHoldFromObject(String bucketName, String objectName, String legalHoldId) {\nSystem.out.printf(\"Deleting legal hold %s from object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n\ncos.deleteLegalHold(\nbucketName,\nobjectName,\nlegalHoldId\n);\n\nSystem.out.printf(\"Legal hold %s deleted from object %s in bucket %s!n\", legalHoldId, objectName, bucketName);\n}\nShow more\n\n\n\n\n\n Extend the retention period of a protected object \n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_04866-18330-19648", "score": 0.4197884798049927, "text": "\nObjectMetadata metadata = new ObjectMetadata();\nmetadata.setContentLength(fileText.length());\n\nPutObjectRequest req = new PutObjectRequest(\nbucketName,\nobjectName,\nnewStream,\nmetadata\n);\nreq.setRetentionLegalHoldId(legalHoldId);\n\ncos.putObject(req);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n}\n\npublic static void copyProtectedObject(String sourceBucketName, String sourceObjectName, String destinationBucketName, String newObjectName) {\nSystem.out.printf(\"Copy protected object %s from bucket %s to %s/%s.n\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n\nCopyObjectRequest req = new CopyObjectRequest(\nsourceBucketName,\nsourceObjectName,\ndestinationBucketName,\nnewObjectName\n);\nreq.setRetentionDirective(RetentionDirective.COPY);\n\ncos.copyObject(req);\n\nSystem.out.printf(\"Protected object copied from %s/%s to %s/%sn\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n}\n\nShow more\n\ndef put_object_add_legal_hold(bucket_name, object_name, file_text, legal_hold_id):\nprint(\"Add legal hold {0} to {1} in bucket {2} with a putObject operation.n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.put_object(\nBucket=bucket_name,\nKey=object_name,\nBody=file_text,\nRetentionLegalHoldId=legal_hold_id)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-18309-19627", "score": 0.4197884798049927, "text": "\nObjectMetadata metadata = new ObjectMetadata();\nmetadata.setContentLength(fileText.length());\n\nPutObjectRequest req = new PutObjectRequest(\nbucketName,\nobjectName,\nnewStream,\nmetadata\n);\nreq.setRetentionLegalHoldId(legalHoldId);\n\ncos.putObject(req);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n}\n\npublic static void copyProtectedObject(String sourceBucketName, String sourceObjectName, String destinationBucketName, String newObjectName) {\nSystem.out.printf(\"Copy protected object %s from bucket %s to %s/%s.n\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n\nCopyObjectRequest req = new CopyObjectRequest(\nsourceBucketName,\nsourceObjectName,\ndestinationBucketName,\nnewObjectName\n);\nreq.setRetentionDirective(RetentionDirective.COPY);\n\ncos.copyObject(req);\n\nSystem.out.printf(\"Protected object copied from %s/%s to %s/%sn\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n}\n\nShow more\n\ndef put_object_add_legal_hold(bucket_name, object_name, file_text, legal_hold_id):\nprint(\"Add legal hold {0} to {1} in bucket {2} with a putObject operation.n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.put_object(\nBucket=bucket_name,\nKey=object_name,\nBody=file_text,\nRetentionLegalHoldId=legal_hold_id)", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04939-57496-59284", "score": 0.7470440864562988, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-57476-59264", "score": 0.7470440864562988, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05088-35529-37138", "score": 0.7220534086227417, "text": "\nThe new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",\n\"MinimumRetention\": {\"Days\": 10},\n\"DefaultRetention\": {\"Days\": 100},\n\"MaximumRetention\": {\"Days\": 1000}\n}\n\ncos.put_bucket_protection_configuration(Bucket=bucket_name, ProtectionConfiguration=new_protection_config)\n\nprint(\"Protection added to bucket {0}n\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to set bucket protection config: {0}\".format(e))\nShow more\n\n\n\n\n\n Check protection on a bucket \n\ndef get_protection_configuration_on_bucket(bucket_name):\ntry:\nresponse = cos.get_bucket_protection_configuration(Bucket=bucket_name)\nprotection_config = response.get(\"ProtectionConfiguration\")\n\nprint(\"Bucket protection config for {0}n\".format(bucket_name))\nprint(protection_config)\nprint(\"n\")\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-python"}, {"document_id": "ibmcld_04866-27024-28791", "score": 0.7172592282295227, "text": "\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nSupported ISO 8601 format for New-Retention-Expiration-Date is [YYYY]-[MM]-[DD]T[hh]:[mm]:[ss]Z or [YYYY][DD]T[hh][ss]Z (for example, 2020-11-28T03:10:01Z or 20201128T031001Z are both valid).\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nSyntax\n\nPOST https://{endpoint}/{bucket-name}/{object-name}?extendRetention= path style\nPOST https://{bucket-name}.{endpoint}/{object-name}?extendRetention= virtual host style\n\nExample request\n\nPOST /BucketName/ObjectName?extendRetention HTTP/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00GMT\nAuthorization: authorization string\nContent-Type: text/plain\nAdditional-Retention-Period: 31470552\n\nExample response\n\nHTTP/1.1 200 OK\nDate: Fri, 8 Dec 2018 17:50:00GMT\nConnection: close\n\n\n\n* Java\n* Python\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-27003-28770", "score": 0.7172592282295227, "text": "\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period that is stored in the object metadata is either increased by the given extra time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nSupported ISO 8601 format for New-Retention-Expiration-Date is [YYYY]-[MM]-[DD]T[hh]:[mm]:[ss]Z or [YYYY][DD]T[hh][ss]Z (for example, 2020-11-28T03:10:01Z or 20201128T031001Z are both valid).\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nSyntax\n\nPOST https://{endpoint}/{bucket-name}/{object-name}?extendRetention= path style\nPOST https://{bucket-name}.{endpoint}/{object-name}?extendRetention= virtual host style\n\nExample request\n\nPOST /BucketName/ObjectName?extendRetention HTTP/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00GMT\nAuthorization: authorization string\nContent-Type: text/plain\nAdditional-Retention-Period: 31470552\n\nExample response\n\nHTTP/1.1 200 OK\nDate: Fri, 8 Dec 2018 17:50:00GMT\nConnection: close\n\n\n\n* Java\n* Python\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-3142-5463", "score": 0.7072832584381104, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-3142-5463", "score": 0.7072832584381104, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04939-62476-64507", "score": 0.706757128238678, "text": "\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-62456-64487", "score": 0.706757128238678, "text": "\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_04939-55110-56793", "score": 0.7022711038589478, "text": "\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09755-1450-3171", "score": 0.6201098561286926, "text": "\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.\n* Go to [IBM Developer Answers](https://developer.ibm.com/answers/topics/ibm-cloud/) to ask general questions about the IBM Cloud Monitoring service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and monitoring.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case) and [manage](https://cloud.ibm.com/docs/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-gettinghelp"}, {"document_id": "ibmcld_16692-1490-3300", "score": 0.6036629676818848, "text": "\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.\n* Go to [IBM Developer Answers](https://developer.ibm.com/answers/topics/ibm-cloud/) to ask general questions about the IBM Cloud Security and Compliance Center Workload Protection service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and workload-protection.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case) and [manage](https://cloud.ibm.com/docs/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-gettinghelp"}, {"document_id": "ibmcld_09755-7-1966", "score": 0.5715370178222656, "text": "\nGetting help and support \n\nIf you have problems or questions when using the IBM Cloud Monitoring service, you have several options to get help with determining the cause of the problem and finding a solution. If you're logged in, you can go directly to the [Support center](https://cloud.ibm.com/unifiedsupport/supportcenter) to review common FAQs, open a support case, or search community content.\n\n\n\n Using the Support Center search field \n\nYou can use the Support Center search field to find answers to your questions from across the IBM Cloud documentation and Stack Overflow forum. You can also manage support cases from the Support Center. You can find links to both the Stack Overflow forum for technical questions and the developerWorks (IBM Developer Answers) forum for all other questions under the Forums section of the Support Center.\n\nTo access the Support Center, log in to the IBM Cloud console, and click Support from the menu bar.\n\nIf you have a basic, advanced, or premium [support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport-plans), you can find call-in numbers and a chat option to get help.\n\nThe Support Center is the preferred method for getting support, but if you can't log in to IBM Cloud, you can use the [New support case](https://cloud.ibm.com/unifiedsupport/cases/add) page to submit a case.\n\n\n\n\n\n Searching forums \n\nYou can search forums to find answers to your questions. The Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-gettinghelp"}, {"document_id": "ibmcld_16692-7-2046", "score": 0.5577725172042847, "text": "\nGetting help and support \n\nIf you have problems or questions when using the IBM Cloud Security and Compliance Center Workload Protection service, you have several options to get help with determining the cause of the problem and finding a solution. If you're logged in, you can go directly to the [Support center](https://cloud.ibm.com/unifiedsupport/supportcenter) to review common FAQs, open a support case, or search community content.\n\n\n\n Using the Support Center search field \n\nYou can use the Support Center search field to find answers to your questions from across the IBM Cloud documentation and Stack Overflow forum. You can also manage support cases from the Support Center. You can find links to both the Stack Overflow forum for technical questions and the developerWorks (IBM Developer Answers) forum for all other questions under the Forums section of the Support Center.\n\nTo access the Support Center, log in to the IBM Cloud console, and click Support from the menu bar.\n\nIf you have a basic, advanced, or premium [support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport-plans), you can find call-in numbers and a chat option to get help.\n\nThe Support Center is the preferred method for getting support, but if you can't log in to IBM Cloud, you can use the [New support case](https://cloud.ibm.com/unifiedsupport/cases/add) page to submit a case.\n\n\n\n\n\n Searching forums \n\nYou can search forums to find answers to your questions. The Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.", "title": "", "source": "https://cloud.ibm.com/docs/workload-protection?topic=workload-protection-gettinghelp"}, {"document_id": "ibmcld_11601-6079-6736", "score": 0.5517978668212891, "text": "\n* and for SAP HANA also use full-system-info-dump on [SAP Note 1732157](https://launchpad.support.sap.com//notes/1732157)\n\n\n\n\n\n\n\n\n\n\n\n Stack Overflow \n\nThe Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new question. Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).\n\nIBM Cloud development and support teams actively monitor Stack Overflow and follow the questions that are tagged with ibm-cloud. When you create a question, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_16324-3229-5312", "score": 0.5425909757614136, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_06953-7-2041", "score": 0.5331802368164062, "text": "\nSearching Discovery data from Watson Assistant \n\nYour Discovery project can provide answers to questions that stump your assistant. Instead of answering with \u201cI don't know\u201d, your assistant can say, \u201cI'm not sure, but I searched my knowledge base and found these answers which might help.\u201d\n\nFor more information about how to search a Discovery project from an assistant, read the appropriate Watson Assistant documentation for your situation.\n\n\n\n* From the new experience user interface, see [Search trigger](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-addsearch-add-trigger).\n* From an actions skill in the classic user interface, see [Configuring the search for an answer](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-what-next-search).\n* From a dialog skill, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\n\n\nIf you use the built-in web chat, you can use answer finding by enabling the Emphasize the answer feature. Answer finding highlights the word or phrase in the search result that is determined to be the exact answer to the customer's question.\n\nFor a more detailed look at the steps to take to connect to a Discovery project from Watson Assistant, take a tutorial that walks you through them. For more information, see [Power your assistant with answers from web resources](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-assistant-fred).\n\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project"}, {"document_id": "ibmcld_06953-2615-5096", "score": 0.5311381220817566, "text": "\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise. However, for advanced use cases, or if you want to be able to troubleshoot issues, a Document Retrieval project type might be a better fit.\n\nTo help you choose the right Discovery project type, review the project type differences that are described in the following table.\n\n\n\nProject type details\n\n Function Conversational Search Document Retrieval \n\n Enrichment support Only the Part of Speech enrichment is applied. The Part of Speech and Entities enrichments are applied. The Entities enrichment is helpful for identifying important information and introduces more ways to filter query results. \n Testing queries from the Improve and customize page in Discovery You see only one of the responses that are returned from the chatbot. You cannot see all of the available responses and cannot analyze individual query results. You can filter query results by enrichment-based facets. You can review details about fields that are indexed in the source documents that are returned for a query. Access to more information makes it easier to troubleshoot unexpected results. \n Search triggers Returns answers from the text field automatically. If answers are stored in another field, you must change the configuration. You can apply a Smart Document Understanding (SDU) model or enrichments to your collections and retrieve useful information from fields other than text when search is triggered from the assistant. \n\n\n\nFor both project types, the best way to test is to trigger search from the Watson Assistant preview. When you configure search support for an assistant, you can fine-tune the experience in ways that aren't available in Discovery.\n\nAnd settings that are available from the Search results tool for a Document Retrieval project type are replaced by configuration settings that you specify in Watson Assistant. For example, the query response title and body are defined in Watson Assistant.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-chat-choose-project"}, {"document_id": "ibmcld_07120-22745-24224", "score": 0.5250082612037659, "text": "\n[Shows that multiple responses are returned for the query.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-rule-response.png)\n\nFigure 26. Multiple responses are returned for the query\n\nOur updates only improved the quality of the accurate responses that were returned before.\n3. Now, let's ask a question that returned poor results previously. Enter What are PTFs? as the search query.\n\nThe same response that was returned as the only response last time is returned again. However, this time we get more than one response. And we can see that the second response that is returned defines the acronym for us.\n\n(\u201cprincipal trading firms\u201d or \u201cPTFs\u201d)\n\nZoom\n\n![Shows responses that are returned to answer the question about PTFs.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-ptf-responses.png)\n\nFigure 27. Responses that answer the question about PTFs\n4. Let's try the other problematic search query. Enter Where do muni bond trades get reported to? as the search query.\n\nThis time it's the third response that provides an answer to the question. You must view the full passage to see the entire definition.\n\nZoom\n\n![Shows responses that are returned to answer the question about muni bonds.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/tut-sdu-muni-responses.png)\n\nFigure 28.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-tutorial-sdu"}, {"document_id": "ibmcld_06981-12510-14371", "score": 0.4927513599395752, "text": "\nAlthough, it might be difficult to know which field to search later for information that you need if the field names don't match the content. The default set are representative field types that are meant to help you get started. Only the text and table fields have special significance. Do not use them to identify anything other than text and tables.\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a question-and-answer pair (often in an FAQ), the answer to the question. \n author Name of author or authors. \n footer Use this tag to denote meta-information about the document (such as the page number or references), that appear at the end of the page. \n header Use this tag to denote meta-information about the document that appears at the start of the page. \n question In a question-and-answer pair (often in an FAQ), the question. \n subtitle The secondary title of the document. \n table_of_contents Use this tag on lists in the document table of contents. \n text By default, every block of text in the document is labeled as text. Apply different labels only to blocks of text with special meaning. \n title The main title of the document. \n table Use this tag to annotate tables in your document. \n image Images are not shown in the document preview. If you enable OCR, text from an image or diagram is displayed in the preview instead. If you want to prevent text from some images from being included in search results, tag the image text as an image. You can exclude the image field from the index later. \n\n\n\n\n\n\n\n Reusing SDU models \n\nAfter you define a model with the SDU tool, you can save it and reuse it in other collections by exporting it from one collection and importing it to another.\n\nTo reuse a model, complete the following steps:\n\n\n\n1. Export the model that you want to reuse. From the SDU toolbar menu, select Export model.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fields"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-1672-3877", "score": 0.7454087734222412, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 0.7063528299331665, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 0.6511023044586182, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04175-0-1274", "score": 0.6444557905197144, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04105-5067-6335", "score": 0.6309937834739685, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_16364-213826-215727", "score": 0.6182568073272705, "text": "\nFor details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Enabling system entities.\n* You can now view a history of conversations with users on the Improve page. You can use this to understand your bot's behavior. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n* You can now import entities from a comma-separated value (CSV) file, which helps with when you have a large number of entities. For details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Importing entities.\n\n\n\n\n\n\n\n 20 September 2016 \n\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_04111-35313-36062", "score": 0.6038397550582886, "text": "\nGet Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET /v1/{crn}/zones/{domain_id}/bot_analytics/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET /v1/{crn}/zones/{domain_id}/bot_analytics/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET /v1/{crn}/zones/{domain_id}/bot_analytics/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04168-6066-7283", "score": 0.5834696888923645, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_03114-11593-13085", "score": 0.5812804102897644, "text": "\n\"body\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"url\": \"https://cloud.ibm.com/docs/assistant?topic=assistant-index\",\n\"id\": \"6682eca3c5b3778ccb730b799a8063f3\",\n\"result_metadata\": {\n\"confidence\": 0.08401551980328191,\n\"score\": 0.73975396\n},\n\"highlight\": {\n\"Shortdesc\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n],\n\"url\":\n\"https://cloud.ibm.com/docs/<em>assistant</em>?topic=<em>assistant</em>-index\"\n],\n\"body\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n]\n}\n}\n]\n}\n]\n},\n\"user_id\": \"58e1b04e-f4bb-469a-9e4c-dffe1d4ebf23\"\n}\nShow more\n\nFor each search result, the title, body, and url properties include content returned from the Discovery query. The search skill configuration determines which fields in the Discovery collection are mapped to these fields in the response. Your application can use these fields to display the results to the user (for example, you might use the body text to show an abstract or description of the matching document, and the url value to create a link the user can click to open the document).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_03369-177225-178461", "score": 0.5777188539505005, "text": "\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs)\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-5067-6335", "score": 0.7630010843276978, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 0.683754026889801, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04175-0-1274", "score": 0.6761091351509094, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04168-6066-7283", "score": 0.6696758270263672, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04105-3403-5572", "score": 0.6636372804641724, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04107-9120-10897", "score": 0.6416659355163574, "text": "\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection \n\nCIS does not meter or bill for traffic that is blocked as part of DDoS mitigation, firewall, or rate limiting. Only requests that are passed through the CIS network to the origin destination incur charges or usage.\n\nCIS also helps keep egress bandwidth charges from your origin under control by only passing along good requests that the origin needs to respond to. All CIS plans offer unlimited and unmetered mitigation of DDoS attacks. You are never charged for attack traffic. There\u2019s no penalty for spikes due to attack traffic, so there's no chargeback by the customer.\n\n\n\n\n\n\n\n Reliability features \n\nZoom\n\n![reliability graphic](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis/images/reliability-graphic.png)\n\nFigure 2. Reliability features\n\n\n\n Global load balancing features \n\nThe global load balancing service distributes your traffic across multiple servers with a combination of origin pools, health checks, and a load balancer. Global load balancing has the following features:\n\n\n\n* Proxy and non-proxy options for load balancing\n* Origin pools and health checks\n\n\n\n\n\n Global anycast network \n\nThe available health check regions are based on the [Cloudflare Global Anycast Network](https://www.cloudflare.com/network/).\n\n\n\n\n\n\n\n DNS features \n\nDNS within CIS has the following features:\n\n\n\n* DNS management - Manage your DNS records, control proxying, and enable DNS security.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_04334-37863-39504", "score": 0.6286624670028687, "text": "\nCommand options \n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList domains for the specified domain cis-demo.\n\nibmcloud cis domains -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-activation-check \n\nPerform activation check on the given domain.\n\nibmcloud cis domain-activation-check DNS_DOMAIN_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nPerform activation check on the specified domain.\n\nibmcloud cis domain-activation-check 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain settings \n\nManipulate domain settings using the following domain-settings commands:\n\n\n\n ibmcloud cis domain-settings \n\nGet details of a feature for given domain.\n\nibmcloud cis domain-settings DNS_DOMAIN_ID [-g, --group GROUP | -f, --feature FEATURE] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n-g, --group\n: Display features in a same group. Valid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_03114-11593-13085", "score": 0.6269066333770752, "text": "\n\"body\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"url\": \"https://cloud.ibm.com/docs/assistant?topic=assistant-index\",\n\"id\": \"6682eca3c5b3778ccb730b799a8063f3\",\n\"result_metadata\": {\n\"confidence\": 0.08401551980328191,\n\"score\": 0.73975396\n},\n\"highlight\": {\n\"Shortdesc\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n],\n\"url\":\n\"https://cloud.ibm.com/docs/<em>assistant</em>?topic=<em>assistant</em>-index\"\n],\n\"body\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n]\n}\n}\n]\n}\n]\n},\n\"user_id\": \"58e1b04e-f4bb-469a-9e4c-dffe1d4ebf23\"\n}\nShow more\n\nFor each search result, the title, body, and url properties include content returned from the Discovery query. The search skill configuration determines which fields in the Discovery collection are mapped to these fields in the response. Your application can use these fields to display the results to the user (for example, you might use the body text to show an abstract or description of the matching document, and the url value to create a link the user can click to open the document).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}, {"document_id": "ibmcld_04105-1672-3877", "score": 0.6217677593231201, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-3136-4483", "score": 0.6211667060852051, "text": "\n* [Enabling Proxy protocol](https://cloud.ibm.com/docs/cis?topic=cis-enable-proxy-protocol)\n\n\n\n* [Using service endpoints to privately connect to CIS](https://cloud.ibm.com/docs/cis?topic=cis-service-endpoints)\n* Working with TLS\n\n\n\n* [Setting Transport Layer Security (TLS) options](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-options)\n* [Using mutual TLS](https://cloud.ibm.com/docs/cis?topic=cis-mtls-features)\n* [Authenticated origin pull](https://cloud.ibm.com/docs/cis?topic=cis-authenticated-origin-pull)\n\n\n\n* Working with WAFs\n\n\n\n* [WAF actions and rule sets](https://cloud.ibm.com/docs/cis?topic=cis-waf-settings)\n* [Using the CIS Security Events capability](https://cloud.ibm.com/docs/cis?topic=cis-using-the-cis-security-events-capability)\n\n\n\n* Working with firewall rules\n\n\n\n* [Creating, editing, and deleting firewall rules](https://cloud.ibm.com/docs/cis?topic=cis-about-firewall-rules)\n* [Assigning firewall rule actions](https://cloud.ibm.com/docs/cis?topic=cis-actions)\n* [Using fields, functions, and expressions](https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions)\n* [Prioritizing options](https://cloud.ibm.com/docs/cis?topic=cis-priority)\n\n\n\n* Working with global load balancers\n\n\n\n* [Configuring a global load balancer](https://cloud.ibm.com/docs/cis?topic=cis-configure-glb)\n* Global load balancer features", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-5067-6335", "score": 0.8328293561935425, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 0.7616074681282043, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 0.7201810479164124, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04175-0-1274", "score": 0.7018718719482422, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04170-7-2189", "score": 0.6987928152084351, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04170-1738-2974", "score": 0.6723483204841614, "text": "\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04113-1734-4014", "score": 0.6596783995628357, "text": "\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-best-practices-for-cis-setup"}, {"document_id": "ibmcld_04183-0-2205", "score": 0.658804178237915, "text": "\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https://cloud.ibm.com/docs/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-mng-data"}, {"document_id": "ibmcld_04168-6066-7283", "score": 0.6556916236877441, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04105-1672-3877", "score": 0.6518772840499878, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04175-0-1274", "score": 0.6970987319946289, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_16437-7-2129", "score": 0.6684202551841736, "text": "\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"}, {"document_id": "ibmcld_16495-7-2129", "score": 0.6684202551841736, "text": "\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"}, {"document_id": "ibmcld_16511-1688-3640", "score": 0.6575422286987305, "text": "\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.\n\nIf there is only one working version of the model, create a snapshot of the current model. This versions the model, which enables you to deploy one version, while you continue to improve the current version. The option to deploy does not appear until you create at least one version.\n\nEach version can be deployed to any number of service instances. Each deployed instance of a model version is given a unique Model ID, but is identical in all other ways.\n4. Click Deploy, choose to deploy it to Discovery, and then click Next.\n5. Select the IBM Cloud space and instance. If necessary, select a different region.\n6. Click Deploy.\n7. The deployment process might take a few minutes. To check the status of the deployment, click Status on the Versions tab next to the version that you deployed.\n\nIf the model is still being deployed, the status indicates \"deploying\". After deployment completes, the status changes to \"available\" or \"deployed\" if the deployment was successful, or \"error\" if problems occurred.\n\nOnce available, make a note of the model ID (model_id).\n\n\n\n\n\n\n\n What to do next \n\nTo use the model, you must export the model, and then import it into Discovery.\n\n\n\n1. Select Machine Learning Model > Versions.\n2. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n3. Download the file to your local system.\n4. From the Discovery service, follow the steps to create a Machine Learning enrichment, which include uploading the ZIP file.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}, {"document_id": "ibmcld_16464-20282-21209", "score": 0.6563133001327515, "text": "\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16511-3250-5366", "score": 0.6246720552444458, "text": "\nSelect Machine Learning Model > Versions.\n2. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n3. Download the file to your local system.\n4. From the Discovery service, follow the steps to create a Machine Learning enrichment, which include uploading the ZIP file. For more details, see [Machine Learning models](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domainmachinelearning) in the Discovery v2 documentation.\n\n\n\nIf you're using a Discovery v1 service instance, you must provide the model ID when it is requested during the Discovery service enrichment configuration process. For more information, see [Integrating your custom model with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wksintegrate-customtooling) in the Discovery v1 documentation.\n\n\n\n\n\n\n\n Deploying a machine learning model to IBM Watson Natural Language Understanding \n\nWhen you are satisfied with the performance of the model, you can deploy a version of it to IBM Watson Natural Language Understanding. This feature enables your applications to use the deployed machine learning model to analyze semantic features of text input, including entities and relations.\n\n\n\n Before you begin \n\nYou must have a Natural Language Understanding service to deploy to. And you must know the IBM Cloud space and instance names that are associated with the service. If you do not remember the space or instance names, find them by logging in to IBM Cloud. If you do not have an IBM Cloud account, sign up for one.\n\n\n\n\n\n About this task \n\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model to the Natural Language Understanding service, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}, {"document_id": "ibmcld_16511-10740-12806", "score": 0.6190695762634277, "text": "\nFrom the list of deployed models, find the model you want to view or undeploy.\n4. To undeploy the model, from the last column of that row, click Undeploy model.\n5. To find the model ID, see the Model ID column.\n\n\n\nAlternatively, you can undeploy models from the Versions pages for rule-based models and machine learning models.\n\n\n\n\n\n\n\n Deleting a version \n\nIf you wish to delete a specific version a same machine learning model, navigate to the Versions page and click the Delete link on the row of the version that you want to delete. Note: The Delete model version link is only active if there are no deployed models associated with it. Undeploy all associated models before deleting the a version.\n\n\n\n\n\n Leveraging a machine learning model in IBM Watson Explorer \n\nExport the trained machine learning model so it can be used in IBM Watson Explorer.\n\n\n\n Before you begin \n\nIf you choose to identify relation types and annotate them, then you must define at least two relation types, and annotate instances of the relationships in the ground truth before you export the model. Defining and annotating only one relation type can cause subsequent issues in IBM Watson Explorer, release 11.0.1.0.\n\n\n\n\n\n About this task \n\nNow that the machine learning model is trained to recognize entities and relationships for a specific domain, you can leverage it in IBM Watson Explorer.\n\n[Watch a brief video](https://www.youtube.com/watch?v=1VoS-xczBow&feature=youtu.be) that illustrates how to export a model and use it in IBM Watson Explorer.\n\n\n\n\n\n Procedure \n\nTo leverage a machine learning model in IBM Watson Explorer, complete the following steps.\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n4. Download the file to your local system.\n5. From the IBM Watson Explorer application, import the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}, {"document_id": "ibmcld_16511-12387-13521", "score": 0.6184945106506348, "text": "\nLog in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n4. Download the file to your local system.\n5. From the IBM Watson Explorer application, import the model.\n\nYou can then map the model to a machine learning model in Watson Explorer Content Analytics. After you perform the mapping step, when you crawl documents, the model finds instances of the entities and relations that your model understands. For more information about how to import and configure the model in IBM Watson Explorer, see the technical document that describes the integration: [Using machine-learning annotators from Knowledge Studio in Watson Explorer](https://www.ibm.com/support/pages/node/597611).\n\n\n\n\n\n Related tasks \n\n[Exporting analyzed documents from Watson Explorer Content Analytics](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_uimawexca)", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}, {"document_id": "ibmcld_16451-3317-5174", "score": 0.6110014915466309, "text": "\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"}, {"document_id": "ibmcld_16524-3358-5215", "score": 0.6110014915466309, "text": "\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-3403-5572", "score": 0.6558284759521484, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 0.6554043292999268, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-1672-3877", "score": 0.6467316150665283, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-5067-6335", "score": 0.6280635595321655, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04111-35313-36062", "score": 0.6251303553581238, "text": "\nGet Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET /v1/{crn}/zones/{domain_id}/bot_analytics/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET /v1/{crn}/zones/{domain_id}/bot_analytics/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET /v1/{crn}/zones/{domain_id}/bot_analytics/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04175-0-1274", "score": 0.6213327646255493, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_16364-213826-215727", "score": 0.5887676477432251, "text": "\nFor details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Enabling system entities.\n* You can now view a history of conversations with users on the Improve page. You can use this to understand your bot's behavior. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n* You can now import entities from a comma-separated value (CSV) file, which helps with when you have a large number of entities. For details, see [Defining entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entities) and search for Importing entities.\n\n\n\n\n\n\n\n 20 September 2016 \n\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https://cloud.ibm.com/docs/assistant?topic=assistant-logs).\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_04170-1738-2974", "score": 0.5821772217750549, "text": "\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_16358-7447-9162", "score": 0.5671999454498291, "text": "\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_03164-1607-3518", "score": 0.5637917518615723, "text": "\nFor more information about it, read the [Slack blog post](https://medium.com/slack-developer-blog/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-slack"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-18607-20398", "score": 0.6270217895507812, "text": "\n[Checkmark icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/checkmark-icon.svg) \n\n\n\n\n\n\n\n\n\n What's in a secret? \n\nSecrets that you store with the service consist of metadata attributes and a secret value. While the metadata attributes help you to identify a secret, the secret value is the data that protected services need to authenticate and authorize you or your application.\n\nCheck out the following image to see how a secret is structured.\n\nZoom\n\n![This image shows the components of a secret. The information in the image is detailed in the surrounding content.](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/secrets-manager//images/example-secret.svg)\n\nFigure 1. JSON representation of Secrets Manager secret\n\n\n\n1. The name, id, and description, and other common fields hold identifying information about a secret. These fields store the general attributes of your secret that you can use to understand its purpose and history.\n2. For most secret types, the secret_data object contains the actual value of your secret.\n\nWhen you use the Secrets Manager API to retrieve the value of a secret, the fields that you see in the secret_data object differ depending on the type of secret that you are inspecting. For example, the following truncated example shows how secret data is represented for an arbitrary secret.\n\n{\n\"name\": \"my-arbitrary-secret\",\n\"secret_type\": \"arbitrary\",\n...\n\"secret_data\": {\n\"payload\": \"The quick brown fox jumped over the lazy dog.\"\n}\n}\n\nIf you're working with IAM credentials, the secret data is listed alongside the other common fields that describe your secret. For example, the following truncated example shows how secret data is represented for an IAM credential.\n\n{", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_00894-7-1811", "score": 0.5756881833076477, "text": "\nConfiguring Secrets Manager \n\nIBM Cloud\u00ae Secrets Manager helps you to securely store and apply secrets for apps across IBM Cloud services.\n\nA secret is anything that provides access to sensitive information, such as an [API key](https://cloud.ibm.com/docs/account?topic=account-manapikey). You can use the Secrets Manager tool integration to access secrets, wherever they are required in the toolchain workflow.\n\nBefore you configure a Secrets Manager tool integration, make sure that you [provision an instance of the Secrets Manager service](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instancecreate-instance-ui).\n\nYou can configure the Secrets Manager tool integration to identify secrets by name or by [Cloud Resource Name (CRN)](https://cloud.ibm.com/docs/account?topic=account-crn).\n\n\n\n Identifying secrets by name \n\nWhen you configure the Secrets Manager tool integration to identify secrets by name, your toolchain can access the following secret types:\n\n\n\n* Identity and Access Management (IAM) credentials secrets.\n* Arbitrary secrets that are stored in the Secrets Manager.\n\n\n\nFor more information about IAM credentials secrets, and Arbitrary secrets in Secrets Manager, see [Working with secrets of different types](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\nConfigure Secrets Manager to securely manage secrets that are part of your toolchain:\n\n\n\n1. If you are configuring this tool integration as you are creating the toolchain, in the Configurable Integrations section, click Secrets Manager. If Secrets Manager is defined as an optional tool integration, it is located under More Tools.\n2. If you have a toolchain and are adding this tool integration to it, from the IBM Cloud console, click the menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12960-7-1811", "score": 0.5756881833076477, "text": "\nConfiguring Secrets Manager \n\nIBM Cloud\u00ae Secrets Manager helps you to securely store and apply secrets for apps across IBM Cloud services.\n\nA secret is anything that provides access to sensitive information, such as an [API key](https://cloud.ibm.com/docs/account?topic=account-manapikey). You can use the Secrets Manager tool integration to access secrets, wherever they are required in the toolchain workflow.\n\nBefore you configure a Secrets Manager tool integration, make sure that you [provision an instance of the Secrets Manager service](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instancecreate-instance-ui).\n\nYou can configure the Secrets Manager tool integration to identify secrets by name or by [Cloud Resource Name (CRN)](https://cloud.ibm.com/docs/account?topic=account-crn).\n\n\n\n Identifying secrets by name \n\nWhen you configure the Secrets Manager tool integration to identify secrets by name, your toolchain can access the following secret types:\n\n\n\n* Identity and Access Management (IAM) credentials secrets.\n* Arbitrary secrets that are stored in the Secrets Manager.\n\n\n\nFor more information about IAM credentials secrets, and Arbitrary secrets in Secrets Manager, see [Working with secrets of different types](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\nConfigure Secrets Manager to securely manage secrets that are part of your toolchain:\n\n\n\n1. If you are configuring this tool integration as you are creating the toolchain, in the Configurable Integrations section, click Secrets Manager. If Secrets Manager is defined as an optional tool integration, it is located under More Tools.\n2. If you have a toolchain and are adding this tool integration to it, from the IBM Cloud console, click the menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12493-22295-23411", "score": 0.5750982761383057, "text": "\n\"crn\": \"crn:v1:bluemix:public:secrets-manager:us-south:a/791f5fb10986423e97aa8512f18b7e65:e415e570-f073-423a-abdc-55de9b58f54e:secret:285d83ce-4a26-c5c3-8e58-48d3140a2415\",\n\"id\": \"285d83ce-4a26-c5c3-8e58-48d3140a2415\",\n\"labels\": ],\n\"last_update_date\": \"2020-10-06T03:54:26Z\",\n\"name\": \"another-test-arbitrary-secret\",\n\"secret_group_id\": \"9ab2250f-a369-4e07-ade7-d417d63ad587\",\n\"secret_type\": \"ARBITRARY\",\n\"state\": 1,\n\"state_description\": \"Active\"\n}\n],\n\"secrets_total\": 2\n},\n\"warnings\": null\n}\n\nIf the secrets belong to a secret group, the data.secrets.secret_group_id value is included in the response to identify the secret group assignment.\n\n\n\n\n\n\n\n Get a secret \n\nUse the following commands to retrieve a secret and its details. Allowable values for SECRET_TYPE are: arbitrary, iam_credentials, imported_cert, kv, private_cert, public_cert, and username_password.\n\nGet a secret.\n\nvault read [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets/SECRET_ID\n\nGet a secret that is assigned to a specified secret group.\n\nvault read [-format=FORMAT] ibmcloud/SECRET_TYPE/secrets/groups/SECRET_GROUP_ID/SECRET_ID\n\n\n\n Prerequisites", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_12376-1665-3857", "score": 0.5671681761741638, "text": "\nsecrets-manager.secret-policies.get Get secret policies. \n\n\n\n\n\n\n\n Events for secret groups \n\nThe following table lists the secret group actions that generate an event.\n\n\n\nTable 2. List of secret group events\n\n Action Description \n\n secrets-manager.secret-group.create Create a secret group. \n secrets-manager.secret-groups.list List secret groups. \n secrets-manager.secret-group.read View the details of a secret group. \n secrets-manager.secret-group.update Update a secret group. \n secrets-manager.secret-group.delete Delete a secret group. \n\n\n\n\n\n\n\n Events for secret locks \n\nThe following table lists the secret lock actions that generate an event.\n\n\n\nTable 2. List of secret lock events\n\n Action Description \n\n secrets-manager.secret-locks.create Create a secret lock. \n secrets-manager.secret-locks.list List secret locks. \n secrets-manager.secret-locks.delete Delete a secret lock. \n secrets-manager.secrets-locks.list List secret locks. \n secrets-manager.secret-version-locks.create Create secret version locks. \n secrets-manager.secret-version-locks.list List secret version locks. \n secrets-manager.secret-version-locks.delete Delete secret version locks. \n\n\n\n\n\n\n\n Events for instance operations \n\nThe following table lists the instance operation actions that generate an event.\n\n\n\n\n\n Events for instance operations \n\nThe following table lists the instance operation actions that generate an event.\n\n\n\nTable 3. List of instance operation events\n\n Action Description \n\n secrets-manager.instance.login Log in to Vault. \n secrets-manager.configuration.create Create a new configuration. \n secrets-manager.configuration-action.create Create a new configuration action. \n secrets-manager.configurations.list List configurations. \n secrets-manager.configuration.read View the details of a configuration. \n secrets-manager.configuration.update Update a configuration. \n secrets-manager.configuration.delete Delete a configuration. \n secrets-manager.endpoints.view Get service instance endpoints. \n secrets-manager.notifications-registration.create Create a registration with Event Notifications. \n secrets-manager.notifications-registration.read Get Event Notifications registration details.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-at-events"}, {"document_id": "ibmcld_12469-6038-7237", "score": 0.5553126335144043, "text": "\nTo learn more about the types of secrets that you can create with Secrets Manager, check out the [docs](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret).\n\nibmcloud secrets-manager secret-create --secret-type SECRET-TYPE --metadata METADATA --resources RESOURCES\n\n\n\n Command options \n\n--secret-type (string)\n: The secret type. Required.\n\nAllowable values are: arbitrary, iam_credentials, imported_cert, public_cert, private_cert, username_password, kv.\n\n--metadata ([CollectionMetadata](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1cli-collection-metadata-example-schema-v1))\n: The metadata that describes the resource array. Required.\n\n--resources ([SecretResource]](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1cli-secret-resource-example-schema-v1))\n: A collection of resources. Required.\n\n\n\n\n\n Examples \n\nibmcloud secrets-manager secret-create --secret-type=arbitrary --metadata='{\"collection_type\": \"application/vnd.ibm.secrets-manager.secret+json\", \"collection_total\": 1}' --resources='[{\"name\": \"example-arbitrary-secret\", \"description\": \"Extended description for this secret.\"", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1"}, {"document_id": "ibmcld_12369-9157-10752", "score": 0.5514870882034302, "text": "\n* Added payload_available and downloaded boolean parameters to the response details of the [Get a secret](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2get-secret), [Get secret version metadata](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2get-secret-version-metadata), [List versions of a secret](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2list-secret-versions) methods. These parameters can help you to identify whether the a secret version is available to be restored, and whether it has already been previously read or accessed.\n* Added the restore query parameter as a request option on the [Invoke an action on a secret](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2update-secret) method. You can use this action to [restore the previous version](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-version-history) of a secret.\n* Updated the [Get a version of a secret](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2get-secret-version) method that can be used to retrieve the previous version of a secret. This API now supports arbitrary, iam_credentials, and username_password secrets, in addition to public_cert and imported_cert.\n\n\n\n\n\n\n\n 20 September 2021 \n\nThis release includes the following updates:\n\n\n\n* Added public_cert secret type that can be used to order domain-validated TLS certificates with the service. For more information, see [Ordering certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-public-certificatesorder-public-certificates).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-api-change-log"}, {"document_id": "ibmcld_00894-5674-7590", "score": 0.547365665435791, "text": "\nThe name of the secret that you select appears in capsule form. You cannot edit the secret name inline, but you can click ![remove icon](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-pill-delete-16.png) to delete the name. You can also replace the existing secret name by selecting the secret name again. If you manually type or paste a secret name into the Secrets field, it is displayed in a different format:\n\nZoom\n\n![Literal Secret Value](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-literal.png)\n\nFigure 2. Secret value\n\nThe format that the secret is displayed in indicates whether the value references a secret that is stored in a backend vault or a secret that is stored in your toolchain. By using references to secrets that are managed by secret providers such as Secrets Manager, your secret values are centralized and stored securely in a single location. This approach resolves secrets sprawl and proliferation, and means that you can update secrets without updating your toolchain. When you use secret references, the actual secret value is resolved when the toolchain runs by dynamically retrieving it from Secrets Manager. This approach is useful when you must rotate the value of your toolchain secrets periodically.\n\n\n\n\n\n\n\n Using IAM credentials secrets \n\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12960-5674-7590", "score": 0.547365665435791, "text": "\nThe name of the secret that you select appears in capsule form. You cannot edit the secret name inline, but you can click ![remove icon](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-pill-delete-16.png) to delete the name. You can also replace the existing secret name by selecting the secret name again. If you manually type or paste a secret name into the Secrets field, it is displayed in a different format:\n\nZoom\n\n![Literal Secret Value](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-literal.png)\n\nFigure 2. Secret value\n\nThe format that the secret is displayed in indicates whether the value references a secret that is stored in a backend vault or a secret that is stored in your toolchain. By using references to secrets that are managed by secret providers such as Secrets Manager, your secret values are centralized and stored securely in a single location. This approach resolves secrets sprawl and proliferation, and means that you can update secrets without updating your toolchain. When you use secret references, the actual secret value is resolved when the toolchain runs by dynamically retrieving it from Secrets Manager. This approach is useful when you must rotate the value of your toolchain secrets periodically.\n\n\n\n\n\n\n\n Using IAM credentials secrets \n\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12353-3-1455", "score": 0.5467974543571472, "text": "\nSecrets Manager docs \n\nExplore recommended content and resources to help you get started with IBM Cloud&reg; Secrets Manager.\n\n Developer tools \n\n[API & SDK reference](https://cloud.ibm.com/apidocs/secrets-manager)[CLI reference](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-cli)\n\n Recommended content \n\n[What is a secret? Learn about secret types that you can create and manage with the service.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)[Creating secrets Try out the service by storing your first secret.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets)[Best practices for organizing your secrets and assigning access Review suggested guidelines for organizing your secrets.](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets)\n\n Video library \n\n[![carousel thumbnail](https://cloud.ibm.com/docs-content/v1/content/secrets-manager-cli-plugin//images/what-is-secrets-mgmt-video-thumbnail.png)<br><br>What is secrets management?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)[![carousel thumbnail](https://cloud.ibm.com/docs-content/v1/content/secrets-manager-cli-plugin//images/secure-manage-secrets-video-thumbnail.png)<br><br>Securely managing your cloud secrets with Secrets Manager](https://www.youtube.com/watch?v=rOp7aGyavnk)\n\n Latest updates", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager-cli-plugin"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02776-3988-5695", "score": 0.6085319519042969, "text": "\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-privacy-policy"}, {"document_id": "ibmcld_09109-6121-7923", "score": 0.6066226363182068, "text": "\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keys"}, {"document_id": "ibmcld_08515-6389-8309", "score": 0.5849761962890625, "text": "\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://www.nist.gov/publications/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api/v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-import-root-keys"}, {"document_id": "ibmcld_08433-6344-8271", "score": 0.5618222951889038, "text": "\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-122.pdf).\n\nA successful POST /v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-create-standard-keys"}, {"document_id": "ibmcld_09513-12728-14481", "score": 0.5524969100952148, "text": "\nThis is applicable to EU-US and Swiss-US customers: [https://www.ibm.com/privacy/details/us/en/privacy_shield.html](https://www.ibm.com/privacy/details/us/en/privacy_shield.html)\n\nData Responsibility at IBM [https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/](https://www.ibm.com/blogs/policy/dataresponsibility-at-ibm/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-Security"}, {"document_id": "ibmcld_04041-14573-16416", "score": 0.5506615042686462, "text": "\n* [Data privacy](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-privacy)\n* [GDPR](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-gdpr)\n\n\n\n\n\n Kubernetes cluster security \n\nThe best place to start is to learn about the security features of the underlying Kubernetes infrastructure. The open source documentation provides a review of recommended practices for [securing a Kubernetes cluster](https://Kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/).\n\nIf you are using IBM Cloud, you can review the topic on Security for the [IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-security) or [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-security).\n\n\n\n\n\n Network security \n\nIBM Cloud provides the underlying network, including the networks and routers, over which customers\u2019 VLAN resides. The customer configures their servers and uses gateways and firewalls to route traffic between servers to protect workloads from network threats. Protecting your cloud network by using firewalls and intrusion prevention system devices is imperative for protecting your cloud-based workloads.\n\n\n\n Firewall configuration \n\nKubernetes clusters should be secured by a firewall to protect the network from unauthorized access from internet traffic. By default IBM Cloud Kubernetes service clusters are preconfigured with a Calico network plug-in that secures the public network interface of every worker node in the cluster. By configuring Kubernetes and Calico network policies you can easily control the inbound and outbound network traffic. For more information, see [Controlling traffic with network policies](https://cloud.ibm.com/docs/containers?topic=containers-network_policies).", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-security"}, {"document_id": "ibmcld_07669-0-587", "score": 0.5496828556060791, "text": "\n\n\n\n\n\n\n  AR-2 - Privacy Impact And Risk Assessment \n\n\n\n  Control requirements \n\nThe organization:\n\nAR-2 (a)\n:   Documents and implements a privacy risk management process that assesses privacy risk to individuals resulting from the collection, sharing, storing, transmitting, use, and disposal of personally identifiable information (PII).\n\nAR-2 (b)\n:   Conducts Privacy Impact Assessments (PIAs) for information systems, programs, or other activities that pose a privacy risk in accordance with applicable law, OMB policy, or any existing organizational policies and procedures.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ar-2"}, {"document_id": "ibmcld_08432-6308-8159", "score": 0.5474294424057007, "text": "\nA unique, human-readable name for easy identification of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-122.pdf).\n\nIf you set the expirationDate in your request, the key is moved to the deactivated state within 1 hour past the key's expiration date.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-create-root-keys"}, {"document_id": "ibmcld_09492-16883-18851", "score": 0.5469025373458862, "text": "\n[https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=en#detail-document](https://www.ibm.com/support/customer/csol/terms/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https://www.ibm.com/privacy/us/en/](https://www.ibm.com/privacy/us/en/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https://www.ibm.com/scripts/contact/contact/us/en/privacy/](https://www.ibm.com/scripts/contact/contact/us/en/privacy/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention / Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-Security"}, {"document_id": "ibmcld_09059-7769-9779", "score": 0.5465097427368164, "text": "\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api/v2/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-create-root-keys"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 0.7837179899215698, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 0.7812432050704956, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 0.7312635183334351, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 0.7221739292144775, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 0.7221739292144775, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 0.7183598875999451, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 0.7183598875999451, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-365833-367834", "score": 0.688035249710083, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 0.688035249710083, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_12717-8170-9862", "score": 0.6820051670074463, "text": "\nCheck whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added \n Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s) RA-5(b) and RA-5(3)(0) Rule was added \n Check whether a security group other than the default for Virtual Private Cloud is attached to all endpoints CM-1 Rule was removed \n Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s) CM-8(3)(a) Rule was removed \n\n\n\n\n\n\n\n Version 1.1.0 \n\nVersion 1.1.0 of the IBM Cloud for Financial Services profile has been updated to include all 565 controls that have been identified as required to ensure that you are compliant with the IBM Cloud for Financial Services reference architecture. As part of that update we've introduced the concept of \"Manual assessments\". When results are returned, you will see a new status: user_evaluation_required - this indicates that the control must be evaluated manually by your organization as the control check is either not yet or cannot be automated.\n\nAdditionally, the phrasing of 42 controls was updated for grammar purposes.", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-fs-change-log"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 0.7692694067955017, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 0.7574228644371033, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 0.7410468459129333, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 0.7410468459129333, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 0.729993462562561, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 0.7225092649459839, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 0.7225092649459839, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_12717-8170-9862", "score": 0.6953157782554626, "text": "\nCheck whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added \n Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s) RA-5(b) and RA-5(3)(0) Rule was added \n Check whether a security group other than the default for Virtual Private Cloud is attached to all endpoints CM-1 Rule was removed \n Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s) CM-8(3)(a) Rule was removed \n\n\n\n\n\n\n\n Version 1.1.0 \n\nVersion 1.1.0 of the IBM Cloud for Financial Services profile has been updated to include all 565 controls that have been identified as required to ensure that you are compliant with the IBM Cloud for Financial Services reference architecture. As part of that update we've introduced the concept of \"Manual assessments\". When results are returned, you will see a new status: user_evaluation_required - this indicates that the control must be evaluated manually by your organization as the control check is either not yet or cannot be automated.\n\nAdditionally, the phrasing of 42 controls was updated for grammar purposes.", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-fs-change-log"}, {"document_id": "ibmcld_07578-367408-369576", "score": 0.6771070957183838, "text": "\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-367382-369550", "score": 0.6771070957183838, "text": "\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01442-1679-3832", "score": 0.7472989559173584, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01441-1679-3819", "score": 0.7448257803916931, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01329-14955-16723", "score": 0.7314057350158691, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01329-59746-61590", "score": 0.7292786836624146, "text": "\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01415-7932-9985", "score": 0.7078014016151428, "text": "\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01441-7-2257", "score": 0.7065575122833252, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 0.7065575122833252, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01471-5654-7396", "score": 0.6998643279075623, "text": "\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https://cloud.ibm.com/apidocs/container-registry/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_01533-8109-9900", "score": 0.6997278928756714, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 0.6997278928756714, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01329-14955-16723", "score": 0.7434992790222168, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01441-1679-3819", "score": 0.7421956062316895, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-1679-3832", "score": 0.7407331466674805, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01415-7932-9985", "score": 0.7397730350494385, "text": "\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01533-8109-9900", "score": 0.7393330335617065, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 0.7393330335617065, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_04340-57846-59619", "score": 0.7329025864601135, "text": "\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-containerregcli"}, {"document_id": "ibmcld_01329-59746-61590", "score": 0.7285541296005249, "text": "\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01533-4546-6910", "score": 0.7282014489173889, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 0.7217547297477722, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01441-1679-3819", "score": 0.7799332737922668, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-1679-3832", "score": 0.778910756111145, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-59746-61590", "score": 0.7648089528083801, "text": "\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01533-8109-9900", "score": 0.7633591890335083, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 0.7633591890335083, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01329-14955-16723", "score": 0.7581168413162231, "text": "\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01441-7-2257", "score": 0.7459712624549866, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 0.7459712624549866, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-58331-60199", "score": 0.7441335916519165, "text": "\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01415-7932-9985", "score": 0.7428812980651855, "text": "\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 0.7529723644256592, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 0.7516742944717407, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 0.7142900228500366, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 0.7142900228500366, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 0.7067649364471436, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 0.6893609762191772, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 0.6893609762191772, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-365833-367834", "score": 0.6857941746711731, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 0.6857941746711731, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-367408-369576", "score": 0.6758597493171692, "text": "\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13149-5520-7284", "score": 0.74161297082901, "text": "\nNote: If you want to build and push the application to your own container registry you can use the Docker CLI to do so. The Dockerfile is provided in the repository and images can be pushed to the Container Registry or any other container registry.\n\n\n\n1. Define an environment variable named MYAPP and set the name of the application by replacing the placeholder with your initials:\n\nexport MYAPP=<your-initials>kubenodeapp\n2. Identify your cluster:\n\nibmcloud ks cluster ls\n3. Initialize the variable with the cluster name:\n\nexport MYCLUSTER=<CLUSTER_NAME>\n4. Initialize the kubectl cli environment:\n\nibmcloud ks cluster config --cluster $MYCLUSTER\n\nMake sure the CLI is configured for the region and resource group where your created your cluster using ibmcloud target -r <region> -g <resource_group>. For more information on gaining access to your cluster and to configure the CLI to run kubectl commands, check the [CLI configure](https://cloud.ibm.com/docs/containers?topic=containers-cs_cli_installcs_cli_configure) section\n5. You can either use the default Kubernetes namespace or create a new namespace for this application.\n\n\n\n1. If you want to use the default Kubernetes namespace, run the below command to set an environment variable:\n\nexport KUBERNETES_NAMESPACE=default\n2. If you want to create a new Kubernetes namespace, follow the steps mentioned under [Copying an existing image pull secret](https://cloud.ibm.com/docs/containers?topic=containers-registrycopy_imagePullSecret) and [Storing the image pull secret in the Kubernetes service account for the selected namespace](https://cloud.ibm.com/docs/containers?topic=containers-registrystore_imagePullSecret) sections of the Kubernetes service documentation. Once completed, run the below command:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-scalable-webapp-kubernetes"}, {"document_id": "ibmcld_11640-8768-10409", "score": 0.7270435094833374, "text": "\nGo directly to the [(RHA) 5.1 Install Software Lifecycle Container Bridge (SLCB)](https://access.redhat.com/articles/5100521sdi-slcb) instructions, and see the next section to learn the specific parameters for IBM Cloud.\n\nYou need to copy the downloaded SLCB exectuable (SLCB01_-70003322.EXE) to your working directory $HOME/sap/install and rename it to slcb. Note that will be the current version number.\n\n\n\n Locating the Installation Dialog parameters for SLCB \n\nIn order to run SLCB for your SAP DI installation, several parameters need to be supplied. One of these parameters is the address of the Container Image Repository. You can take advantage of the Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae Container Registry. The address consists of the endpoint URL for the registry and the namespace that you have created during the setup of the jump host, sap_di_cr - see: [Creating a new Container Registry namespace](https://cloud.ibm.com/docs/sap?topic=sap-rhos-di-set-up-clusterrhos-di-create-cr-ns).\n\n\n\n1. To find the endpoint URL of the registry that you are currently targeting, run the ibmcloud cr api command.\n\nibmcloud cr api\n\nExample output:\n\nRegistry API endpoint https://de.icr.io/api\n2. In this example the domain is icr.io.\n3. The region code precedes the domain - here it is de.\n4. Finally, the address of the Container Image Repository here is de.icr.io/sap_di_cr.\n5. Run the SLCB installation process:\n\n./slcb init\n\n\n\nDuring installation of the SLCB, you're prompted to enter following parameters:\n\n\n\n Parameter Value \n\n Address of the Container Image Repo: de.icr.io/sap_di_cr \n S-User Name: Sxxxxxxxxxx \n S-User Password: xxxxxxxx", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-rhos-di-dataintelligence"}, {"document_id": "ibmcld_05256-7949-9726", "score": 0.7246048450469971, "text": "\nNote that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n\nYes! [Here is how](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n\nYes, you can edit the existing [IAM policy of the service ID](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace. Before you can customize registry IAM policies, you must [enable IBM Cloud IAM policies for IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-user).\n\nCan I use a service ID?\n: Yes, you can create a service ID and assign authorities to it. Note that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n: Yes! [Here is how](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n: Yes, you can edit the existing [IAM policy of the service ID](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry"}, {"document_id": "ibmcld_14893-15230-17570", "score": 0.6322331428527832, "text": "\n- name: test-volume\nreadOnly: true\nmountPath: /fromHost\nvolumes:\n- name: test-volume\nhostPath:\npath: /var/hyperprotect\ntype: Directory\nrestartPolicy: Never\nShow more\n\nThe volumes field here defines the data on the host to be mounted into the pod. It's different from volumes in the HPCR contract.\n\n\n\n\n\n\n\n The images subsection \n\nThe images subsection is meant only for an image that is signed.\n\n\n\n Images described by docker compose \n\nThe container image that is listed in the docker-compose file can be signed or not signed by using Docker Content Trust (DCT).\n\nThe following example shows an image URL:\n\n<container registry>/<username or namespace>/<image name>\neg- us.icr.io/mynamespace/my-haproxy:\n\nThe following shows an example of a notary URL:\n\nnotary: \"https://notary.us.icr.io\"\n\nThe publicKey is the corresponding public key by which the image is signed by using DCT. Use the following command to get the public key:\n\ncat /.docker/trust/tuf/us.icr.io/<username>/<imagename>/metadata/root.json\n\nThe following snippet is an example:\n\nimages:\ndct:\nus.icr.io/mynamespace/my-haproxy:\nnotary: \"https://notary.us.icr.io\"\npublicKey: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpRENDQVM2Z0F3SUJBZ0lSQUxCMXBPYlpEQlRRc09GSFlxazMzaWd3Q2dZSUtvWkl6ajBFQXdJd0tqRW8KTUNZR0ExVUVBeE1mZFhNdWFXTnlMbWx2TDNCeVlXSm9ZWFF4TWpNdmJYa3RhR0Z3Y205NGVUQWVGdzB5TWpBMApNVE14TURFd01ETmFGdzB6TWpBME1UQXhNREV3TUROYU1Db3hLREFtQmdOVkJBTVRIM1Z6TG1samNpNXBieTl3CmNtRmlhR0YwTVRJekwyMTVMV2hoY0hKdmVIa3dXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CQndOQ0FBU1AKWGsrelE2MlFZNjI3MWQ1cTBMZHY3SGc3QzZkMGZOUlRsQmJXekhOWWFDZzlpU0piYnVNdjVBY0JmMjlqQi83eApqYzhzVitxMksyemtkTHV4QWxGWm96VXdNekFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJCkt3WUJCUVVIQXdNd0RBWURWUjBUQVFIL0JBSXdBREFLQmdncWhrak9QUVFEQWdOSUFEQkZBaUIzd0JTa0IxaXAKZHZZYlBMbFBmS3RZT0hsYnZzUllKa0FZM2hnY0xuNWhwQUloQUt6cmhsU3p4K1I5bmdtMTBlZVkyaFNCRmgrawpMWHp6SFkwaktTVzhyM1FhCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n\nFor an image that is not signed, no entry is required in the images subsection. However, for unsigned images, a digest is required. Complete the following steps to get the digest:\n\n\n\n1. Log in to the container registry dashboard.\n2. Open the image.\n3. Click Tag, and then click Digest.\n\n\n\nAfter you get the digest, add this digest in the docker-compose.yaml file. The following is an example:\n\nservices:\n<imagename>:", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-contract_se"}, {"document_id": "ibmcld_03893-78228-79534", "score": 0.6163719892501831, "text": "\nThis directory contains the installation files for gemalto/luna client\nCOPY 64 64\n\nRUN microdnf install -y \ngcc \ngcc-c++ \nopenssh-clients \nbind-utils \niputils \n&& cd 64 && \n NOTE we are accepting the license for installing gemalto client here\n please take a look at the license before moving forward\necho \"y\" | ./install.sh -p sa\n\n Final image \n\nFROM registry.access.redhat.com/ubi8/ubi-minimal\n\n Copy the library files from builder\nCOPY --from=builder /usr/lib/libCryptoki2_64.so /usr/lib/libCryptoki2_64.so\nCOPY --from=builder /usr/lib/libCryptoki2_64.so.2 /usr/lib/libCryptoki2_64.so.2\nCOPY --from=builder /usr/lib/libCryptoki2_64.so.6.3.0 /usr/lib/libCryptoki2_64.so.6.3.0\nShow more\n\nNow, run the following command to build the Docker image:\n\ndocker build -t hsm-client:v1 -f Dockerfile .\n\n\n\n\n\n Step three: Push the Docker image to your container registry \n\nAfter the image is built, the next step is to push the image to your Docker registry (for example, Docker Hub). The commands look similar to:\n\ndocker login -u <DOCKER_HUB_ID> -p <DOCKER_HUB_PWD>\ndocker tag hsm-client:v1 <DOCKER_HUB_ID>/hsm-client:v1\ndocker push <DOCKER_HUB_ID>/hsm-client:v1\n\n\n\n* Replace <DOCKER_HUB_ID> with your Docker Hub id.\n* Replace <DOCKER_HUB_PWD> with your Docker Hub password.\n\n\n\nCreate a Kubernetes image pull secret", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}, {"document_id": "ibmcld_16242-7-2224", "score": 0.609818696975708, "text": "\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-action-response-modes"}, {"document_id": "ibmcld_16242-3349-4513", "score": 0.5843949317932129, "text": "\n[Action response mode](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/response-mode-modal.png)\n\nAction response mode\n2. Click the other mode if you want to change it, and then click Save response mode.\n\n\n\n\n\n\n\n Override system defaults modes \n\nEnterprise\n\nFor Lite and Plus plans, the default settings can\u2019t be changed. For Enterprise plans, you can override system defaults to customize each mode in global settings for actions.\n\nTo override system defaults:\n\n\n\n1. Set the Override System Defaults toggle to On. This toggle is available only for Enterprise plans.\n2. Use the menu to modify any of the settings for either mode.\n\n\n\nIf you customize, the choices for each setting are;\n\n\n\nMode customization choices\n\n Setting Choices \n\n Clarify when one action matches More often, Sometimes, Less often \n Clarify when more than one action matches More often, Sometimes, Less often \n Offer support option when asking a clarifying question More often, Sometimes, Less often \n Step validation attempts before offering support 1 time, 2 times, 3 times \n\n\n\nIf you customize modes, be sure to test any changes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-action-response-modes"}, {"document_id": "ibmcld_16268-7-2150", "score": 0.5808427333831787, "text": "\nUsing autolearning to improve assistant responses \n\nIBM Cloud\n\nUse autolearning to enable your assistant to learn from interactions with your customers and improve responses.\n\nWhen customers interact with your assistant, they often make choices. Your assistant can learn from these user decisions.\n\nFor example, a customer might ask a question that the assistant isn't sure it understands. The assistant asks a clarifying question so the customer can choose the right action from a list. If customers most often click the same action (option #2, for example), your assistant can learn that option #2 is the best answer.\n\nNext time, the assistant can list option #2 as the first choice, so customers can get to it more quickly. If the pattern persists over time, it can change its behavior even more. Your assistant can return option #2 immediately, rather than asking a clarifying question.\n\nAs your assistant learns over time, your customers get the best answer more often and in fewer clicks.\n\n\n\n How autolearning works \n\nBefore your assistant can learn from customer behavior, it must observe a significant amount of real conversation data. The conversations take place in a channel such as the web chat, or in a custom application.\n\nLogs of conversations and user decisions from your live environment are the data source for observation. Your assistant analyzes the logs to gain insights. (It doesn't watch real-time clicks during a conversation.)\n\nWhen the assistant observes enough real conversation data from the live environment, it gains insights to help improve your assistant, providing a better customer experience.\n\nWhen you publish your assistant to the live environment, autolearning starts training the assistant.\n\n\n\n\n\n Applying autolearning \n\nYou can apply autolearning when the following conditions are met:\n\n\n\n* Ask clarifying questions is enabled in global settings. For more information, see [Asking clarifying questions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question).\n* You publish a version of your assistant to the live environment.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-autolearn"}, {"document_id": "ibmcld_16243-1218-3072", "score": 0.5570799112319946, "text": "\n* [Upload/Download](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-upload-download)\n\n\n\n\n\n Clarifying questions \n\nOn the Clarifying questions tab, you can customize how an action asks clarifying questions.\n\nIn the Ask clarifying questions section, you can:\n\n\n\n* Enable or disable if your assistant disambiguates (asks a clarifying question).\n* Modify the text that your assistant uses to introduce the clarification list or when no action matches.\n* Enable or disable response modes, and modify the text that your assistant uses with a response mode. If you enable response modes, you can use the Customize modes section to choose a response mode for each action to set how it behaves.\n\n\n\nFor more information, see [Customizing clarifying questions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-disambiguation-config) and [Response modes](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\n\n\n Change conversation topic \n\nThe Change conversation topic feature enables your assistant to handle digressions, dynamically responding to the user by changing the conversation topic as needed. For more information, see [Allowing your customers to change the topic of the conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-change-topic).\n\nIf necessary, you can disable changing the topic for all actions:\n\n\n\n1. On the Change conversation topic tab, set the switch to Off.\n2. Click Save, and then click Close.\n\n\n\n\n\n Allow change of topic between actions and dialog \n\nIf you are using actions and dialog, you can ensure that customers can change topics between an action and a dialog node.\n\nThis setting is available if you activate dialog in Assistant settings.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settings"}, {"document_id": "ibmcld_16359-8409-10354", "score": 0.5508107542991638, "text": "\nYou can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else. You can change it to something else, such as I need something else or This isn't what I want. \n Connection to support Connect to support The assistant can include a choice to connect to other support in the list of clarifying questions. If the customer picks this choice, the assistant uses your Fallback action. You can change it to something else, such as Talk to a live agent or Search for the answer. \n\n\n\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to apply the customizations. For more information, see [Publishing your content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Disabling clarifying questions \n\nYou can disable clarifying questions for all actions.\n\nTo disable clarification for all actions:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https://cloud.ibm.com/docs-content/v1/content/icons/settings.svg).\n2. On the Clarifying questions tab, ensure that the Response modes switch is set to Off.\n3. Set the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-understand-questions"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01377-13470-15034", "score": 0.7776951193809509, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-13496-15060", "score": 0.7776951193809509, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01388-7-1807", "score": 0.7652289867401123, "text": "\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https://cloud.ibm.com/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access"}, {"document_id": "ibmcld_05429-13694-16089", "score": 0.7450820803642273, "text": "\nFor more information about Container Registry regions, see [IBM Cloud Container Registry regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n What access permissions are required for Code Engine managed access to IBM Cloud Container Registry? \n\nThe user of this Integrations page must have the following IBM Cloud\u00ae Identity and Access Management (IAM) access policies that are assigned to your user account to successfully configure registry access for all users of the project. If you don't have sufficient permissions to perform these actions, you can use this page to help you understand the required permissions and actions you can take.\n\n\n\n* Service: Container Registry\n\n\n\n* Resources: Select from resource group, region, or access management tags.\n* Resource group access:Viewer\n* Roles and actions:Administrator platform access and Reader, Writer, and Manager service access\n\n\n\n* Service: Code Engine\n\n\n\n* Resources: The resource group of this Code Engine project\n* Resource group access:Viewer\n* Roles and actions:Operator platform access and Writer service access\n\n\n\n\n\nFor Code Engine to automatically generate a service ID for accessing images in Container Registry in a specific location, Code Engine sets up this service ID with the Administrator role for the IAM Identity service that is scoped to this service ID. Additionally, Code Engine grants the Manager role for the IBM Cloud Container Registry service that is scoped to the specified location (region). These roles and permissions are required so that Code Engine can use this service ID to access Container Registry on behalf of the user of the respective Code Engine project.\n\nWhen Code Engine configures this service ID with the Administrator platform access and Manager service access to IBM Cloud Container Registry, the access is scoped to only this service ID.\n\nFor more information about Code Engine requirements for accessing images in a container registry, see [Accessing container registries](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry).\n\n\n\n\n\n What's the relationship between the service ID and the registry secret? \n\nWhen you configure default registry access for a specific location, you can view details about what Code Engine does for you, including information about the service ID and its access policies, API key, and registry secret.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-project-integrations"}, {"document_id": "ibmcld_01377-4-1879", "score": 0.7359061241149902, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https://cloud.ibm.com/docs/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https://cloud.ibm.com/docs/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https://cloud.ibm.com/docs/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-4-1879", "score": 0.7359061241149902, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https://cloud.ibm.com/docs/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https://cloud.ibm.com/docs/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https://cloud.ibm.com/docs/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01471-37693-39572", "score": 0.7138683795928955, "text": "\nYou can use the new region by using the domain name jp.icr.io.\n\nFor more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n 21 February 2019 \n\nAutomating access to your namespaces\n: Using tokens to automate pushing and pulling Docker images to and from your namespaces is deprecated. You must now use API keys to automate access to your Container Registry namespaces so that you can push and pull images.\n\nFor more information, see [Creating a user API key manually](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_accessregistry_access_user_apikey_create).\n\n\n\n\n\n 8 January 2019 \n\nEnd of support for Vulnerability Advisor API version 2\n: Vulnerability Advisor\u2019s API version 2 is deprecated and is no longer usable. Use version 3 of the API, see [Vulnerability Advisor for IBM Cloud Container Registry](https://cloud.ibm.com/apidocs/container-registry/va).\n\n\n\n\n\n 4 October 2018 \n\nManaging user access\n: Use IBM Cloud Identity and Access Management (IAM) to control access by users in your account to Container Registry. When IAM access policies are enabled for your account in Container Registry, every user that accesses the service in your account must be assigned an IAM\n\naccess policywith an IAM user role defined. That policy determines the role that the user has within the context of the service, and what actions the user can perform.\n\nFor more information, see [Managing IAM access with Cloud Identity and Access Management](https://cloud.ibm.com/docs/Registry?topic=Registry-iamiam), [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser), and [Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n\n\n 7 August 2018 \n\nExemption policies available in Vulnerability Advisor", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_01437-7-1954", "score": 0.710421621799469, "text": "\nIAM access policies are required from 5 July 2022 \n\nFrom 5 July 2022, to access IBM Cloud\u00ae Container Registry you must be using Cloud Identity and Access Management (IAM) access policies.\n\nIf you started to use Container Registry before the availability of [IAM API key policies in Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notesregistry-25feb2019) in February 2019, you must ensure that you are using IAM access policies to manage access to the IBM Cloud Container Registry service.\n\nPolicy-free authorization is being discontinued in the following Container Registry regions:\n\n\n\n* us-south (us.icr.io)\n* uk-south (uk.icr.io)\n* eu-central (de.icr.io)\n* ap-south (au.icr.io)\n* ap-north (jp.icr.io)\n\n\n\nOther regions are unaffected because they already require IAM access policies for all accounts.\n\n\n\n What are the changes? \n\nBefore 7 June 2019, all account users had full access to the images and settings that are associated with the account. Accounts that use Container Registry for the first time since 7 June 2019 are required to have IAM access policies and other accounts optionally require them. From 5 July 2022, all accounts require IAM access policies.\n\nBy default, account owners already have appropriate policies that give them full access to Container Registry. If policy-free authorization is in use, any other account user IDs and service IDs must be granted appropriate policies so that they can continue to access images and settings.\n\n\n\n\n\n Check whether these changes affect you \n\nTo check whether policy-free authorization is in effect, run the [ibmcloud cr iam-policies-status](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_iam_policies_status) command. If the CLI reports that IAM policy enforcement is disabled, you must [prepare for the changes](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_iam_policynotices_iam_policy_prepare).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_iam_policy"}, {"document_id": "ibmcld_01530-1294-3025", "score": 0.710106611251831, "text": "\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https://cloud.ibm.com/docs/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https://cloud.ibm.com/docs/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https://cloud.ibm.com/docs/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-user"}, {"document_id": "ibmcld_01387-1446-3272", "score": 0.7055864334106445, "text": "\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID. For more information about service IDs, see [Creating and working with service IDs](https://cloud.ibm.com/docs/account?topic=account-serviceidsserviceids).\n\nYou can set permissions so that you can configure access to resources within a namespace at the\n\nresource grouplevel. For more information, see [User permissions for working with namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_setup_cli_namespace_plan_perm).\n\nFor more information about enabling policies for Container Registry, see [Defining IAM access policies](https://cloud.ibm.com/docs/Registry?topic=Registry-useruser).\n\n\n\n\n\n Assign roles \n\nAfter you define the scope of the IAM access policy, you assign a role.\n\nIf a specific role and its actions don't fit the use case that you're looking to address, you can [create a custom role](https://cloud.ibm.com/docs/account?topic=account-custom-rolescustom-access-roles) and pick the actions to include.\n\nReview the following tables that outline the actions that each role allows within the Container Registry service.\n\n\n\n* [Platform management roles](https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=uiplatform_management_roles) enable users to perform tasks on service resources at the platform level, for example, assign user access to the service, create or delete instances, and bind instances to applications.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01496-0-1282", "score": 0.7143493294715881, "text": "\n\n\n\n\n\n\n  Why can't I add a namespace? \n\nSetting up a namespace fails in IBM Cloud\u00ae Container Registry.\n\n  What\u2019s happening \n\nWhen you run ibmcloud cr namespace-add, you're unable to set your entered value as the namespace.\n\n  Why it\u2019s happening \n\nThe following alternatives are possible causes:\n\n\n\n*  You entered a namespace value that is already being used by another IBM Cloud organization.\n*  A namespace was recently deleted and you're reusing its name. If the namespace that was deleted contained many resources, the deletion might not yet be fully processed by Container Registry.\n*  You used invalid characters in the namespace value.\n\n\n\n  How to fix it \n\nYou can fix this problem in the following ways:\n\n\n\n*  Follow any instructions that are in the returned error message.\n*  Check that you entered a valid namespace:\n\n\n\n*  Your namespace must be unique across all IBM Cloud accounts in the same region.\n*  Your namespace must be 4 - 30 characters long.\n*  Your namespace must start and end with a letter or number.\n*  Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\n*  Choose a different value for your namespace.\n*  If you're re-creating a namespace that was deleted, and it contained many images, try again later.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-troubleshoot-add-namespace"}, {"document_id": "ibmcld_10805-7233-8822", "score": 0.7016967535018921, "text": "\nibmcloud fn namespace create <namespace_name> [--description <\"description of your namespace\">]\n\n| <namespace_name> | The display name for the IAM-based namespace. | | -n <description> | Optional: Add a description to the namespace, such as which kind of actions or packages you plan to create. If your description is longer than one word, it must be in quotations. | | --description <description> | Optional: Add a description to the namespace, such as which kind of actions or packages you plan to create. If your description is longer than one word, it must be in quotations. |\n\nThe following example shows sample output from the namespace create command.\n\nok: created namespace myNamespace\n3. Verify that your new namespace is created.\n\nibmcloud fn namespace get <namespace_name_or_id> --properties\n\nThe following example shows sample output from the namespace get command.\n\nDetails of namespace: myNamespace\nDescription: short description\nResource Plan Id: functions-base-plan\nLocation: jp-tok\nID: 05bae599-ead6-4ccb-9ca3-94ce8c8b3e43\n\nYou can also list all namespaces, including IAM-based and Cloud Foundry-based namespaces:\n\nibmcloud fn namespace list\n4. Before you can create entities in the namespace, you must set your CLI context to the namespace by targeting it.\n\nibmcloud fn property set --namespace <namespace_name_or_id>\n\n\n\nAfter you set a property, such as the --namespace property, it is retained until you manually unset it. If you want to switch between IAM namespaces or between Cloud Foundry and IAM namespaces, you must unset the namespace property and then reset it.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-namespaces"}, {"document_id": "ibmcld_10805-8395-9992", "score": 0.6832424402236938, "text": "\nBefore you can create entities in the namespace, you must set your CLI context to the namespace by targeting it.\n\nibmcloud fn property set --namespace <namespace_name_or_id>\n\n\n\nAfter you set a property, such as the --namespace property, it is retained until you manually unset it. If you want to switch between IAM namespaces or between Cloud Foundry and IAM namespaces, you must unset the namespace property and then reset it. For more information, see [ibmcloud fn property set](https://cloud.ibm.com/docs/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_prop_set).\n\n\n\n\n\n Creating a namespace with the API \n\nCreate your IAM-managed namespace with the API.\n\n\n\n1. Create an IAM-enabled namespace.\n\ncurl --request POST --url 'https://jp-tok.functions.cloud.ibm.com/api/v1/namespaces' --header 'accept: application/json' --header 'authorization: <IAM_token>' --data '{\"description\":\"string\",\"name\":\"string\",\"resource_group_id\":\"string\",\"resource_plan_id\":\"string\"}'\n\n| <IAM_token> | Your IBM Cloud Identity and Access Management (IAM) token. To retrieve your IAM token, run ibmcloud iam oauth-tokens. | | -n <name> | The name of the namespace. | | -n <resource_group_id> | The ID of the resource group that you want to create the namespace in. To see resource group IDs, run ibmcloud resource groups. | | -n <resource_plan_id> | The ID of the resource plan, such as functions-base-plan | | -n <description> | Optional: Add a description to the namespace, such as which kind of actions or packages it will contain. |\n\nThe following example shows sample output from the previous command.\n\n{", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-namespaces"}, {"document_id": "ibmcld_01484-4131-5923", "score": 0.6799013614654541, "text": "\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace&interface=ui"}, {"document_id": "ibmcld_01477-4118-5910", "score": 0.6799013614654541, "text": "\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespace"}, {"document_id": "ibmcld_01327-4660-7015", "score": 0.6640390157699585, "text": "\nActions that generate events for namespaces \n\n\n\nTable 9. Actions that generate events for namespaces\n\n Action Description Data Event \n\n container-registry.namespace.create Create a namespace in Container Registry.<br><br>Assign a Container Registry namespace to a resource group. \n container-registry.namespace.delete Delete a namespace from Container Registry. \n container-registry.namespace.list List the Container Registry namespaces in your IBM account. \n\n\n\n\n\n\n\n Actions that generate events for plans \n\n\n\nTable 10. Actions that generate events for plans\n\n Action Description Data Event \n\n container-registry.plan.get Display information about the current pricing plan. \n container-registry.plan.set Upgrade to the standard plan. \n\n\n\n\n\n\n\n Actions that generate events for quotas \n\n\n\nTable 11. Actions that generate events for quotas\n\n Action Description Data Event \n\n container-registry.quota.get Display the current quotas for traffic and storage, and the usage information against those quotas. \n container-registry.quota.set Modify the quotas. Quota settings must be managed separately for your account in each registry instance. You can set quota limits for storage in your free or standard plan. \n\n\n\n\n\n\n\n Actions that generate events for retention policies \n\n\n\nTable 12. Actions that generate events for retention policies\n\n Action Description Data Event \n\n container-registry.retention.analyze List the images that are deleted if you apply a specific retention policy. \n container-registry.retention.list List the image retention policies for your account. \n container-registry.retention.set Set a policy to retain images in a namespace in Container Registry by applying specified criteria. \n\n\n\n\n\n\n\n Actions that generate events for settings \n\n\n\nTable 13. Actions that generate events for settings\n\n Action Description Data Event \n\n container-registry.settings.get Get registry service settings for the targeted account, such as whether platform metrics are enabled. \n container-registry.settings.set Update registry service settings for the targeted account, such as enabling platform metrics. \n\n\n\n\n\n\n\n Actions that generate events for signing images \n\n\n\nTable 14. Actions that generate events for signing images\n\n Action Description Data Event \n\n container-registry.signature.delete Delete a signature from an image in Container Registry. True", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-at_events"}, {"document_id": "ibmcld_04025-18380-19912", "score": 0.6609011888504028, "text": "\nnamespace: <NAMESPACE>\n\n\n\n\n\n Step five: Create the HSM configmap \n\nBecause the console needs to know the configuration settings to use for your HSM, you need to create a Kubernetes [configmap](https://kubernetes.io/docs/concepts/configuration/configmap/) to store these values. The configMap settings depend on whether you configured a daemon for your HSM or not. In that case, the IBM Blockchain Platform operator uses the HSM configuration passed in this configmap to get the details about the HSM client image, such as what image pull secret to use, and the folder mounts that are required. Based on the information provided, when a CA, peer, or ordering node is deployed with HSM enabled, the operator mounts required the files for the HSM client image. If you are using a daemon with your HSM, skip ahead to [Configure the operator to work with an HSM daemon](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-hsm-gemaltodaemon-configmap).\n\nConfigure the operator to work with an HSM that does not use a daemon\n\nCopy the following text and save it to a file named ibp-hsm-config.yaml:\n\nversion: v1\ntype: hsm\nresources:\nlimits: {}\nrequests: {}\nsecurityContext:\nprivileged: false\nrunAsNonRoot: false\nrunAsUser: 0\nlibrary:\nimage: <HSM_IMAGE_URL>\nauth:\nimagePullSecret: <IMAGE_PULL_SECRET>\nfilepath: <HSM_LIBRARY_FILE_PATH>\nenvs:\n- name: <ENVIRONMENT_VARIABLE_NAME>\nvalue: <ENVIRONMENT_VARIABLE_VALUE>\nmountpaths:\n- mountpath: <MOUNTPATH>\nname: <MOUNTPATH_NAME>\nsecret: <HSM_CRYPTO_SECRET>\npaths:\n- key: <KEY>\npath: <PATH>", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-hsm-gemalto"}, {"document_id": "ibmcld_01471-23854-25589", "score": 0.6514303684234619, "text": "\n: If you want to manage your Vulnerability Advisor exemption policies for security issues, depending on the task that you want to complete, you might have to update your access role.\n\nFor more information, see [Access roles for configuring Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n 29 July 2020 \n\nYou can set permissions so that access to resources within a namespace can be configured at the resource group level\n: Namespaces are created in resource groups so that access to resources within a namespace can be configured at the resource group level. If a namespace isn't already in a resource group, you can assign the namespace to a resource group.\n\n\n\n* Namespaces created in version 0.1.485 of the Container Registry CLI or later, or in the IBM Cloud console on or after 29 July 2020, are created in a resource group that you specify so that you can configure access to resources within the namespace at the [resource group](https://cloud.ibm.com/docs/account?topic=account-rgs) level. However, you can still set permissions for the namespace at the account level or in the namespace itself. For more information, see [Set up a namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgs_registry_namespace_add) and [ibmcloud cr namespace-add](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_namespace_add).\n* Namespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020 aren't assigned to resource groups. You can assign an existing namespace to a resource group so that you can configure access to resources within a namespace at the resource group level.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_10852-36156-37516", "score": 0.6500714421272278, "text": "\n* [How do I set IAM policies so that others can work with my namespace?](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamiam_namespace_policies)\n* [How do I set IAM policies so that others can create namespaces in my account?](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamiam_namespace_create)\n* [How do I know which access policies have set for me?](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamiam_set_policies_me)\n* [Platform management roles](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamiam_platform_roles)\n* [Service-specific roles](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamservice_specific_roles)\n* [Setting access policies for a service ID](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamservice-id-set-policy)\n\n\n\n* [Setting access policies for a service ID in the console](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamservice-id-set-ui)\n* [Setting an access policy for your Cloud Functions service ID through the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-iamcli-set)\n\n\n\n\n\n\n\n\n\n Integrating serverless apps \n\n[Binding IBM Cloud services to Cloud Functions entities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-servicesservices)\n\n\n\n* [Binding a service to an action or package](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-servicesservices_bind)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_01409-2859-4626", "score": 0.6486017107963562, "text": "\nGET /api/v1/namespaces/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace. DELETE /api/v1/namespaces/{namespace} container-registry.namespace.delete container-registry.namespace.delete \n\n\n\n\n\n\n\n Plan API methods \n\n\n\nTable 5. Plans\n\n Action Method IAM ACTION AT ACTION \n\n Get plans for the targeted account. GET /api/v1/plans container-registry.plan.get container-registry.plan.get \n Update plans for the targeted account. PATCH /api/v1/plans container-registry.plan.set container-registry.plan.set \n\n\n\n\n\n\n\n Quota API methods \n\n\n\nTable 6. Quotas\n\n Action Method IAM ACTION AT ACTION \n\n Get quotas for the targeted account. GET /api/v1/quotas container-registry.quota.get container-registry.quota.get \n Update quotas for the targeted account. PATCH /api/v1/quotas container-registry.quota.set container-registry.quota.set \n\n\n\n\n\n\n\n Retention API methods \n\n\n\nTable 7. Retentions\n\n Action Method IAM ACTION AT ACTION \n\n List retention policies for all namespaces in the targeted IBM Cloud account. GET /api/v1/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST /api/v1/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST /api/v1/retentions/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_at_iam"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05838-13761-15409", "score": 0.7844263911247253, "text": "\nupdate_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Setting up IBM Cloud\u00ae Monitoring alerts \n\nWhen you set up alerts, make sure to allow your cluster enough time to self-heal. Because Kubernetes has self healing capabilities, configure your alerts only for the issues that arise over time. By observing your cluster over time, you can learn which issues Kubernetes can resolve itself and which issues require alerts to avoid downtime.\n\nOn 15 June 2022, the naming convention for IBM Cloud\u00ae Monitoring alerts is changing to a Prometheus compatible format.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_05754-3185-5238", "score": 0.7801012992858887, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_master"}, {"document_id": "ibmcld_06209-2829-4687", "score": 0.7733402252197266, "text": "\nIn any of these cases, you can [check the versions change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers//images/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\nTo update the Kubernetes master major or minor version:\n\n\n\n1. Review the [Kubernetes changes](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) and make any updates marked Update before master.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10189-3187-5240", "score": 0.7716960906982422, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-debug_master"}, {"document_id": "ibmcld_10394-1469-2994", "score": 0.7531763911247253, "text": "\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_06209-7-1817", "score": 0.7530332803726196, "text": "\nUpdating clusters, worker nodes, and cluster components \n\nYou can install updates to keep your Kubernetes clusters up-to-date in IBM Cloud\u00ae Kubernetes Service.\n\n\n\n Updating the Kubernetes master \n\nPeriodically, the Kubernetes project releases [major, minor, or patch updates](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types). Updates can affect the Kubernetes API server version or other components in your Kubernetes master. IBM updates the patch version, but you must update the master major and minor versions.\n\n\n\n About updating the master \n\nHow do I know when to update the master?\n: You are notified in the IBM Cloud console and CLI when updates are available, and can also check the [supported versions](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) page.\n\nHow many versions behind the latest can the master be?\n: IBM generally supports three versions of Kubernetes at a time. You can update the Kubernetes API server only to the next version ahead of its current version (n+1). Additionally, your worker nodes can be up to two versions behind the master version (n-2).\n\nFor example, if your current Kubernetes API server version is 1.18 (n) and you want to update to 1.20, you must first update to 1.19 (n+1) and then to 1.20 (n+2). Next, you can update the worker nodes up to two version ahead, such as 1.18 to 1.20 (n+2).\n\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10642-2898-4503", "score": 0.7521330118179321, "text": "\nYour worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/openshift//images/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms).\n\nTo update the Red Hat OpenShift master major or minor version:\n\n\n\n1. Review the [Red Hat OpenShift changes](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) and make any updates marked Update before master.\n2. Review any [Kubernetes helpful warnings](https://kubernetes.io/blog/2020/09/03/warnings/), such as deprecation notices.\n3. Check the add-ons and plug-ins that are installed in your cluster for any impact that might be caused by updating the cluster version.\n\n\n\n* Checking add-ons\n\n\n\n1. List the add-ons in the cluster.\n\nibmcloud oc cluster addon ls --cluster CLUSTER\n2. Check the supported Red Hat OpenShift version for each add-on that is installed.\n\nibmcloud oc addon-versions\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10642-1365-3347", "score": 0.7469706535339355, "text": "\nThen, [update the worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10290-70537-72315", "score": 0.7404765486717224, "text": "\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_04489-73641-75415", "score": 0.7382287383079529, "text": "\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud ks cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version. To see available versions, run [ibmcloud ks versions](https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-clics_versions_command).\n\n--force-update\n: Optional: Attempt the update even if the change is greater than two minor versions from the worker node version.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master update command", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05713-438449-439829", "score": 0.7963072061538696, "text": "\n[Version 1.23 CIS Kubernetes benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-123)\n\n\n\n* [1 Master node security configuration](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-section-1-123)\n\n\n\n* [1.1 Master node configuration files](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-11-123)\n* [1.2 API server](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-12-123)\n* [1.3 Controller manager](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-13-123)\n* [1.4 Scheduler](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-14-123)\n\n\n\n* [2 Etcd node configuration](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-section-2-123)\n* [3 Control plane configuration](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-section-3-123)\n\n\n\n* [3.1 Authentication and authorization](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-31-123)\n* [3.2 Logging](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-32-123)\n\n\n\n* [4 Worker node security configuration](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-section-4-123)", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_05608-7-1899", "score": 0.7933714389801025, "text": "\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark"}, {"document_id": "ibmcld_05613-7-1955", "score": 0.7833696007728577, "text": "\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122"}, {"document_id": "ibmcld_05611-7-1955", "score": 0.7813048362731934, "text": "\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-120"}, {"document_id": "ibmcld_05616-7-1945", "score": 0.7809190154075623, "text": "\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125"}, {"document_id": "ibmcld_05610-7-1993", "score": 0.7807220220565796, "text": "\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119"}, {"document_id": "ibmcld_05615-7-1945", "score": 0.7802667617797852, "text": "\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124"}, {"document_id": "ibmcld_05614-7-1955", "score": 0.780021071434021, "text": "\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123"}, {"document_id": "ibmcld_10070-7-1616", "score": 0.7734858393669128, "text": "\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark"}, {"document_id": "ibmcld_05612-7-1934", "score": 0.7723541259765625, "text": "\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05592-13853-15494", "score": 0.7041996121406555, "text": "\nNote that the service_name for IBM Cloud Kubernetes Service is containers-kubernetes. To find a list of service names, run the ibmcloud cbr service-ref-targets command. To find a list of API types for a service, run the ibmcloud cbr api-types --service-name SERVICE command.\n\n\n\nExample command to create a rule that uses the addresses key and the cluster API type and the ipAddress type.\n\nibmcloud cbr rule-create my-rule-1 --service-name containers-kubernetes --api-type crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --zone-id ZONE-ID\n\nThe following command creates a rule that protects the CLUSTER-ID cluster. Only resources in the NETWORK-ZONE-ID network zone can access the cluster. This rule includes both the cluster and management API types.\n\nibmcloud cbr rule-create my-rule-2 --service-name containers-kubernetes --service-instance CLUSTER-ID --zone-id NETWORK-ZONE-ID\n\nThe following example command creates a rule that allows all private network connections, but allows only resources in the allow-client-ip network zone to connect to the cluster over the public network. For more information about this scenario, see [Setting up context-based restrictions](https://cloud.ibm.com/docs/containers?topic=containers-cbr-tutorial).\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=allow-client-ip\n\n\n\n\n\n Creating rules from the console \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=cli"}, {"document_id": "ibmcld_05593-13847-15488", "score": 0.7041996121406555, "text": "\nNote that the service_name for IBM Cloud Kubernetes Service is containers-kubernetes. To find a list of service names, run the ibmcloud cbr service-ref-targets command. To find a list of API types for a service, run the ibmcloud cbr api-types --service-name SERVICE command.\n\n\n\nExample command to create a rule that uses the addresses key and the cluster API type and the ipAddress type.\n\nibmcloud cbr rule-create my-rule-1 --service-name containers-kubernetes --api-type crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --zone-id ZONE-ID\n\nThe following command creates a rule that protects the CLUSTER-ID cluster. Only resources in the NETWORK-ZONE-ID network zone can access the cluster. This rule includes both the cluster and management API types.\n\nibmcloud cbr rule-create my-rule-2 --service-name containers-kubernetes --service-instance CLUSTER-ID --zone-id NETWORK-ZONE-ID\n\nThe following example command creates a rule that allows all private network connections, but allows only resources in the allow-client-ip network zone to connect to the cluster over the public network. For more information about this scenario, see [Setting up context-based restrictions](https://cloud.ibm.com/docs/containers?topic=containers-cbr-tutorial).\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=allow-client-ip\n\n\n\n\n\n Creating rules from the console \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=ui"}, {"document_id": "ibmcld_05595-2977-4795", "score": 0.7041475772857666, "text": "\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various kubectl commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr-tutorial"}, {"document_id": "ibmcld_10067-2911-4724", "score": 0.7032163739204407, "text": "\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cbr-tutorial"}, {"document_id": "ibmcld_05739-8121-9783", "score": 0.6865502595901489, "text": "\nTo check your auto update settings, run the ibmcloud ks ingress alb autoupdate get command.<br> * ALB OAuth-Proxy add-on: networking.k8s.io/v1beta1 is compatible with ALB OAuth-Proxy add-on version 2.0.0 only. If you use the ALB OAuth-Proxy add-on you must update the add-on to version 2.0.0 before updating your cluster to 1.22.<br><br><br> \n Unsupported: Service service.alpha.kubernetes.io/tolerate-unready-endpoints annotation Services no longer support the service.alpha.kubernetes.io/tolerate-unready-endpoints annotation. The annotation has been deprecated since Kubernetes version 1.11 and has been replaced by the spec.publishNotReadyAddresses field. If your services rely on this annotation, update them to use the spec.publishNotReadyAddresses field instead. For more information on this field, see [DNS for Services and Pods](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/). \n\n\n\n\n\n\n\n Update after master \n\nThe following table shows the actions that you must take after you update the Kubernetes master.\n\n\n\nChanges to make after you update the master to Kubernetes 1.22\n\n Type Description \n\n Endpoint Security Mitigation Kubernetes cluster role system:aggregate-to-edit has removed endpoints permissions as a security mitigation for [CVE-2021-25740](https://nvd.nist.gov/vuln/detail/CVE-2021-25740). If your cluster does not require any customizations to the system:aggregate-to-edit cluster role, besides removing the endpoints permission, allow Kubernetes to reconcile the permissions by running the kubectl annotate --overwrite clusterrole/system:aggregate-to-edit rbac.authorization.kubernetes.io/autoupdate=true command.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_122"}, {"document_id": "ibmcld_05590-12010-13179", "score": 0.6810854077339172, "text": "\nSince no operations are specified, resources in the NETWORK-ZONE-ID zone can access both the cluster and management APIs.\n\n{\n\"description\": \"Example rule 1\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"contexts\": [\n{\n\"attributes\":\n{\n\"name\": \"networkZoneId\",\n\"value\": \"NETWORK-ZONE-ID\"\n},\n{\n\"name\": \"endpointType\",\n\"value\": \"private\"\n}\n]\n}\n]\n}\n\nThe following example payload creates a rule that protects the CLUSTER-ID cluster. Only the resources defined in the NETWORK-ZONE-ID zone can access the cluster. Since the cluster API type is specified, resources in the NETWORK-ZONE-ID zone can access the cluster through the cluster APIs over the private network.\n\n{\n\"description\": \"Example rule 2\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"operations\": {\n\"api_types\": [\n{\n\"api_type_id\": \"crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\"\n}\n]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr"}, {"document_id": "ibmcld_05592-12094-13263", "score": 0.6810854077339172, "text": "\nSince no operations are specified, resources in the NETWORK-ZONE-ID zone can access both the cluster and management APIs.\n\n{\n\"description\": \"Example rule 1\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"contexts\": [\n{\n\"attributes\":\n{\n\"name\": \"networkZoneId\",\n\"value\": \"NETWORK-ZONE-ID\"\n},\n{\n\"name\": \"endpointType\",\n\"value\": \"private\"\n}\n]\n}\n]\n}\n\nThe following example payload creates a rule that protects the CLUSTER-ID cluster. Only the resources defined in the NETWORK-ZONE-ID zone can access the cluster. Since the cluster API type is specified, resources in the NETWORK-ZONE-ID zone can access the cluster through the cluster APIs over the private network.\n\n{\n\"description\": \"Example rule 2\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"operations\": {\n\"api_types\": [\n{\n\"api_type_id\": \"crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\"\n}\n]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=cli"}, {"document_id": "ibmcld_05593-12088-13257", "score": 0.6810854077339172, "text": "\nSince no operations are specified, resources in the NETWORK-ZONE-ID zone can access both the cluster and management APIs.\n\n{\n\"description\": \"Example rule 1\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"contexts\": [\n{\n\"attributes\":\n{\n\"name\": \"networkZoneId\",\n\"value\": \"NETWORK-ZONE-ID\"\n},\n{\n\"name\": \"endpointType\",\n\"value\": \"private\"\n}\n]\n}\n]\n}\n\nThe following example payload creates a rule that protects the CLUSTER-ID cluster. Only the resources defined in the NETWORK-ZONE-ID zone can access the cluster. Since the cluster API type is specified, resources in the NETWORK-ZONE-ID zone can access the cluster through the cluster APIs over the private network.\n\n{\n\"description\": \"Example rule 2\",\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"ACCOUNT-ID\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"containers-kubernetes\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"CLUSTER-ID\"\n}\n]\n}\n],\n\"operations\": {\n\"api_types\": [\n{\n\"api_type_id\": \"crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\"\n}\n]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr&interface=ui"}, {"document_id": "ibmcld_10704-1456-3064", "score": 0.6785339713096619, "text": "\nCheck the [VPC quotas documentation](https://cloud.ibm.com/docs/vpc?topic=vpc-quotas) for VPC resource quotas across all your VPC clusters in your VPC.\n\n\n\n How to fix it \n\nVerify that no VPC security groups are blocking traffic to your cluster and that the VPC load balancer is available.\n\n\n\n2. Verify that the VPC load balancer for the Kubernetes LoadBalancer service exists. In the output, look for the VPC load balancer that is formatted kube-<cluster_ID>-<kubernetes_lb_service_UID>. You can get the Kubernetes LoadBalancer service UID by running oc get svc <service_name> -o yaml.\n\nibmcloud is load-balancers\n\n\n\n* If the VPC load balancer is not listed, it does not exist for one of the following reasons:\n\n\n\n\n\n* You reached the maximum number of VPC load balancers permitted per account. Across all your VPC clusters in your VPC, a maximum of 20 VPC load balancers can be created. One VPC load balancer is created for each Kubernetes LoadBalancer service that you create, and it routes requests to that Kubernetes LoadBalancer service only.\n* The VPC load balancer was deleted through the VPC console or the CLI. To re-create the VPC load balancer for your Kubernetes LoadBalancer service, restart the Kubernetes master by running ibmcloud oc cluster master refresh --cluster <cluster_name_or_id>.\n\n\n\nIf you want to remove the load balancing setup for an app in your VPC cluster, delete the Kubernetes LoadBalancer service by running oc delete svc <kubernetes_lb_service_name>. The VPC load balancer that is associated with the Kubernetes LoadBalancer service is automatically deleted from your VPC.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_ts_lb"}, {"document_id": "ibmcld_06260-12518-13816", "score": 0.6783371567726135, "text": "\nID Name Status Subnet CIDR Addresses ACL Public Gateway VPC Zone\n5f5787a4-f560-471b-b6ce-20067ac93439 vpc-prod-dal1 available 10.240.0.0/24 183/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-1\ne3c19786-1c54-4248-86ca-e60aab74ed62 vpc-prod-dal2 available 10.240.64.0/24 183/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-2\n2930a068-51cc-4eca-807b-3f296d0891b4 vpc-prod-dal3 available 10.240.128.0/24 249/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-3\n\n\n\n* Individual worker node IP addresses: If you have a small number of worker nodes that run only one app and don't need to scale, or if you want to add only one worker node, list all the worker nodes in your cluster and note the Primary IP addresses. Only these worker nodes are added. If you delete the worker nodes or add worker nodes to the cluster, you must update your allowlist accordingly.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n\n\n\n2. Add the subnet CIDRs or individual worker node IP addresses to your service's allowlist or your on-premises allowlist for outbound traffic.\n3. Repeat these steps for each cluster that you want to allow traffic to or from.\n\n\n\n\n\n\n\n\n\n Updating IAM allowlists for Kubernetes Service IP addresses", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-firewall"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-143784-145737", "score": 0.7346318960189819, "text": "\nIt is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n* What is the value of using IBM Blockchain Platform over native Hyperledger Fabric?\n\nHyperledger Fabric is a powerful, versatile, pluggable, open source, distributed ledger technology capable of addressing a wide variety of use cases across many industries. IBM Blockchain Platform is IBM's commercial distribution of Hyperledger Fabric. A key benefit of the platform is that IBM tests the open source code for security vulnerabilities daily and provides 24x7x365 support with SLAs appropriate for production environments. The platform is the commercial distribution of Hyperledger Fabric and includes integrated tools that provide end to end features for developers and network operators to develop, test, operate, monitor, and govern Fabric components by using an intuitive console UI.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-143758-145711", "score": 0.7346318960189819, "text": "\nIt is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n* What is the value of using IBM Blockchain Platform over native Hyperledger Fabric?\n\nHyperledger Fabric is a powerful, versatile, pluggable, open source, distributed ledger technology capable of addressing a wide variety of use cases across many industries. IBM Blockchain Platform is IBM's commercial distribution of Hyperledger Fabric. A key benefit of the platform is that IBM tests the open source code for security vulnerabilities daily and provides 24x7x365 support with SLAs appropriate for production environments. The platform is the commercial distribution of Hyperledger Fabric and includes integrated tools that provide end to end features for developers and network operators to develop, test, operate, monitor, and govern Fabric components by using an intuitive console UI.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_04041-14573-16416", "score": 0.7322708368301392, "text": "\n* [Data privacy](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-privacy)\n* [GDPR](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-gdpr)\n\n\n\n\n\n Kubernetes cluster security \n\nThe best place to start is to learn about the security features of the underlying Kubernetes infrastructure. The open source documentation provides a review of recommended practices for [securing a Kubernetes cluster](https://Kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/).\n\nIf you are using IBM Cloud, you can review the topic on Security for the [IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-security) or [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-security).\n\n\n\n\n\n Network security \n\nIBM Cloud provides the underlying network, including the networks and routers, over which customers\u2019 VLAN resides. The customer configures their servers and uses gateways and firewalls to route traffic between servers to protect workloads from network threats. Protecting your cloud network by using firewalls and intrusion prevention system devices is imperative for protecting your cloud-based workloads.\n\n\n\n Firewall configuration \n\nKubernetes clusters should be secured by a firewall to protect the network from unauthorized access from internet traffic. By default IBM Cloud Kubernetes service clusters are preconfigured with a Calico network plug-in that secures the public network interface of every worker node in the cluster. By configuring Kubernetes and Calico network policies you can easily control the inbound and outbound network traffic. For more information, see [Controlling traffic with network policies](https://cloud.ibm.com/docs/containers?topic=containers-network_policies).", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-security"}, {"document_id": "ibmcld_07578-169183-171371", "score": 0.6961326003074646, "text": "\n* Where does IBM store the customer's logs and how long does IBM keep the audit logs for the blockchain platform service?\n\nThe logs are stored in the customer's Kubernetes cluster. IBM does not have access to the logs and it is up to the customer to manage all of their log data including retention management.\n* Do we have access to logging services and what logs are available to me?\n\nWith IBM Blockchain Platform, you can now directly access logs from your Kubernetes dashboard. It is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n\n\n\nCompute Bare Metal Servers for Classic\n\n\n\n* Why don\u2019t I see some of my disks as choices on the 'Create image template' page?\n\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n* Why did my capture fail?\n\nWhen a capture fails, an error occurred.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-169157-171345", "score": 0.6961326003074646, "text": "\n* Where does IBM store the customer's logs and how long does IBM keep the audit logs for the blockchain platform service?\n\nThe logs are stored in the customer's Kubernetes cluster. IBM does not have access to the logs and it is up to the customer to manage all of their log data including retention management.\n* Do we have access to logging services and what logs are available to me?\n\nWith IBM Blockchain Platform, you can now directly access logs from your Kubernetes dashboard. It is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n\n\n\nCompute Bare Metal Servers for Classic\n\n\n\n* Why don\u2019t I see some of my disks as choices on the 'Create image template' page?\n\nDisks that aren't contained within a volume (storage group) aren't eligible to capture and therefore you don't see them listed on the page. If you want a missing disk to show up as a choice, you must submit a [support ticket](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) that asks to associate the disk with a volume.\n* Why did my capture fail?\n\nWhen a capture fails, an error occurred.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05608-1309-3624", "score": 0.689738392829895, "text": "\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark"}, {"document_id": "ibmcld_07578-142389-144373", "score": 0.6735497713088989, "text": "\nVersions 2.1.3 and 2.5.x of the IBM Blockchain Platform can be used with the Ansible collection to deploy a Hyperledger Fabric network.\n* How do I get support for running the IBM Blockchain Platform Ansible playbook?\n\nAnsible is an open source technology and this product is not officially supported by IBM. For support related to the usage of the IBM Blockchain Platform and Ansible playbooks use the [GitHub repository](https://github.com/IBM-Blockchain/ansible-collection/issues).\n* Can the IBM Blockchain Platform monitor the health of a client application?\n\nThe IBM Blockchain Platform console does not monitor the health of blockchain client applications, but IBM Cloud does offer tooling such as [IBM Log Analysis](https://cloud.ibm.com/catalog/services/ibm-log-analysis) and [IBM Cloud Monitoring](https://cloud.ibm.com/catalog/services/ibm-cloud-monitoring) that can be used for their health monitoring.\n* Where does IBM store the customer's logs and how long does IBM keep the audit logs for the blockchain platform service?\n\nThe logs are stored in the customer's Kubernetes cluster. IBM does not have access to the logs and it is up to the customer to manage all of their log data including retention management.\n* Do we have access to logging services and what logs are available to me?\n\nWith IBM Blockchain Platform, you can now directly access logs from your Kubernetes dashboard. It is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-142363-144347", "score": 0.6735497713088989, "text": "\nVersions 2.1.3 and 2.5.x of the IBM Blockchain Platform can be used with the Ansible collection to deploy a Hyperledger Fabric network.\n* How do I get support for running the IBM Blockchain Platform Ansible playbook?\n\nAnsible is an open source technology and this product is not officially supported by IBM. For support related to the usage of the IBM Blockchain Platform and Ansible playbooks use the [GitHub repository](https://github.com/IBM-Blockchain/ansible-collection/issues).\n* Can the IBM Blockchain Platform monitor the health of a client application?\n\nThe IBM Blockchain Platform console does not monitor the health of blockchain client applications, but IBM Cloud does offer tooling such as [IBM Log Analysis](https://cloud.ibm.com/catalog/services/ibm-log-analysis) and [IBM Cloud Monitoring](https://cloud.ibm.com/catalog/services/ibm-cloud-monitoring) that can be used for their health monitoring.\n* Where does IBM store the customer's logs and how long does IBM keep the audit logs for the blockchain platform service?\n\nThe logs are stored in the customer's Kubernetes cluster. IBM does not have access to the logs and it is up to the customer to manage all of their log data including retention management.\n* Do we have access to logging services and what logs are available to me?\n\nWith IBM Blockchain Platform, you can now directly access logs from your Kubernetes dashboard. It is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07507-7174-9217", "score": 0.6729912161827087, "text": "\nFor more information about network isolation, see [FS Cloud Boundary Protection](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection).\n* Not all application models can share infrastructure\n\nShared application infrastructure makes sense only for sets of applications that have similar architectures. For example, sets of applications that use stateless microservices, containers, and managed database services can easily be deployed together. Other applications that are based on VM images with local storage will need separate application infrastructure. It is best practice to identify 2 or 3 common architectural patterns so that a small number of application hosting deployable architectures can be built and used for many applications.\n* Interactions with centralized networking and services\n\n\n\n* Transit gateway\n\n\n\nConnecting the shared infrastructure VPC to the central transit gateway requires a process where both the centralized operations team and the BU operations team coordinate to connect the VPC.\n\n\n\n* Hyper Protect Crypto Services and other centralized services\n\nAuthorizing the connection across accounts requires a process where both the centralized operations team and the BU operations team coordinate to create a service-to-service authorization for the consuming applications.\n\n\n\n* Hosting multiple applications on Kubernetes\n\nRed Hat OpenShift and Kubernetes are designed for efficient hosting of multiple applications. However, it is best practice to leverage Kubernetes names spaces for application isolation and istio for application network ingress and egress controls. The cluster configuration to support an application must be automated, and that automation owned by the shared infrastructure hosting project. However, application owners can provide information to tailor the automation to there needs. Note that application owners should not have permission to modify the configuration of the shared infrastructure directly.", "title": "", "source": "https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-infra-account"}, {"document_id": "ibmcld_04113-7-2190", "score": 0.6723486185073853, "text": "\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https://cloud.ibm.com/docs/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-best-practices-for-cis-setup"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05821-7-2076", "score": 0.6205759048461914, "text": "\nUnderstanding high availability and disaster recovery \n\nUse the built-in Kubernetes and IBM Cloud\u00ae Kubernetes Service features to make your cluster more highly available and to protect your app from downtime when a component in your cluster fails.\n\n\n\n About high availability \n\nHigh availability (HA) is a core discipline in an IT infrastructure to keep your apps up and running, even after a partial or full site failure. The main purpose of high availability is to eliminate potential points of failures in an IT infrastructure. For example, you can prepare for the failure of one system by adding redundancy and setting up failover mechanisms.\n\nWhat level of availability is best?\n: You can achieve high availability on different levels in your IT infrastructure and within different components of your cluster. The level of availability that is correct for you depends on several factors, such as your business requirements, the Service Level Agreements that you have with your customers, and the resources that you want to expend.\n\nWhat level of availability does IBM Cloud offer?\n: See [How IBM Cloud ensures high availability and disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime).\n\nThe level of availability that you set up for your cluster impacts your coverage under the [IBM Cloud HA service level agreement terms](https://cloud.ibm.com/docs/overview?topic=overview-slas). For example, to receive full HA coverage under the SLA terms, you must set up a multizone cluster with a total of at least 6 worker nodes, two worker nodes per zone that are evenly spread across three zones.\n\nWhat are the other cluster components that support highly available architecture?\n: See [Overview of potential points of failure in IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-hafault_domains).\n\nWhere is the service located?\n: See [Locations](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zonesregions-and-zones).\n\nWhat am I responsible to configure disaster recovery options for?", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ha"}, {"document_id": "ibmcld_05832-12787-14780", "score": 0.5980570912361145, "text": "\nFor more information, see [Forwarding Kubernetes API audit logs to an external server](https://cloud.ibm.com/docs/containers?topic=containers-health-auditaudit-api-server-external).\n\n\n\nAm I responsible for keeping Fluentd updated?\n: To change your logging or filter configurations, the Fluentd logging component must be at the latest version. By default, automatic updates to the add-on are enabled. To disable automatic updates, see [Updating cluster components: Fluentd for logging](https://cloud.ibm.com/docs/containers?topic=containers-updatelogging-up).\n\nCan I forward some logs, but not others, from one source in my cluster?\n: Yes. For example, if you have a particularly chatty pod, you might want to prevent logs from that pod from taking up log storage space, while still allowing other pods' logs to be forwarded. To prevent logs from a specific pod from being forwarded, see [Filtering logs](https://cloud.ibm.com/docs/containers?topic=containers-healthfilter-logs).\n\n\n\n\n\n Forwarding cluster and app logs \n\nCreate a configuration for cluster and app logging. You can differentiate between the different logging options by using options.\n\nThe following table shows the different options that you have when you configure logging and their descriptions.\n\n\n\nTable 1. Understanding logging configuration options\n\n Parameter Description \n\n <cluster_name_or_ID> The name or ID of the cluster. \n --logsource The source that you want to forward logs from. Accepted values are container, application, worker, kubernetes, ingress, and storage. This option supports a comma-separated list of log sources to apply to the configuration. If you don't provide a log source, logging configurations are created for container and ingress log sources. \n --type syslog The value syslog forwards your logs to an external server. \n --namespace Optional: The Kubernetes namespace that you want to forward logs from. Log forwarding is not supported for the ibm-system and kube-system Kubernetes namespaces.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health"}, {"document_id": "ibmcld_06104-3423-5552", "score": 0.5919063687324524, "text": "\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-storage-plan"}, {"document_id": "ibmcld_10545-3427-5556", "score": 0.5919063687324524, "text": "\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan"}, {"document_id": "ibmcld_10231-7-2093", "score": 0.5691908597946167, "text": "\nUnderstanding high availability and disaster recovery \n\nUse the built-in Red Hat OpenShift, Kubernetes, and IBM Cloud\u00ae features to make your Red Hat OpenShift cluster more highly available and to protect your app from downtime when a component in your cluster fails.\n\n\n\n About high availability \n\nHigh availability (HA) is a core discipline in an IT infrastructure to keep your apps up and running, even after a partial or full site failure. The main purpose of high availability is to eliminate potential points of failures in an IT infrastructure. For example, you can prepare for the failure of one system by adding redundancy and setting up failover mechanisms.\n\nWhat level of availability is best?\n: You can achieve high availability on different levels in your IT infrastructure and within different components of your cluster. The level of availability that is correct for you depends on several factors, such as your business requirements, the Service Level Agreements that you have with your customers, and the resources that you want to expend.\n\nWhat level of availability does IBM Cloud offer?\n: See [How IBM Cloud ensures high availability and disaster recovery](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime).\n\nThe level of availability that you set up for your cluster impacts your coverage under the [IBM Cloud HA service level agreement terms](https://cloud.ibm.com/docs/overview?topic=overview-slas). For example, to receive full HA coverage under the SLA terms, you must set up a multizone cluster with a total of at least 6 worker nodes, two worker nodes per zone that are evenly spread across three zones.\n\nWhat are the other cluster components that support highly available architecture?\n: See [Overview of potential points of failure in Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-hafault_domains).\n\nWhere is the service located?\n: See [Locations](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zonesregions-and-zones).\n\nWhat am I responsible to configure disaster recovery options for?", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ha"}, {"document_id": "ibmcld_07024-6972-7946", "score": 0.5484660863876343, "text": "\nSimilarly, when an alphanumeric word is used in the dictionary entry, the synonyms are handled with Hankaku characters, except for the same alphanumeric word, which is represented by Zenkaku characters. The Zenkaku word is treated as a separate term from the Hankaku words.\n\nDictionary enrichments that you add to one project can be applied to collections in other projects in the same service instance. In fact, you can apply them to collections in a Content Mining project from the deployed Content Mining application.\n\n\n\n\n\n Dictionary limits \n\nThe number of dictionaries and term entries you can create per service instance depends on your Discovery plan type.\n\n\n\nDictionary plan limits\n\n Plan Number of dictionaries per service instance Number of term entries per dictionary Number of terms for which suggestions can be generated \n\n Cloud Pak for Data Unlimited Unlimited 1,000 \n Premium 100 10,000 1,000 \n Enterprise 100 10,000 1,000 \n Plus (includes Trial) 20 1,000 50", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary"}, {"document_id": "ibmcld_12645-7-2428", "score": 0.5263673067092896, "text": "\nUnderstanding your responsibilities when you use the landing zone deployable architectures \n\nLearn about the management responsibilities and terms and conditions that you have when you use one of the landing zone deployable architectures.\n\n\n\n* For more information about the responsibilities for you and for IBM\u00ae when you use a deployable architecture, see [Understanding your responsibilities when you use deployable architectures](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures).\n* For a high-level view of the service types in IBM Cloud\u00ae and the breakdown of responsibilities between the customer and IBM for each type, see [Shared responsibilities for using IBM Cloud\u00ae products](https://cloud.ibm.com/docs/overview?topic=overview-shared-responsibilities).\n* For the overall terms of use, see [IBM Cloud Terms and Notices](https://cloud.ibm.com/docs/overview/terms-of-use?topic=overview-terms).\n* For more information about the shared responsibilities for each Financial Services Validated service, see [Responsibilities for operating services in your deployment](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-responsibilities) in IBM Cloud Framework for Financial Services.\n\n\n\nReview the following sections for the specific responsibilities for you and for IBM when you use a landing zone deployable architecture.\n\n\n\n Incident and operations management \n\nIncident and operations management includes tasks such as monitoring, event management, high availability, problem determination, recovery, and full state backup and recovery.\n\nThe landing zone deployable architectures do not identify specific responsibilities in this area.\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe rows are read from left to right. The first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Keep deployed services and resources up to date Apply fixes and updates to the compute resources that are created from the deployable architecture.", "title": "", "source": "https://cloud.ibm.com/docs/secure-infrastructure-vpc?topic=secure-infrastructure-vpc-shared-resp"}, {"document_id": "ibmcld_07033-18031-20115", "score": 0.5262583494186401, "text": "\nThe system learns from the types of examples you label, and applies what it learns to identify potential new examples. For example, after you label red, orange, yellow, green, and blue as examples of the color entity type, the Example suggestions panel might show indigo and violet as suggested examples for you to label. Suggestions are not displayed until after you label many examples of an entity type.\n\nThe following example shows suggestions that are made for family member mentions.\n\nZoom\n\n![Shows suggestions for family member entities.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/suggestions-example.png)\n\nFigure 10. Entity example suggestions\n\nYou might notice that a term that you chose to bulk label is not labeled, but is displayed as a suggestion instead. A term is skipped in the following situations:\n\n\n\n* The term might occur in different noun phrases in different sections of the document. For example, the term father might occur in the noun phrases the kindest father and to her father. When a word is included in a noun phrase with adjectives, the meaning can change. Therefore, such terms sometimes are suggested rather than labeled automatically.\n* A word might be a valid example on its own and as part of a multiple-word mention. For example, a mention of IBM might refer to the company International Business Machines, Corp. or might be used as part of a product name, such as IBM Cloud Pak for Data. However, a word or phrase can be part of only one example. Example labels cannot overlap one another. Therefore, you must choose which example suggestion is the most accurate. In this example, where the term IBM is used as part of a product name, it is more accurate to label the full phrase as an example of the Product entity type.\n* The service might recognize that a term is a possible example of more than one entity type. For example, the word top might mean the best or might mean shirt.\n\n\n\nTo investigate a suggestion further, click it to see the word in context within the document.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractor"}, {"document_id": "ibmcld_11463-0-2421", "score": 0.521552562713623, "text": "\n\n\n\n\n\n\n  Understanding your responsibilities when you use Power Virtual Server with VPC landing zone deployable architecture \n\nLearn about the management responsibilities and terms and conditions that you have when you use the Power Virtual Server with VPC landing zone deployable architecture.\n\n\n\n*  For more information about the responsibilities for you and for IBM\u00ae when you use a deployable architecture, see [Understanding your responsibilities when you use deployable architectures](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures).\n*  For a high-level view of the service types in IBM Cloud\u00ae and the breakdown of responsibilities between the customer and IBM for each type, see [Shared responsibilities for using IBM Cloud products](https://cloud.ibm.com/docs/overview?topic=overview-shared-responsibilities).\n*  For the overall terms of use, see [IBM Cloud\u00ae Terms and Notices](https://cloud.ibm.com/docs/overview/terms-of-use?topic=overview-terms).\n\n\n\nReview the following section for the specific responsibilities for you and for IBM when you use the Power Virtual Server with VPC landing zone deployable architecture.\n\n\n\n  Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 1. Security and compliance responsibilities for provisioned components\n\n Task                                                                           IBM responsibility                                                                                                                                                                                                                                                                                                       Your responsibility                                                                          \n\n Ensure that the operating system image does not contain any vulnerabilities.   IBM Cloud provided and verified RHEL and SLES operating system images are used. After deployment, operating system images are updated to the newest state in the defined minor release. Official RHEL and SLES software repositories are used for installation of additional software components (like SQUID proxy).     Customer is responsible to keep the operating system secure and compliant after deployment.  \n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/powervs-vpc?topic=powervs-vpc-responsibilities"}, {"document_id": "ibmcld_07578-36367-38479", "score": 0.5201982855796814, "text": "\nWhen the JSON file is ingested, each item in the array is added as a separate document with a seprarate document ID. Each document shares the same parent ID, which identifies the relationship between them.\n\nYou can quickly find documents that share the same parent ID or other common metadata value from the Manage data page. Customize the view to show the field, such as extracted_metadata.parent_document_id or extracted_metadata.foldername, that the documents share in common.\n* Can I customize Discovery to understand my data\n\nYes. Use the intuitive tools provided with the product to teach Discovery about the unique terminology of your domain. For example, you can teach it to recognize patterns, such as BOM or part numbers that you use, or add dictionaries that recognize your product names and other industry-specific word meanings. For more information, see [Adding domain-specific resources](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain).\n* How does the Smart Document Understanding tool work?\n\nYou can use the Smart Document Understanding tool to teach Discovery about sections in your documents with distinct format and structure that you want Discovery to index. You can define a new field, and then annotate documents to train Discovery to understand what type of information is typically stored in the field. For more information, see [Using Smart Document Understanding](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fields).\n* What's the best way to add synonyms?\n\nYou can use two different methods to define synonyms.\n\n\n\n* To define synonyms that are recognized and tagged when a document is ingested and that can be retrieved by search, create a dictionary and add synonyms for the dictionary term entry. A dictionary defines special terms that you want to tag in your documents, such as product names or industry-specific terminology. You can use the dictionary terms later to create facets and to filter documents. For more information, see [Dictionary](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05998-3108-5122", "score": 0.7841534614562988, "text": "\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/service/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-overview"}, {"document_id": "ibmcld_10495-3085-5099", "score": 0.7841534614562988, "text": "\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/service/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview"}, {"document_id": "ibmcld_13177-14661-16794", "score": 0.7490112781524658, "text": "\n* no matter the environment, all clusters will tend to look the same,\n* it is easier to control who has access to a specific cluster,\n* it gives flexibility in the update cycles for deployments and underlying resources: When there is a new Kubernetes version, it gives you the option to update the Development cluster first, validate your application then update the other environment,\n* it avoids mixing different workloads that may impact each other such as isolating the production deployment from the others.\n\n\n\nHowever, often not all of that properties are needed and the use of fewer resources is desired. Then, another approach is to use [Kubernetes namespaces](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) in conjunction with [Kubernetes resource quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/) to isolate environments and control resource consumption. The following diagram shows a non-production and a production resource group with a Kubernetes cluster in a VPC each. The non-production cluster has a development and testing namespace, the production cluster a production namespace.\n\nZoom\n\n![Diagram showing separate Kubernetes namespaces to isolate environments](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution20-users-teams-applications/multiple-environments-with-namespaces.svg)\n\nUse separate Kubernetes namespaces to isolate environments\n\n\n\n\n\n Setup delivery pipeline \n\nWhen it comes to deploying to the different environments, your continuous integration / continuous delivery pipeline can be setup to drive the full process:\n\n\n\n* continuously update the Development environment with the latest and greatest code from the development branch, running unit tests and integration tests on the dedicated cluster;\n* promote development builds to the Testing environment, either automatically if all tests from the previous stages are OK or through a manual promotion process. Some teams will use different branches too here, merging the working development state to a stable branch as example;", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications"}, {"document_id": "ibmcld_05596-6573-8005", "score": 0.7464965581893921, "text": "\nUnderstanding the YAML file components\n\n Parameter Description \n\n image In us.icr.io/<registry_namespace>/cf-py:latest, replace <registry_namespace> with the namespace of your private image registry. If you are unsure what your namespace is, run the ibmcloud cr namespaces command to find it. \n nodePort Expose your app by creating a Kubernetes service of type NodePort. NodePorts are in the range of 30000 - 32767. You use this port to test your app in a browser later. \n\n\n\n2. Apply the configuration file to create the deployment and the service in your cluster.\n\nkubectl apply -f <filepath>/cf-py.yaml\n\nExample output\n\ndeployment \"cf-py\" configured\nservice \"cf-py-nodeport\" configured\n3. Now that all the deployment work is done, you can test your app in a browser. Get the details to form the URL.\n\na. Get the public IP address for the worker node in the cluster.\n\nibmcloud ks worker ls --cluster <cluster_name>\n\nExample output\n\nID Public IP Private IP Machine Type State Status Zone Version\nkube-dal10-cr18e61e63c6e94b658596ca93d087eed9-w1 169.xx.xxx.xxx 10.xxx.xx.xxx u3c.2x4.encrypted normal Ready dal10 1.26\n\nb. Open a browser and check out the app with the following URL: http://<public_IP_address>:<NodePort>. With the example values, the URL is http://169.xx.xxx.xxx:30872. You can give this URL to a co-worker to try or enter it in your cell phone's browser so that you can see that the app really is publicly available.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cf_tutorial"}, {"document_id": "ibmcld_06294-9054-11040", "score": 0.736578106880188, "text": "\nLearn more about [securing your personal information](https://cloud.ibm.com/docs/containers?topic=containers-securitypi) when you work with Kubernetes resources.\n6. Make the app accessible by exposing the deployment as a NodePort service. Because your VPC worker nodes are connected to a private subnet only, the NodePort is assigned only a private IP address and is not exposed on the public network. Other services that run on the private network can access your app by using the private IP address of the NodePort service.\n\nkubectl expose deployment/hello-world-deployment --type=NodePort --name=hello-world-service --port=8080 --target-port=8080\n\nExample output\n\nservice/hello-world-service exposed\n\n\n\nTable 1. Information about the command options.\n\n Parameter Description \n\n expose Expose a Kubernetes resource, such as a deployment, as a Kubernetes service so that users can access the resource by using the IP address of the service. \n deployment/<hello-world-deployment> The resource type and the name of the resource to expose with this service. \n --name=<hello-world-service> The name of the service. \n --type=NodePort The service type to create. In this lesson, you create a NodePort service. In the following lesson, you create a LoadBalancer service. \n --port=<8080> The port on which the service listens for external network traffic. \n --target-port=<8080> The port that your app listens on and to which the service directs incoming network traffic. In this example, the target-port is the same as the port, but other apps that you create might use a different port. \n\n\n\n7. Now that all the deployment work is done, you can test your app from within the cluster. Get the details to form the private IP address that you can use to access your app.\n\n\n\n1. Get information about the service to see which NodePort was assigned. The NodePorts are randomly assigned when they are generated with the expose command, but within 30000-32767. In this example, the NodePort is 30872.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}, {"document_id": "ibmcld_16098-9054-11040", "score": 0.736578106880188, "text": "\nLearn more about [securing your personal information](https://cloud.ibm.com/docs/containers?topic=containers-securitypi) when you work with Kubernetes resources.\n6. Make the app accessible by exposing the deployment as a NodePort service. Because your VPC worker nodes are connected to a private subnet only, the NodePort is assigned only a private IP address and is not exposed on the public network. Other services that run on the private network can access your app by using the private IP address of the NodePort service.\n\nkubectl expose deployment/hello-world-deployment --type=NodePort --name=hello-world-service --port=8080 --target-port=8080\n\nExample output\n\nservice/hello-world-service exposed\n\n\n\nTable 1. Information about the command options.\n\n Parameter Description \n\n expose Expose a Kubernetes resource, such as a deployment, as a Kubernetes service so that users can access the resource by using the IP address of the service. \n deployment/<hello-world-deployment> The resource type and the name of the resource to expose with this service. \n --name=<hello-world-service> The name of the service. \n --type=NodePort The service type to create. In this lesson, you create a NodePort service. In the following lesson, you create a LoadBalancer service. \n --port=<8080> The port on which the service listens for external network traffic. \n --target-port=<8080> The port that your app listens on and to which the service directs incoming network traffic. In this example, the target-port is the same as the port, but other apps that you create might use a different port. \n\n\n\n7. Now that all the deployment work is done, you can test your app from within the cluster. Get the details to form the private IP address that you can use to access your app.\n\n\n\n1. Get information about the service to see which NodePort was assigned. The NodePorts are randomly assigned when they are generated with the expose command, but within 30000-32767. In this example, the NodePort is 30872.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc_ks_tutorial"}, {"document_id": "ibmcld_06282-4283-5732", "score": 0.7190173268318176, "text": "\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group"}, {"document_id": "ibmcld_06284-4309-5758", "score": 0.7190173268318176, "text": "\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group&interface=ui"}, {"document_id": "ibmcld_08848-0-1791", "score": 0.7139585614204407, "text": "\n\n\n\n\n\n\n  How can I resolve the network error when working with the Kubernetes Service provider? \n\n  What\u2019s happening \n\nDuring the cluster upgrade from Kubernetes Service older version to new version. The Terraform apply fails with the TCP connection error message.\n\nError: Get \"http://localhost/api/v1/\": dial tcp [::1]:80: connect: connection refused\n\nOr\n\nError: {{site.data.keyword.containershort_notm}} cluster unreachable: invalid configuration: no configuration has been provided\n\n  Why it\u2019s happening \n\nYou are combining the cluster provisioning and working with the Kubernetes Service provider at the same time in your Terraform template in the IBM Cloud Schematics workspace or in your localhost. You make a change in the cluster configuration that leads to the cluster re-create. When you run terraform refresh command, you view strange errors such as, network or namespace issues.\n\n  How to fix it \n\nTo troubleshoot this error you need to ensure:\n\n\n\n*  You don't combine the Kubernetes Service provider with the cluster resource at the same time in the Terraform template.\n*  The resources should not be created in the same Terraform template or module where Kubernetes Service provider resources are in use.\n*  The Terraform provider evaluates the provider blocks versus actual resource, and the order in which the resources are defined. For more information, see [Provider configuration](https://developer.hashicorp.com/terraform/language/providers/configurationprovider-configuration).\n\n\n\nIf you cannot resolve this issue, contact support by opening a support case for the service that you want to work with. Make sure to include the incident ID. For more information, see [Using the Support Center](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-ks-network-error"}, {"document_id": "ibmcld_06004-28242-30124", "score": 0.7080240249633789, "text": "\nkind: Service\nmetadata:\n...\n* You can use the kubectl apply -f command to apply to an entire directory, not just a single file.\n* Try out the [kustomize project](https://cloud.ibm.com/docs/containers?topic=containers-appkustomize) that you can use to help write, customize, and reuse your Kubernetes resource YAML configurations.\n\n\n\nWithin the YAML file, you can use labels or annotations as metadata to manage your deployments.\n\nLabels\n: [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) are key:value pairs that can be attached to Kubernetes objects such as pods and deployments. They can be whatever you want, and are useful for selecting objects based on the label information. Labels provide the foundation for grouping objects. See the following examples for ideas for labels.\n\n\n\n* app: nginx\n* version: v1\n* env: dev\n\n\n\nAnnotations\n: [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) are similar to labels in that they are also key:value pairs. They are better for non-identifying information that can be leveraged by tools or libraries, such as holding extra information about where an object came from, how to use the object, pointers to related tracking repos, or a policy about the object. You don't select objects based on annotations.\n\n\n\n\n\n What app update strategies can I use? \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-380995-382843", "score": 0.7263935804367065, "text": "\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-380969-382817", "score": 0.7263935804367065, "text": "\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10214-7502-9481", "score": 0.7208206653594971, "text": "\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/openshift?topic=openshift-access_reference) or in the following table's links.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_05777-8738-10765", "score": 0.7170575261116028, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_07578-401520-403282", "score": 0.6992616057395935, "text": "\nYou can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?\n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/openshift?topic=openshift-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/openshift?topic=openshift-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/openshift?topic=openshift-iam-service-access-roles).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-401494-403256", "score": 0.6992616057395935, "text": "\nYou can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?\n\nRed Hat OpenShift on IBM Cloud uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/openshift?topic=openshift-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/openshift?topic=openshift-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/openshift?topic=openshift-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/openshift?topic=openshift-iam-service-access-roles).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-400150-401930", "score": 0.690771222114563, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-haha).\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-400124-401904", "score": 0.690771222114563, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/openshift?topic=openshift-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-haha).\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in Red Hat OpenShift on IBM Cloud to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Red Hat OpenShift API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-securitysecurity).\n* What access policies do I give my cluster users?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05777-10230-11885", "score": 0.6792424917221069, "text": "\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/containers?topic=containers-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https://cloud.ibm.com/docs/containers?topic=containers-iam-service-access-roles).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_05891-56316-58277", "score": 0.6633948087692261, "text": "\nClassic infrastructure\n\nView the pod security admission configuration for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security get command \n\nibmcloud ks cluster master pod-security get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy disable command \n\nibmcloud ks cluster master pod-security policy disable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the pod security policy for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud ks cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07540-7-2006", "score": 0.6977953910827637, "text": "\nGetting help and support \n\nIBM Cloud\u00ae Event Notifications provides troubleshooting information to isolate and resolve problems, and also offers support. If you cannot resolve your issue with the troubleshooting guide, open an IBM support case.\n\nBy default, account users don't have access to create, update, search, or view cases. The account owner must provide users access by assigning an IBM Cloud\u00ae Identity and Access Management (IAM) access policy. For more information, see [Assigning user access for working with support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-accessaccess).\n\n\n\n Creating a cloud support case \n\nFor more information, see [Using the Support Center](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n Creating a support case for a UI issue \n\nCollecting the following information can help a faster support case resolution for UI issues\n\n\n\n* Provide error codes and reference IDs.\n* Save the full URL of the console when the problem occurred, for example: https://cloud.ibm.com/event-notifications/provision/ac\n* Include the steps to reproduce the issue, along with your inputs and expected outputs.\n* Note the approximate time that the error occurred.\n* Provide the code version and error details:\n\n\n\n1. Right-click on the console page and select the Inspect or Inspect Element option.\n2. Scroll to the end of the output and copy any errors or stack traces.\n\n\n\n* Provide the network response:\n\n\n\n1. While you inspect the page, click the Network tab.\n2. Refresh the page and reproduce the problem.\n3. Starting at the end of the list, click each request and view the Preview tab. If the request has an \"errors\" node, expand that node to show the full error.\n4. Click the Response tab and include the full response string and the URL that generated the response.\n\n\n\n\n\n\n\n\n\n Creating a support case for non-UI issues \n\nCollect the following information to get a faster support case resolution for non-UI issues:\n\n\n\n* guid\n* sourceName", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-getting-help-and-support"}, {"document_id": "ibmcld_07395-7-1761", "score": 0.6901246309280396, "text": "\nGetting help and support for DNS Services \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae DNS Services, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-frequently-asked-questions) in the product documentation.\n* Review [Troubleshooting](https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n* Review [Stack Overflow](https://stackoverflow.com/search?q=dns-svcs+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and dns-svcs so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for DNS Services \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with DNS Services.\n\nProvide the following details:\n\n\n\n1. The specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-gettinghelp"}, {"document_id": "ibmcld_10771-0-1225", "score": 0.6865607500076294, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions about IBM Cloud\u00ae Functions, you can get help by joining the IBM Cloud\u00ae Functions community in Slack, asking questions through a forum, or opening an IBM Cloud support case.\n\n\n\n*  To see whether IBM Cloud is available, [check the IBM Cloud status page](https://cloud.ibm.com/status?selected=status).\n*  Review the forums to see whether other users ran into the same issue. When you use the forums to ask a question, tag your question so that it is seen by the IBM Cloud development teams.\n\n\n\n*  If you have technical questions about developing functions with IBM Cloud\u00ae Functions, post your question on [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud-functions) and tag your question with ibm-cloud-functions.\n\n\n\n*  See [Getting help](https://cloud.ibm.com/docs/get-support) for more details about using the forums.\n*  Contact IBM Support by opening a case. To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https://cloud.ibm.com/docs/get-support).\n\n\n\nWhen you report an issue, include your activation ID. To get an activation ID, run ibmcloud fn activation list.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-gettinghelp"}, {"document_id": "ibmcld_04156-0-1820", "score": 0.6790307760238647, "text": "\n\n\n\n\n\n\n  Getting help and support for CIS \n\nIf you experience an issue or have questions when using CIS, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https://cloud.ibm.com/docs/cis?topic=cis-faq) in the product documentation.\n*  Review [Troubleshooting](https://cloud.ibm.com/docs/cis?topic=cis-troubleshoot-your-cis-network-connection) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n*  Review [Stack Overflow](https://stackoverflow.com/search?q=cis+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cis so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CIS \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CIS.\n\nProvide the following details:\n\n\n\n1.  Provide your CRN:\n\n\n\n*  In the UI, go to the Overview page\n*  In the CLI, run ibmcloud resource service-instances --long\n\n\n\n2.  Provide your Domain name or ID.\n3.  Depending on the issue the following information might also be helpful:\n\n\n\n*  Account ID: Log into [https://cloud.ibm.com](https://cloud.ibm.com) and go to View Profile > Billing\n*  Instance ID: Run the CLI command ibmcloud resource service-instances --long\n*  Geo location\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-gettinghelp"}, {"document_id": "ibmcld_11601-1712-3717", "score": 0.673943042755127, "text": "\nIf you need support but are unable to log in to your account, start a chat by going to the [IBM Cloud Support](https://www.ibm.com/cloud/support) page and clicking Let's talk.\n\n\n\n New support case with IBM Cloud Support \n\nIf you need to open a support case, collect as much information as possible to help the IBM Cloud Support team to analyze, triage and diagnose your problem as quickly as possible.\n\n\n\n\n\n Requesting support for SAP-certified IBM Power Virtual Servers \n\nAll performance-related issues need to be checked by IBM Power Systems and IBM Cloud support first, to establish whether any infrastructure-related issues exist, before a case of the software stack (SAP Workloads) can be opened.\n\nIf the issue is operating system (OS) related, go the support portal of the distribution (AIX or Linux\u00ae) to open a case.\n\nYou can check whether the infrastructure is set up correctly by running a python script on Linux\u00ae: python chk_numa_lpm.py. For more information, see [SAP Note 2923962 - - Check SAP HANA NUMA Layout on IBM Power Systems Virtual Servers](https://launchpad.support.sap.com//notes/2923962).\n\n\n\n\n\n Requesting support for resources in the European Union \n\nEuropean Union (EU) support is available to customers who choose to enable the EU supported setting. EU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe.\n\nGlobal teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the primary user or account owner. For more information, see [Enabling the EU Supported setting](https://cloud.ibm.com/docs/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* Your resources are in the appropriate European data center.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_00384-0-1839", "score": 0.6716212034225464, "text": "\n\n\n\n\n\n\n  Getting help and support for CDN \n\nIf you experience an issue or have questions when using CDN, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https://cloud.ibm.com/docs/CDN?topic=CDN-faqs) in the product documentation.\n*  Review [Troubleshooting](https://cloud.ibm.com/docs/CDN?topic=CDN-troubleshoot-cdn-working) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n*  Review [Stack Overflow](https://stackoverflow.com/search?q=cdn+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cdn so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CDN \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CDN.\n\nProvide the following details:\n\n\n\n1.  Go to the [All CDNs page](https://cloud.ibm.com/cdn).\n2.  From the UI, provide the following information:\n\n\n\n*  (Required) Hostname, for example, example.testingcdn.net\n*  CNAME, for example, example.cdn.appdomain.cloud\n*  HTTPS status, for example, Yes (Wildcard)\n*  Status, for example, Running\n\n\n\nFrom the API, run listDomainMappings or listDomainMappingByUniqueId to get the following domain mapping information:\n\n\n\n*  (Required) domain\n*  cname\n*  protocol\n*  status\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-gettinghelp"}, {"document_id": "ibmcld_13830-7-2040", "score": 0.6704820394515991, "text": "\nGetting help and support for Transit Gateway \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae Transit Gateway, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-faqs-for-transit-gateway) in the product documentation.\n* Review [Troubleshooting](https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-troubleshooting) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n* Review [Stack Overflow](https://stackoverflow.com/search?q=transit-gateway+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and transit-gateway so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for Transit Gateway \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with Transit Gateway.\n\nProvide the following details:\n\n\n\n1. Provide your transit gateway ID:\n\n\n\n* Run ibmcloud tg gateways to get the Transit Gateway ID for the transit gateway in question from the output, and then collect the output of these commands ibmcloud tg gateway GATEWAY_ID and ibmcloud tg connections GATEWAY_ID.\n* In the output of the previous command, get the connection IDs for the connections to the relevant VPCs, and if relevant, the classic infrastructure connection. Also, collect the output of the following command against each connection ID: ibmcloud tg connection GATEWAY_ID CONNECTION_ID.", "title": "", "source": "https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-getting-help-and-support"}, {"document_id": "ibmcld_11601-4756-6466", "score": 0.660973072052002, "text": "\nThe [SAP ONE Support Launchpad](https://launchpad.support.sap.com) provides access to task-driven support resources from SAP, available with live web chat or incidnt tickets, and the following features:\n\n\n\n* Knowledge Base for SAP Notes\n* Incidents for connection with SAP Product Support teams\n* Software Downloads\n* Systems, Installations and License Keys\n\n\n\n[Full information on SAP Support](https://support.sap.com/en/my-support.html) provides additional details, including guidance on how to use the SAP ONE Support Launchpad.\n\n\n\n SAP ONE Support process for IBM Power \n\nIf the issue is related to IBM Power and SAP, open a case by going to [support.sap.com](https://support.sap.com/en/index.html) and click Report an Incident.\n\nAll performance-related issues must be checked by [IBM Cloud Customer Support](https://cloud.ibm.com/docs/get-support) first to rule out any infrastructure-related issues before a case on the software stack is opened.\n\nProvide details and run the following commands to attach the output to the case:\n\n\n\n* For AIX:\n\n\n\n* perfsap on [SAP Note 1170252](https://launchpad.support.sap.com//notes/1170252)\n\n\n\n* For Linux:\n\n\n\n* sapsysinfo on [SAP Note 618104](https://launchpad.support.sap.com//notes/618104)\n* supportconfig on [SAP Note 1642802](https://launchpad.support.sap.com//notes/1642802)\n* and for SAP HANA also use full-system-info-dump on [SAP Note 1732157](https://launchpad.support.sap.com//notes/1732157)\n\n\n\n\n\n\n\n\n\n\n\n Stack Overflow \n\nThe Stack Overflow forum provides a wide variety of searchable answers for your IBM Cloud questions. If you don't find an existing answer, ask a new question. Go to [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-help-support"}, {"document_id": "ibmcld_16633-0-1263", "score": 0.6593846678733826, "text": "\n\n\n\n\n\n\n  Getting help and support for watsonx.data \n\nIf you experience an issue or have questions when using IBM\u00ae watsonx.data, you can use the following resources before you open a support case.\n\n\n\n*  Review the [FAQs](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-faqs) in the product documentation.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n*  Review [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to see whether other users experienced the same problem. When you ask a question, tag the question with ibm-cloud and service-Name, so that it's seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https://cloud.ibm.com/docs/overview?topic=overview-feedback).\n\n\n\n  Providing support case details \n\nTo ensure that the support team can start investigating your case to provide a timely resolution, you must include detailed information along with steps to re-create the issue, if applicable.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-help-and-support"}, {"document_id": "ibmcld_07540-1577-2381", "score": 0.657241702079773, "text": "\nStarting at the end of the list, click each request and view the Preview tab. If the request has an \"errors\" node, expand that node to show the full error.\n4. Click the Response tab and include the full response string and the URL that generated the response.\n\n\n\n\n\n\n\n\n\n Creating a support case for non-UI issues \n\nCollect the following information to get a faster support case resolution for non-UI issues:\n\n\n\n* guid\n* sourceName\n* region of the instance\n* topicName (if the issue is related to a topic)\n* channelName (if the issue is related to a channel)\n* subscriptionName (if the issue is related to subscriptions)\n* notification_id (if the issue is related to sending notification)\n* Error message received\n* Status of notification shown in LogDNA (in the case of notification sent but not received)", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-getting-help-and-support"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07098-7-2215", "score": 0.6949208974838257, "text": "\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https://cloud.ibm.com/apidocs/discovery-dataquery). For an overview of query concepts, see the [Query overview](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_02590-7911-9371", "score": 0.6775263547897339, "text": "\nTo prevent [dangerous client bugs and backward-compatibility hazards](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-uris"}, {"document_id": "ibmcld_07191-1691-3739", "score": 0.6768439412117004, "text": "\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https://cloud.ibm.com/docs/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameters"}, {"document_id": "ibmcld_13446-24100-26099", "score": 0.6765000224113464, "text": "\nAsynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n timestamps \n\nAn optional boolean that indicates whether the service produces timestamps for the words of the transcript. By default (false), timestamps are not returned. For more information, see [Word timestamps](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadataword-timestamps).\n\n\n\nTable 27. The timestamps parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n Transfer-Encoding \n\nAn optional value of chunked that causes the audio to be streamed to the service. By default, audio is sent all at once as a one-shot delivery. For more information, see [Audio transmission](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-inputtransmission).\n\n\n\nTable 28. The Transfer-Encoding parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Not applicable; always streamed \n Synchronous HTTP Request header of POST /v1/recognize method \n Asynchronous HTTP Request header of POST /v1/recognitions method \n\n\n\n\n\n\n\n word_alternatives_threshold \n\nAn optional double between 0.0 and 1.0 that specifies the threshold at which the service reports acoustically similar alternatives for words of the input audio. By default, word alternatives are not returned. For more information, see [Word alternatives](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-spottingword-alternatives).\n\n\n\nTable 29. The word_alternatives_threshold parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_07191-7-2252", "score": 0.6751959919929504, "text": "\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https://cloud.ibm.com/docs/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameters"}, {"document_id": "ibmcld_00460-28506-30205", "score": 0.6714748740196228, "text": "\nThe parameter was replaced with the endpoint POST /{db}/_design/{ddoc}/_view/{view}/queries and is supplied as a queries request body parameter. You can also make multiple queries with the following new endpoints:\n\n\n\n* POST /{db}/_all_docs/queries\n* POST /{db}/_design_docs/queries\n\n\n\nSending several queries to a view\n: Sending multiple queries to a view that uses a POST request to /$DATABASE/_design/$DDOC/_view/$VIEWNAME is deprecated with [multi-querying a MapReduce view](https://cloud.ibm.com/apidocs/cloudantpostviewqueries). For more information, see the previous deprecation note about replacing the queries parameter.\n\n\n\n\n\n 4 April 2018 \n\nThe following changes were made in build 6875:\n\nNew! Audit facility\n: Internal audit facility is added to the platform.\n\nIBM Cloudant Query error messages\n: Improve error messages for IBM Cloudant Query.\n\n\n\n\n\n\n\n March 2018 \n\n\n\n 30 March 2018 \n\nThe following changes were made in build 6870:\n\nkill command\n: Fix how the kill command works when you terminate an operating system process.\n\n_changes endpoint\n: Fix _changes endpoint shard substitution.\n\nCompaction resumption\n: Fix compaction resumption for terminated compactions.\n\n\n\n\n\n 13 March 2018 \n\nThe following changes were made in build 6761:\n\nNew! _dbs_info endpoint\n: Introduce new _dbs_info endpoint to get information from a list of databases. See [Get a list of all databases in the instance](https://cloud.ibm.com/apidocs/cloudantgetalldbs).\n\nNew! Pluggable storage engine\n: Add a pluggable storage engine.\n\nImprovement\n: Update MochiWeb to version 2.17.\n\nAttachments\n: Ensure deterministic revisions for attachments. See [COUCHDB-3255](https://issues.apache.org/jira/browse/COUCHDB-3255).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_15845-18362-19949", "score": 0.6663182973861694, "text": "\ninvalid_generation_parameter \n\nMessage: The generation query parameter is invalid.\n\nFor versions on and after 5/31/2019, the 'generation' query parameter must be set to 1 to allow VPC API requests for use with generation 1 compute resources and set to 2 to allow VPC API requests for use with generation 2 compute resources.\n\nHow to set the generation parameter\n\nIn the CLI: ibmcloud is target --gen 1\n\nIn the API:\n\ncurl -X GET \"$rias_endpoint/v1/regions?version=$version&generation=1\"\n-H \"Authorization: $iam_token\"\n\n\n\n\n\n invalid_id_format \n\nMessage: Bad ID format. Ensure format is correct.\n\nMake sure that the ID you provided does not contain any malformed data.\n\nYou may get this error message if you provide a malformed start query when making a pagination request. For example, GET /v1/network_acls?start=23fbba08-ceb3-4cbe-a951-84ff20a06069?version=$version&generation=1 contains two ?s. Fix the query and try again.\n\n\n\n\n\n invalid_route \n\nMessage: The requested route does not exist.\n\nThe requested route on the API URL you provided does not exist. Verify that the URL you specified to call the API endpoint is correct.\n\n\n\n\n\n invalid_request_field \n\nMessage: A field provided in the request is not valid.\n\nFor example, to update the network ACL used by a subnet use the PATCH /v1/subnets/{subnet_id}?version=$version&generation=1 -d '{ \"network_acl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019 API.\n\nThe following request would be invalid because \u201cnetworkacl\u201d is not a valid field, PATCH /v1/subnets/{subnet_id}?version=$version&generation=1 -d '{ \"networkacl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-rias-error-messages"}, {"document_id": "ibmcld_13446-19419-21379", "score": 0.6618281602859497, "text": "\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_15845-33451-35257", "score": 0.6559804081916809, "text": "\nMessage: Member port is missing.\n\nMember port is a required field. Provide a value for member port.\n\n\n\n\n\n member_not_found \n\nMessage: Member with ID <member_id> cannot be found.\n\nProvide a member ID where the user has read access and read access to the subnet where the member resides.\n\n\n\n\n\n member_over_quota \n\nMessage: Member cannot be created. Quota of member instances under the pool has reached maximum limit.\n\nThe quotas per resource are specified in [Quotas and limits for VPC](https://cloud.ibm.com/docs/vpc-on-classic?topic=vpc-on-classic-quotas).\n\n\n\n\n\n missing_generation_parameter \n\nMessage: The generation query parameter is required.\n\nFor versions on and after 5/31/2019, the generation query parameter is required for VPC for generation 1 compute resources API requests.\n\n\n\n\n\n missing_ims_account_id \n\nMessage: There is no classic infrastructure (IMS) account linked to your account.\n\nTo create a Classic Access VPC, your account must be linked to a classic infrastructure (IMS) account. See [Setting up access to your Classic Infrastructure from VPC](https://cloud.ibm.com/docs/vpc-on-classic?topic=vpc-on-classic-setting-up-access-to-your-classic-infrastructure-from-vpc) to learn more.\n\n\n\n\n\n missing_version \n\nMessage: The version parameter is required, and it must be of the form YYYY-MM-DD.\n\nA version parameter is required for all API requests. The version must comply with the format YYYY-MM-DD. For single-digit months or dates, such as January 1st, the version should look like 2019-01-01. The date given in the version parameter must be later than 2019-01-01 but before the current date. Check out these [API examples](https://cloud.ibm.com/docs/vpc-on-classic?topic=vpc-on-classic-creating-a-vpc-using-the-rest-apis) for how to provide the version parameter.\n\n\n\n\n\n network_conflict", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-rias-error-messages"}, {"document_id": "ibmcld_13446-4441-6470", "score": 0.6558250188827515, "text": "\nTable 5. The base_model_version parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of /v1/recognize connection request \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n character_insertion_bias \n\nAn optional float between -1.0 and 1.0 that indicates whether the service is biased to recognize shorter (negative values) or longer (positive values) strings of characters when developing transcription hypotheses. By default, the service uses a default bias of 0.0. The value that you specify represents a change from a model's default. For more information, see [Character insertion bias](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-parsinginsertion-bias).\n\n\n\nTable 6. The character_insertion_bias parameter\n\n Availability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Beta for all models. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n Content-Type \n\nAn optional audio format (MIME type) that specifies the format of the audio data that you pass to the service. The service can automatically detect the format of most audio, so the parameter is optional for most formats. It is required for the audio/alaw, audio/basic, audio/l16, and audio/mulaw formats. For more information, see [Specifying an audio format](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-specifying).\n\n\n\nTable 7. The Content-Type parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket content-type parameter of JSON start message", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13297-4312-5935", "score": 0.6792922019958496, "text": "\nTo use the WebSocket interface, you first use the /v1/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST /v1/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-basic-request"}, {"document_id": "ibmcld_10833-0-1231", "score": 0.6767127513885498, "text": "\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled /whisk.system/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n /whisk.system/websocket         Package  uri               Utilities for communicating with WebSockets \n /whisk.system/websocket/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe /whisk.system/websocket/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws://mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocket"}, {"document_id": "ibmcld_13779-3555-3945", "score": 0.668609619140625, "text": "\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}/v1/synthesize'\n+ '?access_token=' + access_token\n+ '&customization_id={customization_id}'\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nfunction onOpen(evt) {\nvar message = {\ntext: '<ibm:prompt id=\"goodbye\"/>',\naccept: 'audio/ogg;codecs=opus'\n};\nwebsocket.send(JSON.stringify(message));\n}\n\n. . .\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-use"}, {"document_id": "ibmcld_10852-48513-49624", "score": 0.666940450668335, "text": "\n* [Reading an object with the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_arch)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_13455-24911-26512", "score": 0.6575862169265747, "text": "\n\"content-type\": \"audio/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13432-4611-6782", "score": 0.6531738042831421, "text": "\n* For information about the results of a speech recognition request, see [Understanding speech recognition results](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-basic-response).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of audio data with a single request:\n\n\n\n* The WebSocket interface accepts a maximum of 100 MB of audio.\n* The synchronous HTTP interface accepts a maximum of 100 MB of audio.\n* The asynchronous HTTP interface accepts a maximum of 1 GB of audio.\n\n\n\nFor more information about using compression to maximize the amount of data that you can send to the service, see [Data limits and compression](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-limits).\n\n\n\n\n\n Advantages of the WebSocket interface \n\nThe WebSocket interface has a number of advantages over the HTTP interface. The WebSocket interface\n\n\n\n* Provides a single-socket, full-duplex communication channel. The interface lets the client send multiple requests to the service and receive results over a single connection in an asynchronous fashion.\n* Provides a much simpler and more powerful programming experience. The service sends event-driven responses to the client's messages, eliminating the need for the client to poll the server.\n* Allows you to establish and use a single authenticated connection indefinitely. The HTTP interfaces require you to authenticate each call to the service.\n* Reduces latency. Recognition results arrive faster because the service sends them directly to the client. The HTTP interface requires four distinct requests and connections to achieve the same results.\n* Reduces network utilization. The WebSocket protocol is lightweight. It requires only a single connection to perform live-speech recognition.\n* Enables audio to be streamed directly from browsers (HTML5 WebSocket clients) to the service.\n* Returns results as soon as they are available when you use a next-generation model or request interim results.\n\n\n\n\n\n\n\n\n\n Using speech recognition parameters \n\nThe service's speech recognition interfaces share largely common parameters for transcribing speech to text.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-service-features"}, {"document_id": "ibmcld_13455-26115-26611", "score": 0.649164080619812, "text": "\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13455-10817-12822", "score": 0.642839789390564, "text": "\ncontent-type: 'audio/l16;rate=22050'\n};\nwebsocket.send(JSON.stringify(message));\n}\n\nIf it receives the request successfully, the service returns the following text message to indicate that it is listening. The listening state indicates that the service instance is configured (the JSON start message was valid) and is ready to accept audio for a recognition request.\n\n{'state': 'listening'}\n\nIf the client specifies an invalid query parameter or JSON field for the recognition request, the service's JSON response includes a warnings field. The field describes each invalid argument. The request succeeds despite the warnings.\n\n\n\n\n\n Send audio and receive recognition results \n\nAfter it sends the initial start message, the client can begin to send audio data to the service. The client does not need to wait for the service to respond to the start message with the listening message. Once it begins listening, the service processes any audio that was sent before the listening message.\n\nThe client must send the audio as binary data. The client can send a maximum of 100 MB of audio data per send request. It must send at least 100 bytes of audio for any request. The client can send multiple requests over a single WebSocket connection. For information about using compression to maximize the amount of audio that you can pass to the service with a request, see [Data limits and compression](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-limits).\n\nThe WebSocket interface imposes a maximum frame size of 4 MB. The client can set the maximum frame size to less than 4 MB. If it is not practical to set the frame size, the client can set the maximum message size to less than 4 MB and send the audio data as a sequence of messages. For more information about WebSocket frames, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nHow the service sends recognition results over a WebSocket connection depends on whether the client requests interim results.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13455-8123-9745", "score": 0.6428372859954834, "text": "\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&model=es-ES_BroadbandModel';\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\nwebsocket.onclose = function(evt) { onClose(evt) };\nwebsocket.onmessage = function(evt) { onMessage(evt) };\nwebsocket.onerror = function(evt) { onError(evt) };\n\nThe client can open multiple concurrent WebSocket connections to the service. The number of concurrent connections is limited only by the capacity of the service, which generally poses no problems for users.\n\n\n\n\n\n Initiate a recognition request \n\nTo initiate a recognition request, the client sends a JSON text message to the service over the established connection. The client must send this message before it sends any audio for transcription. The message must include the action parameter but can usually omit the content-type parameter:\n\naction (required string)\n: Specifies the action to be performed:\n\n\n\n* start begins a recognition request. It can also specify new parameters for subsequent requests. For more information, see [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more).\n* stop signals that all audio for a request has been sent. For more information, see [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop).\n\n\n\ncontent-type (optional string)\n: Identifies the format (MIME type) of the audio data for the request. The parameter is required for the audio/alaw, audio/basic, audio/l16, and audio/mulaw formats.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13790-7847-9406", "score": 0.6417704820632935, "text": "\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\nwebsocket.onclose = function(evt) { onClose(evt) };\nwebsocket.onmessage = function(evt) { onMessage(evt) };\nwebsocket.onerror = function(evt) { onError(evt) };\n\n\n\n\n\n Send input text \n\nTo synthesize text, the client passes a simple JSON text message to the service with the following parameters:\n\ntext (required string)\n: Provides the text that is to be synthesized. The client can pass plain text or text that is annotated with the Speech Synthesis Markup Language (SSML). The client can pass a maximum of 5 KB of input text with the request. The limit includes any SSML that you specify. For more information, see [Specifying input text](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingHTTPinput) and the sections that follow it. (SSML input can also include the <mark> element. For more information, see [Specifying an SSML mark](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timingtiming-mark).)\n\naccept (required string)\n: Specifies the requested format (MIME type) of the audio. Use / to request the default audio format, audio/ogg;codecs=opus. For more information, see [Using audio formats](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-audio-formats).\n\nThe Ogg audio format is not supported with the Safari browser. If you are using the the Text to Speech service with the Safari browser, you must specify a different format in which you want the service to return the audio.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13297-4312-5935", "score": 0.7336077690124512, "text": "\nTo use the WebSocket interface, you first use the /v1/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST /v1/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-basic-request"}, {"document_id": "ibmcld_13779-3555-3945", "score": 0.6939412951469421, "text": "\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}/v1/synthesize'\n+ '?access_token=' + access_token\n+ '&customization_id={customization_id}'\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nfunction onOpen(evt) {\nvar message = {\ntext: '<ibm:prompt id=\"goodbye\"/>',\naccept: 'audio/ogg;codecs=opus'\n};\nwebsocket.send(JSON.stringify(message));\n}\n\n. . .\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-use"}, {"document_id": "ibmcld_10833-0-1231", "score": 0.693124532699585, "text": "\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled /whisk.system/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n /whisk.system/websocket         Package  uri               Utilities for communicating with WebSockets \n /whisk.system/websocket/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe /whisk.system/websocket/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws://mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocket"}, {"document_id": "ibmcld_13455-1311-2796", "score": 0.6840513348579407, "text": "\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the /v1/recognize method available at the following endpoint:\n\nwss://api.{location}.speech-to-text.watson.cloud.ibm.com/instances/{instance_id}/v1/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss://api.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13384-1568-2859", "score": 0.6737185716629028, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), use the /v1/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&model=en-US_Telephony'\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), use the POST /v1/recognize method. The specified custom model is used for that request.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?model=en-US_Telephony&language_customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?model=en-US_Telephony&language_customization_id={customization_id}\"\n* For the [asynchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-async), use the POST /v1/recognitions method. The specified custom model is used for that request.\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse"}, {"document_id": "ibmcld_13790-7847-9406", "score": 0.666423499584198, "text": "\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\nwebsocket.onclose = function(evt) { onClose(evt) };\nwebsocket.onmessage = function(evt) { onMessage(evt) };\nwebsocket.onerror = function(evt) { onError(evt) };\n\n\n\n\n\n Send input text \n\nTo synthesize text, the client passes a simple JSON text message to the service with the following parameters:\n\ntext (required string)\n: Provides the text that is to be synthesized. The client can pass plain text or text that is annotated with the Speech Synthesis Markup Language (SSML). The client can pass a maximum of 5 KB of input text with the request. The limit includes any SSML that you specify. For more information, see [Specifying input text](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingHTTPinput) and the sections that follow it. (SSML input can also include the <mark> element. For more information, see [Specifying an SSML mark](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timingtiming-mark).)\n\naccept (required string)\n: Specifies the requested format (MIME type) of the audio. Use / to request the default audio format, audio/ogg;codecs=opus. For more information, see [Using audio formats](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-audio-formats).\n\nThe Ogg audio format is not supported with the Safari browser. If you are using the the Text to Speech service with the Safari browser, you must specify a different format in which you want the service to return the audio.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13361-1589-2935", "score": 0.6656568050384521, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the /v1/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST /v1/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse"}, {"document_id": "ibmcld_10852-48513-49624", "score": 0.661787748336792, "text": "\n* [Reading an object with the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_arch)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_13455-7-1568", "score": 0.6571429371833801, "text": "\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the /v1/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13790-1284-2889", "score": 0.6498211622238159, "text": "\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nYou call the /v1/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id}/v1/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}/v1/synthesize.\n\nA WebSocket client calls the /v1/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07171-3905-5713", "score": 0.5828704833984375, "text": "\nYou again need the {environment_id} and {configuration_id} IDs you collected at the start of this procedure.\n\ncurl -X PUT -u \"apikey\":\"{apikey_value}\" -H \"Content-Type: application/json\" -d @my_config.json \"{url}/v1/environments/{environment_id}/configurations/{configuration_id}?version=2019-04-30\"\n\nIf you are creating a configuration or modifying the default configuration, create another custom configuration instead of updating an existing configuration. Before you create the configuration, remove the \"configuration_id\": field from your my_config.json file, and then run the following command:\n\ncurl -X POST -u \"apikey\":\"{apikey_value}\" -H \"Content-Type: application/json\" -d @my_config.json \"{url}/v1/environments/{environment_id}/configurations?version=2019-04-30\"\n\nBoth commands return the contents of the updated configuration file.\n\nReplace {apikey} and {url} with your API key and URL.\n\n\n\n\n\n Integrating multiple custom models \n\nYou can apply more than one custom model to identical fields using the API. Follow the steps in [Integrating your custom model with the API](https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wksintegrate-customAPI) and use the example here as a guide.\n\nYou cannot apply multiple custom models using the Discovery tooling. Only the entity and relations enrichments can be customized.\n\nYou must specify a different destination_field for each identical source_field. In addition, each source_field must be enriched by a unique model. For example, if you want to apply multiple custom models to the source_field of text and you apply the model{watson_knowledge_studio_model_ID} to the entities enrichment, you must not use that model again for the entities enrichment.\n\n\"enrichments\": [\n{\n\"source_field\": \"text\",\n\"destination_field\": \"enriched_text\",", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-integrating-with-wks"}, {"document_id": "ibmcld_05256-7949-9726", "score": 0.5735321044921875, "text": "\nNote that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n\nYes! [Here is how](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n\nYes, you can edit the existing [IAM policy of the service ID](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace. Before you can customize registry IAM policies, you must [enable IBM Cloud IAM policies for IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-user).\n\nCan I use a service ID?\n: Yes, you can create a service ID and assign authorities to it. Note that service IDs are also automatically created by the Code Engine UI when you automatically create access to your IBM Cloud Container Registry. DO NOT delete this service ID as you will lose access to the images in the registry.\n\nCan I access images in a different registry?\n: Yes! [Here is how](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryimages-different-account).\n\nCan I restrict pull access to a certain regional registry or even a single namespace?\n: Yes, you can edit the existing [IAM policy of the service ID](https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registryauthorize-cr-service-id) that restricts the Reader service access role to that regional registry or a registry resource such as a namespace.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry"}, {"document_id": "ibmcld_06885-16589-17887", "score": 0.572833776473999, "text": "\nUse that url to verify that the app is running.\n\n\n\n\n\n Pipeline customization \n\nCustom scripts are extension points in the pipeline where adopters, teams, and users can provide scripts to run custom tasks that are required by their continuous integration and continuous deployment strategies.\n\nCustom scripts control the pipeline stages. You can use a configuration file (pipeline-config.yaml) to configure the behavior of stages, script content, and the base image that runs the scripts. The scripts and configuration for pipeline stages are loaded from a Git repository (repo) that can either be the application (app) repo (similar to .travis.yml or Jenkinsfile) or a custom repo.\n\nMore detailed information on customizing the CI pipelines can be found [here](https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts).\n\n\n\n\n\n Wrapping up \n\nBy completing the CI part of this tutorial, you:\n\n\n\n* Created a DevSecOps CI toolchain\n* Modified some code in the application repository\n* Ran the ci-pr pipeline before you merge your changes\n* Ran the ci-pipeline to build, test, and deploy your changes to your dev environment.\n\n\n\n\n\n\n\n\n\n Next steps \n\nContinue to [Part 3: Set up a Continuous Deployment (CD) toolchain](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-cd-toolchain).", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-ci-toolchain"}, {"document_id": "ibmcld_09896-3915-4600", "score": 0.561854362487793, "text": "\n\"features\": {\n\"categories\": {\n\"model\": \"your-model-id-here\"\n}\n}\n}\n* Example cURL request:\n\ncurl --request POST --header \"Content-Type: application/json\" --user \"apikey\":\"{apikey}\" \"{url}/v1/analyze?version=2021-02-16\" --data @parameters.json\n\n\n\n\n\n\n\n Deleting a custom categories model \n\nTo delete a categories model from your service instance, use the Delete categories model method. Replace {url} and {apikey} with your service URL and API key, and replace {model_id} with the model ID of the model you want to delete.\n\n\n\n* The following example undeploys a categories model.\n\ncurl --user \"apikey\":\"{apikey}\" \"{url}/v1/models/categories/{model_id}?version=2021-02-16\" --request DELETE", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-categories"}, {"document_id": "ibmcld_09902-1273-2070", "score": 0.5592490434646606, "text": "\n* Example parameters.json file:\n\n{\n\"url\": \"www.url.example\",\n\"features\": {\n\"entities\": {\n\"model\": \"your-model-id-here\"\n},\n\"relations\": {\n\"model\": \"your-model-id-here\"\n}\n}\n}\n* Example curl request:\n\ncurl --user \"apikey\":\"{apikey}\" \"{url}/v1/analyze?version={date}\" --request POST --header \"Content-Type: application/json\" --data @parameters.json\n\n\n\n\n\n\n\n Deleting custom entities and relations models \n\nTo delete an entities or relations model from your service instance, use the Delete model method. Replace {url} and {apikey} with your service URL and API key, and replace {model_id} with the model ID of the model you want to delete.\n\n\n\n* The following example undeploys an entities or relations model.\n\ncurl --user \"apikey\":\"{apikey}\" \"{url}/v1/models/{model_id}?version={date}\"\n--request DELETE", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entities-and-relations"}, {"document_id": "ibmcld_08111-18275-20054", "score": 0.5576812028884888, "text": "\n* Your public IP address.\n* Your local machine type, for example, Windows, Linux, or Mac\n* A prefix to use for your resources so that you can easily identify them.\n* The region the resources are created in. For example, us-south-1, or br-sao.\n* For each server, Bastion, app, web, db, you enter the:\n\n\n\n* Custom image ID for the server. Images are region-specific. To find the image IDs for your region, open the IBM Cloud shell and enter ibmcloud target -r < region_name > to set your region, then ibmcloud is images to see a list of images for that region.\n* OS image to use, either Windows or Linux.\n* The CPU percentage for the App Instance Group\n* The minimum number of servers to have in the App Instance Group for Auto scale.\n* The maximum number of server to have in the App Instance Group for Auto scale.\n* The bandwidth per second in GB.\n* The VSI spread strategy for the db server (host or power spread) for anti-affinity. Power spread is recommended here.\n* The VSI spread strategy for the web and app servers (host or power spread) for anti-affinity. Host spread is recommended here if more than 4 are created for each server type.\n\n\n\n\n\n5. If you are using DBaas, modify the user_input.auto.tfvars file in the root level folder. You must enter:\n\n\n\n* enable_dbaas - set to true\n* Admin password - minimum 10 characters, A-Z, a-z, 0-9\n* The DB endpoint access - either 'private', 'public' or 'public-and-private' (for mysql databases)\n* Whether to enable auto-scaling in DBaaS - true or false\n\n\n\n6. If you are using DBaaS, you can modify the optional parameters in the root level db_variables.tf file. These variables are set to defaults and can be modified to match your solution.\n7. Initialize the Terraform CLI.\n\nterraform init\n8. Create a Terraform execution plan.", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-create-three-tier-resilient-vpc-mzr-modular"}, {"document_id": "ibmcld_03891-12932-14810", "score": 0.5528502464294434, "text": "\n[Add another node](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/addremove_addnode.png)\n\nFigure 5. Add another node\n\nYou will need to:\n\n\n\n* Give the node a display name. A best practice will be to give the node a display name that matches the pattern used for the other nodes in the ordering service. By default, nodes are given the name <name of ordering service>_1, <name of ordering service>_2, and so on.\n* Select a CA. This should be the CA used to create your MSP.\n* Enter an enroll ID and secret. Again, if you created an enroll ID and secret for your existing ordering nodes, you may use the same enroll ID and secret here.\n* Select an MSP. If you are adding to an ordering service you created in your console, reuse the MSP you used when creating that ordering service. If the new node is being added to an ordering service created elsewhere, use the MSP you exported to that console.\n* Choose a Fabric version for the new node. Note that this must be the same Fabric version used by the other nodes in the ordering service. If you choose a different Fabric version, the new node will be unable to join the consenter set.\n* Associate identity. You will only have to associate an identity if you are using a different MSP from the MSP that was originally used when creating the ordering service.\n\n\n\nThe TLS Certificate Signing Request (CSR) hostname is an option available to advanced users who to want specify a custom domain name that can be used to address the ordering service endpoint. Custom domain names are not a part of this tutorial, so leave the TLS CSR hostname blank for now.\n\nTask: Create an ordering service\n\n\n\nTable 2. Create an ordering service\n\n Display name MSP ID Enroll ID Secret Version \n\n Add another node Ordering Service_2 \n CA Ordering Service2 CA \n Ordering Service Identity OS2 OS2pw", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-add-remove-orderer"}, {"document_id": "ibmcld_13880-16435-16974", "score": 0.5507300496101379, "text": "\n* Use social identity providers.\n* Add a date picker to the statistics page to filter displayed data.\n* Use a custom login page for App ID.\n\n\n\n\n\n\n\n Related Content \n\nHere are links to additional information on the topics covered in this tutorial. The app itself is available in this [GitHub repository](https://github.com/IBM-Cloud/github-traffic-stats).\n\nDocumentation:\n\n\n\n* [App ID documentation](https://cloud.ibm.com/docs/appid?topic=appid-getting-started)\n* [Db2 on Cloud](https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-about)", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-serverless-github-traffic-analytics"}, {"document_id": "ibmcld_07380-4-1902", "score": 0.5496073365211487, "text": "\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Updating custom resolver locations \n\nYou can update custom resolver locations in IBM Cloud\u00ae DNS Services by using the UI, CLI, or API.\n\n\n\n Updating a resolver location using the UI \n\nFrom the custom resolver details page, select the Resolver locations tab. Here you can enable or disable your custom resolver by setting the toggle switch. Change the priority of your resolver location by clicking the up or down arrows to alter the priority order of the list.\n\nWhen the resolver location is disabled, the Subnet column changes to a list menu from which you can select a different subnet for your resolver location. When the resolver location is enabled, the Subnets column becomes static.\n\n\n\n\n\n Updating a resolver location using the CLI \n\nTo update a resolver location using the CLI, run the following command:\n\nibmcloud dns custom-resolver-location-update RESOLVER_ID LOCATION_ID [--subnet SUBNET_CRN] [--enabled true|false] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* RESOLVER_ID is the ID of custom resolver.\n* LOCATION_ID is the ID of the custom resolver location.\n* --subnet is the CRN of the subnet.\n* --enabled determines whether to enable the custom resolver location.\n* -i, --instance is the instance name or ID. If this is not set, the context instance specified by dns instance-target INSTANCE is used instead.\n* --output specifies output format. Currently, JSON is the only supported format.\n\n\n\n\n\n\n\n Adding a resolver location using the API \n\nTo update a custom resolver location using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store the following values in variables to be used in the API command:\n\n\n\n* instance_id, which is the unique identifier of a service instance.\n* resolver_id, which is the unique identifier of a custom resolver.\n* location_id, which is the custom resolver location ID.", "title": "", "source": "https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-cr-res-loc-update"}, {"document_id": "ibmcld_01595-17454-18582", "score": 0.5480389595031738, "text": "\nFor more details on on using these forums, check the [Getting help page here](https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportusing-avatar).\n\nFor information about opening an IBM support ticket, or about support levels and ticket severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severitysupport-case-severity).\n\nPlease provide as much of the following information as possible when submitting a ticket:\n\n\n\n* What OS is the client running on?\n* What version of the client is being used (this can be found using the 'C' command on the client)?\n* If this is a UI issue, paste or attach any associated browser console logs and screenshots\n* Paste or attach any associated requesting application logs and timezone\n* Paste or attach any associated Secure Gateway Client logs and timezone\n* Provide the details of the destination being used (either a screenshot or fill out the fields below):\n\n\n\n* Destination ID\n* Protocol\n* Destination-side Authentication\n* Uploaded certificates (just names and which Box folder or link they were uploaded to)", "title": "", "source": "https://cloud.ibm.com/docs/SecureGateway?topic=SecureGateway-troubleshooting"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16288-1733-3996", "score": 0.6416411399841309, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16291-1353-3298", "score": 0.6254798173904419, "text": "\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}, {"document_id": "ibmcld_03158-8929-11062", "score": 0.6200247406959534, "text": "\nFor more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16294-6972-8764", "score": 0.6124680042266846, "text": "\n7. Return to the SMS with IntelePeer integration setup page. Click Next to go to Step 1 of your SMS with IntelePeer integration setup.\n8. Enter your Account Secret information. Click Next to go to Step 2 of your SMS with IntelePeer integration setup.\n9. Enter your Auth token information. Click Next to go to Step 3 of your SMS with IntelePeer integration setup.\n10. Optional: Enter the phone number that your Intelepeer account uses for SMS integration. The webhook URI is used to transfer messages, but if you add your phone number in this optional field, you can easily refer to it later. Click Next to go to Step 4 of your SMS with IntelePeer integration setup.\n11. Copy the value from the Webhook URI field.\n\nYou will add this URI to the webhook configuration in IntelePeer. If you want to support more than one phone number, you must add the URI to the webhook for each phone number separately.\n12. Go to your [IntelePeer Customer Portal](https://customer.intelepeer.com/) site, under the My Applications section, select SMS API Management.\n13. Go to the phone number(s) you want to enable for SMS. Toggle the Enabled/Disabled radial button beside the number and set it to Enabled. It may take a few minutes for the phone number to become activated for SMS.\n14. Once the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_16291-7-1781", "score": 0.6113919019699097, "text": "\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https://www.nice.com/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https://help.nice-incontact.com/content/resources/images/icons/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}, {"document_id": "ibmcld_16288-7-2218", "score": 0.6088804006576538, "text": "\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16294-4288-5934", "score": 0.6078246831893921, "text": "\nScroll to the Messaging section, and then find the Webhook field that defines what to do when A message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n14. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n15. Click Save.\n16. From the Develop tab in the sidebar, click Messaging > Settings > Geo permissions. If Messaging is not present, go to the Search Bar at the top and search for 'Messaging', then select SMS Geographic Permissions.\n17. From the Messaging Geographic Permissions page, select the country codes of the phone numbers that can text your Twilio number. By default, no country codes are allowed to text your Twilio number.\n18. Return to the SMS with Twilio integration setup page. Click Finish.\n\n\n\n\n\n\n\n\n\n Integrating with SMS with IntelePeer \n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up an SMS with IntelePeer account and get a phone number.\n\n\n\n1. Go to the [IntelePeer website](https://www.intelepeer.com/).\n2. Create an account or start a free trial.\n\nWhen you get an IntelePeer phone number, it supports voice and SMS. If the number is not automatically enabled for SMS, you will need to enable it manually. Your new phone number is listed as an active number. Refer to the [Atmosphere Messaging Quick Start Guide](https://docs.intelepeer.com/atmosphere/Content/Atmosphere-SMS-Messaging/Atmosphere-SMS-Messaging-Quick-Start-Guide.htm)\n\n\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. Go to the Integrations page by clicking the integrations icon (!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_16287-1442-3506", "score": 0.6053651571273804, "text": "\nThe trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.\n\nDepending on the architecture of your existing telephony infrastructure, there are multiple ways you might integrate it with Watson Assistant. For more information about common integration patterns, read the blog post [Hey Watson, can I have your number?](https://medium.com/ibm-watson/hey-watson-can-i-have-your-number-7de8fc7621ed) on Medium.\n\n\n\n Set up the integration \n\nYou must have Manager role access to the instance and Viewer role access to the resource group to complete setup. For more information about access levels, see [Managing access](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-access-control).\n\nTo set up the integration:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Choose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16289-2888-4673", "score": 0.6049298048019409, "text": "\nYou will need this value in a subsequent step.\n\n\n\n\n\n\n\n Configuring the phone number \n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say/Play widget onto your flow canvas.\n2. Configure the Say/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex"}, {"document_id": "ibmcld_16288-4884-6869", "score": 0.6016088128089905, "text": "\n\"assistant_phone_number\":\"+18882346789\",\n\"sip_custom_invite_headers\": {\n\"X-customer-name\": \"my_name\",\n\"X-account-number\": \"12345\"\n}\n}\n}\n}\n}\nShow more\n\nYou can then reference these headers in your assistant. For example, you might check the header value in a step condition to determine the next step. You can also use these headers when searching the assistant logs; for example, you might search for a custom header to find all the messages associated with particular account.\n* Disable the ring that callers will hear while the assistant is contacted: Choose whether you want the caller to hear a signal that indicates that the assistant is being contacted.\n\nA 180 Ringing response is sent from the assistant back to the SIP trunk provider while your assistant processes the incoming call invitation. The ringing response is sent by default.\n* Don't place callers on hold while transferring to a live agent: Choose whether the phone integration puts the caller on hold.\n\nIf your SIP trunk provider manages holds, disable this feature. For example, some SIP trunk providers prefer to have the assistant send a SIP REFER request, so they can put the call on hold themselves.\n\n\n\nFor more information about the SIP protocol, see [RFC 3261](https://tools.ietf.org/html/rfc3261) and about the RTP protocol, see [RFC 3550](https://tools.ietf.org/html/rfc3550).\n\n\n\n\n\n Configuring backup call center support \n\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16288-1733-3996", "score": 0.6194952130317688, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03158-8929-11062", "score": 0.6104801893234253, "text": "\nFor more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16289-2888-4673", "score": 0.6052240133285522, "text": "\nYou will need this value in a subsequent step.\n\n\n\n\n\n\n\n Configuring the phone number \n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say/Play widget onto your flow canvas.\n2. Configure the Say/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex"}, {"document_id": "ibmcld_16321-7-1807", "score": 0.6041388511657715, "text": "\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16321-1374-3426", "score": 0.6018548011779785, "text": "\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16288-6287-8401", "score": 0.6007722020149231, "text": "\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03160-2884-4664", "score": 0.5972902774810791, "text": "\nIn the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say/Play widget onto your flow canvas.\n2. Configure the Say/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Services.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-flex"}, {"document_id": "ibmcld_03369-20825-22706", "score": 0.5951470136642456, "text": "\nIf you would like to send us feedback on the new experience, please use [this form](https://form.asana.com/?k=vvRdQAmGMFAeEGRryhTA2w&d=8612789739828).\n\n\n\n\n\n 4 February 2022 \n\nFuzzy matching updates\n: Interactions between the stemming and misspelling fuzzy matching features are not allowed. Improve fuzzy matching behavior by limiting the interactions between different fuzzy matching features. This change applies to the following languages: English, French, German, and Czech. For more information, see [How fuzzy matching works](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-fuzzy-matching).\n\n\n\n\n\n 13 January 2022 \n\nNew setting for options customer response type\n: In actions, a new List options setting allows you to enable or disable the options customer response from appearing in a list. This can be useful to prevent a phone integration from reading a long list of options to the customer. As part of this change, all customer response types now have a Settings icon. Allow skipping has moved from Edit Response and is now found in the new settings.\n\n\n\n\n\n 24 December 2021 \n\nApache Log4j security vulnerability updates\n: Watson Assistant upgraded to using Log4j version 2.17.0, which addresses all of the Critical severity and High severity Log4j CVEs, specifically CVE-2021-45105, CVE-2021-45046, and CVE-2021-44228.\n\n\n\n\n\n 10 December 2021 \n\nChannel transfer in Phone integration\n: The phone integration now supports the channel_transfer response type. For more information, see [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16288-7-2218", "score": 0.5923668146133423, "text": "\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03369-31953-34073", "score": 0.5825196504592896, "text": "\nDeploy your assistant on the phone in minutes\n: We have partnered with [IntelePeer](https://intelepeer.com/) to enable you to generate a phone number for free within the phone integration. Simply choose to generate a free number when following the prompts to create a phone integration, finish the setup, and a number is assigned to your assistant. These numbers are robust and ready for production.\n\nConnect to your existing service desks\n: We have added step-by-step documentation for connecting to [Genesys](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled.\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16287-7751-9832", "score": 0.7027895450592041, "text": "\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_03165-4477-6547", "score": 0.6597449779510498, "text": "\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https://community.ibm.com/community/user/watsonapps/viewdocument/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-sms"}, {"document_id": "ibmcld_16287-4493-6675", "score": 0.655129611492157, "text": "\nOn the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n9. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.\n\nIf you created specialized custom models that you want your assistant to use, choose the Speech to Text service instance that hosts the custom models now, and you can configure your assistant to use them later. The Speech to Text service instance must be hosted in the same location as your Watson Assistant service instance. For more information, see [Using a custom language model](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-custom-language).\n\nFor more information about language models, see [Languages and models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models) in the Speech to Text documentation.\n\nClick Next.\n10. On the Text to Speech page, select the instance of the Text to Speech service you want to use for the phone integration.\n\n\n\n* If you have existing Text to Speech instances, select the instance you want to use from the list.\n* If you do not have any existing Text to Speech instances, click Create new instance to create a new Standard instance.\n\n\n\n11.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16294-8240-10414", "score": 0.6504716873168945, "text": "\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https://www.twilio.com/docs/sms/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_16289-2888-4673", "score": 0.6420162916183472, "text": "\nYou will need this value in a subsequent step.\n\n\n\n\n\n\n\n Configuring the phone number \n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say/Play widget onto your flow canvas.\n2. Configure the Say/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex"}, {"document_id": "ibmcld_16321-35490-37376", "score": 0.6391007900238037, "text": "\nIf no tenantPhoneNumber value is provided, the tenant ID from the phone integration configuration for the active call is used. Optional. \n userPhoneNumber string The phone number to send the SMS message to. The format of the number must match the format that is required by the SMS provider. If no userPhoneNumber value is provided, the voice caller's phone number from From header of the incoming SIP INVITE request is used. Optional. \n\n\n\nIf your SMS integration supports more than one SMS phone number, or you are using a SIP trunk different from your SMS provider, be sure to specify the phone number that you want to use to send the text message. Otherwise, the text is sent using the same phone number that was called.\n\nAfter the assistant receives an SMS message, a new conversation turn is initiated with the text input vgwSMSMessage. This input indicates that a message was received from the caller. The text of the customer's message is included as the value of the vgwSMSMessagecontext variable.\n\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your assistant to handle such a failure by creating actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16294-4288-5934", "score": 0.6341840028762817, "text": "\nScroll to the Messaging section, and then find the Webhook field that defines what to do when A message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n14. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n15. Click Save.\n16. From the Develop tab in the sidebar, click Messaging > Settings > Geo permissions. If Messaging is not present, go to the Search Bar at the top and search for 'Messaging', then select SMS Geographic Permissions.\n17. From the Messaging Geographic Permissions page, select the country codes of the phone numbers that can text your Twilio number. By default, no country codes are allowed to text your Twilio number.\n18. Return to the SMS with Twilio integration setup page. Click Finish.\n\n\n\n\n\n\n\n\n\n Integrating with SMS with IntelePeer \n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up an SMS with IntelePeer account and get a phone number.\n\n\n\n1. Go to the [IntelePeer website](https://www.intelepeer.com/).\n2. Create an account or start a free trial.\n\nWhen you get an IntelePeer phone number, it supports voice and SMS. If the number is not automatically enabled for SMS, you will need to enable it manually. Your new phone number is listed as an active number. Refer to the [Atmosphere Messaging Quick Start Guide](https://docs.intelepeer.com/atmosphere/Content/Atmosphere-SMS-Messaging/Atmosphere-SMS-Messaging-Quick-Start-Guide.htm)\n\n\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. Go to the Integrations page by clicking the integrations icon (!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_03179-1292-3261", "score": 0.6265343427658081, "text": "\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https://business.facebook.com/overview) website, and click Create account and follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https://business.facebook.com/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https://www.twilio.com/whatsapp/request-access) web page.\n\nTips for specifying the following values:\n\n\n\n* Phone Number: Specify the Twilio phone number that you created earlier.\n\nConsider provisioning more than one phone number and going through the process of getting permission for the numbers in parallel. If your number was used by a different business previously (because Twilio assigned you a number that was used before, for example), WhatsApp will reject it.\n* Are you working with an ISV: No\n* Twilio Account SID: From the Twilio site, click the home icon to go to your project dashboard to find the SID.\n* Facebook Business Manager ID: Add the ID for the account that you created in the previous step.\n\n\n\n4. Click Request Now.\n\n\n\nGive WhatsApp time to evaluate and approve your request. It can take up to 7 days for your request to be approved.\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-whatsapp"}, {"document_id": "ibmcld_03158-2940-4987", "score": 0.6265124082565308, "text": "\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16290-6035-7786", "score": 0.6231380105018616, "text": "\nSelect Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent \n\nNow that your Genesys Cloud environment can connect to Watson Assistant, you can set up the ability for your assistant to transfer calls back to your live agents. To do so, follow these steps:\n\n\n\n1. In the Genesys Cloud console, go to DID Numbers -> DID Ranges and create a new range. Specify the following information:\n\n\n\n* In the DID Start and DID End fields, specify a phone number. (Once again, you do not need to use a real phone number; you can just make up an identifier for your Genesys environment, such as 1-888-888-1234.)\n\n\n\n![Genesys create range](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/phone-genesys-create-range.png)\n\n\n\n* In the Service Provider field, type a descriptive name (for example, Watson).\n\n\n\n2. If you have not already set up a queue to enable callers to wait for available agents, follow these steps to create a simple one now:\n\n\n\n1. Click Admin.\n2. Under Contact Center, click Queues.\n3. Create a new queue and give it a descriptive name.\n4. Add yourself as a member.\n5. Click Save.\n\n\n\n3. Create a simple call flow. Your business might already have something more complex for routing.\n\n\n\n1. Click Admin.\n2. Click Architect.\n3. In the Flows: Inbound Call section, click + to create a new flow.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-genesys"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16321-19290-20983", "score": 0.659983217716217, "text": "\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16288-10521-12298", "score": 0.61151123046875, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https://support.twilio.com/hc/en-us/articles/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16321-17031-18399", "score": 0.6025445461273193, "text": "\nThe following example shows a transfer that uses all of the configurable parameters:\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_headers\":\n{\n\"name\": \"Customer-Header1\",\n\"value\": \"Some-Custom-Info\"\n},\n{\n\"name\": \"User-to-User\",\n\"value\": \"XXXXXX\"\n}\n],\n\"transfer_headers_send_method\": \"refer_to_header\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"I'll transfer you to an agent\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\nThe connect_to_agent response type supports the following phone-specific properties.\n\n\n\n Parameter Default Description \n\n service_desk.sip.uri N/A The SIP or telephone URI to transfer the call to, such as sip:12345556789@myhost.com or tel:+18883334444. Optional when using the hangup method. \n service_desk.sip.transfer_method refer Determines how to transfer the call:<br><br><br><br> * refer: The call is transferred by sending a SIP REFER request. This is the default value.<br> * hangup: The call is transferred by sending a SIP BYE request.<br><br><br> \n service_desk.sip.transfer_target_header Transfer-Target The SIP header that contains the transfer target when a BYE request is used for transferring the call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_08091-5945-8032", "score": 0.5931764841079712, "text": "\nFor more information, see [Case severity and initial response times](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases. These services are in a trial stage of development and they aren't production-ready. A beta release helps IBM development and marketing teams to assess the value of the service in the market. This assessment enables teams to make updates before the service is released as a GA service or container image.\n\nIf the root cause analysis determines the issue is a defect in the beta service or container image, IBM isn't required to provide a fix. Additionally, the case is assigned the appropriate 3 or 4 severity level.\n\n\n\n\n\n Third-party services \n\nThird-party services are provided by vendors outside of IBM. These services are provided by individual software entities, IBM Business Partners, or independent software vendors (ISV).\n\nSupport for third-party services is provided by the service provider. This includes third-party products that are deployed by using the IBM Cloud Provider Plug-in for Terraform. If the root cause analysis determines that the issue is a defect in a third-party service, IBM isn't required to provide a fix. However, IBM shares analysis with the third-party service provider, if needed, and can work through Marketplace with the third-party service to help solve the issue.\n\n\n\n\n\n Open source or community service \n\nOpen source or community services are provided by open source communities outside of IBM.\n\nIf the root cause analysis determines that the issue is a defect in an open source or community service, IBM isn't required to provide a fix. IBM closes the case and refers you to the community or forum for assistance. You can get community assistance for technical issues through [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar&interface=ui"}, {"document_id": "ibmcld_16321-17975-19755", "score": 0.5901294350624084, "text": "\nservice_desk.sip.transfer_method refer Determines how to transfer the call:<br><br><br><br> * refer: The call is transferred by sending a SIP REFER request. This is the default value.<br> * hangup: The call is transferred by sending a SIP BYE request.<br><br><br> \n service_desk.sip.transfer_target_header Transfer-Target The SIP header that contains the transfer target when a BYE request is used for transferring the call. This option is supported only in the hangup method. \n service_desk.sip.transfer_headers N/A A list of custom header field name/value pairs to be added to a transfer request \n service_desk.sip.transfer_headers_send_method custom_header The method by which the SIP transfer headers are sent:<br><br><br><br> * custom_header: Sends the transfer headers as part of the SIP message. This is the default value.<br> * contact_header: Sends the transfer headers in the Contact header. This option is not supported in the hangup method.<br> * refer_to_header: Sends the transfer headers in the Refer-To header. This option is not supported in the hangup method.<br><br><br> \n\n\n\nIf you define a SIP URI as the transfer target, escape the at sign (@) in the URI by adding two backslashes (\\) in front of it. This is to prevent the string from being recognized as part of the entity shorthand syntax.\n\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_04617-1524-2696", "score": 0.5876379013061523, "text": "\nUpdates to these buildpacks will be made when IBM Cloud is upgraded to a new version of Cloud Foundry. Problems or issues with these runtimes on IBM Cloud can be reported to IBM, and we will assist in determining if IBM Cloud is the source of the problem. For issues that are related to IBM Cloud, IBM will provide a fix; however, for defects in the buildpack or runtime itself, IBM will assist in reporting them to the appropriate community. IBM will not provide fixes for these buildpacks and runtimes.\n\n\n\n\n\n External buildpacks \n\nFor external buildpacks, support will not be provided by IBM. You might need to contact the Cloud Foundry Community for support.\n\n\n\n\n\n Third-party services \n\nThe buildpacks enable you to use some third-party services, such as Dynatrace or New Relic, within your apps. IBM does not provide support for third-party services. For information about using third-party services in IBM Cloud\u00ae, see the information about the service you want to use in the latest [IBM Cloud\u00ae Service terms](https://www-03.ibm.com/software/sla/sladb.nsf/sla/bm). Before you use a third-party service, also review the licensing information from the service provider.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-buildpack_support_statement"}, {"document_id": "ibmcld_03158-17978-19852", "score": 0.5848984718322754, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https://cloud.ibm.com/unifiedsupport/cases/form).\n2. Click Customer success as the case type.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_12789-1513-3693", "score": 0.5765127539634705, "text": "\nThird-party services that offer paid usage-based pricing plans receive disbursements through an Electronic Funds Transfer (EFT). To set up this method to receive disbursements in IBM Cloud Partner Center Sell, you must submit the EFT form when you set up your first usage-based pricing plan. You can download the form from the Payments to me page.\n\n\n\n\n\n When are disbursements sent to me? \n\nIf any disbursements are due to a third-party provider, they are sent on the last business day of the second calendar month. For example, March activity would be paid on the last calendar day of May, unless the last day of the month falls on a weekend or holiday. In this case, disbursements are sent on the next business day. Disbursements are calculated from beginning of the month to the end of the month.\n\n\n\n\n\n What is the fee structure? \n\nDisbursements are paid against revenue recognized by IBM\u00ae in a royalty month. IBM pays a third-party provider for each sale of a product as follows:\n\n\n\n* As-a-service products: 87% of net revenue\n* Software products: 80% of net revenue\n\n\n\n\n\n\n\n Can a third-party provider run activity reports and payout reconciliations? \n\nWe are adding features to support reports in the near future. Disbursements are based on the quantities that you submit to the usage metering service and the price that is defined when you set up your pricing plan in Partner Center. Third-party disbursements are calculated as a percentage of the net revenue for each product sold by IBM for a given calendar month. Net revenue is defined as the revenue recognized by IBM or an IBM affiliate calculated using applicable discounts, refunds, returns, offsets, and other adjustments determined in accordance with the current revenue recognition policies of IBM and its affiliates and the controlling accounting principles. For full detail regarding payouts, refer to the Digital Platform Reseller Agreement that must be signed in Partner Center to offer usage-based pricing.\n\n\n\n\n\n How can I generate a new IBM Cloud Identity and Access Management API Key? \n\nYou're given your API Key when you enable IAM. It is critical that you save the API Key. The value is not shown again.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-3p-faqs"}, {"document_id": "ibmcld_14309-4212-6111", "score": 0.572648823261261, "text": "\n[Deploying third-party router or firewall in converged or management clusters](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-nsx-t-3rd-party.svg)\n\nFigure 2. Deploying third-party router or firewall in converged or management clusters\n\nThis architecture pattern deployment is summarized as follows:\n\n\n\n1. Depending on the network preference selection, your vCenter Server instance is deployed with both public and private connectivity or private connectivity only.\n2. You can optionally deploy a gateway cluster to host Juniper vSRX or your own routing or firewall device. In this case, you might put public and private VLANs behind the firewall.\n3. You can deploy third-party network devices into vCenter Server clusters by bringing in your own license and following the hardware and software guidance as provided by the specific third-party vendor. Discuss the technical details with the vendor.\n4. You can integrate the third-party network device or a router into using service insertion. With service insertion, you can apply third-party services to north-south traffic as well as east-west traffic that passes through a router. The services typically provide advanced security features, such as an intrusion detection system (IDS) or an intrusion prevention system (IPS).\n5. When you use service insertion and after, deploy a service instance, you can configure the type of traffic that the router redirects to the service. Configuring traffic redirection is similar to configuring a firewall.\n6. Alternatively, you can add the device into north-south traffic path and customize the NSX-T customer topology. Contact your third-party vendor to discuss the wanted network topology, for example, router mode versus transparent.\n\n\n\nThe following diagram presents the routing topology and routing for this pattern.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-3rd-party-router"}, {"document_id": "ibmcld_12867-4-1990", "score": 0.5716952085494995, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Defining your support experience \n\nMaking sure that your users understand how to get help and support for your product is key. Defining your support experience includes providing details about how users can contact your support team and escalate issues. To define your product's support experience, you need to select the type of support that is provided, add support details, and then provide information about how users can escalate support cases.\n\n\n\n Selecting your product's support provider \n\nSelect your product's support provider to add the necessary details that are associated with the third-party or community provider types.\n\nThird-party products\n: Provided by individual service entities, IBM Business Partners, or independent service vendors (ISV). Support for third-party products is provided by the third-party provider. If the root cause analysis determines that the issue is a defect in a third-party product, IBM Cloud isn't required to provide a fix. However, IBM Cloud shares analysis with the third-party provider, if needed, and can work with the third-party provider to help solve the issue.\n\nCommunity products\n: Provided by open source communities. If a root cause analysis determines that a support issue is a defect in an open source or community product, IBM Cloud isn't required to provide a fix. IBM Cloud closes the case and refers users to the community or forum for assistance. Users can get community assistance for technical issues through [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud).\n\nUse the following steps to select your product's support provider.\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My Products.\n2. Select the product that you're onboarding, and click Support.\n3. Select your product's support provider.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-sw-support-details"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14105-0-1469", "score": 0.6274504661560059, "text": "\n\n\n\n\n\n\n  Differences between versions of XenServer \n\nLicensing is the only difference between versions of XenServer that are installed on the system. If you want to upgrade your license to a higher class license after installation, you experience no downtime to reinstall your server. Contact IBM Cloud\u00ae sales for pricing information.\n\nNote: Not all available features are supported.\n\nThe following lists of features are included for each of the different licenses that are offered (as of XenServer 6.0):\n\nXenServer free, advanced, enterprise license features\n\n\n\n*  XenServer Hypervisor\n*  Conversion Tools\n*  Management integration with Microsoft System Center VMM\n*  Resilient distributed management architecture\n*  VM disk snapshot and revert\n*  XenCenter Management Console\n*  XenMotion Live Migration\n\n\n\nXenServer advanced and enterprise license features\n\n\n\n*  Automated VM protection and recovery (Automated VM protection and recovery is only available for the Advanced and Enterprise editions in the 6.0 release and later.)\n*  Distributed virtual switching\n*  Heterogeneous Pools\n*  High Availability\n*  Memory Optimization\n*  Performance alerting and reporting\n\n\n\nXenServer Enterprise license features\n\n\n\n*  Dynamic workload balancing\n*  GPU pass-thru\n*  Host power management\n*  IntelliCache\n*  Live memory snapshot and revert\n*  Provisioning Services (virtual)\n*  Role-based administration\n*  StorageLink\n*  Web management console with delegated admin\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-differences-between-versions-of-xenserver"}, {"document_id": "ibmcld_00482-7060-8729", "score": 0.6095803380012512, "text": "\nThis retrieval gives you a current version of the document that you store, and a list of all the other conflicting documents that must also be retrieved, for example ...rev=2-61ae00e029d4f5edd2981841243ded13 and ...rev=1-7438df87b632b312c53a08361a7c3299. Each of these other conflicting versions is also retrieved and stored, for example:\n\nhttps://$ACCOUNT.cloudant.com/products/$_ID?rev=2-61ae00e029d4f5edd2981841243ded13https://$ACCOUNT.cloudant.com/products/$_ID?rev=1-7438df87b632b312c53a08361a7c3299\n\nOnce you have all of the conflicting revisions of a document available, you can resolve the conflicts.\n\nIn an earlier scenario, the differences between the versions of the document were for different fields within the document, making it easier to merge them.\n\nMore complicated conflicts are likely to require correspondingly more analysis. To help, you might choose from various conflict resolution strategies, such as:\n\n\n\n* Time based - uses a simple test of the first or most recent edit.\n* User assessment - the conflicts are reported to users, who then decide on the best resolution.\n* Sophisticated merging algorithms - often used with [version control systems](https://en.wikipedia.org/wiki/Merge_%28version_control%29). An example is the [3-way merge](https://en.wikipedia.org/wiki/Merge_%28version_control%29Three-way_merge).\n\n\n\nFor a practical example of how to implement these changes, see [this project with sample code](https://github.com/glynnbird/deconflict).\n\n\n\n\n\n Upload the new revision \n\nSee the following final revisions after you resolve and merge changes from the previous conflicting revisions:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-conflicts"}, {"document_id": "ibmcld_06941-0-1401", "score": 0.6011120080947876, "text": "\n\n\n\n\n\n\n  Migration FAQ \n\nFind answers to questions that are commonly asked about migrating from Discovery v1 to v2.\n\nDo the two versions have all the same features?\n:   There are many feature differences between the two versions. For a full feature comparison, see [Getting the most from Discovery](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nHow do I know which version I'm using now?\n:   When you open the product user interface in v2, the following page is displayed:\n\nZoom\n\n![Shows the main My Projects page with a single Sample Project tile.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/gs-home-page.png)\n\nFigure 1. Home page from the Sample Project\n\nHow long will the migration take?\n:   The time you need to set aside for the migration differs based on the amount of data you want to retain in your existing v1 service instance.\n\nDo I need to update my existing applications for them to work with v2?\n:   Yes. You will need to edit any existing applications to account for changes that are introduced with Discovery v2. For more information, see the [API version comparison](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\nTo get started, see [Migrating to Discovery v2](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data--migration-faq"}, {"document_id": "ibmcld_05873-80552-82182", "score": 0.5981721878051758, "text": "\n* [CVE-2020-1752](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https://istio.io/latest/news/security/istio-security-2020-008/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https://istio.io/latest/news/releases/1.6.x/announcing-1.6/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_12897-4335-5761", "score": 0.5931748747825623, "text": "\n\"_rev\": \"2-61ae00e029d4f5edd2981841243ded13\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"Latest smartphone from Samsung\",\n\"price\": 650\n}\n\nAt the same time, someone else - working with a replicated database - reduces the price.\n\nSee a different revision, conflicting with the previous one because of different price value:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"2-f796915a291b37254f6df8f6f3389121\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"\",\n\"price\": 600\n}\n\nThe two databases are then replicated. The difference in document versions results in a conflict.\n\n\n\n Get conflicting revisions \n\nYou identify documents with conflicts by using the conflicts=true option.\n\nSee the following example of finding documents with conflicts:\n\nhttps://$ACCOUNT.cloudant.com/products/$_ID?conflicts=true\n\nSee the following example response that shows conflicting revisions that affect documents:\n\n{\n\"_id\":\"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\":\"2-f796915a291b37254f6df8f6f3389121\",\n\"name\":\"Samsung Galaxy S4\",\n\"description\":\"\",\n\"price\":600,\n\"_conflicts\":[\"2-61ae00e029d4f5edd2981841243ded13\"]\n}\n\nThe version with the changed price was chosen arbitrarily as the latest version of the document. The conflict with another version is noted by providing the ID of that other version in the _conflicts array. In most cases, this array has only one element, but many conflicting revisions might exist.\n\n\n\n\n\n Merge the changes", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvcc"}, {"document_id": "ibmcld_07578-638952-640633", "score": 0.5900803208351135, "text": "\n\"url\": \"http://xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",\n\"type\": \"terraform_v1.0\"\n}]\n}\n\n\nNo, if the Terraform version is specified in the payload or template, only the version that is specified in versions.tf is considered during provisioning. To consider the current Terraform version, you can configure the required_version parameter as required_version = \">=1.0.0. <2.0\". For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint).\n* Can I specify only the provider version in the version parameter? Or is it mandatory to provide the required_version parameter in the versions.tf file?\n\nYes, you need to specify the version = \"x.x.x\" as it signifies the IBM Cloud provider version. Whereas required_version = \">1.0.0, <2.0\" signifies the Terraform version to provision. For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint). If the version parameter is not declared in your versions.tf file, the current version of the provider plug-in is automatically used in Schematics. For more information, see [Version constraints for the Terraform providers](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintsprovider-version-contraint).\n* What is the difference between delete, and destroy in Schematics?\n\nDestroy delete the associated cloud resource from the workspace. Delete workspace is to used to delete the workspace. The recommendation is to destroy the resource first from the workspace, and then set delete workspace.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-638910-640591", "score": 0.5900803208351135, "text": "\n\"url\": \"http://xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",\n\"type\": \"terraform_v1.0\"\n}]\n}\n\n\nNo, if the Terraform version is specified in the payload or template, only the version that is specified in versions.tf is considered during provisioning. To consider the current Terraform version, you can configure the required_version parameter as required_version = \">=1.0.0. <2.0\". For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint).\n* Can I specify only the provider version in the version parameter? Or is it mandatory to provide the required_version parameter in the versions.tf file?\n\nYes, you need to specify the version = \"x.x.x\" as it signifies the IBM Cloud provider version. Whereas required_version = \">1.0.0, <2.0\" signifies the Terraform version to provision. For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint). If the version parameter is not declared in your versions.tf file, the current version of the provider plug-in is automatically used in Schematics. For more information, see [Version constraints for the Terraform providers](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintsprovider-version-contraint).\n* What is the difference between delete, and destroy in Schematics?\n\nDestroy delete the associated cloud resource from the workspace. Delete workspace is to used to delete the workspace. The recommendation is to destroy the resource first from the workspace, and then set delete workspace.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_04621-100453-102201", "score": 0.5851765275001526, "text": "\n* The buildpack was updated to download the latest 1.x [MariaDB Connector/J JDBC driver](https://mariadb.com/kb/en/about-mariadb-connector-j/) when performing [auto-configuration for MySQL type of services](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-auto_config).\n\n\n\nUpdated Node.js buildpack v3.0-20160125-1224\n: This release is fully synchronized with the [Cloud Foundry community Node.js](https://github.com/cloudfoundry/nodejs-buildpack) buildpack. In addition to community changes, modifications were made to certain defaults, along with optimizations to reduce staging time and updates to the App Management feature.\n\n\n\n* Buildpack updates:\n\n\n\n* Node.js v4.2.4 (IBM SDK for Node.js Version 4) is now the default runtime on IBM Cloud, replacing v0.12.9. This change might cause your app to behave differently if a particular version is not specified for your app. To learn how to specify a version of Node.js for your IBM Cloud app, see [Node.js runtime](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-nodejs_runtime) documentation.\n* NODE_ENV is now set to production by default. This change will cause some node dependencies to behave differently. For example, the Express framework will no longer return stack traces in the web browser for faulty endpoints, but instead displays Internal Server Error. When NPM_CONFIG_PRODUCTION is set to true, NPM will set NODE_ENV to production for subshell scripts in the NPM install phase only. This function allows users to set NODE_ENV to another value like development for app runtime. For clarity, NPM scripts will see the message NODE_ENV=production.\n* A Bug-fix to the Monitoring and Analytics service is included.\n\n\n\n* Caching updates:", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"}, {"document_id": "ibmcld_12095-15701-17402", "score": 0.5848379135131836, "text": "\n\"url\": \"http://xxxxx.git\",\n\"branch\": \"main\"\n},\n\"template_data\": [{\n\"folder\": \"\",\n\"type\": \"terraform_v1.0\"\n}]\n}\n\nShow more\n\nNo, if the Terraform version is specified in the payload or template, only the version that is specified in versions.tf is considered during provisioning. To consider the current Terraform version, you can configure the required_version parameter as required_version = \">=1.0.0. <2.0\". For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint).\n\n\n\n\n\n Can I specify only the provider version in the version parameter? Or is it mandatory to provide the required_version parameter in the versions.tf file? \n\nYes, you need to specify the version = \"x.x.x\" as it signifies the IBM Cloud provider version. Whereas required_version = \">1.0.0, <2.0\" signifies the Terraform version to provision. For more information, see [Version constraints for the Terraform](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintstf-version-constraint). If the version parameter is not declared in your versions.tf file, the current version of the provider plug-in is automatically used in Schematics. For more information, see [Version constraints for the Terraform providers](https://cloud.ibm.com/docs/schematics?topic=schematics-version-constraintsprovider-version-contraint).\n\n\n\n\n\n What is the difference between delete, and destroy in Schematics? \n\nDestroy delete the associated cloud resource from the workspace. Delete workspace is to used to delete the workspace. The recommendation is to destroy the resource first from the workspace, and then set delete workspace.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-general-faq"}, {"document_id": "ibmcld_07067-1816-3544", "score": 0.5769221782684326, "text": "\n* For more information about feature differences, see [the feature comparison table](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-chooseversion-choose-comparison).\n* For more information about detailed API differences, see [API version comparison](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\nDiscovery v2 is available for all users of Plus or Enterprise plan instances, or Premium plan instances that were created after 15 July 2020. v2 is also available for IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data users.\n\n\n\n Migration overview \n\nMigrating from Discovery v1 to v2 is a multistep process that you can do independently.\n\nThe two versions of the Discovery service have many differences, but you can adopt techniques and utilities that were applied to a v1 instance for use with your new v2 instance.\n\nTo migrate from v1 to v2, you must complete the following high-level steps:\n\n\n\n1. [Plan the migration](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-plans).\n2. [Transfer your documents](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-docs).\n3. [Update your application to use the v2 API](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-difs).\n4. Regression test and deploy the updated application.\n5. [Delete your v1 plan service instance](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-delete).\n\n\n\nSome steps require you to make programmatic changes by using the API and others involve changes that you can make from the product user interface.\n\n\n\n\n\n Plan the migration", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13898-1476-2906", "score": 0.6131590604782104, "text": "\n* Showing configuration information\n* Navigating through the configuration hierarchy\n\n\n\nWhen you log on to the system, the system is in operational mode. You must switch to configuration mode for the commands.\n\nYou can tell which mode that you are in based on the prompt. You are in operational mode if the prompt is #, and configuration mode if the prompt is $.\n\nFollow these steps to configure the private VLAN by using the CLI. Remember the values needed to configure the VLAN are:\n\n\n\n* VLAN name of the VLAN to be routed through Brocade 5400 vRouter device (2254)\n* Gateway and mask (CIDR format) of the VLAN to be routed (10.52.69.201/29)\n* Private bond name of the Brocade 5400 vRouter Device (bond0)\n\n\n\n\n\n1. SSH into your Brocade 5400 vRouter (public or private IP address) by using vyatta as the Username. Supply the password when prompted.\n\nYou should create a new user within Brocade 5400 vRouter and disable the default initial user vyatta.\n2. Configure the vif:\n\n\n\n* Type configure at the command prompt to enter configuration mode.\n* Type set interfaces bonding bond0 vif 2254 address 10.52.69.201/29 at the command prompt to set the vif.\n* Type commit at the command prompt to commit the settings.\n* Type save to save the settings.\n* Type exit to switch back to operation mode.\n\n\n\n3. Type show interfaces to check the settings that you committed.\n4. Route any remaining VLANs through the Brocade 5400 vRouter device.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-basic-configuration-of-vyatta-5400"}, {"document_id": "ibmcld_16372-2879-3373", "score": 0.6003258228302002, "text": "\ninstance.updateHomeScreenConfig({\nis_on: true,\ngreeting: 'What can I tell you about credit cards?',\nstarters: {\nis_on: true,\nbuttons: [\n{ label: 'Card interest rates' },\n{ label: 'Cards with rewards' },\n{ label: 'Business cards' }\n]\n}\n});\n\n\n\nFor complete working code, see the [Change launcher and home screen text for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/change-launcher-and-home-screen-text) example.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-custom-text-for-page"}, {"document_id": "ibmcld_05338-7-1901", "score": 0.5918185710906982, "text": "\nDefining commands and arguments for your workloads \n\nWhen you create a container image for your IBM Cloud\u00ae Code Engine workloads, you can define commands and arguments for your job or application to use at run time.\n\nContainer images include two pieces of metadata that tell the container runtime what command, inside the image to run when the container is created. These metadata fields are called Entrypoint and Command. For those users who are familiar with Dockerfile, the fields equate to the ENTRYPOINT and CMD commands. These two fields contain arrays of strings that are combined to create the command line that is used when you run your container.\n\nFor example, if your container image has an Entrypoint value of /myapp and a Command value of --debug, then the full command that is run is /myapp --debug (an array of two strings). Notice that because this action is a concatenation of two arrays, if Entrypoint is an empty array then the Command array's first array element is the executable that is run in your container.\n\nWhen you create a Code Engine application or job, you can provide values for both the Entrypoint and Command arrays.\n\n\n\nDocker and Code Engine names\n\n Description Docker name Code Engine name \n\n The command that is run by the container. ENTRYPOINT command \n The arguments that are passed to the command. CMD args \n\n\n\n\n\n* If --command is used, then any image Entrypoint value is overwritten and any image cmd values are ignored.\n* If --argument is used, then any image Command value in overwritten.\n\n\n\nTo better understand this process, let's look at a few examples,\n\n\n\nImages and Code Engine examples\n\n Image Entrypoint Image Cmd Code Engine command Code Engine args Command that is run \n\n /myapp --debug <not set> <not set> /myapp --debug \n /myapp --debug /myapp2 <not set> /myapp2 \n /myapp --debug <not set> -d /myapp -d \n /myapp --debug /myapp2 -d /myapp2 -d", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cmd-args"}, {"document_id": "ibmcld_04168-13620-14649", "score": 0.5770920515060425, "text": "\nbrew install --HEAD -s https://raw.githubusercontent.com/cloudflare/homebrew-cloudflare/master/curl.rb\n\nThen, perform an HTTP/3 cURL with the --http3 command-line flag:\n\n./curl -I https://blog.cloudflare.com/ --http3\n\nConfirm HTTP/3 appears in the response and that there were no error messages.\n\n\n\n\n\nContribute in GitHub\n\nOpen doc issue\n\nEdit topic\n\n\n\n\n\nOn this page[HTTP/2](https://cloud.ibm.com/docs/cis?topic=cis-http-conceptshttp-2)[HTTP/3](https://cloud.ibm.com/docs/cis?topic=cis-http-conceptshttp-3)\n\n\nFeedback\n\nFocus sentinel\n\n Give us your feedback \n\nTell us about your experience0/1500\n\n\n\nDon't include any sensitive or personal information.\n\nHow satisfied are you with your experience?\n\nHow satisfied are you with your experience?\n\n1\n\n2\n\n3\n\n4\n\n5\n\ninfo icon\n\nYour feedback is carefully reviewed, but you won't be contacted in response. Need help? Try searching the docs or chatting with the Virtual Assistant in console.\n\nCancel\n\nSubmit\n\nFocus sentinel Cookie Preferences\n\nYour privacy choices\n\nYour privacy choices\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_16360-1493-3354", "score": 0.5769108533859253, "text": "\nAll phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download). The format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nwhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\nWhere is your nearest location?,find_location\nDo you have a store in Raleigh?,find_location\n2. From the main actions page, click the Upload icon ![Upload icon](https://cloud.ibm.com/docs-content/v1/content/icons/upload.svg).\n3. Select the intents file that you downloaded.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\nThe intents in column 2 are created as new actions, and the phrases in column 1 are created as example phrases for the corresponding action. For example, if you upload the example from step 1, two new actions are created for the weather_conditions and find_location intents. The underscores (_) in the intent names are replaced with spaces, for example, the weather_conditions intent becomes the weather conditions action.\n\nIn this example, the weather_conditions action will have three example phrases: Tell me the current weather conditions., Is it raining?, and What's the temperature?. The find_location action will have two example phrases: Where is your nearest location? and Do you have a store in Raleigh?.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-upload-download-actions"}, {"document_id": "ibmcld_03403-2780-4346", "score": 0.5744186043739319, "text": "\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close![Close arrow](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close_arrow.png) icon to finish adding the about_restaurant intent.\n\n\n\nYou added an intent and provided examples of utterances that real users might enter to trigger this intent.\n\n\n\n\n\n Add a dialog node that is triggered by the about_restaurant intent \n\nAdd a dialog node that recognizes when the user input maps to the intent that you created in the previous step, meaning its condition checks whether your assistant recognized the about_restaurant intent from the user input.\n\n\n\n1. Click the Dialog tab.\n2. Find the General_Greetings node in the dialog tree.\n\nYou will add a node that checks for questions about the restaurant after this initial greeting node to reflect the flow you might expect to encounter in a normal conversation. For example, Hello. then Tell me about yourself.\n3. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the General_Greetings node, and then select Add node below.\n\n![Shows the Add node below menu opened from the #General_Greetings dialog node.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03249-17439-19450", "score": 0.5725440979003906, "text": "\n* [Moving on after multiple failed attempts](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-stop-trying-after-3)\n* [Preventing a Found response from displaying when it is not needed](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-stifle-found-responses)\n* [Handling requests to exit a process](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slotsdialog-slots-node-level-handler)\n\n\n\n\n\n Asking for everything at once \n\nInclude an initial prompt for the whole node that clearly tells users which units of information you want them to provide. Displaying this prompt first gives users the opportunity to provide all the details at once and not have to wait to be prompted for each piece of information one at a time.\n\nFor example, when the node is triggered because a customer wants to order a pizza, you can respond with the preliminary prompt, I can take your pizza order. Tell me what size pizza you want and the time that you want it delivered.\n\nIf the user provides even one piece of this information in their initial request, then the prompt is not displayed. For example, the initial input might be, I want to order a large pizza. When your assistant analyzes the input, it recognizes large as the pizza size and fills the Size slot with the value provided. Because one of the slots is filled, it skips displaying the initial prompt to avoid asking for the pizza size information again. Instead, it displays the prompts for any remaining slots with missing information.\n\nFrom the Customize pane where you enabled the Slots feature, select the Prompt for everything checkbox to enable the intial prompt. This setting adds the If no slots are pre-filled, ask this first field to the node, where you can specify the text that prompts the user for everything.\n\n\n\n\n\n Capturing multiple values \n\nYou can ask for a list of items and save them in one slot.\n\nFor example, you might want to ask users whether they want toppings on their pizza.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots"}, {"document_id": "ibmcld_02934-24362-26111", "score": 0.5724451541900635, "text": "\nShould I go ahead? Your pizza is on its way! see *Complex response* \n\n\n\nComplex response Because users might include affirmative or negative statements at other times during the dialog (Oh yes, we want the pizza delivered at 5pm) or (no guests tonight, let's make it a small), use the slot_in_focus property to make it clear in the slot condition that you are looking for a Yes or No response to the prompt for this slot only.\n\n(yes || no) && slot_in_focus\n\nThe slot_in_focus property always evaluates to a Boolean (true or false) value. Only include it in a condition for which you want a boolean result. Do not use it in slot conditions that checks for an entity type and then save the entity value, for example.\n\nIn the Not found prompt, clarify that you are expecting the user to provide a Yes or No answer.\n\n{\n\"output\":{\n\"text\": {\n\"values\": [\n\"Respond with Yes to indicate that you want the order to\nbe placed as-is, or No to indicate that you do not.\"\n]\n}\n}\n}\n\nIn the Found prompt, add a condition that checks for a No response (#no). When found, ask for the information all over again and reset the context variables that you saved earlier.\n\n{\n\"conditions\": \"no\",\n\"output\":{\n\"text\": {\n\"values\": [\n\"Let's try this again. Tell me what size pizza\nyou want and the time...\"\n]\n}\n},\n\"context\":{\n\"size\": null,\n\"time\": null,\n\"confirmation\": null\n}\n}\nShow more\n\n\n\n\n\n Replacing a slot context variable value \n\nIf, at any time before the user exits a node with slots, the user provides a new value for a slot, then the new value is saved in the slot context variable, replacing the previously-specified value. Your dialog can acknowledge explicitly that this replacement has occurred by using special properties that are defined for the Found condition:", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_06583-3442-4914", "score": 0.5723902583122253, "text": "\nThe mysql command has many options; [see the official documentation](https://dev.mysql.com/doc/refman/5.7/en/mysqldump.htmlmysqldump-syntax) and [command reference](https://dev.mysql.com/doc/refman/5.7/en/mysqldump.htmlmysqldump-option-summary) for a fuller view of its capabilities.\n\n\n\n Restoring mysqldump's output \n\nThe resulting output of mysqldump can then be uploaded into a new Databases for MySQL deployment. As the output is SQL, it can simply be sent to the database through the mysql command. We recommend that imports be performed with the admin user.\n\nSee the [Connecting with mysql](https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-connecting-mysql) documentation for details on connecting as admin by using mysql. To connect with the mysql command, you need the admin user's connection string and the TLS certificate, which can both be found in the UI. The certificate needs to be decoded from the base64 and stored as an arbitrary local file. To import the previously created dump.sql into a database deployment named example-mysql, the mysql command can be called with -f dump.sql as a parameter. The parameter tells mysql to read and run the SQL statements in the file.\n\nAs noted in the [Connecting with mysql](https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-connecting-mysql) documentation, the Cloud Databases CLI plug-in simplifies connecting. The previous mysql import can be run using a command like:", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-migrating"}, {"document_id": "ibmcld_11439-13936-14359", "score": 0.5696130394935608, "text": "\n(https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-power-iaas-faqssnap-storage-req)\n* [Does the snapshot and volume clone supports any safeguard policy?](https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-power-iaas-faqssnap-clone-safeguard)\n* [Can you tell me more about the backup process using the PowerHA Toolkit for IBM i?](https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-power-iaas-faqspoweha-toolkit)", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-volume-snapshot-clone"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": []}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_15507-3037-4690", "score": 0.7491378784179688, "text": "\nSelect Schedule lifecycle.\n4. In Image status, select the status change for the image.\n5. In Deprecation details, select whether to change status Immediately or to Schedule future date.\n6. If you selected Schedule future date, you need to fill out the following:\n\n\n\n* Select either By calendar date or By number of days.\n\n\n\n* If you selected By calendar date, enter the date and time information. This is the date and time when the status change will occur.\n* If you selected By number of days, put in the number of days that will pass before the status is changed.\n\n\n\n\n\n7. Click Save.\n\n\n\nUse the following steps to schedule the entire lifecycle of the image:\n\nYou can schedule the complete lifecycle for the image. The image is first deprecated and then changes to obsolete according to the schedule that you define. Use the following steps to schedule a lifecycle change.\n\n\n\n1. In [IBM Cloud console](https://cloud.ibm.com/login), go to Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2. On the Custom images tab, click the Actions icon ![More Actions icon](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/icons/action-menu-icon.svg) for a specific image and select from the available options.\n3. Select Schedule lifecycle.\n4. Select Schedule complete lifecycle.\n\n\n\n* If you selected By calendar date, enter the date and time for when you want the status change occur.\n* If you selected By number of days, put in the number of days that you want to pass before the status is changed.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15507-5434-7003", "score": 0.7474120855331421, "text": "\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15507-8094-9618", "score": 0.7439085245132446, "text": "\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15647-25269-26966", "score": 0.739314079284668, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15646-25256-26940", "score": 0.7371864318847656, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15646-29196-30599", "score": 0.7348654866218567, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-29235-30638", "score": 0.7348654866218567, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15507-6657-8493", "score": 0.7309262752532959, "text": "\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15507-9295-10840", "score": 0.7291718125343323, "text": "\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the API \n\nMake a PATCH /images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15544-7685-9445", "score": 0.728858470916748, "text": "\nUsing the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instance.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by using calendar date and time or number of days. The obsolescence date must always be after the deprecation date. \n\n\n\n\n\n\n\n Importing a custom image by using the CLI \n\nMake sure that your compatible custom image is available in IBM Cloud Object Storage. For more information, see [Creating a Linux custom image](https://cloud.ibm.com/docs/vpc?topic=vpc-create-linux-custom-image), [Creating a Windows custom image](https://cloud.ibm.com/docs/vpc?topic=vpc-create-windows-custom-image), [Bring your own license](https://cloud.ibm.com/docs/vpc?topic=vpc-byol-vpc-about) and [Uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) to IBM Cloud Object Storage.\n\nWhen you have an image available in IBM Cloud Object Storage, you can import it to IBM Cloud VPC infrastructure by using the command-line interface (CLI).\n\nTo import a custom image by using the CLI, use the ibmcloud is image-create command. Specify the name of the custom image to be created by using the IMAGE_NAME variable. You must also specify the source; for example, specify the --file option with the image file location. Specify the --os-name option with the name of the operating system for the image.\n\nibmcloud is image-create IMAGE_NAME [--file IMAGE_FILE_LOCATION] [--os-name OPERATING_SYSTEM_NAME]", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-importing-custom-images-vpc&interface=ui"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 0.7470061779022217, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12463-30147-31055", "score": 0.6642571687698364, "text": "\n: With IBM Cloud Secrets Manager, you can create secrets dynamically and lease them to applications while you control access from a single location. Built on open source HashiCorp Vault, Secrets Manager helps you get the data isolation of a dedicated environment with the benefits of a public cloud.\n\nIn this release, Secrets Manager offers support for the following types of secrets:\n\n\n\n* IAM credentials, which consist of a service ID and API key that are generated dynamically on your behalf.\n* Arbitrary secrets, such as custom credentials that can be used to store any type of structured or unstructured data.\n* User credentials, such as usernames and passwords that you can use to log in to applications.\n\n\n\nTo find out more about capabilities and use cases for Secrets Manager, check out the [announcement blog](https://www.ibm.com/cloud/blog/announcements/introducing-ibm-cloud-secrets-manager-beta).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-release-notes"}, {"document_id": "ibmcld_12493-32071-33807", "score": 0.657232403755188, "text": "\nData deleted (if it existed) at: ibmcloud/arbitrary/secrets/d26702aa-77ae-400e-4f25-9790a9cabf9c\n\n\n\n\n\n\n\n\n\n Dynamic secrets \n\nDynamic secrets are single-use credentials that are generated only when they are read or accessed.\n\nTo create a dynamic secret by using the Vault CLI, use the role command to scope the secret with the wanted level of permissions in your IBM Cloud account. Then, use the creds command to generate credentials for the role.\n\n\n\n Create a role \n\nUse the following commands to register a role for a [secrets engine that supports dynamic secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types). After you create a role, you can [generate credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-iam-creds-for-role) for it. The configuration that you define for role, such as its name, lease duration, and access permissions, is inherited by the generated credentials.\n\nCreate a role in the default secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/roles/ROLE_NAME access_groups=ACCESS_GROUP_ID,ACCESS_GROUP_ID ttl=LEASE_DURATION [description=\"DESCRIPTION\"] [labels=LABEL,LABEL]\n\nCreate a role in a specified secret group.\n\nvault write [-format=FORMAT] ibmcloud/SECRET_TYPE/roles/groups/SECRET_GROUP_ID/ROLE_NAME access_groups=ACCESS_GROUP_ID,ACCESS_GROUP_ID ttl=LEASE_DURATION [description=\"DESCRIPTION\"] [labels=LABEL,LABEL]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to create secrets.\n\n\n\n\n\n Command options \n\nSECRET_TYPE\n: The type of secret that you want to create. Currently, iam_credentials is supported.\n\nSECRET_GROUP_ID", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_06832-3322-5473", "score": 0.648592472076416, "text": "\nThe resolved value of a by CRN or by name secret reference is never exposed to the front-end and is always dynamically resolved at runtime within a toolchain and pipeline based on a permitted [authorization](https://cloud.ibm.com/iam/authorizations) being available (configured using IAM Authorizations and Access Policies).\n\nWithin IBM Cloud\u00ae, the dynamic process of resolving by CRN and by name secrets references in toolchains and pipelines is performed using internal virtual private endpoints (VPE) to all IBM Cloud\u00ae Secrets Manager and IBM\u00ae Key Protect provider instances in all regions. This ensures all request and response data between toolchains, pipelines, and IBM Cloud\u00ae Secrets Manager and IBM\u00ae Key Protect provider instances is kept within the in-boundary private IBM Cloud network and does not travel over any public network channels.\n\nIn addition to manually selecting chosen secrets on a one-by-one basis from any bound secrets integrations in a toolchain, the option of using a Secret Hint is also available. This option enables a toolchain template to be predefined with suggested secrets names (also known as Hints) that are a short form secret reference. The format of a secret hint is {vault::secret-name} whereby no secret integration name is included. This provides flexibility to the toolchain author in that all required secret names can be prepopulated into a toolchain.yml and then these names are automatically resolved against whatever secrets integrations are configured for the toolchain.\n\nAs previously described, you can configure Secrets Manager to reference secrets by CRN. For more information, see [Cloud Resource Names (CRN)](https://cloud.ibm.com/docs/account?topic=account-crn). This format allows for greater flexibility because you can reference secrets from an Secrets Manager instance in a different account if the correct [authorization](https://cloud.ibm.com/iam/authorizations) is in place. For more information see [Configuring Secrets Manager](https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager).\n\nThe secrets that are used in both CI and CD are outlined as follows:", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-toolchains-secrets"}, {"document_id": "ibmcld_06832-1757-3915", "score": 0.645298421382904, "text": "\nIn particular, this means vaulting the required secrets by using an approved in-boundary vault provider, such as IBM Cloud\u00ae Secrets Manager, IBM\u00ae Key Protect, or [HashiCorp Vault](https://www.vaultproject.io) and then linking your toolchain secrets to those resources.\n\nThe secrets management capabilities that are provided in the toolchain setup and pipeline user interfaces enable selection of vaulted secrets by using secrets integrations for IBM Cloud\u00ae Secrets Manager, IBM\u00ae Key Protect, or HashiCorp Vault. By using the Secrets Picker dialog, a toolchain or pipeline editor can select named secrets from a bound secrets integration, that is either configured by CRN (Cloud Resource Name) or by name, that is then resolved by reference at runtime within the toolchain and pipeline. After a secret is chosen, a CRN or canonical secret reference is injected into the corresponding toolchain or pipeline secure property where the format is either crn:v1:...secret:<secret-guid> if it's a Secrets Manager integration configured by CRN, or alternatively {vault::integration-name.secret-name} if it's a vault integration using any of the supported providers and configured by name.\n\nThe canonical by name reference format, currently does not resolve a secret that includes the period character in the secret name because this character is used to delimit each section of the canonical path.\n\nRegardless of which type of secret reference is used, either by CRN or by name, the front-end user interface components and Secrets Picker dialog only use a secret reference. The resolved value of a by CRN or by name secret reference is never exposed to the front-end and is always dynamically resolved at runtime within a toolchain and pipeline based on a permitted [authorization](https://cloud.ibm.com/iam/authorizations) being available (configured using IAM Authorizations and Access Policies).\n\nWithin IBM Cloud\u00ae, the dynamic process of resolving by CRN and by name secrets references in toolchains and pipelines is performed using internal virtual private endpoints (VPE) to all IBM Cloud\u00ae Secrets Manager and IBM\u00ae Key Protect provider instances in all regions.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-toolchains-secrets"}, {"document_id": "ibmcld_12717-7818-8740", "score": 0.6361201405525208, "text": "\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-fs-change-log"}, {"document_id": "ibmcld_12945-5261-7283", "score": 0.6360788941383362, "text": "\nBy using references to secrets that are managed by secret providers such as Key Protect, your secret values are centralized and stored securely in a single location. This approach resolves secrets sprawl and proliferation, and means that you can update secrets without updating your toolchain. When you use secret references, the actual secret value is resolved when the toolchain runs by dynamically retrieving it from Key Protect. This approach is useful when you must rotate the value of your toolchain secrets periodically.\n\n\n\n\n\n Adding a Key Protect tool integration to your toolchain template \n\nYou can add a Key Protect tool integration to your toolchain template by adding a service definition to the toolchain.yml file in your template repo. This file is the design blueprint for your toolchain and includes all of the tool integrations that are available when you create a toolchain instance based on that template. To customize an existing toolchain template to include a Key Protect tool integration, insert a YAML definition.\n\nkp-tool:\nservice_id: keyprotect\nparameters:\nname: kp-compliance-secrets\nregion: us-south\nresource-group: default\ninstance-name: ffs-secrets\n\nFor more information about customizing toolchain templates, see [Create a template for a custom toolchain](https://www.ibm.com/cloud/architecture/tutorials/create-a-template-for-a-custom-toolchain).\n\nIn certain scenarios, you can add a Key Protect tool integration dynamically while creating a toolchain. For example, if you click New to mint a new API key, you can select the Save this key in a secrets store for reuse checkbox to save the API key in a Key Protect instance to use it again later. If you do not already have a Key Protect instance, a new instance is created for you.\n\n\n\n\n\n Authorizing your toolchain to access secrets \n\nReferences to secrets that are stored in Key Protect are dynamically resolved when the toolchain runs. To access the required secrets, you must authorize your toolchain to access the Key Protect instance.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-keyprotect"}, {"document_id": "ibmcld_12415-7-1973", "score": 0.6268528699874878, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_12498-9696-11699", "score": 0.6262459754943848, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12493-7080-8333", "score": 0.6235241293907166, "text": "\ncreated_at 2020-10-05T17:43:49Z\ndescription An updated group of secrets.\nid 9c6d20ad-779e-27c5-3842-2a20b19abfcf\nname my-updated-secret-group\ntype application/vnd.ibm.secrets-manager.secret.group+json\nupdated_at 2020-10-05T17:56:56Z\n\n\n\n\n\n\n\n Delete a secret group \n\nUse this command to delete a secret group.\n\nvault delete auth/ibmcloud/manage/groups/SECRET_GROUP_ID\n\n\n\n Prerequisites \n\nYou need the [Manager service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to delete secret groups.\n\n\n\n\n\n Examples \n\nDelete a secret group by its assigned ID.\n\nvault delete auth/ibmcloud/manage/groups/9c6d20ad-779e-27c5-3842-2a20b19abfcf\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nSuccess! Data deleted (if it existed) at: auth/ibmcloud/manage/groups/9c6d20ad-779e-27c5-3842-2a20b19abfcf\n\n\n\n\n\n\n\n\n\n Static secrets \n\n\n\n Create a secret \n\nUse the following commands to add a static secret, such as a user credential or an arbitrary secret, to your Secrets Manager instance. Allowable values for SECRET_TYPE are: arbitrary,imported_cert, [kv](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-manage-kv-cli), private_cert, public_cert, and username_password.\n\nCreate a secret in the default secret group.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06063-54813-57067", "score": 0.6264350414276123, "text": "\nBut when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images. Find a person or team in your organization who is responsible for monitoring and removing vulnerabilities. Depending on your organizational structure, this person might be part of a security, operations, or deployment team. Enable [content trust](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) so that images must be approved by a trusted signer before they can be pushed to the container registry.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-security"}, {"document_id": "ibmcld_09835-0-777", "score": 0.6253488659858704, "text": "\n\n\n\n\n--------------------\n\n\n\n  Identifying software vulnerabilities \n\nYou can also use the IBM Cloud Monitoring Workload Protection service to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nThe ability to monitor software vulnerabilities is included when you use the [Graduated Tier - Sysdig Secure + Monitor service plan](https://cloud.ibm.com/docs/monitoring?topic=monitoring-service_plans). This plan integrates IBM Cloud Security and Compliance Center Workload Protection as part of IBM Cloud Monitoring.\n\nFor more information, see the [IBM Cloud Security and Compliance Center Workload Protection documentation.](https://cloud.ibm.com/docs/workload-protection)\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-workoad-protection"}, {"document_id": "ibmcld_10510-53754-56042", "score": 0.6217705011367798, "text": "\nTo protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry or the [internal registry](https://docs.openshift.com/container-platform/4.11/registry/index.html) that is automatically set up in your Red Hat OpenShift cluster, and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-security"}, {"document_id": "ibmcld_01447-1492-3786", "score": 0.6142010688781738, "text": "\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview"}, {"document_id": "ibmcld_01494-54686-56173", "score": 0.6125654578208923, "text": "\n* [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexabout)\n\n\n\n* [Data protection](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexabout_data_protection)\n\n\n\n* [Types of vulnerabilities](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indextypes)\n\n\n\n* [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexpackages)\n* [Configuration issues - version 3 only](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexapp_configurations)\n\n\n\n* [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_set_version)\n* [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing)\n\n\n\n* [Reviewing a vulnerability report by using the console - version 3 only](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing_gui)\n* [Reviewing a vulnerability report by using the CLI](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_registry_cli)\n\n\n\n* [Setting organizational exemption policies](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_managing_policy)\n\n\n\n* [Setting exemption policies by using the console](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_managing_policy_gui)\n* [Setting exemption policies by using the CLI](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_managing_policy_cli)\n\n\n\n\n\n\n\n\n\n Setting up Terraform for Container Registry", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-sitemap"}, {"document_id": "ibmcld_06004-36463-38401", "score": 0.6100024580955505, "text": "\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https://cloud.ibm.com/docs/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https://cloud.ibm.com/docs/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https://cloud.ibm.com/docs/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_10510-55512-57559", "score": 0.609002947807312, "text": "\nTo avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images. Find a person or team in your organization who is responsible for monitoring and removing vulnerabilities. Depending on your organizational structure, this person might be part of a security, operations, or deployment team. Enable [content trust](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) so that images must be approved by a trusted signer before they can be pushed to the container registry. Then, [install the open source Portieris project](https://github.com/IBM/portieris) admission controller to block container deployments from unsigned images.\n3. Regularly scan running containers:. Even if you deployed a container from an image that passes the vulnerability check, the operating system or binaries that run in the container might get vulnerable over time. To protect your app, you must ensure that running containers are regularly scanned so that you can detect and remediate vulnerabilities. Depending on the app, to add extra security, you can establish a job that takes down vulnerable containers after they are detected.\n\n\n\nYou can use the built-in container registry to automate the container image build process from your source code in an external source repository to your internal registry. However, images are not automatically scanned for vulnerabilities when they are pushed to the internal registry. To set up image scanning, set up a registry namespace and push your images to the managed IBM Cloud Container Registry instead.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-security"}, {"document_id": "ibmcld_06063-56617-58585", "score": 0.5988360643386841, "text": "\nFind a person or team in your organization who is responsible for monitoring and removing vulnerabilities. Depending on your organizational structure, this person might be part of a security, operations, or deployment team. Enable [content trust](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) so that images must be approved by a trusted signer before they can be pushed to the container registry. Then, [install the open source Portieris project](https://github.com/IBM/portieris) admission controller to block container deployments from unsigned images.\n3. Regularly scan running containers:. Even if you deployed a container from an image that passes the vulnerability check, the operating system or binaries that run in the container might get vulnerable over time. To protect your app, you must ensure that running containers are regularly scanned so that you can detect and remediate vulnerabilities. Depending on the app, to add extra security, you can establish a job that takes down vulnerable containers after they are detected.\n\n\n\nZoom\n\n![Deploying containers with trusted content](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers/images/cs_image_security.png)\n\nFigure 1. Deploying containers with trusted content\n\n)\n\n\n\nSecurity for images and deployments\n\n Security feature Description \n\n Secured Docker private image repository in IBM Cloud Container Registry Set up your own Docker [image repository](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started) in a multi-tenant, highly available, and scalable private image registry that is hosted and managed by IBM. By using the registry, you can build, securely store, and share Docker images across cluster users. /n Learn more about [securing your personal information](https://cloud.ibm.com/docs/containers?topic=containers-securitypi) when you work with container images.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-security"}, {"document_id": "ibmcld_01533-4546-6910", "score": 0.5945055484771729, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 0.5921509861946106, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12389-7-2298", "score": 0.7186452150344849, "text": "\nBest practices for rotating and locking secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can design a strategy for rotating your secrets and sensitive data. Review the following suggested guidelines for implementing best practices around your secrets management.\n\n\n\n Define your rotation strategy \n\nAs you use Secrets Manager to design your secrets management strategy, consider how often you want to rotate your secrets based on the internal guidelines for your organization. Determine ahead of time which users or service IDs require access to rotate secrets, and how those secrets can be rotated manually to avoid interruptions to your applications.\n\n\n\n1. Determine a frequency of rotation for your secrets.\n\nAfter you store a secret in Secrets Manager, you decide the frequency of its rotation. You might want to rotate secrets due to personnel turnover, process malfunction, or according to your organization's internal guidelines. Rotate your secrets regularly, for example every 90 days, to meet best practices around secrets management.\n2. Test out rotation workflows for each type of secret that you manage in Secrets Manager.\n\nThe way in which Secrets Manager evaluates a request to rotate a secret differs depending on the type of secret. For example, some secrets are replaced immediately with the data that you provide on rotation, whereas other secrets, such as public certificates, move into an extra validation step. For more information about how Secrets Manager handles rotation requests, see [Manually rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotationmanual-rotate-by-type).\n3. Establish a process for deploying the newest secret versions to your applications.\n\nUse an automated flow to obtain and deploy the latest version of your secret after it is rotated. For more information, see [Avoid application outages by locking your secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-rotate-secretsbest-practices-lock-secrets).\n\n\n\n\n\n\n\n Set up alerts for expiring secrets \n\nConnect to the Event Notifications service so that Secrets Manager can notify you in advance when your secrets or certificates are about to expire.\n\n\n\n1. Set up alerts for your instance by enabling event notifications.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-rotate-secrets"}, {"document_id": "ibmcld_12447-4-2115", "score": 0.7115607261657715, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Manually rotating secrets \n\nWith IBM Cloud\u00ae Secrets Manager, you can manually create new versions of a secret by using the UI or APIs.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. Rotating your credentials limits how long a protected resource can be accessed by a single secret, which can protect your business against the risks that are associated with compromised credentials. Rotate your secrets regularly, for example every 30 or 60 days, so that you're always meeting best practices around secrets management.\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAll the secrets that you store in Secrets Manager can be rotated and replaced on-demand. How Secrets Manager evaluates a request to rotate a secret depends on the secret type.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) Arbitrary secrets are immediately replaced with the data that you provide on rotation. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) IAM credentials, which consist of a service ID and API key, are immediately regenerated according to their initial configuration. If the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}, {"document_id": "ibmcld_12384-4-1975", "score": 0.7095115184783936, "text": "\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Automatically rotating secrets \n\nYou can schedule automatic rotation for secrets by using IBM Cloud\u00ae Secrets Manager.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. By scheduling automatic rotation of your secrets at regular intervals, you can reduce the likelihood of compromise and ensure that your credentials never expire.\n\nAutomatic rotation is available only for secrets that are generated by Secrets Manager. If the secret was imported initially, you must provide new secret data to rotate it. For more information, see [Manually rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAutomatic rotation is supported for [private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates), [public certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesorder-certificates), [user credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) and [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials). Depending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation"}, {"document_id": "ibmcld_12384-1459-3676", "score": 0.7026340961456299, "text": "\nDepending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content. The time-to-live (TTL) of the renewed certificate is set according to the [certificate template](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) that was selected when the certificate was first created.<br><br>After the time-to-live (TTL) or validity period of a private certificate exceeds the validity period of its issuing certificate authority, the certificate can no longer be rotated automatically. \n [Public certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that the request to renew the certificate is being processed. Secrets Manager uses DNS validation to verify that you own the domains that are listed as part of the certificate. This process can take a few minutes to complete. If the validation completes successfully, a new certificate is issued and its status changes back to Active. If the validation doesn't complete successfully, the status of the certificate changes to Active, Rotation failed. \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) The existing password value is replaced with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols. The username value does not change. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) The Service ID's API key value is replaced with a new API key. The previous API key remains available for the remaining time in the defined TTL. \n\n\n\n\n\n\n\n\n\n Scheduling automatic rotation in the UI", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation"}, {"document_id": "ibmcld_12493-26511-27722", "score": 0.6836340427398682, "text": "\n\"crn\": \"crn:v1:bluemix:public:secrets-manager:us-south:a/791f5fb10986423e97aa8512f18b7e65:e415e570-f073-423a-abdc-55de9b58f54e:secret:fe874c2b-e8fd-bbb6-9f19-e91bbe744735\",\n\"id\": \"fe874c2b-e8fd-bbb6-9f19-e91bbe744735\",\n\"labels\": [],\n\"last_update_date\": \"2020-10-22T14:54:25Z\",\n\"name\": \"updated-name-arbitrary-secret\",\n\"secret_type\": \"ARBITRARY\",\n\"state\": 1,\n\"state_description\": \"Active\"\n},\n\"warnings\": null\n}\n\n\n\n\n\n\n\n Rotate a secret \n\nUse this command to rotate a secret. Allowable values for SECRET_TYPE are: arbitrary, iam_credentials, imported_cert, kv, private_cert, public_cert, and username_password.\n\nvault write [-format=FORMAT] [-force] ibmcloud/SECRET_TYPE/secrets/SECRET_ID/rotate [payload=\"SECRET_DATA\"] [password=PASSWORD] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-cli"}, {"document_id": "ibmcld_12415-1547-3664", "score": 0.6821699142456055, "text": "\nFor more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n What happens when my secret expires? \n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n\n\n\n\n\n What are differences between the Reader and SecretsReader roles? \n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance. Readers can't access the payload of a secret.\n* As a secrets reader, you can browse a high-level view of secrets, and you can access the payload of a secret. A secrets reader can't create secrets or modify the value of an existing secret.\n\n\n\n\n\n\n\n How is Secrets Manager different from Key Protect? \n\nThere are a few key differences between using Key Protect and Secrets Manager to store your sensitive data. Secrets Manager offers flexibility with the types of secrets that you can create and lease to applications and services on-demand. Whereas, Key Protect delivers on encryption keys that are rooted in FIPS 140-2 Level 3", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_12447-19672-21563", "score": 0.6816898584365845, "text": "\nFor more information about the command options, see [ibmcloud secrets-manager secret-version-create](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-version-create-command).\n\n\n\n\n\n\n\n Manually rotating secrets with the API \n\nYou can manually rotate your secrets and certificates by using the Secrets Manager API.\n\n\n\n Rotating arbitrary secrets \n\nYou can rotate arbitrary secrets by calling the Secrets Manager API.\n\nThe following example request creates a new version of your secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\ncurl -X POST -H \"Authorization: Bearer {iam_token}\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d '{\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"payload\": \"Updated arbit\",\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \n\"https://{instance_ID}.{region}.secrets-manager.appdomain.cloud/api/v2/secrets/{id}/versions\"\n\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API docs](https://cloud.ibm.com/apidocs/secrets-manager/secrets-manager-v2update-secret).\n\n\n\n\n\n Rotating key-value secrets \n\nYou can rotate key-value secrets by calling the Secrets Manager API.\n\nThe following example request creates a new version of your secret.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}, {"document_id": "ibmcld_12492-53535-54571", "score": 0.6763272285461426, "text": "\n}'\n\nRotate a username_password secret in the default secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/username_password/secrets/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"password\": \"new-password\"\n}'\n\nRotate an imported_cert secret in the default secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/imported_cert/secrets/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"certificate\": \"new-certificate\",\n\"private_key\": \"new-private-key\",\n\"intermediate\": \"new-intermediate-certificate\"\n}'\n\n\n\n\n\n Example responses \n\nA request to rotate a kv secret in the default secret group returns the following response:\n\n{\n\"request_id\": \"e00000b-0000-0ad1-beb0-00000d0000\",\n\"lease_id\": \"\",\n\"renewable\": false,\n\"lease_duration\": 0,\n\"data\": {\n\"created_by\": \"iam-ServiceId-9ca2000007-f0000d-400000e-8b02-ed6b000000\",\n\"creation_date\": \"2022-01-25T19:22:04Z\",", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}, {"document_id": "ibmcld_12447-3178-4817", "score": 0.6745651364326477, "text": "\nSecrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI \n\nYou can manually rotate your secrets and certificates by using the Secrets Manager UI.\n\n\n\n Rotating arbitrary secrets \n\nYou can use the Secrets Manager UI to manually rotate your arbitrary secrets.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets Manager UI, go to the Secrets list.\n4. In the row for the secret that you want to rotate, click the Actions menu ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/991f60ddbe3ab0a9aa69481a07a0a73b359fa329/icons/actions-icon-vertical.svg)> Rotate.\n5. Select a new file or enter a new secret value.\n6. Optional: Add metadata to your secret or to a specific version of your secret.\n\n\n\n1. Upload a file or enter the metadata and the version metadata in JSON format.\n\n\n\n7. To rotate the secret immediately, click Rotate.\n8. Optional: Check the version history to view the latest updates.\n\nIn the row of the secret that you rotated, click the Actions menu !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}, {"document_id": "ibmcld_12492-51531-52986", "score": 0.6722428798675537, "text": "\nTo set an automatic rotation policy for a secret, see [Set secret policies](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-apivault-set-secret-policies).\n\n\n\nTable 8. Rotate secret request parameters\n\n Request parameters Description \n\n payload The new secret data to assign to an arbitrary or a kv secret. \n password The new password to assign to a username_password secret. \n certificate The new certificate to assign to an imported_cert secret. \n private_key The new private key to assign to an imported_cert secret. \n intermediate The new intermediate certificate data to assign to an import_cert secret. \n\n\n\n\n\n Example requests \n\nRotate an arbitrary secret in the default secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/arbitrary/secrets/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"payload\": \"new-secret-data\"\n}'\n\nRotate an arbitrary secret in an existing secret group.\n\ncurl -X POST \"https://{instance_id}.{region}.secrets-manager.appdomain.cloud/v1/ibmcloud/arbitrary/secrets/groups/{group_id}/{secret_id}/rotate\" -H 'Accept: application/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"payload\": \"new-secret-data\"\n}'\n\nRotate a kv secret in the default secret group. [Learn more](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-manage-kv&interface=apioverview-kv).\n\ncurl -X POST 'https://{instance_id}.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-vault-api"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12422-4-1817", "score": 0.7297207117080688, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials"}, {"document_id": "ibmcld_12428-4-1817", "score": 0.7297207117080688, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"}, {"document_id": "ibmcld_02196-1557-3551", "score": 0.7065054178237915, "text": "\nComplete the following steps to add a credential to a service that is managed by IAM:\n\n\n\n1. From the Resource list page, select the name of the service to open the service details page. Then, select the Credentials tab, and click New Credential.\n2. From the Add New Credential dialog, provide a Name.\n3. Specify the role. This value sets the IAM service access role. For more information, see [IAM Access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n4. Optionally, you can provide a Service ID by either allowing IAM to generate a unique value for you, or by providing an existing Service ID. For more information, see [Creating and working with service IDs](https://cloud.ibm.com/docs/account?topic=account-serviceids).\n5. Optionally, you can provide more parameters as a valid JSON object that contains service-specific configuration parameters, provided either inline or in a file.\n\nMost services don't require extra parameters, and for services that do, each service defines its own unique list of parameters. For a list of supported configuration parameters, see the documentation for the particular service offering.\n6. Click Add to generate the new service credential.\n\n\n\n\n\n Creating a service credential without an IAM service role \n\nServices managed by IAM that generate new credentials can assign an IAM Service access role. This role grants access to the entire service instance. For services with fine-grained resource access, you might want to grant access only to a subresource, such as a Cloud Object Storage bucket. In this case, you can choose to continue without selecting a role so that the new credential is created without an IAM Service role. This way, you can manage the fine-grained access by creating an IAM policy that you scope to a specific resource, like a bucket. To create the credential without an IAM service role, complete the following steps:\n\n\n\n1. From the Resource list page, select the name of the service to open the service details page.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-service_credentials&interface=ui"}, {"document_id": "ibmcld_12404-4-1838", "score": 0.6937353610992432, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Configuring the IAM credentials engine \n\nYou can set up IAM credentials for your IBM Cloud\u00ae Secrets Manager service instance by configuring the IAM credentials engine.\n\nIn Secrets Manager, the IAM credentials engine serves as the backend for the iam_credentials secret type. Before you can create IAM credentials, you must configure the IAM credentials engine for your service instance. You can enable your instance by entering an [API key](https://cloud.ibm.com/docs/account?topic=account-serviceidapikeys) that is associated with a service ID in your IBM Cloud account.\n\n\n\n Before you begin \n\nIf you're setting up IAM credentials for the first time, be sure that you're assigned the [Manager service role](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam) on the Secrets Manager instance. To configure the IAM secrets engine, you need a [service ID API key](https://cloud.ibm.com/docs/account?topic=account-serviceidapikeys) with the following access:\n\n\n\n* [Editor platform role](https://cloud.ibm.com/docs/account?topic=account-account-servicesaccess-groups-account-management) on the IAM Access Groups Service.\n* [Operator platform role](https://cloud.ibm.com/docs/account?topic=account-account-servicesidentity-service-account-management) on the IAM Identity Service.\n* [Service ID creator service role](https://cloud.ibm.com/docs/account?topic=account-account-servicesidentity-service-account-management) on the IAM Identity Service.\n\n\n\nThe service ID creator service role is only required when you disable the creation of service IDs in your IAM settings. If the account in which you want to generate IAM credentials allows access to only specific IP addresses, you must also update the IP address settings in the account to allow incoming requests from Secrets Manager.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine"}, {"document_id": "ibmcld_00589-8040-10059", "score": 0.6908040046691895, "text": "\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_02196-3106-4924", "score": 0.6862431764602661, "text": "\nIn this case, you can choose to continue without selecting a role so that the new credential is created without an IAM Service role. This way, you can manage the fine-grained access by creating an IAM policy that you scope to a specific resource, like a bucket. To create the credential without an IAM service role, complete the following steps:\n\n\n\n1. From the Resource list page, select the name of the service to open the service details page. Then, click Service credentials > New Credential+.\n2. Provide a Name.\n3. Select None as the role so that the new credential is created without an IAM Service role.\n4. Next, go to Manage > Access (IAM) > Service IDs.\n5. Select the service ID with the same name as the service credential key, and click Assign access.\n\n\n\n\n\n\n\n\n\n Adding a credential when binding an IAM-enabled service by using the API \n\nServices that are managed by IBM Cloud Identity and Access Management (IAM) can generate a resource key, also known as a credential. Credentials are service-specific and vary based on how each service defines the credentials they need to generate. A credential might contain a user name, password, host name, port, and a URL.\n\nHowever, while the contents of each credential is unique to the service that generates it, all services managed by IAM require that new credentials include an IAM Service access role. Some services might generate more data that requires parameters to be passed in. For example, a service might require you to input a language parameter to set the default language that is returned in the resource key that is generated.\n\nTo create a resource key, call the [Resource Controller API](https://cloud.ibm.com/apidocs/resource-controller/resource-controllercreate-resource-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-service_credentials&interface=ui"}, {"document_id": "ibmcld_02196-18343-19589", "score": 0.6812170743942261, "text": "\n\"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/4329073d16d2f3663f74bfa955259139:8d7af921-b136-4078-9666-081bd8470d94::\"\n},\n\"iam_compatible\": true,\n\"migrated\": false,\n\"resource_instance_url\": \"/v2/resource_instances/8d7af921-b136-4078-9666-081bd8470d94\",\n\"resource_alias_url\": null\n}\n]\n}\n\n\n\n Credential level access \n\nThe access of the user must be equal to or greater than the access of the service credential. For example, if the credential has the IAM service role Writer, then the user that is trying to view the credential must have the IAM service role Writer or Manager for that particular service assigned. When a user doesn't have the correct access, details such as the API key value are redacted:\n\n\"credentials\": {\n\"REDACTED\": \"REDACTED\"\n},\n\n\n\n\n\n IAM level access \n\nWhen the credential level access can't be determined by comparing the access of the user and the credential, the credential is redacted:\n\n\"credentials\": {\n\"REDACTED\": \"REDACTED_EXPLICIT\"\n},\n\nTo view the credential, the user must have the IAM level access action resource-controller.credential.retrieve_all. This action is given with the Administrator role, and overrides any credential level access enabling the user to view the credential.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-service_credentials&interface=ui"}, {"document_id": "ibmcld_12479-10614-12085", "score": 0.6748796701431274, "text": "\nTo configure the IAM secrets engine from the IBM Cloud CLI, run the [ibmcloud secrets-manager config-update](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-configuration-update-command) command.\n\nibmcloud secrets-manager config-update --engine-config '{\"api_key\": \"$API_KEY\"}'\n\nSuccess! Now you can [create an IAM credential](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentialsiam-credentials-ui) that you can use to dynamically generate service IDs and API keys. Continue to the next step.\n\n\n\n\n\n\n\n\n\n Step 2: Create an IAM credential \n\nIAM credentials are dynamic secrets that you can use to access an IBM Cloud resource on-demand, such as a Cloud Object Storage bucket. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo create an IAM credential from the IBM Cloud CLI, run the [ibmcloud secrets-manager secret-create](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-create-command) command.\n\nexport SECRET_ID=ibmcloud secrets-manager secret-create --resources '[{\"name\":\"test-iam-credentials\",\"description\":\"Extended description for my secret.\"", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"}, {"document_id": "ibmcld_07578-419683-421572", "score": 0.6743904948234558, "text": "\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-419665-421554", "score": 0.6743904948234558, "text": "\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02737-20268-21516", "score": 0.6780838370323181, "text": "\n\"location\": \"/v1/cb967e0d-43c1-454a-968d-0efa24766846/Users/34e1ea6d-cc02-4941-9462-7e9c5a40b360\",\n\"lastModified\": \"2018-12-10T16:05:36.675Z\",\n\"resourceType\": \"User\"\n},\n\"schemas\": [\n\"urn:ietf:params:scim:schemas:core:2.0:User\"\n],\n\"name\": {\n\"givenName\": \"test\",\n\"familyName\": \"test\",\n\"formatted\": \"test test\"\n},\n\"id\": \"34e1ea6d-cc02-4941-9462-7e9c5a40b360\"\n}\n\n\n\n\n\n\n\n Finding user-related events \n\nYou can track the events of specific Cloud Directory users in Activity Tracker by using their email. Before you can begin tracking, the email must be mapped to a Cloud Directory GUID.\n\n\n\n1. Obtain an IAM token, a tenant ID, and a region as described in the previous section.\n2. Insert the IAM token, the tenant ID, and the email into the following command to obtain the user information.\n\ncurl -X GET\n--header 'Accept: application/json'\n--header 'Authorization: Bearer <IAMToken>'\n'https://<region>.appid.cloud.ibm.com/<tenantID>/users?email=<emailAddress>'\n\nThe email address must be escaped. For example, myTest%40yahoo.com instead of myTest@yahoo.com.\n\nAlternatively, you can use the [Management APIs](https://us-south.appid.cloud.ibm.com/swagger-ui//Config/getAuditStatus). Your output would look similar to the following JSON object:\n\n{\n\"users\": [", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-at-events"}, {"document_id": "ibmcld_00033-4979-5757", "score": 0.6036441326141357, "text": "\nFor details, see [Configuring and viewing logs](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n How can I track actions performed by users on a serverless Spark instance? \n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"}, {"document_id": "ibmcld_02536-7-1973", "score": 0.59599769115448, "text": "\nUsing the Track Access template \n\nUse the IBM Cloud Activity Tracker Track Access template to gain insight on your IBM Cloud access requests. Monitor login requests, unauthorize access, and denied requests.\n\n\n\n Overview \n\nThe Activity Tracker track access template includes the following artifacts:\n\n\n\n* Parsing templates to pull additional information from the data to enhance searchability and simplify customization such as region, RC and accountID.\n* Views and screens that allow you to monitor activity in your account.\n\n\n\nThis template uses global events that are available through the Frankfurt region. In Activity Tracker, you can monitor global events through the instance in Frankfurt (EU-DE). Deploy this template in the Frankfurt region to monitor activity.\n\n\n\n\n\n Deploying the track access templates \n\nComplete the following steps to deploy the track access template objects in 1 Activity Tracker instance:\n\n\n\n Step 1. Launch the template library \n\nThe Activity Tracker hosted event search offering template library offers multiple tiles that group predefined views, dashboards, and screens by area. One of them is the Track Archiving template.\n\nComplete the following steps to launch the Activity Tracker template library:\n\n\n\n1. [Log in to your IBM Cloud account](https://cloud.ibm.com/login).\n\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/6f3c07c34058f637b1c86044ca4f9b24214330a7/icons/icon_hamburger.svg) > Observability.\n3. Select Activity Tracker.\n\nThe list of Activity Tracker instances is displayed.\n\nThere is 1 instance per region.\n4. Select the Activity Tracker instance in the region where you want to deploy the template. Then, click Open Dashboard.\n\n\n\n\n\n\n\n Step 2. Install the template \n\nComplete the following steps to deploy the Track Access template:\n\n\n\n1. From the Activity Tracker instance UI, click the Settings icon !", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-templates-track-access"}, {"document_id": "ibmcld_00786-4443-6049", "score": 0.5947945713996887, "text": "\nOn the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Account. On the Account page, in the Change username section, find your Git Repos and Issue Tracking username. Your username is also displayed as the first segment of the URL for any personal Git repos that you create.\n6. Use your Git Repos and Issue Tracking username and personal access token to authenticate with your Git repo from an external Git client.\n\n\n\nTo learn more, see [Personal access tokens](https://us-south.git.cloud.ibm.com/help/user/profile/personal_access_tokens.md).\n\n\n\n\n\n Creating an SSH key \n\nTo create an SSH key, see [Generate an SSH key pair](https://us-south.git.cloud.ibm.com/help/user/ssh.mdgenerate-an-ssh-key-pair). Accessing your repositories with SSH authentication might require more configuration for proxies and firewalls.\n\nTo learn more, see [Use SSH keys to communicate with GitLab](https://us-south.git.cloud.ibm.com/help/user/ssh.html).\n\n\n\n\n\n Verifying host key fingerprints \n\nThe first time that you connect to a server by way of Git over SSH, the Git client prompts you to accept the host key fingerprint of the server. You can use the following host key fingerprints to verify SSH connections with the IBM Cloud Git Repos and Issue Tracking servers. Proceed with the connection only if the host key fingerprint matches the specified value for the server that is provided in the following code snippets.\n\nau-syd.git.cloud.ibm.com:\nECDSA:\nSHA256:oUpjbxJ+UVIlBvcdcKuprZ0JEtCWkTu1yFTdfFHoEF8\nMD5:ca:34:27:f1:49:fd:b4:9d:e8:ce:d2:7b:99:a1:dd:98", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-git_working"}, {"document_id": "ibmcld_12938-4452-6058", "score": 0.5947945713996887, "text": "\nOn the Git Repos and Issue Tracking User Settings dashboard, from the menu, click your avatar and select Edit profile. Click Account. On the Account page, in the Change username section, find your Git Repos and Issue Tracking username. Your username is also displayed as the first segment of the URL for any personal Git repos that you create.\n6. Use your Git Repos and Issue Tracking username and personal access token to authenticate with your Git repo from an external Git client.\n\n\n\nTo learn more, see [Personal access tokens](https://us-south.git.cloud.ibm.com/help/user/profile/personal_access_tokens.md).\n\n\n\n\n\n Creating an SSH key \n\nTo create an SSH key, see [Generate an SSH key pair](https://us-south.git.cloud.ibm.com/help/user/ssh.mdgenerate-an-ssh-key-pair). Accessing your repositories with SSH authentication might require more configuration for proxies and firewalls.\n\nTo learn more, see [Use SSH keys to communicate with GitLab](https://us-south.git.cloud.ibm.com/help/user/ssh.html).\n\n\n\n\n\n Verifying host key fingerprints \n\nThe first time that you connect to a server by way of Git over SSH, the Git client prompts you to accept the host key fingerprint of the server. You can use the following host key fingerprints to verify SSH connections with the IBM Cloud Git Repos and Issue Tracking servers. Proceed with the connection only if the host key fingerprint matches the specified value for the server that is provided in the following code snippets.\n\nau-syd.git.cloud.ibm.com:\nECDSA:\nSHA256:oUpjbxJ+UVIlBvcdcKuprZ0JEtCWkTu1yFTdfFHoEF8\nMD5:ca:34:27:f1:49:fd:b4:9d:e8:ce:d2:7b:99:a1:dd:98", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-git_working"}, {"document_id": "ibmcld_12518-7-1970", "score": 0.5937001705169678, "text": "\nAuditing events for account, IAM, catalog management \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud\u00ae Activity Tracker service to track how users and applications interact with an IBM Cloud\u00ae account, the IBM Cloud catalog, private catalogs, and with IBM Cloud Identity and Access Management (IAM).\n\nTo get started with monitoring your user's actions, see [Activity Tracker](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-getting-startedgetting-started).\n\n\n\n Account management events \n\nYou can track the following events:\n\n\n\n* Managing an account by creating an account, updating information, activating an account, or creating a Subscription account\n* Adding or removing users\n* Creating organizations\n\n\n\n\n\n\n\n IAM events \n\nYou must create an instance of the Activity Tracker service in the Frankfurt (eu-de) region to start tracking IAM events. When you create the instance, you can track the following events:\n\n\n\n* Managing access groups by creating and deleting groups or adding and removing users\n* Creating, updating, or deleting service IDs\n* Creating, updating, or deleting API keys\n* Creating, updating, or deleting access policies\n* Creating, updating, or deleting trusted profiles\n* Logging in to IBM Cloud by using an API key, authorization code, passcode, password, or an API key associated with a service ID\n* Logging in to IBM Cloud by using a trusted profile. For more information, see [Monitoring login sessions for trusted profiles](https://cloud.ibm.com/docs/account?topic=account-trusted-profile-monitor).\n\n\n\nFor more information, see [IAM events](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_iam).\n\n\n\n\n\n Catalog management events \n\nYou can track the following events:\n\n\n\n* Viewing or updating account settings\n* Viewing or updating a catalog\n* Listing all products in a catalog\n* Listing all products in an account\n* Creating, updating, viewing, or deleting a product", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-acct_iam_tracking"}, {"document_id": "ibmcld_07242-3813-5067", "score": 0.5904041528701782, "text": "\nDiscovery provides an API that can be embedded in your application to track events. Calling this API with the appropriate information when a user performs an action sends a signal back to Discovery, which can then be viewed in the logs.\n\nEvents can help gather information on computing metrics (like clickthrough rate) to measure how effective the application is at helping end users find relevant information, or can be used to help seed training by reviewing the queries and clicks to start to build ground truth.\n\nYou can add this API wherever users interact with your results. For example, in a search UI, you can add the API when a user clicks on a document link. In a chatbot interface, you can use the API to track when the user clicks on Expand or More details.\n\nDiscovery results return additional information that can be used for tracking events, including a session token.\n\n\"matching_results\": 179,\"session_token\": \"1_LKczxWGEWx59fYD0_VV8HFUpb6\"\n\nTo record an event, make a POST to the /api/v1/events endpoint. See the [Events API](https://cloud.ibm.com/apidocs/discoverycreate-event) for details.\n\nOnce an event is recorded, it can be read back out using the /api/v1/logs endpoint. Join events to the associated query using the session_token.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-usage"}, {"document_id": "ibmcld_12791-13518-15352", "score": 0.5796427726745605, "text": "\nYou can assign users access to manage licenses and entitlements within an account. Any member of an account can view and use an account\u2019s entitlement.\n\n\n\nTable 13. Roles and example actions for the license and entitlement service\n\n Roles Actions \n\n Viewer Not applicable \n Operator Not applicable \n Editor Editors can create entitlements and view, update, bind, or delete only the entitlements they acquired. \n Administrator Administrators can create entitlements and view, update, bind, or delete any entitlements in the account. \n\n\n\n\n\n\n\n Partner Center \n\nYou can give users access to view and edit partner profile details, offers, fast tracks, and to create and view support cases.\n\n\n\nTable 14. Roles and example actions for the Partner Center service\n\n Roles Actions \n\n Viewer View details about partner profile, offers, fast tracks, support cases. \n Editor View and edit partner profile, offers, and fast tracks. Create, edit, and view support cases. \n Operator \n Administrator View and edit partner profile, offers, and fast tracks. Create, edit, and view support cases. \n\n\n\n\n\n\n\n Partner Center - Sell \n\nYou can give users access to onboard, validate, and publish products.\n\n\n\nTable 15. Roles and example actions for the Partner Center - Sell service\n\n Roles Actions \n\n Administrator Create, edit, validate, and publish products \n Editor Validate and edit products \n Approver Approves or rejects a workflow instance's task \n\n\n\n\n\n\n\n Projects \n\nYou can give users access to configure, validate, and monitor Infrastructure as Code (IaC) deployments.\n\n\n\nTable 16. Roles and example actions for the Project service\n\n Roles Actions \n\n Viewer View details about projects, configurations, and deployments. \n Operator View details about projects, configurations, and deployments<br><br>Validate a configuration<br><br>Edit a configuration", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-account-services"}, {"document_id": "ibmcld_00693-28329-30382", "score": 0.5687758922576904, "text": "\n4. Select Private, if it is not already selected.\n5. Click Save changes.\n\n\n\n\n\n\n\n Project membership \n\nGit Repos and Issue Tracking is a cloud hosted social coding environment that is available to all Continuous Delivery users. If you are a Git Repos and Issue Tracking project Maintainer or Owner, you can invite any user and group members to the project. IBM Cloud places no restrictions on who you can invite to a project. Because you can invite anyone into a GitLab project, be careful to invite only those users or groups who are part of your company or organization, unless you explicitly intend otherwise.\n\nFor more information about managing GitLab project members, see [Members of a project](https://docs.gitlab.com/ee/user/project/members/).\n\n\n\n\n\n Project email settings \n\nBy default, Git Repos and Issue Tracking notifies project members by way of email about project activities. These emails typically include customer-owned data that was provided to Git Repos and Issue Tracking by users. For example, if a user posts a comment to an issue, Git Repos and Issue Tracking sends an email to all subscribers that includes information such as a copy of the comment, the user who posted it, and when the comment was posted. To turn off all email notifications for your project, complete the following steps:\n\n\n\n1. From the project sidebar, click Settings > General.\n2. On the General Settings page, click Visibility > project features > permissions.\n3. Select the Disable email notifications checkbox.\n4. Click Save changes.\n\n\n\n\n\n\n\n Project integrations and webhooks \n\nGit Repos and Issue Tracking projects might also be configured with integrations or webhooks to other systems, or equipped with access tokens, deploy tokens, and deploy keys. To review or change the integrations, webhooks, tokens, and keys that might be configured with your project, from the project sidebar, complete the following steps:\n\n\n\n1. From the project sidebar, click Settings.\n2. Click Integrations to work with your project's integrations with other applications.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd_data_security"}, {"document_id": "ibmcld_12946-12737-13963", "score": 0.568606436252594, "text": "\n* Public projects are visible to all site visitors. The content in a public project is visible to everyone who accesses Continuous Delivery, even if they are not invited to the project.\n* Private projects are visible to select users only. For more information about granting users access to a project, see [Project members](https://us-south.git.cloud.ibm.com/help/user/project/members/index.md).\n* Internal projects are visible to all logged-in users. Any user who has an IBM Cloud account can view these projects.\n\n\n\nFor more information about the project settings, see [Change project visibility](https://us-south.git.cloud.ibm.com/help/user/public_access.mdchange-project-visibility).\n\nWhen you use Git Repos and Issue Tracking, the content that you contribute to a project is licensed under any terms that are specified in that project. When you create a project, include a file that describes the license that applies to the content. When you contribute to a project, your name and the email address that is associated with your commits might be visible to the public. The email address that is associated with your IBM Cloud account is used when you create commits through the Git Repos and Issue Tracking web interface.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-limitations_usage"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13159-9124-9552", "score": 0.6847665309906006, "text": "\nSee this document on how to [use resource reclamation](https://cloud.ibm.com/docs/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [Serverless Computing](https://www.ibm.com/cloud/learn/serverless)\n* [Serverless: Code patterns](https://developer.ibm.com/depmodels/serverless/patterns/)\n* [Getting started with IBM Cloud Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-getting-started)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp"}, {"document_id": "ibmcld_00007-7-2159", "score": 0.6770113706588745, "text": "\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine"}, {"document_id": "ibmcld_00007-1713-3490", "score": 0.6753023862838745, "text": "\nSee [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https://cloud.ibm.com/docs/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-cli).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine"}, {"document_id": "ibmcld_00055-7-1864", "score": 0.6750542521476746, "text": "\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https://cloud.ibm.com/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}, {"document_id": "ibmcld_00096-7-2347", "score": 0.672063946723938, "text": "\nExplore creating serverless instances and submitting applications using the CLI \n\nLearn how to use the IBM Analytics Engine CLI to create the services that you need to create and manage a serverless instance, and submit and monitor your Spark applications.\n\nYou create a serverless instance by selecting the IBM Analytics Engine Standard serverless plan. When a serverless instance is provisioned, an Apache Spark cluster is created, which you can customize with library packages of your choice, and is where you run your Spark applications.\n\n\n\n Objectives \n\nYou will learn how to install and set up the following services and components that you will need to use the CLI:\n\n\n\n* An IBM Cloud Object Storage instance in which your IBM Analytics Engine instance stores custom application libraries and Spark history events.\n* A Object Storage bucket for application files and data files.\n* An IBM Analytics Engine serverless instance. This instance is allocated compute and memory resources on demand whenever Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the instance. The price is based on the actual usage of resources consumed by the instance, billed on a per second basis.\n* Logging service to help you to troubleshoot issues that might occur in the IBM Analytics Engine instance and submitted application, as well as to view any output generated by your application. When you run applications with logging enabled, logs are forwarded to an IBM Log Analysis service where they are indexed, enabling full-text search through all generated messages and convenient querying based on specific fields.\n\n\n\n\n\n\n\n Before you begin \n\nTo start using the the Analytics Engine V3 CLI you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* To install the IBM Cloud CLI. See [Getting started with the IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started) for the instructions to download and install the CLI.\n\n\n\nNow you can start using the Analytics Engine V3 CLI. You must follow the instructions in steps 1 and 2 to install the required services before you start with step 3 to upload and submit Spark applications. Step 4 shows you how to create a logging instance and enable logging. Step 5 shows you how to delete an Analytics Engine instance, although this step is optional.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-cli"}, {"document_id": "ibmcld_00033-7-2292", "score": 0.6635173559188843, "text": "\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"}, {"document_id": "ibmcld_11728-4840-5537", "score": 0.6623977422714233, "text": "\nCreate a [Knative-compliant container image](https://knative.dev/docs/serving/samples/hello-world/helloworld-python/index.html).\n3. [Deploy the image](https://developers.redhat.com/blog/2020/04/30/serverless-applications-made-faster-and-simpler-with-openshift-serverless-ga) to your Red Hat OpenShift Serverless processor that runs in your Satellite cluster. You can use the Red Hat OpenShift web console in the developer perspective, or use the kn command line tool for Satellite Serverless.\n\n\n\nNow, you have a managed Satellite location that runs on your edge environment and performs on-demand model inferencing for your edge data through your AI-trained model and Red Hat OpenShift Serverless.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-edge-usecase"}, {"document_id": "ibmcld_00052-7-2119", "score": 0.6619275212287903, "text": "\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https://test.cloud.ibm.com/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"}, {"document_id": "ibmcld_07578-107943-110247", "score": 0.6590906381607056, "text": "\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-107922-110226", "score": 0.6590906381607056, "text": "\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16628-0-1541", "score": 0.5500860810279846, "text": "\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query"}, {"document_id": "ibmcld_00539-3574-5364", "score": 0.4983970522880554, "text": "\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query. We recommend that you use the _explain mechanism to check each IBM Cloudant query to ensure it is using an index before you deploy to production.\n\nFor example, a type=json index on firstname, surname and date is suitable for finding documents for:\n\n\n\n* A known firstname, lastname, and date.\n* A known firstname, lastname, and a range of date values (that use $lt, $lte, $gt, $gte operators).\n* A known firstname and lastname sorted by date.\n\n\n\nIt can also be used to assist queries on firstname, surname, date, and other attributes. In other words, it might be able to answer only part of the query but it can help reduce the number of documents that are scanned to find the answer.\n\n\n\n\n\n How can I ensure that my query is efficent? \n\nIdeally, an IBM Cloudant Query execution would need to scan only one document for each document returned. If a query has to scan a million documents for each one returned, it is clearly not optimal, and is in need of a secondary index to help.\n\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_16662-0-1981", "score": 0.49494433403015137, "text": "\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_sql"}, {"document_id": "ibmcld_00499-7504-8695", "score": 0.48960641026496887, "text": "\n\"year\": 2010\n}\n}\n\nSee the following example that uses the command line to show how to identify the index that was used to answer a query:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"$SERVICE_URL/movies/_explain\" \t-X POST \t-H \"Content-Type: application/json\" \t-d '{\n\"selector\": {\n\"$text\": \"Pacino\",\n\"year\": 2010\n}\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.ExplainResult;\nimport com.ibm.cloud.cloudant.v1.model.PostExplainOptions;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\nCloudant service = Cloudant.newInstance();\n\nMap<String, Object> selector = new HashMap<>();\nselector.put(\"$text\", \"Pacino\");\nselector.put(\"year\", 2010);\n\nPostExplainOptions explainOptions =\nnew PostExplainOptions.Builder()\n.db(\"movies\")\n.selector(selector)\n.build();\n\nExplainResult response =\nservice.postExplain(explainOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nimport { CloudantV1 } from '@ibm-cloud/cloudant';\n\nconst service = CloudantV1.newInstance({});\n\nlet selector: CloudantV1.Selector = {\n'$text': 'Pacino',\n'year': 2010\n};\n\nservice.postExplain({\ndb: 'movies',\nselector: selector\n}).then(response => {\nconsole.log(response.result);\n});", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-selector-expressions"}, {"document_id": "ibmcld_00539-6216-7731", "score": 0.4888264238834381, "text": "\nIf in doubt, use the [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.\n\nFor more information, see [Explain plans](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryexplain-plans).\n\n\n\n\n\n Can I use IBM Cloudant Query with a Lucene index? \n\nYes! IBM Cloudant Query supports two types of indexes:\n\n\n\n* \"type\": \"json\" - a fixed-order index powered by IBM Cloudant's MapReduce API. Good for fixed, boilerplate queries that match every term in the index.\n* \"type\": \"text\" - a Lucene index powered by IBM Cloudant's Search API. Good for general-purpose queries across one, some, or all indexed fields.\n\n\n\nA type=text index is created with an index definition like this:\n\n{\n\"index\": {\n\"fields\": [\n{ \"name\": \"firstname\", \"type\": \"string\"},\n{ \"name\": \"surname\", \"type\": \"string\"},\n{ \"name\": \"date\", \"type\": \"string\"}\n]\n},\n\"ddoc\": \"textindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"text\"\n}\n\nNotice that the fields array requires each attribute to be named and typed (unlike type=json indexes).\n\nThe resultant index can be used by queries that contain one or more of the indexed fields:\n\n{\n\"selector\": {\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_11164-6586-7646", "score": 0.4826572835445404, "text": "\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime"}, {"document_id": "ibmcld_00499-6096-7785", "score": 0.4736101031303406, "text": "\nIf two or more candidate indexes still exist, the index with the first alphabetical name is chosen.\n* If a json type index and a text type index might both satisfy a selector, the json index is chosen by default.\n* The text type index is chosen when the following conditions are met:\n\n\n\n* A json type index and a text type index exist in the same field (for example fieldone).\n* The selector can be satisfied only by using a text type index.\n\n\n\n\n\nFor example, assume that you have a text type index and a json type index for the field foo, and you want to use a selector similar to the following sample:\n\n{\n\"foo\": {\n\"$in\": [\"red\",\"blue\",\"green\"]\n}\n}\n\nIBM Cloudant Query uses the text type index because a json type index can't satisfy the selector.\n\nHowever, you might use a different selector with the same indexes:\n\n{\n\"foo\": {\n\"$gt\": 2\n}\n}\n\nIn this example, IBM Cloudant Query uses the json type index because both types of indexes can satisfy the selector.\n\nTo identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data. The details of the index in use are shown in the index object within the result.\n\nSee the following example that uses HTTP to show how to identify the index that was used to answer a query:\n\nPOST /movies/_explain HTTP/1.1\nHost: $SERVICE_URL\nContent-Type: application/json\n{\n\"selector\": {\n\"$text\": \"Pacino\",\n\"year\": 2010\n}\n}\n\nSee the following example that uses the command line to show how to identify the index that was used to answer a query:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"$SERVICE_URL/movies/_explain\" \t-X POST \t-H \"Content-Type: application/json\" \t-d '{\n\"selector\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-selector-expressions"}, {"document_id": "ibmcld_16670-7352-7811", "score": 0.47248172760009766, "text": "\ngosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_join_data"}, {"document_id": "ibmcld_11164-4529-7122", "score": 0.47241365909576416, "text": "\nFor more information about particular high availability and disaster recovery practices specific to each service or infrastructure option, refer the documentation for that service.\n\n\n\n\n\n High availability for the network \n\nExcept for the oldest pod that still has some single points of failure, the IBM Cloud network is designed in such a way that a single point of failure never happens. Diverse, redundant connectivity exists at every point of the network, by using diverse telecommunication providers for the same service connectivity whenever possible within each region. Diverse dark fiber providers are used to connect every edge site to all of the regional compute facilities. Each edge site additionally has redundant backbone connectivity into other regions, and peers with multiple providers, both directly and indirectly, through a local exchange. No single event should ever result in a service disruption that is noticed by our customers.\n\nYou can always choose to \"break\" having no single point of failure with how you order or configure your SoftLayer classic servers. For Direct Link, you must order redundant connections if you want full redundancy because it's not built-in or automatic.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location. For the console and platform services, there are no actions that you need to take to prepare for an event of a catastrophic failure in a region.\n\n\n\n Disaster recovery plan \n\nIBM Cloud follows best practices for disaster recovery. All IBM Cloud applications automatically recover and restart after any disaster event. Recovery is from electronic backups at a recovery center or alternative computing facilities that restore computing. Before any potential disaster, the disaster recovery plan includes the systems and hosting requirements for hardware, software, networking connectivity, and offsite backup capabilities.\n\nThe following list includes the requirements that IBM adheres to for a disaster recovery plan:\n\n\n\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime"}, {"document_id": "ibmcld_16666-11924-13606", "score": 0.4723722040653229, "text": "\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!/bin/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_hp_intro"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13481-6212-7871", "score": 0.7616052627563477, "text": "\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift://catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift://catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine-spark-integration-1.4.51.jar)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_13481-5443-6857", "score": 0.7539070248603821, "text": "\n.config(\"spark.hive.metastore.uris\", \"thrift://catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:///tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00029-8568-9861", "score": 0.7399786710739136, "text": "\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"/opt/ibm/jdk/lib/security/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:///opt/ibm/jdk/jre/lib/security/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"/opt/ibm/connectors/data-engine/hms-client/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:///tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos://mybucket.ALIAS NAME/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift://catalog.us.dataengine.cloud.ibm.com:9083.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_13481-1627-2985", "score": 0.7332453727722168, "text": "\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine. It also includes the convenience library to configure the connection to the Hive metastore. The following example shows a Spark batch job for a show tables example in Python:\n\nimport sys\nfrom dataengine import SparkSessionWithDataengine\n\nif __name__ == '__main__':\ncrn = sys.argv[1]\napikey = sys.argv[2]\n\nprint(\" Start SparkSessionWithDataengine example\")\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\n\nprint(\" Setup IBM Cloud Object Storage access\")\nspark = session_builder.appName(\"AnalyticEngine DataEngine integration\") \n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.getOrCreate()\n\nprint(\" Got a spark session, listing all tables\")\nspark.sql('show tables').show()\n\nspark.stop()\nShow more\n\nPrepare a JSON file to start that program, as in the following example (listTablesExample.json):\n\n{\n\"application_details\": {", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16635-0-1693", "score": 0.729292094707489, "text": "\n\n\n\n\n\n\n  HMS Overview \n\n\n\n  Hive Metastore \n\nHive Metastore (HMS) is a service that stores metadata related to Presto and other services in a backend Relational Database Management System (RDBMS) or Hadoop Distributed File System (HDFS).\n\nWhen you create a new table, information related to the schema such as column names, data types etc is stored in the metastore relational database. A metastore enables the user to see the data files in the HDFS object storage as if they are stored in tables with HMS.\n\nMetastore acts as a bridge between the schema of the table and the data files stored in object storages. HMS holds the definitions, schema, and other metadata for each table and maps the data files and directories to the table representation which is viewed by the user. Therefore, HMS is used as a storage location for the schema and tables. HMS is a metastore server that connects to the object storage to store data and keeps its related metadata on PostgreSQL.\n\nAny database with a JDBC driver can be used as a metastore. Presto makes requests through thrift protocol to HMS. The Presto instance reads and writes data to HMS. HMS supports 5 backend databases as follows. In IBM\u00ae watsonx.data, PostgreSQL database is used.\n\n\n\n*  Derby\n*  MySQL\n*  MS SQL Server\n*  Oracle\n*  PostgreSQL\n\n\n\nCurrently HMS in watsonx.data supports Iceberg table format.\n\nFollowing three modes of deployment are supported for HMS. In watsonx.data the remote mode is used.\n\n\n\n*  Embedded Metastore - Derby with singe session.\n*  Local Metastore - MySQl with multiple session accessible locally.\n*  Remote Metastore - metastore runs on its own separate JVM and accessible via thrift network APIs.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hms_overview"}, {"document_id": "ibmcld_13481-7-1988", "score": 0.7272180318832397, "text": "\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16636-0-1664", "score": 0.7154108285903931, "text": "\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside /opt/presto/etc/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift://<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hudi-conn"}, {"document_id": "ibmcld_00032-0-1390", "score": 0.7148512601852417, "text": "\n\n\n\n\n\n\n  Working with Spark SQL and an external metastore \n\nSpark SQL uses Hive metastore to manage the metadata of a user's applications tables, columns, partition information.\n\nBy default, the database that powers this metastore is an embedded Derby instance that comes with the Spark cluster. You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n\nPlacing your metadata outside of the Spark cluster will enable you to reference the tables in different applications across your IBM Analytics Engine instances. This, in combination with storing your data in IBM Cloud Object Storage, helps persisting data and metadata and allows you to work with this data seamlessly across different Spark workloads.\n\n\n\n  Enabling and testing an external metastore with IBM Analytics Engine \n\nTo enable and test an external metastore with IBM Analytics Engine, you need to perform the following steps:\n\n\n\n1.  Create a metastore to store the metadata. You can choose to provision either an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n2.  Configure IBM Analytics Engine to work with the database instance.\n3.  Create a table in one Spark application and then access this table from another Spark application.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-external-metastore"}, {"document_id": "ibmcld_13481-7434-8879", "score": 0.7144527435302734, "text": "\nThe SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine-spark-integration-1.4.51.jar)\n* [spark-dataengine-python](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine_spark-1.4.51-py3-none-any.whl)\n\n\n\nAn example of how to use the Python helper can be found in the [Watson Studio Notebooks section](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastoreusage_watson_notebooks).\n\nUse the following example to get started with IBM\u00ae Analytics Engine (IAE) or Spark runtimes in Watson Studio when using Scala. Submit the following application using a notebook or the spark-submit command:\n\npackage com.ibm.cloud.dataengine\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession.{Builder => SessionBuilder}\nimport SparkSessionBuilderAddOn._\nobject SparkSessionBuilderHMSConfigTest {\ndef main(args: Array[String]) = {\nval spark = SparkSession\n.builder()\n.appName(\"Spark DataEngine integration\")\n.enableDataengine(args(0), args(1), \"public\")\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\n.config(\"fs.stocator.scheme.list\", \"cos\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_13481-3545-4909", "score": 0.6929629445075989, "text": "\ncurl -X POST https://api.us-south.ae.cloud.ibm.com/v3/analytics_engines/<GUID of Analytic Engine>/spark_applications --header \"Authorization: Bearer $TOKEN\" -H \"content-type: application/json\" -d @listTablesExample.json\n\n\n\n\n\n Apache Spark Data Engine integration \n\nFor self-hosted Apache Spark installations use the following instructions.\n\n\n\n1. Ensure that [Stocator](https://github.com/CODAIT/stocator) is installed according to the instructions provided.\n2. Download the Hive-compatible client with the provided [instructions](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n3. Either download the [provided convenience libraries](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastoreconvenience_libraries) or, in case you don't want to use them, set the following settings in SparkContext yourself:\n\nspark = SparkSession.builder.appName('Python-App') \n.config(\"spark.sql.pyspark.jvmStacktrace.enabled\", True) \n.config(\"spark.hive.metastore.truststore.path\", \"file:///opt/ibm/jdk/jre/lib/security/cacerts\") \n to access IBM Cloud Object Storage ensure that stocator is available\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03798-0-2240", "score": 0.695706844329834, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_02597-4595-6892", "score": 0.6916458606719971, "text": "\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_07578-1042894-1044946", "score": 0.6763913035392761, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1042765-1044817", "score": 0.6763912439346313, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16252-7-1601", "score": 0.6757787466049194, "text": "\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https://www.ibm.com/cloud/watson-assistant/pricing/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/plus.png)\n\n\n\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https://cloud.ibm.com/apidocs/assistant/assistant-v2listlogs)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan"}, {"document_id": "ibmcld_03107-4-1607", "score": 0.6750543117523193, "text": "\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https://www.ibm.com/cloud/watson-assistant/pricing/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png)\n\n\n\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_02597-3131-5174", "score": 0.674706757068634, "text": "\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/images/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_03704-1531-3564", "score": 0.6702122688293457, "text": "\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_01705-7074-9036", "score": 0.6664997339248657, "text": "\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https://cloud.ibm.com/docs/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accounts"}, {"document_id": "ibmcld_16252-10129-10965", "score": 0.6599482297897339, "text": "\nAn Enterprise with Data Isolation plan instance must be provisioned for you first.\n* When you upgrade from a legacy Standard plan, you change the metrics that are used for billing purposes. Instead of basing billing on API usage, the Plus plan bases billing on the number of monthly active users. If you built a custom app to deploy your assistant, you might need to update the app. Ensure that the API calls from the app include user ID information. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n* You cannot change from a Trial plan to a Lite plan.\n\n\n\n\n\nFor answers to common questions about subscriptions, see the [How you're charged](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03735-1425-3233", "score": 0.7542135119438171, "text": "\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_03735-7-1918", "score": 0.7370725870132446, "text": "\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_01623-6277-8255", "score": 0.713272213935852, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_04260-0-1777", "score": 0.703718364238739, "text": "\n\n\n\n\n\n\n  Using the Pricing calculator to estimate your monthly cost per user per month \n\nThe pricing information for your system resources is shown on the side of the provisioining window and shows all of your equipment and physical resource costs. To view the cost estimates for your organization on a per user basis, use the pricing calculator. You can get estimates for different configurations before you begin provisioning. The pricing calculator is on the DaaS estimate tab on the main Citrix-DaaS product page.\n\n\n\n  What the pricing calculator does \n\nThe pricing calculator looks at several factors to estimate your cost and savings with different Citrix-DaaS configurations:\n\n\n\n1.  The geographic area and region where your resources are located.\n2.  The number of users that use your system.\n3.  The operating system that your system uses.\n4.  The boot volume size on your system.\n5.  The profile settings for your system, including the image to use, CPU, RAM, etc.\n\n\n\nThe calculator takes the inputs and creates a per user estimate for your configuration.\n\n\n\n\n\n  Calculating cost per user for your system \n\nTo calculate the cost per users for your Citrix-DaaS configuration:\n\n\n\n1.  From the Citrix-DaaS product page, select the DaaS estimate tab. The pricing calculator is shown.\n2.  Enter the geographic, user, OS, and boot volume information for your system.\n3.  Verify that the profile settings listed match your system or match the system that you are estimating. If they do not match, select Change Profile to enter the correct profile information.\n\n\n\nThe calculator shows you the cost estimate per user for your system.\n\nIf you want to see estimates for different profiles, or different numbers of users, modify the specific fields to see new estimates.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/citrix-daas?topic=citrix-daas-pricing-calculator-monthly-cost"}, {"document_id": "ibmcld_11163-81224-83154", "score": 0.7005176544189453, "text": "\n: To help you decide and analyze what services you'd like to purchase, you can use the cost estimator. Now, you can go through the console and select each service you'd like to have, and add all of the costs in an easy to use tool. You can even enter projected data usages, lookups per second, writes per second, and queries per second to get a more accurate estimation of your monthly expenditures. You can use the cost estimator with each catalog service you select, or you can click the Cost Estimator icon ![Cost Estimator icon](https://cloud.ibm.com/docs-content/v1/content/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef/overview/icons/calculator.svg) in the console menu to get a summary of your estimated costs. For more information, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\n\n\n\n\n 01 November 2018 \n\nUpdated global location names\n: As IBM Cloud continues to expand our global availability footprint, we\u2019re updating our location naming structure to better support an understandable, consistent hierarchy of geographies, regions, and data centers around the world. If you\u2019re familiar with our current global regions, you\u2019ll recognize names like US South and Sydney. We\u2019re aligning these location names to the names of the city in which the data centers physically exist.\n\nFor now, the programmatic IDs are not changing, so there\u2019s no impact from an API perspective. The following table shows the old and new location names. For more information and a comprehensive list of data centers and regions, see [Service availability](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\nTable 1. New location names\n\n Previous Location Display Name New Location Display Name Code \n\n US South Dallas us-south \n US East Washington DC us-east \n United Kingdom London eu-gb \n Germany Frankfurt eu-de \n Sydney Sydney au-syd \n AP North Tokyo jp-tok \n\n\n\n\n\n\n\n\n\n October 2018", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-whatsnew"}, {"document_id": "ibmcld_12539-0-2074", "score": 0.6794376969337463, "text": "\n\n\n\n\n\n\n  Estimating architecture costs in a project \n\nCost estimation is available for deployable architectures in the IBM Cloud catalog. Depending on the deployable architecture, a starting cost is estimated based on the available data. This estimate is meant to be a starting point to help you determine how much your account could be charged for deploying an architecture. This estimated amount is subject to change as the architecture is customized within a project, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n  Viewing the starting cost for your deployable architecture \n\nDepending on the deployable architecture that you select from the catalog, there is an estimated starting cost.\n\nTo view the estimated starting cost, complete the following steps:\n\n\n\n1.  Go to the catalog details page for the deployable architecture.\n2.  Next, click the Starting at amount for additional details about the cost summary.\n\n\n\nAfter you add the deployable architecture to your project, you can configure the input values. By doing so, you can tailor the architecture to match your needs. Adjusting the configuration input might adjust the estimated cost.\n\n\n\n1.  Go to the Projects page, and select a project.\n2.  Go to Configurations, and select a configuration of the deployable architecture.\n3.  Enter the input values to configure the deployable architecture, and click Save. For more information about configuring and deploying, see [Configuring and deploying a deployable architecture](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-config-project).\n4.  After saving, the validation checks are run and a new cost estimate is computed. This might take a few minutes. After the validation is complete, you can view the estimated cost for the configured architecture on the validation modal in the Cost estimate successful section.\n\n\n\nThis estimated amount is subject to change as the architecture is customized and deployed, and it does not include all resources, usage, licenses, fees, discounts, or taxes.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-cost-estimate-project"}, {"document_id": "ibmcld_07578-275933-277579", "score": 0.6765274405479431, "text": "\nFor more information, see [Pricing](https://cloud.ibm.com/docs/satellite?topic=satellite-sat-pricing).\n* Can I estimate my costs?\n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n* What are the terms of the service level agreement?\n\nSee the [IBM Cloud terms of service](https://cloud.ibm.com/docs/overview?topic=overview-slas) and the [Satellite additional service description](http://www.ibm.com/software/sla/sladb.nsf/sla/bm-8913-01).\n\nSatellite Infrastructure Service is IBM-operated and as such, is covered in the IBM Cloud Satellite cloud service terms with additional information outlined in the [IBM Cloud Additional Services Description](http://www.ibm.com/support/customer/csol/terms/?id=i126-8979).\n* What compliance standards does the service meet?\n\nIBM Cloud is built by following many data, finance, health, insurance, privacy, security, technology, and other international compliance standards. For more information, see [IBM Cloud compliance](https://cloud.ibm.com/docs/overview?topic=overview-compliance).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-275907-277553", "score": 0.6765274405479431, "text": "\nFor more information, see [Pricing](https://cloud.ibm.com/docs/satellite?topic=satellite-sat-pricing).\n* Can I estimate my costs?\n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n* What are the terms of the service level agreement?\n\nSee the [IBM Cloud terms of service](https://cloud.ibm.com/docs/overview?topic=overview-slas) and the [Satellite additional service description](http://www.ibm.com/software/sla/sladb.nsf/sla/bm-8913-01).\n\nSatellite Infrastructure Service is IBM-operated and as such, is covered in the IBM Cloud Satellite cloud service terms with additional information outlined in the [IBM Cloud Additional Services Description](http://www.ibm.com/support/customer/csol/terms/?id=i126-8979).\n* What compliance standards does the service meet?\n\nIBM Cloud is built by following many data, finance, health, insurance, privacy, security, technology, and other international compliance standards. For more information, see [IBM Cloud compliance](https://cloud.ibm.com/docs/overview?topic=overview-compliance).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_11857-1988-2975", "score": 0.6671180129051208, "text": "\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https://cloud.ibm.com/docs/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-sat-pricing"}, {"document_id": "ibmcld_02301-4342-5268", "score": 0.6618199944496155, "text": "\nIf you're not sure how much your typical usage might cost, you can estimate it by using the [cost estimator](https://cloud.ibm.com/estimator/review).\n3. Review your subscription details, and then enter your payment information.\n\nAfter your payment information is processed, your subscription credit is added to your account. You can monitor your subscription usage on this same Subscriptions page. See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\n\n\nYour subscription renews automatically. If you want to discontinue your subscription renewal, [contact support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Converting a Pay-As-You-Go account to a Subscription account \n\nYou can convert your Pay-As-You-Go account to a Subscription account at any time. Contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to get started.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-upgrading-account"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03729-7-2197", "score": 0.6635029911994934, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_03797-4528-6268", "score": 0.6622517108917236, "text": "\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_03798-0-2240", "score": 0.6564056277275085, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_16315-6754-8418", "score": 0.6397730708122253, "text": "\n\"card_title\": \"Let\u2019s dispute a charge\",\n\"card_description\": \"Follow along with this guided journey to learn how to find and dispute charges.\",\n\"user_defined_type\": \"IBM_BETA_JOURNEYS_TOUR\",\n\"steps\":\n{\n\"response_type\": \"text\",\n\"text\": \"Charges are listed on the Transactions page. Click your profile photo in the top right corner of your screen, and then click Transactions from the menu.\"\n},\n{\n\"response_type\": \"text\",\n\"text\": \"Here you can view your charges.n Scroll through the Transactions page and review your charges. Each charge contains a merchant name, transaction date, and amount charged.\"\n},\n{\n\"response_type\": \"image\",\n\"source\": \"https://example.com/image.png\",\n\"alt_text\": \"Image showing location of Dispute option\",\n\"description\": \"The option to Dispute is marked in red on the right hand side of each row in the Transactions table. Just click here to file a dispute.\"\n},\n{\n\"response_type\": \"video\",\n\"source\": \"https://vimeo.com/769580398\",\n\"description\": \"Watch this short video to learn what to expect now that you\u2019ve filed a dispute.\"\n}\n]\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Starting a journey without opening the web chat \n\nAlthough journeys are part of the web chat integration, you can make it possible for your customers to start a journey directly from your website without opening the web chat window at all. For example, you might want to include a Show me button on your website that customers can click to launch an interactive tour of the page.\n\nTo start a journey without opening the web chat:\n\n\n\n1. In the action that sends the journey response, edit the JSON that defines the journey. Include \"skip_card\": true to bypass the introductory card.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-journeys"}, {"document_id": "ibmcld_07578-1033424-1035350", "score": 0.6304155588150024, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1033295-1035221", "score": 0.6304155588150024, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03797-5893-7322", "score": 0.6258212924003601, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage),", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}, {"document_id": "ibmcld_03794-0-812", "score": 0.6151442527770996, "text": "\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-charge-limit"}, {"document_id": "ibmcld_11408-13151-14243", "score": 0.6151401996612549, "text": "\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https://cloud.ibm.com/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_03797-3428-4809", "score": 0.5992644429206848, "text": "\n[Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https://cloud.ibm.com/billing/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/billing-usage/images/example-invoice-console.png)\n\nFigure 3.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05171-35863-37705", "score": 0.6109464168548584, "text": "\nThe main difference is we are routing HTTP GET requests rather than POST, and sending all the output in the response from getGalleryImages, which is exposed by the galleryController on the last line of the example.\n\nvar express = require('express');\nvar galleryRouter = express.Router();\n\nvar router = function(title) {\n\nvar galleryController =\nrequire('../controllers/galleryController')(title);\n\ngalleryRouter.route('/')\n.get(galleryController.getGalleryImages);\n\nreturn galleryRouter;\n};\nmodule.exports = router;\n\nWe next turn our attention to the controller for the gallery.\n\nNote how we set up the multer upload, which truncates some code we ignore for now. We require modules ibm-cos-sdk, multer, and multer-s3. The code shows how to configure an S3 object that points to an Object Storage server endpoint. We are statically setting values such as the endpoint address, region, and bucket for simplicity, but they might easily be referenced from an environment variable or JSON configuration file.\n\nWe define upload in the imageUploadRouter by creating a new multer instance with storage as its only property. This property tells the multer where to send the file from our multipart/form-data. Since the IBM Cloud Platform uses an implementation of the S3 API, we set storage to be an s3-multer object. This s3-multer object contains an s3 property that is assigned to our s3 object. There is also a bucket property that is assigned to the myBucket variable, which in turn is assigned a value of web-images. The s3-multer object now has all the data necessary to upload files to our Object Storage bucket when it receives data from the upload form. The name (or key) of the uploaded object is the original file name.\n\nUse a time stamp as part of the file name to maintain file name uniqueness.\n\nvar galleryController = function(title) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-web-application"}, {"document_id": "ibmcld_04709-7-2265", "score": 0.6100718379020691, "text": "\nComparing IBM Cloud Classic and VPC infrastructure environments \n\nCompare the key differences between IBM Cloud\u00ae infrastructure environments to decide which one is best for your workloads and applications. Check out this [video](https://mediacenter.ibm.com/media/IBM%20Bare%20Metal%20Servers%20-%20Classic%20vs.%20VPC%20Infrastructure%20Explainer%20Video/1_hn1d69nn) to learn more about the differences between the Classic and VPC infrastructures.\n\nIf you aren't familiar with the environment types, review the following descriptions.\n\n\n\n* Classic infrastructure is our existing IaaS platform. This environment is best for lift and shift workloads so you can move applications quickly and keep the same architecture.\n* VPC infrastructure is our new IaaS platform, based on software-defined networking and ideal for cloud-native applications.\n\n\n\nClassic infrastructure and VPC infrastructure are cost neutral, so you can focus on what environment best meets your needs.\n\n\n\n Compute differentiators \n\nSee the following table for the compute differences between classic and VPC.\n\n\n\nTable 1. Compute comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, go to the row and find the details for the feature that you're interested in.\n\n Category Classic Infrastructure VPC Infrastructure \n\n Services Full catalog of services, such as Bare Metal Servers, Virtual Servers instances, VMware, SAP Virtual Servers and Bare Metal Servers \n Performance and availability Better availability achievable through zone architecture \n Pricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"}, {"document_id": "ibmcld_04543-123733-125151", "score": 0.609210729598999, "text": "\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound. Must be false if the reserved IP is unbound. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-delete \n\nRelease one or more reserved IPs.\n\nibmcloud is subnet-reserved-ip-delete SUBNET (RESERVED_IP1 RESERVED_IP2 ...) [--vpc VPC] [-f, --force] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP1: ID or name of the reserved IP.\n* RESERVED_IP2: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --force, -f: Force the operation without confirmation.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private clouds \n\n\n\n ibmcloud is vpc \n\nView details of a VPC.\n\nibmcloud is vpc VPC [--show-attached] [--output JSON] [-q, --quiet]\n\n\n\n Command options", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-vpc-reference"}, {"document_id": "ibmcld_15545-123837-125255", "score": 0.609210729598999, "text": "\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound. Must be false if the reserved IP is unbound. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-delete \n\nRelease one or more reserved IPs.\n\nibmcloud is subnet-reserved-ip-delete SUBNET (RESERVED_IP1 RESERVED_IP2 ...) [--vpc VPC] [-f, --force] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP1: ID or name of the reserved IP.\n* RESERVED_IP2: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --force, -f: Force the operation without confirmation.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private clouds \n\n\n\n ibmcloud is vpc \n\nView details of a VPC.\n\nibmcloud is vpc VPC [--show-attached] [--output JSON] [-q, --quiet]\n\n\n\n Command options", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"}, {"document_id": "ibmcld_15558-123889-125307", "score": 0.609210729598999, "text": "\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound. Must be false if the reserved IP is unbound. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-delete \n\nRelease one or more reserved IPs.\n\nibmcloud is subnet-reserved-ip-delete SUBNET (RESERVED_IP1 RESERVED_IP2 ...) [--vpc VPC] [-f, --force] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP1: ID or name of the reserved IP.\n* RESERVED_IP2: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --force, -f: Force the operation without confirmation.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private clouds \n\n\n\n ibmcloud is vpc \n\nView details of a VPC.\n\nibmcloud is vpc VPC [--show-attached] [--output JSON] [-q, --quiet]\n\n\n\n Command options", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"}, {"document_id": "ibmcld_16082-123733-125151", "score": 0.609210729598999, "text": "\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound. Must be false if the reserved IP is unbound. One of: true, false.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-delete \n\nRelease one or more reserved IPs.\n\nibmcloud is subnet-reserved-ip-delete SUBNET (RESERVED_IP1 RESERVED_IP2 ...) [--vpc VPC] [-f, --force] [--output JSON] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP1: ID or name of the reserved IP.\n* RESERVED_IP2: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --force, -f: Force the operation without confirmation.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n\n\n Virtual private clouds \n\n\n\n ibmcloud is vpc \n\nView details of a VPC.\n\nibmcloud is vpc VPC [--show-attached] [--output JSON] [-q, --quiet]\n\n\n\n Command options", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-reference"}, {"document_id": "ibmcld_04709-1717-3966", "score": 0.6050409078598022, "text": "\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"}, {"document_id": "ibmcld_15545-123006-124212", "score": 0.5977250933647156, "text": "\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-update \n\nUpdate a reserved IP.\n\nibmcloud is subnet-reserved-ip-update SUBNET RESERVED_IP [--vpc VPC] [--name NEW_NAME] [--auto-delete true | false] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update my-subnet my-reserved-ip --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --auto-delete false\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2 --output JSON\n\n\n\n\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"}, {"document_id": "ibmcld_04543-122902-124108", "score": 0.5977250337600708, "text": "\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-update \n\nUpdate a reserved IP.\n\nibmcloud is subnet-reserved-ip-update SUBNET RESERVED_IP [--vpc VPC] [--name NEW_NAME] [--auto-delete true | false] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update my-subnet my-reserved-ip --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --auto-delete false\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2 --output JSON\n\n\n\n\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-vpc-reference"}, {"document_id": "ibmcld_15558-123058-124264", "score": 0.5977250337600708, "text": "\n--------------------\n\n\n\n\n\n\n\n ibmcloud is subnet-reserved-ip-update \n\nUpdate a reserved IP.\n\nibmcloud is subnet-reserved-ip-update SUBNET RESERVED_IP [--vpc VPC] [--name NEW_NAME] [--auto-delete true | false] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update my-subnet my-reserved-ip --name my-reserved-ip2\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --auto-delete false\n* ibmcloud is subnet-reserved-ip-update 2201-3f2e33d4-2140-44b4-843c-d73e03d585f1 2201-7fc11925-47ff-4080-a314-be64c662c302 --name my-reserved-ip2 --output JSON\n\n\n\n\n\n\n\n Command options \n\n\n\n* SUBNET: ID or name of the subnet.\n* RESERVED_IP: ID or name of the reserved IP.\n* --vpc: ID or name of the VPC. It is only required to specify the unique resource by name inside this VPC.\n* --name: The new name of the reserved IP.\n* --auto-delete: Indicates whether this reserved IP member automatically deletes when either target is deleted, or the reserved IP is unbound.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03735-1425-3233", "score": 0.7110859155654907, "text": "\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_12858-3912-5854", "score": 0.7015686631202698, "text": "\n8. Select the broker that you want to link to this plan. If you haven't added a broker to your account, you can't link a broker to your plan. After you add a broker, you can link it by editing the pricing plan.\n9. Click Save.\n10. Click Add metrics.\n11. In the Usage metrics section, click Add metrics.\n12. Enter 1 as the smallest unit that customers pay.\n13. Select Instance as the unit.\n14. Enter Instance as the display name for the unit.\n15. Select Per unit as the charge method.\n16. Enter 1 as the USD price.\n17. Click Done.\n18. When you are ready to submit your pricing plan and metering for review, click Request update.\n\n\n\n\n\n\n\n Step 5: Add features for your service \n\nIf you completed the steps to define your pricing plan, you can add a list of features for your service. These features uniquely identify your product's attributes and differentiate your pricing plan from others. By providing a list of features for your product, you can help customers choose the most suitable pricing plan for their use case.\n\nYou can add up to five features for your product, but you must add at least one. The first feature that you add appears more prominently. Include the most important and differentiating details as the first feature.\n\nTo add features for your service, complete the following steps:\n\n\n\n1. Click Pricing.\n2. Select a pricing plan from the table that you previously added. After you select a plan, you are redirected to the Pricing plan details page.\n3. Click Add features.\n4. Enter a description for each feature.\n\n\n\n* You can remove any feature that you add by clicking Remove feature.\n\n\n\n5. Click Save.\n\n\n\n\n\n\n\n Step 6: Review and submit the digital platform reseller agreement \n\nIf you plan to offer usage-based pricing plans, it is required to review and submit the IBM Digital Platform Reseller Agreement. This legal agreement sets the terms and conditions under which providers can onboard and sell products in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-svc-pricing"}, {"document_id": "ibmcld_03727-4-1792", "score": 0.7010937929153442, "text": "\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Updating your pricing plan \n\nYou can update the pricing plan of an IBM Cloud\u00ae service if plan updates are enabled for that specific service. For example, you might want to upgrade or reduce your pricing plan. You can update the service's pricing plan from the service instance dashboard.\n\nAre you looking for details about upgrading your account type? See [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) for more information.\n\nYou can update the pricing plan only for certain services. If plan updates are enabled for the service, a Plan option is displayed on the service instance dashboard. Each service has a different set of steps to follow if you update your plan.\n\n\n\n Updating a plan in the console \n\n\n\n1. From the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/icon_hamburger.svg) > Resource List, and select the service.\n2. Click Plan in the service instance dashboard. Select the pricing plan that you want, and click Save.\n\nSome services have pricing plans that are not selectable from the Plan page. Typically, these plans aren't selectable because they require assistance from the IBM Cloud Sales team or they require a migration before you can update plans. See the documentation for the specific service for information about the required next steps.\n\n\n\nDepending on the type of plan updates you make, your next steps can vary. For example, if you reduced the pricing plan, restart your app. Or, if you upgraded the pricing plan, you might need to restart your app, and then take other actions.\n\nComplete the following steps to restart your app:\n\n\n\n1. Click the Navigation Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-changing"}, {"document_id": "ibmcld_12815-5234-7392", "score": 0.6891961097717285, "text": "\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-get-started"}, {"document_id": "ibmcld_01623-6277-8255", "score": 0.672982931137085, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_12407-4383-5026", "score": 0.6690242290496826, "text": "\nTo update your service plan after you create an instance, see [Updating your service plan](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-changing).\n\n\n\n\n\n Upgrading a Secrets Manager instance to the Standard plan \n\nWhen your Trial instance expires, you lose access to your secrets, and integrations. To preserve your data, and prevent any disruptions in your workflow, you must upgrade to the Standard plan before your Trial plan expires. Follow the steps to [update your pricing plan](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-changing&interface=ui). You can use the UI, API, and CLI to complete this process.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-create-instance&interface=ui"}, {"document_id": "ibmcld_12838-9061-11120", "score": 0.6579793691635132, "text": "\nDescribe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't submit your pricing plan for approval until the broker is linked.\n9. Click Save.\n\n\n\nBefore you can submit your pricing plan for approval, you must complete the following tasks:\n\n\n\n* If you had to skip the step to link your broker to the plan because you didn't have one yet, start to develop your broker, and come back to link it to your plan when you're done.\n* [Add metrics to your plan](https://cloud.ibm.com/docs/sell?topic=sell-service-add-metrics) to determine how customers are charged, and request metering approval.\n* [Add plan features](https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-infoservice-add-feature) to describe why a customer might want to choose a specific plan.\n* When your metrics are approved, you can test the pricing and usage from a customer's perspective and provide evidence from your testing to get the final approval for your pricing plan.\n\n\n\n\n\n\n\n Listing pricing plan features \n\nIf you completed the steps to define your pricing plan, you can add a list of features for the plan. These features uniquely identify your product's attributes and differentiate your pricing plan from others. By providing a list of features for your product, you can help customers choose the most suitable pricing plan for their use case.\n\nYou can add up to five features for your product, but you must add at least one. The first feature that you add appears more prominently. Include the most important and differentiating details as the first feature.\n\nTo add features for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon !", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}, {"document_id": "ibmcld_12850-1472-3281", "score": 0.6542119979858398, "text": "\n[Enter the United Nations Standard Products and Services Code (UNSPSC)](https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-infoservice-unspsc)\n4. [Add a paid pricing plan](https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-infoadd-plan-paid)\n5. [Confirm the digital platform reseller agreement](https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-infodra)\n\n\n\n\n\n\n\n Adding metrics to your pricing plan \n\nIf you offer a paid integrated product and add a paid pricing plan that requires customers to pay for their usage, you must add metrics to your pricing plan to aggregate your product's usage. After you add metrics to your plan, you must request an initial metering approval, so you can submit your resource usage and start reviewing your metrics.\n\nTo add metrics to your pricing plan, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select a usage-based plan from the table and click Add metrics.\n4. In the Usage metrics section, click Add metrics.\n5. Complete the required fields.\n6. Click Done.\n7. To submit your pricing plan and metering for review, click Request approval in the Metering approval section.\n\n\n\n\n\n\n\n Submitting resource usage to the IBM Cloud Usage Metering API \n\nTo review how customers understand and experience your pricing plan, and validate that your metered plans are correctly configured, you must submit your resource usage. Submitting your resource usage includes creating your metering JSON, calling the Usage Metering API, and providing the evidence of your testing.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-submitusage"}, {"document_id": "ibmcld_12838-3128-5008", "score": 0.6480704545974731, "text": "\nIf you need to update your ECCN after you add it, you must contact IBM Cloud Support.\n\nYou must submit your tax and EFT documents and receive approval before you can provide the ECCN if you're using a usage-based pricing plan.\n\n\n\n1. Go to Partner Center > Sell > My products.\n2. Open the service that you want to edit and go to the Pricing tab.\n3. Click Enter your ECCN and provide the ECCN for your service.\n4. Click Save.\n\n\n\n\n\n\n\n Providing the UNSPSC \n\nYou must provide your ECCN before the UNSPSC.\n\nIn addition to ECCN, you must provide the UNSPSC that applies to your product. The UNSPSC is required for both free and usage-based pricing plans. If you need help with selecting the UNSPSC for your service, see [How to select UNSPSC codes?](https://help.ungm.org/hc/en-us/articles/360013132940-How-to-select-UNSPSC-codes-). Providing your UNSPSC is a required step in the onboarding process.\n\nTo provide the UNSPSC code that applies to your product, complete the following steps:\n\n\n\n1. Go to Partner Center > Sell > My products.\n2. Open the service that you want to edit and go to the Pricing tab.\n3. Click Add UNSPSC and select the UNSPSC code for your service.\n4. Click Save.\n\n\n\n\n\n\n\n Accepting agreement terms and conditions \n\nDepending on the type of plans you are adding for your product, you must sign an agreement that outlines the terms and conditions of providing a product in the IBM Cloud. Or, you can upload a custom digital provider agreement in .pdf, .doc, or .docx file format.\n\nCustom digital provider agreements must be reviewed and approved by IBM, which increases the time it takes for you to complete the onboarding process. The uploaded files are scanned for viruses, which might take a few minutes to complete. If a virus is detected, it is recommended to run another virus scan on your file, and then try uploading it again.\n\n\n\n Digital provider agreement", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}, {"document_id": "ibmcld_12838-7607-9492", "score": 0.6443822979927063, "text": "\nAll plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Link a broker to the plan.\n\nIf you haven't finished adding a broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't complete your pricing plan until the broker is added and linked to your plan.\n9. Click Save.\n\n\n\n\n\n\n\n Adding a paid pricing plan \n\nBy adding a usage-based pricing plan, you are indicating that you offer your product as a paid integrated product, and customers need to pay to use it. All information that is entered on the Add plan panel is displayed to customers in the IBM Cloud catalog to help them purchase your service.\n\nWhen you add a usage-based pricing plan, you provide your suggested retail pricing information. However, IBM reserves the right to set the final pricing for any product that is offered to customers in the IBM Cloud catalog.\n\nTo add a paid pricing plan for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Click Add plan.\n4. Select Usage-based.\n5. Enter a name for your plan.\n6. Describe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-1033424-1035350", "score": 0.740024209022522, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1033295-1035221", "score": 0.740024209022522, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_08067-0-1736", "score": 0.7229182124137878, "text": "\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support"}, {"document_id": "ibmcld_08056-3796-5774", "score": 0.6424997448921204, "text": "\nTo upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https://cloud.ibm.com/user/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-get-supportfaq"}, {"document_id": "ibmcld_03729-7-2197", "score": 0.6374726295471191, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_05428-7-1872", "score": 0.6159390211105347, "text": "\nPricing for Code Engine \n\nIBM Cloud\u00ae Code Engine is different from traditional cloud computing technologies, you pay for only the resources that you use. You are billed for the memory and vCPU that your workloads consume, as well as any incoming HTTP calls. If your app scales to zero or your job or build isn't running, you are not consuming resources and so you are not charged.\n\nCode Engine includes a free tier so that you can experiment with Code Engine before you commit.\n\nYou are billed for the following entities,\n\n\n\n* [Applications](https://cloud.ibm.com/docs/codeengine?topic=codeengine-pricingapp-pricing)\n* [Job runs](https://cloud.ibm.com/docs/codeengine?topic=codeengine-pricingjob-pricing)\n* [Build runs](https://cloud.ibm.com/docs/codeengine?topic=codeengine-pricingbuild-pricing)\n\n\n\nEntities such as [projects](https://cloud.ibm.com/docs/codeengine?topic=codeengine-manage-project) do not incur charges, but instead serve as a folder for your entities. Entities such as secrets, bindings, or subscriptions do not incur charges, but do contribute to the overall limits of your project. For more information, see [Limits and quotas for Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-limits).\n\nThe costs that are provided in this topic are guidelines and do not represent actual costs. They represent a starting point for estimates of costs that are incurred in environments with a similar configuration. Actual costs can vary by geography. For the most up-to-date prices, see [Code Engine pricing](https://www.ibm.com/cloud/code-engine/pricing).\n\n\n\n Application pricing \n\nWhen you deploy an application, charges apply for HTTP requests and for the CPU and memory resources that are consumed by running instances of the application. Incoming HTTP calls are billed by the number of HTTP calls that are received by your application.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-pricing"}, {"document_id": "ibmcld_08474-7-1664", "score": 0.6122302412986755, "text": "\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_11730-5345-7171", "score": 0.6103924512863159, "text": "\nMany extra software packages require access to or from the host, so extra software packages are not allowed to be installed.\n\nMaintenance: IBM provides software updates that you choose when to apply to the host. Because IBM is responsible for providing these updates, you cannot install extra software that is not managed by IBM. Extra software also uses mores CPU, memory, and disk storage resources on the host, which impacts the amount available to your Satellite-enabled IBM Cloud services and applications that run on the hosts.\n\n\n\n\n\n What am I charged for when I use IBM Cloud Satellite? \n\nIBM Cloud Satellite provides a convenient way for you to consume IBM Cloud services in any location that you want, with visibility across your locations. For more information, see [Pricing](https://cloud.ibm.com/docs/satellite?topic=satellite-sat-pricing).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\n\n\n What are the terms of the service level agreement? \n\nSee the [IBM Cloud terms of service](https://cloud.ibm.com/docs/overview?topic=overview-slas) and the [Satellite additional service description](http://www.ibm.com/software/sla/sladb.nsf/sla/bm-8913-01).", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-faqs"}, {"document_id": "ibmcld_11483-1714-3878", "score": 0.6074250936508179, "text": "\nThe time your job takes (and therefore, its cost) depends on how many iterations you make in a session and how many shots are run in each iteration. Thus, you can manage your cost by running only as many iterations and shots as you need.\n\nAdditionally, an instance administrator can limit how much is spent. To set cost limits, navigate to the [IBM Cloud Instances page](https://cloud.ibm.com/quantum/instances) then click the instance and set the Cost limit.\n\nThe instance's cost limit refers to the total cost of all jobs run with this instance since it was created, and it will always be greater than or equal to the Total cost. After the instance reaches the specified limit, no further jobs can be run and no more cost is incurred.\n\nThe cost limit is always specified in US dollars (USD), then converted to runtime seconds. However, for monthly billing purposes, you are charged in your local currency, specified on your IBM Cloud account. Because currency exchange rates can fluctuate, the cost for X runtime seconds might be different when initially calculated in USD than when you're actually charged in your local currency. As a result, if your local currency is not USD, the total amount charged for the number of seconds specified in this field could vary from the dollar amount you specify.\n\n\n\n\n\n How to remove a cost limit \n\nAn instance administrator can remove the cost limit. To do so, navigate to the [IBM Cloud Instances page](https://cloud.ibm.com/quantum/instances), then open the instance and click the edit button by the Cost limit. Delete the value and click Save.\n\n\n\n What happens when the cost limit is reached \n\nWhen the instance's cost limit is reached, the currently running job is stopped. Its status is set to Cancelled with a reason of Ran too long. Any available partial results are kept.\n\nNo further jobs can be submitted by using this instance until the cost limit is increased.\n\n\n\n\n\n\n\n How to see what you're being charged \n\nYou are sent a monthly invoice that provides details about your resource charges. You can check how much has been spent at any time on the [IBM Cloud Billing and usage page](https://cloud.ibm.com/billing).", "title": "", "source": "https://cloud.ibm.com/docs/quantum-computing?topic=quantum-computing-cost"}, {"document_id": "ibmcld_07578-1031881-1033895", "score": 0.6071900129318237, "text": "\nFor information about case severity, see [Case severity and initial response times](https://cloud.ibm.com/docs/get-support?topic=get-support-support-case-severity).\n\nTo escalate a case, complete the following steps:\n\n\n\n1. Contact IBM Cloud Support by phone or chat:\n\n\n\n* Pay-as-you-go or subscription accounts can contact support by phone and can find the number in the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* Contact by chat from the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Chat with IBM from the Chat with a support agent tile.\n\n\n\n2. Provide your existing case number and a request to escalate the case.\n3. Provide the justification an escalation and explain the business impact of your problem or issue.\n\n\n\nIf your support inquiry requires a more immediate response, consider upgrading to the premium or advanced support plan so that you can open severity 1-4 support cases. To upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n* How do I change my email preferences for notifications?\n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https://cloud.ibm.com/user/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03765-7-1896", "score": 0.74030601978302, "text": "\nManaging payments \n\nDepending on your account type, you can easily manage your payment methods by using the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud\u00ae console or by going to [IBM\u00ae Billing](https://myibm.ibm.com/billing/).\n\nA valid credit card is required for all Pay-As-You-Go and Subscription accounts. Every month, the credit card is charged with the usage amount that is accumulated during that month. When updates to your payment details are approved, they are applied to your account within 24 hours. The contact that is specified in the billing address section receives an email confirming that the updates are applied.\n\nYou can contact IBM Cloud Support to get help with payment-related issues. From the console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/help.svg) > Support center, and then click Create a case to get in touch.\n\n\n\n Before you begin \n\nTo manage payments, you need to be assigned the operator role or higher on the billing account management service. See [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services) for more information.\n\n\n\n\n\n Managing payment methods for new US-based Pay-As-You-Go accounts with credit card billing \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_07578-1045891-1047755", "score": 0.7076483368873596, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1045762-1047626", "score": 0.7076483368873596, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03765-5710-7263", "score": 0.7051289677619934, "text": "\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/edit-tagging.svg).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03704-4411-6289", "score": 0.702789306640625, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_03776-6753-8705", "score": 0.6850630640983582, "text": "\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the console.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03765-1346-3055", "score": 0.6638051271438599, "text": "\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.\n\n\n\nYou can\u2019t enter a PO Box as the billing address.\n\nWhen you add a new credit card, it becomes the default credit card. Recurring payments are charged to the default payment method.\n\nComplete the following steps to edit your active payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Edit menu.\n2. To edit the billing address, click Edit and update the billing address.\n3. To edit the card details, click Edit and update the card number or expiration date.\n\n\n\nYou can only have one address that's associated with your payment methods. All credit cards in the account will be updated to the same address.\n\nComplete the following steps to set a new default payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03776-7-2223", "score": 0.6629204750061035, "text": "\nVideo - How can I manage billing and usage in IBM Cloud? \n\nLearn about the IBM Cloud\u00ae billing options and tools that you can use to track your usage and manage invoicing and payments.\n\n\n\n* Video transcript\n\nIBM Cloud offers multiple billing options so you can tailor how you pay based on your resource usage and your organization's procurement practices. You get the most flexibility with a Pay-As-You-Go account. You pay only for the billable services that you use each month, with no long-term contracts or commitments. If you know you have a significant amount of usage, you can purchase a subscription to get a discount. With a subscription, you commit to a certain amount of usage over a period of time. The larger the subscription, the better the discount. You can choose to pay upfront or be billed monthly, quarterly, or annually.\n\nAs an account owner, you have full access to monitoring resource usage, viewing invoices, and managing payments in the console. However, if you want to delegate billing tasks to another user, you can assign a user an Identity and Access Management (IAM) policy with the Administrator role on the Billing account management service.\n\nWhen you're ready to start tracking your resource usage and managing your billing and payment preferences, go to the Billing and usage section of the IBM Cloud console. Monitoring resource usage can help you understand what's coming in your next bill. On the Usage page, you can view current and past usage, and drill down by resource type to view the plans and instances in your account.\n\nYou can also export usage reports and choose from a high-level summary overview or a service instance view. If you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03765-2725-4571", "score": 0.6600032448768616, "text": "\n[Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusage"}, {"document_id": "ibmcld_03704-3030-4892", "score": 0.655360758304596, "text": "\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03771-7-2029", "score": 0.7081132531166077, "text": "\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http://ibm.com/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03771-1594-3365", "score": 0.7043728232383728, "text": "\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_16727-1068047-1069909", "score": 0.7018786668777466, "text": "\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1065299-1067188", "score": 0.6995564699172974, "text": "\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03764-2220-3440", "score": 0.6834930777549744, "text": "\n[Actions icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https://www.ibm.com/support/customer/zz/en/selectcountrylang.html). For more information, see [Requesting paperless invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-invoice-faq"}, {"document_id": "ibmcld_03795-7-1690", "score": 0.6794021129608154, "text": "\nWhy can't I view the invoices for my Pay-As-You-Go or Subscription account in the console? \n\nInvoices that are managed outside of the console can not be viewed by going to Manage > Billing and Usage > Invoices in the IBM Cloud console.\n\n What\u2019s happening \n\nAs a Pay-As-You-Go or Subscription account owner, you might not be able to view your invoices from the Invoices page in the IBM Cloud console.\n\nWhen you try to view your invoices, one of the following messages is displayed:\n\nYour invoices are managed through IBM.com.\n\nThis account is invoiced on a separate billing platform.\n\n Why it\u2019s happening \n\nIf you have a Pay-As-You-Go account that is billed in a currency other than US dollars or a Subscription account, you view your invoices on the [IBM Invoices](https://www.ibm.com/support/customer/invoices/) website, which is linked from the Invoices page in the console.\n\n How to fix it \n\nIf you're visiting the Invoices website for the first time, sign up with your IBMid and complete your profile. Then, add access to your account with your IBM customer number.\n\n\n\n1. Go to [IBM Invoices](https://www.ibm.com/support/customer/invoices/), and select your region.\n2. Log in with the same IBMid and password that you use to log in to IBM Cloud.\n3. Complete your profile on the Invoices website.\n4. From the Invoices website, go to the Accesses tab. Add access to your account and provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option or contact the [eCustomer Care team](https://www-112.ibm.com/software/howtobuy/passportadvantage/paocustomer/docs/en_US/ecare.html) for help.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice"}, {"document_id": "ibmcld_07578-1062822-1064465", "score": 0.6787227392196655, "text": "\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https://www.ibm.com/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https://cloud.ibm.com/icons/download.svg) and choose an invoice format.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03764-7-1642", "score": 0.6706558465957642, "text": "\nFAQs for invoices \n\nReview the following FAQs to find helpful information about invoices. To find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Where can I access my invoice? \n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https://www.ibm.com/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices) for more information.\n\n\n\n\n\n Why does my usage not match my invoice? \n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I manage my invoices? \n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-invoice-faq"}, {"document_id": "ibmcld_03771-2998-4769", "score": 0.6649398803710938, "text": "\nFor some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts \n\nIf you own one of the following accounts, you can view your invoice on the [Invoices@IBM](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the IBM console.\n\n\n\n* New and existing Pay-As-You-Go accounts that are based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nTo save a copy of your invoice, click the PDF icon in the Invoice Number column. Then, click the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg).\n\n\n\n Getting access to Invoices@IBM \n\nIf you are attempting to access the [Invoices@IBM](http://ibm.com/invoices) website for the first time, you can sign up with your IBMid, complete your profile, and provide your IBM customer number to access your account. Your IBM customer number is used for identification purposes during your registration process with the IBM Invoices page and during other interactions with [IBM Support](https://www.ibm.com/support/home/).\n\nTo ensure that access is granted to the correct individuals, you must register using an email address that includes your company's domain, such as ibm.com. Requests using personal, non-company-specific email addresses might not be approved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_16727-1066874-1068548", "score": 0.6615428924560547, "text": "\n[Download icon](https://cloud.ibm.com/icons/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https://www.ibm.com/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https://cloud.ibm.com/icons/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https://www.ibm.com/support/customer/zz/en/selectcountrylang.html). For more information, see [Requesting paperless invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03710-0-838", "score": 0.8420499563217163, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-subscription-code"}, {"document_id": "ibmcld_12597-0-804", "score": 0.7818843722343445, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"}, {"document_id": "ibmcld_03786-7-2105", "score": 0.7157050371170044, "text": "\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https://cloud.ibm.com/billing/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https://www.ibm.com/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_03786-1684-3421", "score": 0.7062903642654419, "text": "\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https://cloud.ibm.com/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https://cloud.ibm.com/docs/account?topic=account-codes) or [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_03785-7-2010", "score": 0.6825125217437744, "text": "\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription-account"}, {"document_id": "ibmcld_03732-0-1673", "score": 0.6812024116516113, "text": "\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https://cloud.ibm.com/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-codes"}, {"document_id": "ibmcld_07578-1066746-1068772", "score": 0.670402467250824, "text": "\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?\n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n* What happens if I spend my entire subscription amount before my term ends?\n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) to sign up for a new subscription.\n* Is there a monthly minimum amount required for Subscription accounts?\n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n* Can I cancel my Subscription account before the end of my term commitment?\n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?]", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07578-1050413-1052321", "score": 0.6668773293495178, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1050284-1052192", "score": 0.6668773293495178, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10906-10094-12223", "score": 0.664583683013916, "text": "\n<br><br> * Activate a subscription code<br><br><br> With an IBM Cloud subscription, you get discounted usage for platform services and support by committing to a minimum spending commitment for a certain period of time. After you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to your stand-alone account or enterprise. Applying the code ensures that the credit is added to your account, and you don't have unexpected overage charges. Make sure to add any purchased subscriptions to your account before creating resources. For more information, see [applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code). \n <br><br> * Create and configure an enterprise<br><br><br> When you create an enterprise, the account that you used to initiate the process is automatically added to the enterprise, and a new enterprise account is created to manage the billing for the enterprise. Follow the steps in the [Setting up an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial) documentation to create an enterprise. Keep in mind that when using an enterprise, users within each account in the enterprise can create, use, and collaborate on resources just as they can in a stand-alone account. \n <br><br> * Assign enterprise access to users<br><br><br> If you chose to create an enterprise, you might require that administrators manage the enterprise performing functions, such as creating account groups, creating and managing accounts. Review the access that is required, and add users as needed. For more information, see [Assigning access for enterprise management](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-assign-access-enterprise). \n <br><br> * Create resource groups<br><br><br> Use resource groups to organize an account's resources for access control and billing purposes. For example, creating a resource group per project allows costs to be tracked at the project level even when your resources are distributed across regions.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-get-started-checklist"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>10", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03709-0-1479", "score": 0.805654764175415, "text": "\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-feature-code"}, {"document_id": "ibmcld_03711-0-822", "score": 0.7373665571212769, "text": "\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cant-create-service-feature-code"}, {"document_id": "ibmcld_03732-0-1673", "score": 0.6940120458602905, "text": "\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https://cloud.ibm.com/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-codes"}, {"document_id": "ibmcld_07578-1048947-1050776", "score": 0.6362296342849731, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1048818-1050647", "score": 0.6362296342849731, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03704-7496-9340", "score": 0.6316312551498413, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_02672-0-1128", "score": 0.6154432892799377, "text": "\n\n\n\n\n\n\n  Set up environments, feature flags, and properties \n\nUse feature flags to enable or disable a feature in your application code. You can also manage the properties for distributed applications centrally.\n\n\n\n  Environments \n\nEnvironments in App Configuration represent your application environments. Typical environments might be dev, staging, or production. Environments manage your feature flags and properties to various deployments from development to production. For more information, see [Environments](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-environments).\n\n\n\n\n\n  Feature flags \n\nSeparate code delivery from feature enablement. Dark launch feature code in the application to a set of target users. For more information, see [feature flags](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-feature-flags).\n\n\n\n\n\n  Properties \n\nConfigure and manage properties for distributed applications and environments centrally in one place. For more information, see [Properties](https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-properties).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-ff-prop-env"}, {"document_id": "ibmcld_02689-1748-4183", "score": 0.6000963449478149, "text": "\nWithin your application, the isEnabled() method of the App Configuration SDK is used to activate conditional blocks of code to turn features on and off based on the state of a feature flag. Use feature flags to dark launch features into production and then switch them on only for selected users or roll them out to your users selectively and independently from deployments. Each feature flag must belong to a collection.\n\n\n\n\n\n Properties \n\nProperties are configuration parameters that don't change often, but that still need centralized management. Consolidate properties for all your app and environment components into one central cloud dashboard, with App Configuration, thus avoiding the hassle of managing multiple parameter files. Within your application, the getCurrentValue() method of the App Configuration SDK is used to access the current value of a property. Each property must belong to a collection.\n\n\n\n\n\n Segments \n\nUsing App Configuration, a single feature flag, or property, can have many values, with each value applied to a specific group of entities (users, devices, infrastructure components). Each group is called a segment. Members of a segment share one or more common attributes as defined by a set of segment rules. Segments are optional.\n\n\n\n\n\n Attribute \n\nAn attribute is a parameter that is used to define a segment. Attributes are used to create segment rules on the App Configuration dashboard, but names of the attributes and values of each attribute are defined in your code. At run time, the App Configuration SDK fetches the segment rules into your application instance and determine whether it is a part of the segment.\n\n\n\n\n\n Targeting definition \n\nFeature flags and properties are targeted to segments based on a set of rules that are called the targeting definition. With targeting, you can override the default value for a flag or property, for any segment you define.\n\n\n\n\n\n App Configuration SDK \n\nThe App Configuration SDK handles the automatic delivery of the appropriate flag state or property value into your application. It connects to the endpoints provided by the App Configuration API, fetches collections, and evaluates segment and targeting rules. Server-side SDKs connect to the App Configuration service through a web socket for real-time updates. Client-side SDKs pull values from the App Configuration service upon a lifecycle change such being opened or brought to the foreground.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-overview"}, {"document_id": "ibmcld_07578-1050413-1052321", "score": 0.5917329788208008, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1050284-1052192", "score": 0.5917329788208008, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>11", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-7896-8949", "score": 0.7402171492576599, "text": "\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https://cloud.ibm.com/billing/payments). Credit card transactions are automatically retried within 24 hours after you update the information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-1710-3705", "score": 0.7381445169448853, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7-2194", "score": 0.7257727384567261, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03782-0-720", "score": 0.6912975311279297, "text": "\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-section-error"}, {"document_id": "ibmcld_03713-6236-8279", "score": 0.6906905770301819, "text": "\nFor more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https://cloud.ibm.com/billing/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03799-0-731", "score": 0.6731299161911011, "text": "\n\n\n\n\n\n\n  Why can't I update my billing address? \n\nYou can't update the billing address for a credit card in the IBM Cloud console. You must contact support to update the billing address on an existing credit card.\n\n  What\u2019s happening \n\nWhen you try update your payment details, you can't update the billing address for the credit card.\n\n  Why it\u2019s happening \n\nOn the [Payment methods page](https://cloud.ibm.com/billing/payments), you can't edit the billing address in the IBM Cloud Console.\n\n  How to fix it \n\nTo update the billing address for a credit card, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Depending on your level of support, you can chat with a support agent or open a case.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-update-billing-address"}, {"document_id": "ibmcld_03713-3269-5168", "score": 0.6719462871551514, "text": "\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_01660-2990-4730", "score": 0.648341178894043, "text": "\nGo to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n\n\n\n\n\n How do I upgrade my account? \n\nTo upgrade your Lite account, go to your [account settings](https://cloud.ibm.com/account/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_07578-1071351-1073249", "score": 0.643775999546051, "text": "\nSome countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https://cloud.ibm.com/billing/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https://cloud.ibm.com/account/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03713-4689-6647", "score": 0.64202481508255, "text": "\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>12", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-3269-5168", "score": 0.8023335933685303, "text": "\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-1710-3705", "score": 0.7789823412895203, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7-2194", "score": 0.7416072487831116, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7896-8949", "score": 0.7350395917892456, "text": "\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https://cloud.ibm.com/billing/payments). Credit card transactions are automatically retried within 24 hours after you update the information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-6236-8279", "score": 0.7209750413894653, "text": "\nFor more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https://cloud.ibm.com/billing/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-4689-6647", "score": 0.719546914100647, "text": "\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03794-0-812", "score": 0.683615505695343, "text": "\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-charge-limit"}, {"document_id": "ibmcld_03782-0-720", "score": 0.6767630577087402, "text": "\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-section-error"}, {"document_id": "ibmcld_02273-0-665", "score": 0.672267496585846, "text": "\n\n\n\n\n\n\n  Why can't I submit the form to add my credit card information? \n\nYou can't submit your credit card information to upgrade your Lite account to a billable account.\n\n  What\u2019s happening \n\nThe Upgrade account button is disabled.\n\n  Why it\u2019s happening \n\nThis problem happens when your information isn't entered correctly.\n\n  How to fix it \n\nComplete the following steps:\n\n\n\n1.  Complete all of the required fields to add your credit card and billing information in the IBM Cloud console.\n\nEnsure that you specified a business account and not a personal account type, if you are providing a VAT ID or tax identification number.\n2.  Click Upgrade account.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-ts_addcc"}, {"document_id": "ibmcld_03793-7-1857", "score": 0.6521772742271423, "text": "\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https://cloud.ibm.com/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-ccibm"}]}
