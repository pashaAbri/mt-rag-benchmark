{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00550-7-2005","score":23.017904,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_00612-7-2163","score":22.040432,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00576-7385-9302","score":21.35437,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-7-1957","score":20.886553,"text":"\nLearning Center \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Learning Center offers a video series to help you learn to use IBM Cloudant. The videos start with the basics of using IBM Cloudant. Then the videos walk you through document structure, the API, indexing and querying, and include an Under the Hood topic that highlights the architecture that powers the service.\n\nYou can use the [playlist](https:\/\/www.youtube.com\/embed\/playlist?list=PLzpeuWUENMK3F93hGaS4ezGmlX4Bipt4S) to go through the courses, or navigate directly to the topic of your choosing.\n\n\n\n Introduction to IBM Cloudant video \n\nLearn about the IBM Cloudant 17-part video series that provides an overview of the IBM Cloudant database-as-a-service.\n\n\n\n* Introduction to IBM Cloudant video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 1 - What is IBM Cloudant?\n\nIBM Cloudant is a database, run as a service in the IBM Cloud\u00ae. Its job is to store your application's data securely and make it possible for you to retrieve it quickly and efficiently. IBM Cloudant's key features are shown in the following list:\n\nDatabase\n: Stores and retrieves data. More specifically, it is a JSON document store. JSON comes from JavaScript and represents simple objects in a universal file format.\n\nDocument\n: The unit of storage in IBM Cloudant. Documents are added, updated, and deleted in their entirety.\n\nHTTP API\n: Any IBM Cloudant operation can be achieved by using HTTPS. HTTP is the protocol that powers the World Wide Web and IBM Cloudant is a database that is built for the web. Most databases are hidden in a private network, inaccessible but to a handful of machines. The IBM Cloudant service sits (mainly) on the public internet where it can be accessed by anyone with an internet connection (and permission to do so).\n\nIBM Cloudant wasn't written entirely by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00513-7-2197","score":20.453413,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00580-20968-23077","score":20.44006,"text":"\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_11586-7-1910","score":19.32235,"text":"\nFast Path of IBM Cloud for VMware \n\nThis page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as SAP Sizing.\n\nUse the links in this section to quickly access relevant documents that you are already familiar with.\n\n\n\n Learn \n\nAn Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the US) and a designated site location (also referred to as zone, which is a data center site). For more information:\n\n\n\n* [IBM Cloud Classic Infrastructure environment introduction](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-classic-env-introduction)\n\n\n\nCertified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many different SAP workload scenarios. For more information:\n\n\n\n* [Infrastructure certified for SAP - VMware Software-Defined Data Center](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offeringsiaas-vmware)\n\n\n\nThe following is an overview of the SAP-certified profiles with IBM Cloud Bare Metal servers for SAP HANA and SAP NetWeaver. For more information:\n\n\n\n* [VMware SSDC certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-vmware)\n* [VMware SDDC certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-vmware)\n* [Compute Profiles of SAP-certified VMware on Classic Infrastructure](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-compute-os-design-considerationscompute-vmware)\n\n\n\nYour business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server, and therefore determine how your applications are run in the available infrastructure. For more information:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-fast-path-site-map-vmware-sddc"},{"document_id":"ibmcld_00512-7-2158","score":18.599947,"text":"\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00512-1696-3972","score":18.380203,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_11582-7-1935","score":18.306955,"text":"\nFast Path of IBM Cloud Intel Bare Metal \n\nThis page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as SAP Sizing.\n\nUse the links in this section to quickly access relevant documents that you are already familiar with.\n\n\n\n Learn \n\nAn Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the US) and a designated site location (also referred to as zone, which is a data center site). For more information:\n\n\n\n* [IBM Cloud Classic Infrastructure environment introduction](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-classic-env-introduction)\n\n\n\nCertified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many different SAP workload scenarios. For more information:\n\n\n\n* [Infrastructure certified for SAP - Bare Metal server](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offeringsiaas-intel-bm)\n\n\n\nThe following is an overview of the SAP-certified profiles with IBM Cloud Bare Metal servers for SAP HANA and SAP NetWeaver. For more information:\n\n\n\n* [Intel Bare Metal server certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-intel-bm)\n* [Intel Bare Metal server certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-intel-bm)\n* [Compute Profiles of SAP-certified Bare Metal on Classic Infrastructure](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-compute-os-design-considerationscompute-baremetal)\n\n\n\nYour business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server, and therefore determine how your applications are run in the available infrastructure. For more information:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-fast-path-site-map-intel-bm"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00623-7-1781","score":22.906187,"text":"\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to \/$DATABASE\/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST \/$DATABASE\/_index HTTP\/1.1\nContent-Type: application\/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"},{"document_id":"ibmcld_00580-4796-6846","score":22.344917,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-6386-8382","score":21.237389,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00526-7-1750","score":21.035332,"text":"\nOverview \n\nDocuments are [JSON objects](https:\/\/en.wikipedia.org\/wiki\/JSONData_types.2C_syntax_and_example). Documents are also containers for your data, and are the basis of the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database.\n\nIf you're using an [IBM Cloudant service on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicibm-cloud-public), documents are limited to a maximum size of 1 MB. Exceeding this limit causes a [413 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).\n\nIBM Cloudant uses an [eventually consistent](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem) model for data. If you use the eventually consistent model, it's possible, under some conditions, to retrieve older document content. For example, older content is retrieved when your application writes or updates a document that is followed immediately by a read of the same document.\n\nIn other words, your application would see the document content as it was before the write or update occurred. For more information about this model, see the topic on [Consistency](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem).\n\n\n\n Document fields \n\nAll documents must have two fields:\n\n\n\n* A unique _id field. The _id field is detailed in the next section.\n* A _rev field. The _rev field is a revision identifier, and is [essential to the IBM Cloudant replication protocol](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-document-versioning-and-mvccdocument-versioning-and-mvcc).\n\n\n\nIn addition to these two mandatory fields, documents can generally contain any other content that can be described by using JSON, subject to some caveats detailed in the following sections.\n\n\n\n Document IDs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documents"},{"document_id":"ibmcld_13493-1220-3010","score":20.946772,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_00580-37889-39953","score":20.820454,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00614-2964-4661","score":20.589294,"text":"\nSeveral of the fields have default values:\n\n\n\nTable 2. Default values for monitoring API request fields\n\n Field Default value \n\n DURATION 5 minutes \n END No default value \n START The current time \n\n\n\n\n\n Results format \n\nBy default, the monitoring results are returned in [JSON format](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-clusterwith-format=json-default). If you prefer, you can choose to receive the results in [raw format](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-clusterwith-format=raw).\n\nThe results include a text string that identifies the metric that is stored on the server that provides the API capability, for example:\n\nsumSeries(net.cloudant.mycustomer001.db.df.srv.used)\n\nThe results include cluster-level data.\n\nIBM Cloudant stores the queried data at the following resolutions: 10 seconds for the past 24 hours; 1 minute for the past 7 days; and 1 hour for the past 2 years. As a result, and to ensure that IBM Cloudant always stores the higher resolution interval length, deltas on the boundary of these resolutions are trimmed by one interval's length.\n\n\n\n\n\n With format=json (default) \n\nUnless you specify otherwise, the metric data that is returned is in JSON format. Each value that is returned consists of [datapoint, timestamp] values.\n\nSee an example monitoring request for disk use data returned in JSON format:\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/disk_use?cluster=myclustername&format=json\"\n\nSee an example result after you request disk use data in JSON format:\n\n[\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.used)\",\n\"datapoints\":\n523562172416.0, 1391019360],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_00545-6736-7963","score":20.578924,"text":"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe response is a JSON object that contains all documents in the database that match the parameters. The following table describes the meaning of the individual fields:\n\n\n\nTable 2. JSON object fields\n\n Field Description Type \n\n offset Offset where the document list started. Numeric, Null (The type can be null when keys are specified.) \n rows Array of document objects. Array \n total_rows Number of documents in the database or view that match the parameters of the query. Numeric \n pdate_seq Current update sequence for the database. String \n\n\n\nSee the following example response after a request for all documents in a database:\n\n{\n\"total_rows\": 3,\n\"offset\": 0,\n\"rows\": [\n{\n\"id\": \"5a049246-179f-42ad-87ac-8f080426c17c\",\n\"key\": \"5a049246-179f-42ad-87ac-8f080426c17c\",\n\"value\": {\n\"rev\": \"2-9d5401898196997853b5ac4163857a29\"\n}\n},\n{\n\"id\": \"96f898f0-f6ff-4a9b-aac4-503992f31b01\",\n\"key\": \"96f898f0-f6ff-4a9b-aac4-503992f31b01\",\n\"value\": {\n\"rev\": \"2-ff7b85665c4c297838963c80ecf481a3\"\n}\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-get-documents"},{"document_id":"ibmcld_00576-7385-9302","score":20.091732,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00623-1515-3180","score":20.02019,"text":"\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",\n\"type\" : \"json\",\n\"partitioned\": false\n}\n\nSee the following example of returned JSON, confirming that the index was created:\n\n{\n\"result\": \"created\"\n}\n\n\n\nTable 1. Request body format\n\n Field Description \n\n index fields - A JSON array of field names that uses the [sort syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querysort-syntax). Nested fields are also allowed, for example, person.name. \n ddoc (optional) Name of the design document in which the index is created. By default, each index is created in its own design document. Indexes can be grouped into design documents for efficiency. However, a change to one index in a design document invalidates all other indexes in the same document. \n type (optional) Can be json or text. Defaults to json. \n name (optional) Name of the index. If no name is provided, a name is generated automatically. \n partitioned (optional, boolean) Determines whether this index is partitioned. For more information, see [the partitioned field](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querysection1-the-partitioned-field). \n\n\n\n\n\n The partitioned field \n\nThis field sets whether the created index is a partitioned or global index.\n\n\n\nTable 2. Partitioned field values\n\n Value Description Notes \n\n true Create the index as partitioned. Can be used only in a partitioned database. \n false Create the index as global. Can be used in any database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-7123-9213","score":20.208982,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-7-1696","score":20.14492,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_06968-15099-17180","score":19.135187,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00580-3166-5282","score":18.570173,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00576-1572-3411","score":18.49455,"text":"\nIn most cases, the information is returned in the form of a JSON document.\n\nHEAD\n: The HEAD method retrieves the HTTP header of a GET request without the body of the response.\n\nPOST\n: Upload data. In IBM Cloudant's API, the POST method sets values, uploads documents, sets document values, and starts some administration commands.\n\nPUT\n: Used to \"store\" a specific resource. In IBM Cloudant's API, PUT creates new objects, including databases, documents, views, and design documents.\n\nDELETE\n: Deletes the specified resource, including documents, views, and design documents.\n\nCOPY\n: A special method that copies documents and objects.\n\nIf the client (such as some web browsers) doesn't support the use of HTTP methods, POST can be used instead with the X-HTTP-Method-Override request header set to the actual HTTP method.\n\n\n\n Method not allowed error \n\nIf you use an unsupported HTTP request type with a URL that doesn't support the specified type, a [405](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) error is returned. The error that lists the supported HTTP methods, as shown in the following example.\n\n\n\n Example error message in response to an unsupported request \n\n{\n\"error\":\"method_not_allowed\",\n\"reason\":\"Only GET,HEAD allowed\"\n}\n\n\n\n\n\n\n\n\n\n JSON \n\nIBM Cloudant stores documents that use JSON (JavaScript Object Notation) encoding, so anything encoded into JSON can be stored as a document. Files that include media, such as images, videos, and audio, are called BLOBs (Binary Large Objects). BLOBs can be stored as attachments associated with documents.\n\nMore information about JSON can be found in the [JSON Guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-json-works).\n\n\n\n\n\n Distributed systems \n\nBy using IBM Cloudant's API, you can interact with a collaboration of numerous machines, called a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_07578-447531-449109","score":18.472708,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":18.472708,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00576-7385-9302","score":18.451124,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00554-7-1717","score":17.814981,"text":"\nHow is data stored in IBM Cloudant? \n\nEvery database in IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae is formed of one or more distinct shards, where the number of shards is referred to as Q. A shard is a distinct subset of documents from the database.\n\n\n\n Concepts \n\nAll Q shards together contain the data within a database. Each shard is stored in three separate copies. Each shard copy is called a shard replica. Each shard replica is stored on a different server. The servers are available within a single Region. If the Region supports Availability Zones, the replicas are stored on servers in different Zones. The collection of servers in a Region is called a cluster.\n\nZoom\n\n![A single database is split into Q shards, which are each stored in triplicate on three separate servers.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/sharding_database.svg)\n\nFigure 1. Data storage\n\nA document is assigned to a particular shard by using consistent hashing of its ID. This assignment means that a document is always stored on a known shard and a known set of servers.\n\nZoom\n\n![A single document is assigned to a single shard so ends up on three replicas on three separate servers.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/sharding_document.svg)\n\nFigure 2. Document consistent hashing\n\nOccasionally, shards are rebalanced. Rebalancing involves moving replicas to different servers. Rebalancing occurs for several reasons, for example, when server monitoring suggests that a server is more heavily or lightly used than other servers, or when a server must be taken out of service temporarily for maintenance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-"},{"document_id":"ibmcld_00580-9670-11721","score":17.583586,"text":"\nThat's the end of this part. The next part is called The Document ID.\n\n\n\n\n\n\n\n The _id video \n\nLearn how _ids work in IBM Cloudant, how they are different from relational databases, and how you can define your own _id.\n\n\n\n* The _id video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 3 - The Document _id.\n\nIn the previous section, we saw how data is stored in IBM Cloudant documents with flexibility on how your application stores JSON objects in IBM Cloudant databases. However, a few hard and fast rules exist.\n\nOne rule is that every document must contain a unique identifier that is called _id, which is a string. Two documents in the same database can have the same _id field. In other databases, you specify which column is the unique identifier, but in IBM Cloudant, it's always _id and can't be changed.\n\nAlso, unlike relational databases, IBM Cloudant does not have \"auto-incrementing IDs\" that is, an ID field that starts at 1 and increments for each document added.\n\nIBM Cloudant's _id field is one of the following strings:\n\n\n\n* A 32-character string generated by IBM Cloudant. The ID is a meaningless sequence of numbers and letters that are guaranteed to be unique.\n* A string that is defined by you (if you know something unique about your data).\n\n\n\nThe following examples show how to supply your own document _id:\n\nUsing it to store something that you know is unique that is, the email address of a user. Your registration mechanism can enforce a one-user-per-email address policy. Some users choose to encode the document type in the _id, for example, user:56, book:55. The last example shows with a 32-digit string (generated in your app) that is designed to sort in approximate date and time order. This method makes it easy to retrieve the latest documents from the database, without a secondary index.\n\nIBM Cloudant takes your document _ids and stores them in an index (like the contents page of book).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-23465-25360","score":28.37287,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":28.37287,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":25.748283,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-5537-7566","score":25.075338,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_12904-22084-23929","score":24.394058,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-21994-23839","score":24.394058,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00629-29811-31959","score":23.573776,"text":"\ncurl \"$SERVICE_URL\/$DATABASE\/_changes?feed=continuous&include_docs=true&since=now&filter=mydesigndoc\/myfilter\"\n\nThe ordering of documents within the _changes feed is not always the same. In other words, changes might not appear in strict time order. The reason is that data is returned from multiple IBM Cloudant nodes, and eventual consistency rules apply.\n\n\n\n\n\n Replication pitfalls \n\nTo replicate successfully, the sum of the document size and all attachment sizes must be less than the maximum request size of the target cluster. For example, if the maximum HTTP request size is 11 MB, then the following scenarios apply:\n\n\n\nTable 1. Various scenarios based on maximum HTTP request size 11 MB\n\n Document size Attachment size Total size Replicates? \n\n 1 MB Five 2-MB attachments 11 MB Yes \n 1 MB One 10-MB attachment 11 MB Yes \n 1 MB One hundred 1-MB attachments 101 MB No \n\n\n\nSeveral considerations apply when you use replication.\n\n\n\n Incorrect user permissions \n\nFor replication to proceed optimally when you replicate from database \"a\" to database \"b\", the credentials that are supplied must have:\n\n\n\n* _reader and _replicator permissions on database \"a\".\n* _writer permissions on database \"b\".\n\n\n\nAPI keys are generated in the IBM Cloudant Dashboard or through the [API](https:\/\/cloud.ibm.com\/apidocs\/cloudant). Each key can be given individual permissions that relate to a specific IBM Cloudant database. IBM Cloudant must be able to write its checkpoint documents at the \"read\" end of replication, otherwise no state is saved and replication cannot resume from where it stopped. If the state is not saved, it can lead to performance problems when replication of large data sets resumes. The reason is that without checkpoints, the replication process restarts from the beginning each time that it is resumed.\n\n\n\n\n\n Replication document is conflicted \n\nAnother consequence of setting user permissions incorrectly is that the _replicator document becomes conflicted. The _replicator document records the current state of the replication process. In an extreme case, the document can become huge because it contains many unresolved conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-guide"},{"document_id":"ibmcld_00485-1687-3253","score":23.51584,"text":"\nFull-text search No No Yes, requires separate installer or container. Yes \n Partition queries No No Yes Yes \n Shard splitting No No Yes Available as tool for IBM Ops. \n Selector on changes feed No Yes Yes Yes \n Rate limits No No No User-defined [provisioned throughput capacity](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioned-throughput-capacity) settings \n Request size 4 GB (default) 4 GB (default) 4 GB (default) 11 MB \n Attachment size 4 GB (default) 4 GB (default) 4 GB (default) 10 MB \n Security auth [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) [IBM Cloudant legacy auth with API Keys](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-work-with-your-accountauthorization), [IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant), or [CouchDB Auth](https:\/\/docs.couchdb.org\/en\/stable\/intro\/security.html) \n LDAP No No No No \n\n\n\nThe CouchDB _show, _list, _update, and _rewrite functions were deprecated in Apache CouchDB 3.0. For more information, see [deprecated feature warnings](https:\/\/docs.couchdb.org\/en\/stable\/whatsnew\/3.0.htmldeprecated-feature-warnings).\n\nAs a result, these functions are no longer supported for IBM Cloudant. They do not appear in IBM Cloudant documentation, and while the APIs currently remain in service, their use is not recommended. The IBM Cloudant Support team no longer supports them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-couchdb-and-cloudant"},{"document_id":"ibmcld_00556-7-1696","score":23.40907,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00526-7-1750","score":23.388592,"text":"\nOverview \n\nDocuments are [JSON objects](https:\/\/en.wikipedia.org\/wiki\/JSONData_types.2C_syntax_and_example). Documents are also containers for your data, and are the basis of the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database.\n\nIf you're using an [IBM Cloudant service on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicibm-cloud-public), documents are limited to a maximum size of 1 MB. Exceeding this limit causes a [413 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).\n\nIBM Cloudant uses an [eventually consistent](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem) model for data. If you use the eventually consistent model, it's possible, under some conditions, to retrieve older document content. For example, older content is retrieved when your application writes or updates a document that is followed immediately by a read of the same document.\n\nIn other words, your application would see the document content as it was before the write or update occurred. For more information about this model, see the topic on [Consistency](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem).\n\n\n\n Document fields \n\nAll documents must have two fields:\n\n\n\n* A unique _id field. The _id field is detailed in the next section.\n* A _rev field. The _rev field is a revision identifier, and is [essential to the IBM Cloudant replication protocol](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-document-versioning-and-mvccdocument-versioning-and-mvcc).\n\n\n\nIn addition to these two mandatory fields, documents can generally contain any other content that can be described by using JSON, subject to some caveats detailed in the following sections.\n\n\n\n Document IDs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documents"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2890648263}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-23465-25360","score":21.060345,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":21.060345,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_06968-16615-18789","score":20.165495,"text":"\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_12748-0-2435","score":19.354038,"text":"\n\n\n\n\n\n\n  Limits \n\nIBM Cloud\u00ae Security and Compliance Center has the following known limits that might impact your experience.\n\n\n\nTable 1. Security and Compliance Center limits\n\n                            Limit                                                        \n\n Custom rules               500 per enterprise account  <br>100 per stand-alone account  \n Rule description           256 characters                                               \n Rule size                  4096 characters                                              \n Target                     1 per rule                                                   \n Condition                  16 per rule                                                  \n Property                   24 per condition                                             \n Label                      32 per rule                                                  \n Custom libraries           10 per enterprise account  <br>5 per stand-alone account     \n Library name               64 Characters                                                \n Library description        256 characters                                               \n Library size               Less than 1 MB                                               \n Profile name               64 characters                                                \n Profile description        256 Characters                                               \n Profile size               Less than 1 MB                                               \n Custom profiles            20 per enterprise account  <br>5 per stand-alone account     \n Control                    1200 per library  <br>600 per profile                        \n Control name               64 characters                                                \n Control description        256 characters                                               \n Specification              100 per control per library  <br>400 per control per profile \n Specification description  256 characters                                               \n Assessment                 10 per specification per library or profile                  \n Attachment                 50 per account                                               \n Exclusion                  8 per attachment                                             \n Scan                       1 per attachment - at any time                               \n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-service-limits"},{"document_id":"ibmcld_06968-18330-20453","score":19.150436,"text":"\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_07578-1268470-1270517","score":18.225973,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1271119-1273166","score":18.225973,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00581-0-1268","score":17.981913,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_12904-22084-23929","score":17.520401,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-21994-23839","score":17.520401,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00646-7-1813","score":25.571188,"text":"\nCreating a web-based To-Do list \n\nCreate a simple web-based to-do list to get familiar with the basic IBM Cloud features.\n\n\n\n Objectives \n\n\n\n1. From this tutorial, you learn how to create a basic website that interfaces with your IBM Cloud database to read and write data.\n\nThe project is a simple to-do list, where you can see a list of notes. You can add and delete notes. Each of your notes has a tag, and you can filter your notes by tag.\n2. To create this to-do list, your application needs to be able to read and write to the database. To read to-dos in \"newest first\" order and to filter by tag, your database needs to have some secondary indexes. Now, we can create all of that.\n\n\n\nYou can complete the tutorial in less than an hour. It doesn't cost you anything over your current IBM Cloudant bill (so it's free if you are on the IBM Cloudant Lite plan).\n\nThe website that you create is served from your local machine, so no other services are required apart from IBM Cloud.\n\nAfter you complete it, you have a basic understanding of how applications can interface with IBM Cloudant through an IBM Cloudant SDK (in this case, NodeJS).\n\n\n\n\n\n Before you begin \n\nYou need the following implements to complete this tutorial:\n\n\n\n1. An IBM Cloudant service instance and some service credentials. You can create the instance and credentials in the IBM Cloudant Dashboard by following the [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial. Be sure to make a note of the APIKey and URL when you create your service credentials.\n2. Ensure you have access to a Mac or Linux\u2122 terminal.\n3. Download [Git](https:\/\/git-scm.com\/downloads).\n4. Download [Node.js and npm](https:\/\/docs.npmjs.com\/downloading-and-installing-node-js-and-npm).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-web-based-todo-list"},{"document_id":"ibmcld_16729-107144-108976","score":24.216915,"text":"\nDatabases[Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant)Getting started with IBM Cloudant\n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Getting started tutorial demonstrates how to use the IBM Cloud\u00ae dashboard to create an IBM Cloudant service instance and obtain service credentials to connect to it. Finally, it guides you through the creation of a simple, locally hosted web application that uses your IBM Cloudant database.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-04-03\n\n\n\n[Creating a backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-a-backup)Creating a backup\n\nThis tutorial demonstrates how to use the CouchBackup utility to back up and restore a CouchDB or IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae instance. CouchBackup backs up the database to a file. If the database fails, you can use the backup file to restore the information to an existing database.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-02-20\n\n\n\n[Creating and populating a database](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud)Creating and populating a database\n\nThis tutorial shows you how to use the Python programming language to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database in your IBM Cloud service instance. You also learn how to populate the database with a simple collection of data.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-20\n\n\n\n[Using a Dedicated Hardware plan instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud)Using a Dedicated Hardware plan instance\n\nThis tutorial shows you how to create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dedicated Hardware plan instance that uses the IBM Cloud\u00ae Dashboard.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_05499-1332-3032","score":23.865046,"text":"\nYou can create one [from the console](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) or by using CLI commands. In addition, create service credentials that you can pass to your application.\n\n\n\n1. Create an IBM Cloudant service instance, follow the steps in [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant). Name your instance CloudantFruitCounter. Be sure to complete the task by creating your service credentials.\n2. Open the IBM Cloudant dashboard for your instance and click Create database.\n3. In the Create database window, enter the database name fruitcounter.\n4. Do not select the Partitioned option, and click Create.\n\n\n\n\n\n\n\n Step 2: Test your application locally \n\nBefore you create your code as an application in Code Engine, test your code locally to make sure that it is functioning correctly.\n\n\n\n1. Retrieve the IBM Cloudant service credentials from the IBM Cloudant dashboard. For more information about retrieving credentials, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials).\n2. Set environment variables with the values from the service credentials.\n\nexport CLOUDANT_URL=<your_url>\n\nexport CLOUDANT_APIKEY=<your_key>\n\nexport DBNAME=\"fruitcounter\"\n3. Clone the fruit-counter repository, change to this directory, and then install and start the dependencies.\n\ngit clone https:\/\/github.com\/IBM\/CodeEngine\ncd CodeEngine\/fruit-counter\nnpm install\nnpm run start\n4. Open a browser and go to [http:\/\/localhost:8080](http:\/\/localhost:8080).\n5. Pick your favorite fruit and submit your choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-tutorial-cloudant-local"},{"document_id":"ibmcld_12889-716-2014","score":23.593317,"text":"\n(https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public)[IBM Cloudant security Describes IAM, security compliance, and securing your connection and data.](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant)[Try IBM Cloudant for free Describes the steps to get started with IBM Cloudant for free.](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant)\n\n Video library \n\n[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/Cloudant\/\/images\/cloudant-intro.png)<br><br>Introducing IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-centercloudant-course-intro-video)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/Cloudant\/\/images\/document.png)<br><br>The Document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-centerthe-document-video)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/Cloudant\/\/images\/_id.png)<br><br>The _id](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-centerthe-id-video)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/Cloudant\/\/images\/rev-token.png)<br><br>The rev token](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-centerthe-rev-token-video)[![carousel thumbnail","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant\/getting-started.html"},{"document_id":"ibmcld_00522-7-1725","score":22.934605,"text":"\nDigging deeper into IBM Cloudant Dashboard \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard gives new and experienced IBM Cloudant users the opportunity to add, edit, and delete documents. The IBM Cloudant users can refine the indexing and querying options that best suit their application's use-cases.\n\n\n\n Objectives \n\nSet up some basic indexes using the Dashboard to see how each of IBM Cloudant's querying mechanisms works.\n\n\n\n\n\n Before you begin \n\nYou need to create a service instance in IBM Cloudant before you start this tutorial. You can follow the instructions in the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial to create one.\n\n\n\n\n\n Step 1. The data set \n\n\n\n1. Create a database called books.\n2. Create some sample data that represents a book in a library as shown in the following example:\n\n{\n\"_id\": \"BXP9G5ZQY9Q4EA13\",\n\"author\": \"Dickens\",\n\"title\": \"David Copperfield\",\n\"year\": 1840,\n\"pages\": 723,\n\"publisher\": \"Penguin\",\n\"url\": \"https:\/\/www.somurl.com\/dc\"\n}\n3. Continue to add some documents that match the pattern in the previous step by using the IBM Cloudant Dashboard.\n\nThe documents store simple key\/value pairs that hold metadata about each book: its author and its publisher. In this example, we address the following three use-cases:\n\n\n\n1. A query facility that allows a user to find a book by a known publisher and year.\n2. A general-purpose search engine that allows a user to find books by a combination of one or more of the following descriptors: author, title, year, and publisher.\n3. A report that details the number of books that are published by year.\n\n\n\n\n\n\n\n\n\n Step 2. Querying books by publisher and year - IBM Cloudant Query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_09715-2612-4022","score":22.667984,"text":"\n[IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-monitoring)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services"},{"document_id":"ibmcld_12896-1393-3153","score":22.510284,"text":"\nRetrieving data](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudretrieving-data).\n\n\n\n\n\n\n\n Installing Python \n\nNormally, you don't run commands individually in Python. You usually create a script, which is a list of the commands you want to run, stored in a Python file, with a py extension.\n\n\n\n1. Set up service credential requirements.\n\na. Create a service instance and credentials by following the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial.\n\nb. [Locate your service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentialslocating-your-service-credentials) by following this tutorial.\n2. Install the required version of Python.\n\nYou must have a current version of the [Python programming language](https:\/\/www.python.org\/) that is installed on your system. [: note]\n\na. Check that Python is installed by running the following command at a prompt:\n\npython3 --version\n\nb. Verify that you get a result similar to the following example:\n\nPython 3.8.1\n3. Verify that your Python Client Library meets the requirement.\n\nThe following examples use the deprecated python-cloudant client library.\n\na. Check that the client library installed successfully by running the following command at a prompt:\n\npip freeze\n\nYou get a list of all the Python modules installed on your system.\n\nb. Inspect the list, looking for an IBM Cloudant entry similar to the following example:\n\ncloudant==2.14.0\n\n\n\n\n\n\n\n Step 1: Connecting to a service instance \n\nYou must connect to your service instance before you create a database.\n\nThe following components are identified as normal import statements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloud"},{"document_id":"ibmcld_04108-0-1506","score":22.455103,"text":"\n\n\n\n\n\n\n  Accessing your Cloudant database through CIS \n\nFollow these steps to access your Cloudant database through IBM Cloud\u00ae Internet Services (CIS).\n\n\n\n  Before you begin \n\nThese instructions assume you have already added a domain to CIS as outlined in the [Getting started](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedgetting-started) page.\n\n\n\n\n\n  Step 1: Add your CIS domain to the Cross-Origin Resource Sharing (CORS) \n\n\n\n*  Navigate to your Cloudant database and open the Account > CORS page.\n*  Add your CIS domain to the origin domains input field. For example, https:\/\/cloudant.test.foo.com.\n\n\n\n\n\n\n\n  Step 2. Configure CIS to point to your Cloudant database \n\n\n\n*  Navigate to the CIS dashboard and create a load balancer or DNS record that points to your Cloudant database hostname. For example, https:\/\/cloudant.test.foo.com -> 111-222-333-444-555-test.cloudant.com.\n*  Enable proxy for the DNS record or load balancer.\n\n\n\n\n\n\n\n  Step 3. Create a page rule to set the Host Header Override \n\n\n\n*  In the CIS dashboard, navigate to Performance > Page rules.\n*  Create a page rule for the URL you want, for example, https:\/\/cloudant.test.foo.com\/.\n*  Select the Rule Behavior setting Host Header Override.\n*  Set as the Cloudant database hostname, for example, 111-222-333-444-555-test.cloudant.com.\n\n\n\nTo learn more about Cloudant, see the [Cloudant documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantgetting-started-with-cloudant).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-access-cloudant-through-cis"},{"document_id":"ibmcld_05499-7-1742","score":22.436426,"text":"\nBuilding applications that store information in IBM Cloudant \n\nLearn how to build your Code Engine application from source code that is stored on your local workstation. This tutorial uses sample source that is used to build the app. This application connects to an IBM Cloudant database and stores input from that app.\n\nA build, or image build, is a mechanism that you can use to create a container image from your source code. Code Engine supports building from a Dockerfile and Cloud Native Buildpacks.\n\nBefore you begin\n\n\n\n* [Set up your Code Engine CLI environment](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-install-cli).\n* [Create and work with a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project).\n* [Git](https:\/\/git-scm.com\/downloads)\n* [Node.js and NPM](https:\/\/docs.npmjs.com\/downloading-and-installing-node-js-and-npm)\n\n\n\nAll Code Engine users are required to have a Pay-as-you-Go account. Tutorials might incur costs. Use the Cost Estimator to generate a cost estimate based on your projected usage. For more information, see [Code Engine pricing](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricing).\n\n\n\n Step 1: Create an IBM Cloudant service instance and database \n\nYour first step is to create an IBM Cloudant service instance and then create a database. You can create one [from the console](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) or by using CLI commands. In addition, create service credentials that you can pass to your application.\n\n\n\n1. Create an IBM Cloudant service instance, follow the steps in [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-tutorial-cloudant-local"},{"document_id":"ibmcld_00553-1-1322","score":22.362642,"text":"\nProduct guide \n\n Cloudant \n\n--------------------\n\n\n\n* Get started\n\n\n\n* [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant)\n* [Plans and provisioning](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public)\n* [Pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricing)\n* [Limits](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits)\n* [Connecting](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-connecting)\n* [Learning Center](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center)\n* Security & compliance\n\n\n\n* [Security](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-security)\n* [Compliance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-compliance)\n* [Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-privacy-and-governance)\n* [Audit logging](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-audit-logging)\n* [General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-general-data-protection-regulation-gdpr-)\n\n\n\n* [Transaction Engine notice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-overview-te)\n* [Service Changes and Deprecations for IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-deprecations-for-ibm-cloudant)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-http-works-with-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12904-7-1919","score":28.920818,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-7-1874","score":28.596096,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-1499-3456","score":27.199068,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":26.877867,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00489-2612-4354","score":26.77427,"text":"\nSERVICE_NAME cloudantnosqldb \n SERVICE_PLAN_NAME Lite plan (lite) or Standard plan (standard) \n LOCATION The location where you want to deploy includes the following cities: Sydney au-syd, Chennai in-che, Osaka jp-osa, Tokyo jp-tok, Seoul kr-seo, Frankfurt eu-de, London eu-gb, Dallas us-south, Washington DC us-east. \n legacyCredentials Defaults to true. This field dictates whether the instance uses both legacy and IAM credentials or IAM credentials only. \n\n\n\nSERVICE_PLAN_NAME is the type of pricing plan you select when you create an instance. For more information, see [Plans](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicplans-and-provisioning) in the documentation for details on using the IBM Cloudant Lite or Standard plan.\n\nFor more information about choosing an authentication method, see the [IAM guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant). The IBM Cloudant team recommends that you use IAM access controls over IBM Cloudant legacy authentication whenever possible.\n\nNow, we create a service instance that is called, cs20170517a.\n\n\n\n1. Set your target resource group and region by using the following format. To run this command, you need to know the region and resource groups, which you find in the following steps.\n\nFor more information, see [General CLI (ibmcloud) commands](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_target) under ibmcloud target.\n\nibmcloud target [-r REGION_NAME] [-g RESOURCE_GROUP]\n2. To see a list of regions, run the following command.\n\nibmcloud regions\n3. To see a list of resource groups, run the following command.\n\nibmcloud resource groups\n4. Create an instance of an IBM Cloudant service by using the Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-instance-on-ibm-cloud-by-using-the-ibm-cloud-cli"},{"document_id":"ibmcld_00558-2925-4840","score":26.133928,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-2979-4903","score":26.103882,"text":"\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00540-7-1622","score":25.638796,"text":"\nFinding your IBM Cloudant plan \n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\n\n\n Step 1: Finding your plan \n\nThe following steps show where you can see the type of plan that you selected.\n\n\n\n1. Go to the [IBM Cloud Dashboard](https:\/\/cloud.ibm.com\/).\n2. Authenticate with your username and password.\nThe IBM Cloud Dashboard opens to the Resource list.\n3. Click an instance to find more information.\n4. Click Plan. A checkmark indicates the plan that you use as shown in the following screen capture. For more information, see the [Migration FAQ](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration).\n\nZoom\n\n![Standard dashboard includes a serverless scaling of throughput and storage. Includes 20 GB of free data storage, extra storage metered. Users can adjust provisioned throughput capacity in blocks of 100 reads\/sec, 50 writes\/sec, 5 global queries\/sec. Max JSON document size of 1 MB. $1.00 USD\/GB of data storage. $0.25 USD\/Read capacity. $0.50 USD\/Write capacity. $5.00 USD\/Global Query capacity.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/ibmcloud_instance_standard_plan.png)\n\nFigure 1. Standard dashboard\n\nIf the Plan tab indicates that you're on the Standard plan, you don't need to read any further. You're already on a paid SLA-backed IBM Cloudant service. No further action is required.\n\n\n\n\n\n\n\n Step 2: Finding your legacy Enterprise plan \n\nYou can find your Enterprise plan in the IBM Cloudant Dashboard by following these steps.\n\n\n\n1. Open the IBM Cloudant Dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan"},{"document_id":"ibmcld_00612-7-2163","score":24.995218,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_16729-112397-114109","score":24.92935,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.871078544}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-31052-33321","score":16.078785,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07103-29564-31587","score":16.05723,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11142-7-1829","score":14.583178,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_07103-13283-15511","score":14.166313,"text":"\nYou cannot create new service instances that use the Lite plan type in any location, including London. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 22 September 2022 \n\nPlus plan supports more entity extractors\n: The maximum number of entity extractors that you can create with a Plus plan increased from 3 to 6.\n\nYou cannot apply a Smart Document Understanding model to Microsoft Excel files\n: The quality of structural analysis that can be produced for Excel files is not sufficient. Starting on 22 September 2022, you cannot apply an SDU model to Excel files. This change does not impact Excel files in collections where an SDU model was applied before 22 September 2022.\n\n\n\n\n\n 16 September 2022 \n\nIn-context document preview is now available for PDF files that are crawled\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page. The in-context view is available for PDF files to which a Smart Document Understanding model is applied.\n\n\n\n\n\n 15 August 2022 \n\nSDKs were updated to reflect the latest API changes.\n: The following [Discovery v2 API](https:\/\/cloud.ibm.com\/apidocs\/discovery-data) changes are now reflected in the SDKs:\n\n\n\n* Use the new document classifier API to get, add, update, or delete a document classifier.\n* A new document status API is available. You can use it to get a list of the documents in a collection and to get details about a single document.\n* You can now get, add, and remove a stop words or expansion list for a collection.\n* A smart_document_understanding field is returned with the Get collection method. This new field specifies whether an SDU model is enabled for the collection and indicates the model type.\n* A similar parameter is available from the Query method. Use it to find documents that are similar to documents of interest to you.\n* The suggested_refinements parameter of the Query method is deprecated. The suggested_refinements parameter was used to identify dynamic facets from Premium plan data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07103-32746-34817","score":13.370624,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07128-7-1957","score":13.360114,"text":"\nAbout Discovery v1 \n\nIBM Watson\u2122 Discovery v1 is deprecated. As of 1 October 2021, you cannot create new v1 instances. Lite or Advanced plan service instances are Discovery v1 instances, as are service instances that you created with a Premium plan before 16 July 2020. Existing v1 service instances are supported until 11 July 2023. Any v1 instances that still exist on that date will be deleted. Migrate your solutions to use Discovery v2 before 11 July 2023. For more information, see the [Discovery v2 documentation](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nDiscovery makes it possible to rapidly build cognitive, cloud-based exploration applications that unlock actionable insights hidden in unstructured data \u2014 including your own proprietary data, as well as public and third-party data.\n\n![Discovery architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/about-discovery1.png)\n\nWith Discovery, it only takes a few steps to prepare your unstructured data, create a query that pinpoints the information you need, and then integrate those insights into your new application or existing solution.\n\nHow does Discovery do it? By using data analysis combined with cognitive intuition to take your unstructured data and enrich it so you can discover the information you need.\n\nIBM Watson\u2122 Discovery brings together a functionally rich set of integrated, automated Watson APIs to:\n\n\n\n* Crawl, convert, enrich and normalize data.\n* Securely explore your proprietary content as well as free and licensed public content.\n* Apply additional enrichments such as concepts, relations, and sentiment through Natural Language Understanding (NLU).\n* Simplify development while still providing direct access to APIs.\n\n\n\nTo try out Discovery, see the [IBM Watson\u2122 Discovery Query Demo](https:\/\/www.ibm.com\/demos\/live\/watson-discovery\/self-service\/home).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-about"},{"document_id":"ibmcld_16727-1079289-1081125","score":13.052542,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":13.052542,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_02660-1509-3609","score":11.900911,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_01029-0-4062","score":11.330397,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12343-7-1769","score":18.810625,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_12341-1239-2954","score":17.608286,"text":"\nThe releases of these SDKs should be published on [NPM](https:\/\/www.npmjs.com\/). Your NPM package should be [scoped](https:\/\/docs.npmjs.com\/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https:\/\/www.npmjs.com\/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https:\/\/github.com\/airbnb\/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_12343-1428-3200","score":17.57392,"text":"\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.\n\n\n\n Docstrings \n\nAll non-trivial methods should have docstrings. Docstrings should follow the [PEP257 guidelines](https:\/\/www.python.org\/dev\/peps\/pep-0257\/). For more examples, see the [Google style guide regarding docstrings](https:\/\/google.github.io\/styleguide\/pyguide.html381-docstrings).\n\n\n\n\n\n\n\n Dependencies \n\nYour Python SDK should use synchronous network calls, using a library like [requests](https:\/\/pypi.org\/project\/requests\/).\n\n[PyJWT](https:\/\/pyjwt.readthedocs.io\/en\/latest\/) is recommended for encoding and decoding JSON web tokens.\n\nYour SDK should use [logging](https:\/\/docs.python.org\/3\/library\/logging.html) to assist users with low-level debugging.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core) provides configuration and authentication support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_02602-1716-3243","score":16.995333,"text":"\n2. To view summary usage help for all the toolkit commands, enter the following command:\n\napic\n3. To view usage help for any command, use the --help option. For example:\n\napic validate --help\n\n\n\n\n\n\n\n\n\n Installing LoopBack connectors \n\nBefore you can use a LoopBack data source to access data in a backend system such as a database, you must install the data source connector. The In-memory and email connectors are built in to LoopBack, so you don't need to install them.\n\n\n\n Prerequisites \n\nThe Oracle, DB2, and SQLLite connectors require C compiler tools to build and install binary extensions. The exact requirements depend on your operating system as described in the following list.\n\nLinux\n\n\n\n* Python v2.7 (v3.x is not supported)\n* make\n* A C\/C++ compiler toolchain, for example GCC version 4.2 or later.\n* On Debian and Debian-derived distributions (Ubuntu, Mint etc), use the command: apt-get install build-essential\n\n\n\nMac OS X\n\n\n\n* [Python Releases for Mac OS X](https:\/\/www.python.org\/downloads\/mac-osx\/)\n* [Xcode](https:\/\/developer.apple.com\/xcode\/?cm_mc_uid=46449280653414622613810&cm_mc_sid_50200000=1459433716)\n\n\n\nWindows\n\n\n\n* [Microsoft .NET Framework 4](https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=17851)\n* [Visual Studio](https:\/\/visualstudio.microsoft.com\/downloads\/)\n* [Python v2.7.10](https:\/\/www.python.org\/downloads\/release\/python-2710\/)\n* [Microsoft Windows SDK for Windows 10](https:\/\/developer.microsoft.com\/en-us\/windows\/downloads\/windows-10-sdk)\n* npm version 3: See the following note.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-creating_apis"},{"document_id":"ibmcld_00462-1307-2903","score":16.637629,"text":"\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https:\/\/www.python.org\/about\/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https:\/\/github.com\/IBM\/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https:\/\/pkg.go.dev\/mod\/github.com\/IBM\/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com\/IBM\/cloudant-go-sdk\/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https:\/\/github.com\/ibm\/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant\/couchbackup\n\nFor more information, see [couchbackup](https:\/\/github.com\/cloudant\/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https:\/\/curl.haxx.se\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_12343-2679-4417","score":16.606588,"text":"\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples \n\nFor your Python SDK, you will want some simple code samples and explanations of what each does. Linking out to the API reference documentation for more advanced use is strongly encouraged.\n\nAt minimum, the samples should be included in the README.md file. They should communicate how to install the library, and complete the basic operations provided by your API.\n\nThe samples should include simple installation and initialization instructions for the popular frameworks and data science tools. Additional examples should be available in an \/examples directory for more advanced operations which can be copied and pasted in to user applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_00620-14227-15704","score":15.815807,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_12341-2467-4426","score":15.798749,"text":"\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture \n\nAll network calls from your SDK should be asynchronous. All asynchronous calls should be handled using Promises, not callbacks.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using node-sdk-core \n\n[IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* NPM metadata\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_02693-7-1869","score":15.77248,"text":"\nApp Configuration server SDK for Python \n\nApp Configuration service provides SDK to integrate with your Python application.\n\n\n\n Integrating server SDK for Python \n\nApp Configuration service provides SDK to integrate with your Python application. You can evaluate the values of your feature flag or property by integrating the App Configuration SDK.\n\n\n\n1. Use either one of the following methods to install the SDK:\n\nUsing pip\n\npip install --upgrade ibm-appconfiguration-python-sdk\n\nUsing easy_install\n\neasy_install --upgrade ibm-appconfiguration-python-sdk\n2. In your Python application code, include the SDK module with:\n\nfrom ibm_appconfiguration import AppConfiguration, Feature, Property, ConfigurationType\n3. Initialize the sdk to connect with your App Configuration service instance.\n\nappconfig_client = AppConfiguration.get_instance()\nappconfig_client.init(region=AppConfiguration.REGION_US_SOUTH, guid='GUID', apikey='APIKEY')\nappconfig_client.set_context(collection_id='collection_id', environment_id='environment_id')\n\nWhere:\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: GUID of the App Configuration service. Obtain it from the service credentials section of the App Configuration service dashboard.\n* apikey: ApiKey of the App Configuration service. Obtain it from the service credentials section of the App Configuration service dashboard.\n* collection_id: ID of the collection created in App Configuration service instance.\n* environment_id: ID of the environment created in App Configuration service instance.\n\n\n\nThe init() and set_context() are the initialisation methods and should be invoked only once by using appconfig_client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-python"},{"document_id":"ibmcld_02698-7-1759","score":15.603768,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-7-2422","score":20.798252,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16295-7-1721","score":20.551758,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":20.430843,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16280-4696-6712","score":20.097395,"text":"\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_03421-1518-3290","score":19.741062,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":19.635452,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03196-30333-32476","score":19.38366,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_16326-3092-4450","score":19.30687,"text":"\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed. Any login, splash, cookie, or warning screens might be captured in the image.\n\nTo enter a URL:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Enter URL, then click Continue.\n3. Enter the path of your website URL, for example, https:\/\/www.example.com or example.com.\n4. Click Continue.\n\n\n\n\n\n\n\n Uploading an image \n\nYou can upload an image of your organization's website. Images are stored for 24 hours. Maximum file size is 1 MB. Supported file types are JPEG and PNG.\n\nTo upload an image:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Upload an image, then click Continue.\n3. Drag a file or click to upload, then click Change background.\n\n\n\nImages are stored for 24 hours. A warning message might appear on the Preview page about the time limit expiration. To clear this message:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Clear background setting, then click Continue.\n3. Click Remove background to finish.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03080-1529-3357","score":19.30002,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16389-0-2061","score":19.237926,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":24.809278,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":24.48803,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16389-0-2061","score":24.157297,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_16368-7-2072","score":23.244928,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-1518-3290","score":23.09677,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":22.762173,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03166-4588-6408","score":21.9945,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16384-7-2422","score":21.641088,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_02855-3103-4802","score":21.577124,"text":"\nFor more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-alternate).\n8. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security).\n9. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted in your deployed cluster environment. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n10. Copy the script HTML element.\n11. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n12. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n13. Refresh the web page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":21.556967,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":21.520197,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-13982-15842","score":18.917252,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16384-1889-3334","score":18.84775,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16384-7-2422","score":18.75705,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_02855-6718-8435","score":17.655243,"text":"\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03166-8640-10452","score":17.571943,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-5574-7284","score":17.030699,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16299-1512-2608","score":16.278328,"text":"\n* [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop): You can use the web chat API to extensively customize the appearance and behavior of the web chat.\n* Customizing the phone integration: You can use commands and context variables to extensively configure how your assistant interacts with users using the phone integration. (More information coming soon.)\n* Customizing the SMS integration: You can use commands and context variables to customize how your assistant interacts with users using text messages. (More information coming soon.)\n* [Extending your assistant using webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview): You use webhooks to call external services that extend the capabilities of your assistant or log activity.\n* Developing a custom channel: If none of the built-in channel integrations meet your needs, you can use the Watson Assistant REST API and SDKs to develop a custom client application that interacts with your assistant. (More information coming soon.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-develop-overview"},{"document_id":"ibmcld_03421-1518-3290","score":15.884114,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":15.755007,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.7328286205,"ndcg_cut_10":0.7328286205}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16298-6367-7794","score":22.23402,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_16387-7-1890","score":21.14776,"text":"\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public\/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https:\/\/www.npmjs.com\/package\/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"},{"document_id":"ibmcld_16385-7-2272","score":20.527142,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_03180-5630-7213","score":20.379684,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_03188-4819-6738","score":20.03967,"text":"\nFor more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored. The information is stored in the context.integrations.chat.browser_info object.\n\nYou can design your dialog to take advantage of details about the web browser in use. The following properties are taken from the window object that represents the window in which the web chat is running:\n\n\n\n* browser_name: The browser name, such as chrome, edge, or firefox.\n* browser_version: The browser version, such as 80.0.0.\n* browser_OS: The operating system of the customer's computer, such as Mac OS.\n* language: The default locale code of the browser, such as en-US.\n* page_url: Full URL of the web page in which the web chat is embedded. For example: https:\/\/www.example.com\/products\n* screen_resolution: Specifies the height and width of the browser window in which the web page is displayed. For example: width: 1440, height: 900\n* user_agent: Content from the User-Agent request header.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_16388-7-1918","score":20.011976,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_03422-4-2013","score":19.70068,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Securing the web chat \n\nUnderstand what you need to do to secure your web chat integration.\n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 (RS256) to encrypt communication. RS256 signatures use a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nThe following diagram illustrates the requests that are sent back and forth to authenticate a request.\n\n![Shows the order in which requests are sent among your website, web chat, and the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-security.png)\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\n\n\n Before you begin \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_02855-16710-18404","score":19.459341,"text":"\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-22154-24172","score":19.088104,"text":"\nWhen you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\nFor more information about security, see [Security](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=key-conceptssecurity).\n\n\n\n Enable security \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nAfter you enable security, users cannot submit messages through the web chat unless you take steps to prove their origin. Do not enable it until you have support for authentication in place.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16368-14455-16070","score":18.610952,"text":"\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.\n\nFor more information about how user identity information is specified and how it is used, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\n\n\n\n\n Security and administration \n\nSecuring the web chat\n: To secure the web chat, you can use JSON Web Token (JWT) to authenticate users and encrypt private data. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\nControlling the web chat version\n: The web chat code hosted by IBM Cloud is regularly updated with improvements and new features. By default, the embed script automatically uses the latest version of the web chat. To avoid unexpected changes that might affect your website, you might want to control which version of the web chat your website uses, giving you an opportunity to test each new version before you deploy in in production., in order to avoid unexpected changes when a new version is released.\n\nFor more information about web chat versioning, see [Controlling the web chat version](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03166-1557-3458","score":16.909416,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-7-1700","score":16.825329,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16375-7-1735","score":15.67973,"text":"\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n<\/head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16334-17373-19365","score":15.637235,"text":"\n* Home screen: The web chat home screen has been updated to have a more modern look. For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configweb-chat-configure-home-screen).\n* Agent events: New events are now fired by the web chat when interacting with a human agent using a service desk integration. If you are using a custom service desk integration based on the [starter kit](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter), you can use these events to create a pre-chat form before the agent escalation occurs, to create a post-chat form after the agent conversation ends, or to specify what happens if an agent isn\u2019t available (like create a ticket submission form). For more information, see [Agent events summary](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventssummary).\n* Markdown support: The web chat now fully supports common Markdown formatting in messages received from an assistant. You might need to review existing assistant output that contains strings that might be recognized as Markdown. (For example, a line of text that begins with a greater-than (>) character is interpreted as a block quote.)\n* Time zone: The time zone set in the context by the web chat no longer overrides any time zone set by the assistant.\n* Locale: Any locale configured for the web chat is now sent to the assistant as part of the context.\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16365-1312-3051","score":15.294594,"text":"\nFor more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16377-7-1723","score":14.918216,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_16377-1361-3020","score":14.845154,"text":"\nTo create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens. This handler uses the [customPanels.getPanel()](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-topicid) instance method to open a custom panel that will contain the pre-chat form.\n\nYour handler should return a promise that is resolved when the custom panel is closed. This prevents the web chat window from opening until after the pre-chat form is completed.\n\nfunction windowOpenHandler(event, instance) {\nreturn new Promise((resolve) => {\n\/\/ Save a reference to the resolve function so we can resolve\n\/\/ this promise later.\npromiseResolve = resolve;\ncreateOpenPanel(event, instance);\n\nconst customPanel = instance.customPanels.getPanel();\ncustomPanel.open({ hidePanelHeader: true,\ndisableAnimation: true });\n});\n}\n2. In your onLoad event handler, use the [on()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodson) instance method to subscribe to the window:open event, registering the handler as the callback.\n\ninstance.on({ type: 'window:open', handler: windowOpenHandler });\n3. Create a function that creates the pre-chat form you want to show inside the custom panel. Make sure you resolve the promise when the user closes the panel.\n\nfunction createOpenPanel(event, instance) {\nconst customPanel = instance.customPanels.getPanel();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_03080-7-1901","score":14.842017,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16368-8719-10427","score":14.787983,"text":"\n[development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows you how to implement a custom launcher, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n\nKeeping the web chat always open\n: If you want to keep the web chat always open on your page, use the [openChatByDefault](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationoptionsopenChatByDefault) configuration open to render the page with the chat window open, and the [hideCloseButton](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationoptionshideCloseButton) option to prevent customers from closing it.\n\nChanging the size or position of the web chat\n: Your website design might require that you change where and how the web chat window renders on your website. For example, you might want it to appear in a different position on the page, at a different size, or nested within another element on the page.\n\nTo change the size of the web chat window, you can use the [updateCSSVariables()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdatecssvariables) instance method to modify the CSS styling.\n\nIf you need to change the position of the web chat window, or you need to change the size beyond the limits allowed in the CSS, you can use a custom DOM element to contain the web chat window. To do this, use the [element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationoptionselement) configuration option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03080-1529-3357","score":14.670113,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-14167-16117","score":15.364774,"text":"\n{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use a Content Security Policy (CSP), and implement other basic web security precautions.\n\n\n\n\n\n\n\n Billing \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nBy default, the web chat creates a unique, anonymous ID the first time a new user starts a session. This identifier is stored in a first-party cookie, which remains active for 45 days. If the same user returns to your site and chats with your assistant again while this cookie is still active, the web chat integration recognizes the user and uses the same user ID. This means that you are charged only once per month for the same anonymous user.\n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":15.271368,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16365-7-1700","score":14.783534,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16727-5954-7906","score":13.900988,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-5954-7906","score":13.900988,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03418-4-2127","score":13.889846,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_16334-35243-37326","score":13.677181,"text":"\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.\n* Starter kit update: The starter kit now allow you to customize the timeout that occurs when the web chat integration checks whether any service desk agents are online.\n\n\n\n\n\n\n\n 3.1.1 \n\nRelease date: 22 October 2020\n\n\n\n* Accessibility improvement: Changed how the announcement text is generated to prevent announcements from being duplicated. Announcement text is hidden text that is provided for use by screen readers to indicate when dynamic web page changes occur.\n\n\n\n\n\n\n\n 3.1.0 \n\nRelease date: 8 October 2020\n\n\n\n* Suggestions now allow for trial and error: If customers select a suggestion and find that the response is not helpful, they can open the suggestions list again and try a different suggestion.\n\n\n\n\n\n\n\n 3.0.0 \n\nRelease date: 22 September 2020\n\n\n\n* Choose when a link to support is included in suggestions: The Suggestions beta feature has moved to its own tab. Now you can enable suggestions even if your web chat is not set up to connect to a service desk solution. That's because now you can control if and when the option to connect to customer support is available from the suggestions list. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n* Search result format change: To support the ability to show more than 3 search results in a response, the search skill response type format changed. If you are using pre:receive or receive handlers to process search results, you might need to update your code. The results property was replaced by the primary_results and additional_results properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03418-1763-3833","score":13.092622,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_16295-7-1721","score":13.012229,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03422-14609-15163","score":12.747503,"text":"\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02774-5358-7120","score":22.579962,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_02766-3003-4951","score":20.909388,"text":"\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.\n3. On the Identity Providers tab, set the providers that you want to use, to On.\n4. Optional: Decide whether to turn off Anonymous users, or leave the default, which is On. When set to On, user attributes are associated with the user from the moment they begin interacting with your app. For more information about the path to becoming an identified user, see [Progressive authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymousprogressive).\n\n\n\nApp ID provides default credentials to help with your initial setup of Facebook and Google+. You are limited to 20 uses of the credentials per instance, per day. Because they are IBM credentials, they are meant to be used only for development. Before you publish your app, update the configuration to your own credentials.\n\n\n\n\n\n Adding redirect URIs \n\nYour application redirects users to App ID for authentication. After authentication completes, App ID redirects users back to your application. In order for App ID to be able to redirect users back to your app, you need to register the redirect URI. During the sign-in flow, App ID validates the URIs before it allows clients to participate in the authorization workflow, which helps to prevent phishing attacks and grant code leakage. By registering your URI, you're telling App ID that the URI is trusted and it's OK to redirect your users.\n\n\n\n1. Click Authentication Settings to see your URI and token configuration options.\n2. In the Add web redirect URI field, type the URI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_02734-1732-3794","score":19.047562,"text":"\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02774-6807-8305","score":18.873703,"text":"\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.\n\nibmcloud iam oauth-tokens\n3. Make a POST request to the \/users endpoint that contains a description of the user and the attributes that you want to set as a JSON object.\n\nHeader:\n\nPOST <managementUrl>\/management\/v4\/<tenantID>\/users\nHost: <managementServerURL>\nAuthorization: 'Bearer <IAMToken>'\nContent-Type: application\/json\n\nBody:\n\n{\n\"idp\": \"<identityProvider>\",\n\"idp-identity\": \"<userUniqueIdentifier>\",\n\"profile\": {\n\"attributes\": {\n\"mealPreference\":\"vegeterian\"\n}\n}\n}\n\n\n\nTable 2. The components of the POST request\n\n Components Description \n\n idp The identity provider that the user authenticates with. Options include: saml, cloud_directory, facebook, google, appid_custom, ibmid. \n idp-identity The unique identifier provided by the identity provider. \n profile The user's profile that contains the custom attribute JSON mapping. \n\n\n\nExample request:\n\n$ curl --request POST --url 'https:\/\/<managementURI>\/users --header 'Authorization: Bearer <IAMToken>' --header 'Content-Type: application\/json' --data '{\"idp\": \"saml\", \"idp-identity\": \"user@ibm.com\", \"profile\": { \"attributes\": { \"role\": \"admin\",\n\"frequent_flyer_points\": 1000 }}}'\n4. Verify that registration was successful.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_12604-3436-5285","score":18.507984,"text":"\nMarla and half of the team members are based in the Ireland, and the other half are based in the United States.\n\n\n\n1. For trusted entity type, select Federated users.\n2. For authentication method, select Users federated by IBM Cloud App ID from the list.\n\nIf the users that you are creating a trusted profile for use IBM Cloud App ID, you should create the trusted profile as an App ID user, and likewise for IBMid. This way, your own SAML attributes can give you an idea of how to structure the trusted profile conditions. Other users with the same IdP can have different SAML attributes and you should use your own only as a hint. To use attributes in a claim that are different than your own, input them manually.\n3. Select the default identity provider (IdP) you created.\n4. Click View your identity provider (IdP) data. Marla uses this in the following steps to see which attributes she can leverage to create conditions.\n5. Click Add a condition.\n6. Click Filter attributes and select country.\n\n\n\n* These are the attributes available from personal data.\n\n\n\n7. Set Qualifier to Equals.\n8. For the Value, click Add manually and enter us. This way, Marla can enter attribute values that she isn't assigned in the personal identity provider data.\n9. Click Add a condition and repeat steps 6-8. Instead of us, enter ire.\n10. Click Add a condition again and click Add manually.\n\n\n\n1. Let's say there's an attribute that is called team in the corporate user directory that identifies an employee's team by manager. Enter the condition team equals marla.\n\n\n\n11. Click Add a condition again and click Add manually.\n\n\n\n1. Let's say there's an attribute that is called job-role in the corporate user directory that identifies an employee's job role. Enter the condition job-role equals dev.\n\n\n\n12. Set the session duration to 8 hours.\n13. Click Continue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-trustedprofile-fedusers-tutorial"},{"document_id":"ibmcld_03966-11017-13066","score":17.89914,"text":"\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user. If that option is not available, it can be enabled on your CA by overriding the CA configuration. See an example of how to enable this feature in [Modifying a CA configuration after deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-ca-modify-json). Note this action does not revoke the associated certificates for the user. If you need to do that you would need to insert the associated signed certificate into the organization MSP under the \"revocation_list\": section. And then update that MSP definition everywhere that it occurs on the network.\n\n\n\n Creating new CA admins \n\nBy default, only the CA admin that is created during deployment has the ability to register new identities. You can create identities with the ability the register new users by using the Attributes panel of the registration process.\n\nOn the second side panel, click the Add Attribute button. Provide an attribute name of hf.Registrar.Roles. Enter an attribute value of . You can also use this panel to create an identity that can register only certain identity types, such as clients or peers, or within a certain affiliation. You can also create an identity that has the ability to revoke an identity and all the certificates that the identity has been issued. You can see a full list of the attributes in the [Registering a new identity](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/users-guide.htmlregistering-a-new-identity) section of the Fabric CA users guide.\n\n\n\n\n\n\n\n Enrolling an identity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_02734-7-2170","score":17.88357,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02185-4-2040","score":17.813719,"text":"\n* UI\n* Terraform\n\n\n\n\n\n\n\n Creating dynamic rules for access groups \n\nYou can create dynamic rules to automatically add federated users to access groups based on specific identity attributes. When your users log in with a federated ID, the data from the identity provider (IdP) dynamically maps your users to an access group based on the rules that you set.\n\nUsers already have specific identity information within your company's domain, and when they log in with a federated ID, this data can be passed through by using SAML assertions. The SAML assertions or attribute statements that are configured within the IdP provide the data that is used to create each rule. For example, you might have a true or false attribute statement that defines users as a manager. This information can be used to add all users who are managers to a specific access group for managers that you created in your IBM Cloud\u00ae account. For more information, see the tutorial about how to [Control access to cloud resources](https:\/\/developer.ibm.com\/tutorials\/use-iam-access-groups-to-effectively-manage-access-to-your-cloud-resources\/) and an [Example rule](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rulesexample).\n\nOnly users who are already invited to the account can be mapped to access groups by using dynamic rules.\n\n\n\n Setting up rules by using the console \n\nDynamic rules are created by setting conditions that must be matched by the data that is configured within the IdP and passed in with a user's federated ID during login. You can add more than one condition for a rule. All conditions set in the rule must be met for a user to be added to an access group.\n\nTo create a rule, follow these steps:\n\n\n\n1. In the IBM Cloud console, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the access group that you want to create a rule for. This action opens the group Details page.\n3. Select Dynamic rules.\n4. Click Add rule.\n5. Enter the information from your IdP that is dynamically provided for you on the Add rule page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-rules&interface=ui"},{"document_id":"ibmcld_03966-9450-11507","score":17.202179,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03871-30641-32553","score":16.239685,"text":"\nEnter the User ID for the console instance.\n6. Enter the Password for the console instance.\n7. Select Proceed without certificate verification, or Cancel if you're planning to add the CA certificates to the operating systems trusted CA certificate store.\n8. Enter a name for your environment.\n9. Select the CAs and peers that belong to your organization, along with the ordering nodes of your channels, click OK when done.\n\n\n\nIn steps 5 and 6, you can alternatively enter an API key and secret that you generate using the [IBM Blockchain Platform REST APIs](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-ibp-v2-apisconsole-icp-manage-create-api-key).\n\nYou also need to import your admin identities into the wallet pane and associate them with your nodes. You need to associate an admin identity with your peers, CA, and an ordering node before you can connect with your network.\n\n\n\n1. Click on the environment that you created in the Fabric Environments pane.\n2. You can see an Alert sign next to the peer and ordering node. Click on the alert to associate an admin identity with the node.\n3. Select Add a new wallet.\n4. Select Create a new wallet.\n5. Enter a name for your wallet to identify the orderer or peer admin of your network.\n6. Select Add a new identity.\n7. Enter name for your peer or orderer admin identity.\n8. Select Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-7-1700","score":22.622274,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":20.88727,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16368-7-2072","score":19.29935,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-20684-22621","score":18.679989,"text":"\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2. To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3. To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Securing the web chat \n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16374-0-2178","score":18.305288,"text":"\n\n\n\n\n\n\n  Supporting global audiences \n\nYou can build an assistant that understands customer messages in any of the languages that are supported by the service. The responses from your assistant are defined by you and can be written in any language you want.\n\nHowever, some of the phrases that are displayed in the web chat widget are part of the web chat itself and do not come from the assistant. By default, these hardcoded phrases are specified in English, but you can apply a different language by adding lines to the embedded web chat script.\n\nThe hardcoded phrases used by the web chat widget are specified in language pack files. The web chat provides language packs that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1.  To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.  To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3.  To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global"},{"document_id":"ibmcld_16384-1889-3334","score":18.272726,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16365-10062-12114","score":18.104067,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16334-21500-23502","score":18.034931,"text":"\nFor more information about these response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n* Link to start web chat: You can now create a set of HTML links that go directly to your web chat and start conversations on specific topics. For example, you might want to send an email inviting customers to update their account information; you can include a link that opens the web chat on your site and sends the initial message I want to update my account. For more information, see [Creating links to web chat](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationpageLinks).\n* CSS improvements: Support for CSS styles has been improved to change the way the web chat resets styles in areas where you can include your own custom content, such as user-defined responses and writeable elements. The new approach better protects custom content from accidental style overrides. For more information about custom content and CSS classes, see [Theming & custom content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/testfest.html?to=api-render).\n\nIf you have any custom content (such as user-defined responses or writeable elements), verify that any styling is still rendering as you expect. Consider using the new [ibm-web-chat--default-styles class](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/testfest.html?to=api-renderhelper_classes) to maintain consistency with the web chat default styles.\n* Support for Carbon components: As part of the new styling support, you can now use [Carbon components](https:\/\/www.carbondesignsystem.com\/components\/overview\/) in user-defined responses and web chat writeable elements. These components will inherit any theming customizations you have made to the web chat.\n* New embedded script: The embedded script you use to add the web chat to your website has been updated to avoid unexpected code changes when you lock on to a web chat version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16381-0-734","score":17.927729,"text":"\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"},{"document_id":"ibmcld_03080-1529-3357","score":17.875402,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":23.85148,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":23.417511,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":22.768803,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-581893-583377","score":22.373667,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_06160-5357-7356","score":21.65432,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":21.512589,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":21.14265,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-10037-11653","score":20.805492,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":20.370161,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10684-1332-2528","score":19.950851,"text":"\nYour Flow Logs for VPC gathers information from the VPC, VPC subnet, or VPC load balancer level. However, you can use the flow logs to gather information that is specific to your worker nodes. Separate flow log files are created for ingress and egress traffic.\n\n\n\n1. In the CLI, find the ibm-cloud.kubernetes.io\/instance-id label value for the worker node.\n\noc describe node <worker_node_ip> | grep instance-id\n\nExample output.\n\nibm-cloud.kubernetes.io\/instance-id=1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n2. In the IBM Cloud UI, click your IBM Cloud Object Storage instance in the Resource list.\n3. Click the bucket where your flow logs are collected.\n4. Download and decompress the flow log object.\n5. Open the file and navigate through the file directory until you reach directories that begin with instance-id=.\n6. Find the file directory that contains the instance ID found in the first step. The ID is included at the end of the file directory name. Example.\n\ninstance-id=crn%3AV1%...%3Ainstance%3A1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n7. In the instance=id= directory, locate the record-type=ingress and record-type=egress files. Your ingress and egress traffic logs are located here.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-flow-log"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":29.840057,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-8154-10055","score":26.53095,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-10731-12253","score":26.089338,"text":"\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud oc worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\noc describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal12","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-18717-20364","score":26.009844,"text":"\nComplete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-6354-8294","score":25.936148,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-11131-12823","score":25.812786,"text":"\nIf applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Kubernetes version preparation guide](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n* If you want to apply a patch update, review the [Kubernetes version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud ks worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\nkubectl describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05598-24740-26499","score":25.483097,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1562\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1562, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1562. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1561\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change logs](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1561, released 27 September 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1561. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.14_1559\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_10405-18875-19733","score":25.439066,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.57_1580_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N\/A N\/A N\/A \n RHEL 8 Packages N\/A N\/A N\/A \n Red Hat OpenShift on IBM Cloud. N\/A N\/A N\/A \n Haproxy af5031 8398d1 [CVE-2023-23916](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2023-23916). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.9.57_1580_openshift, released 13 March 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.9.57_1580_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.56_1576_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_49"},{"document_id":"ibmcld_10642-9304-11080","score":25.250126,"text":"\nYou can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only. These rules do not impact worker node reloads which means reloading happens immediately when requested.\n\nWhat if I choose not to define a config map?\n: When the config map is not defined, the default is used. By default, a maximum of 20% of all your worker nodes in each cluster can be unavailable during the update process.\n\n\n\n Prerequisites \n\nBefore you update your classic infrastructure worker nodes, review the prerequisite steps.\n\nUpdates to worker nodes can cause downtime for your apps and services. Your worker node machine is reimaged, and data is deleted if not [stored outside the pod](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan).\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10068-170960-171999","score":25.183367,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1533_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.29 4.3.31 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.htmlocp-4-3-31). The update resolves CVE-2020-8558 (see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6319989)). \n RHEL 7 packages N\/A N\/A Updated worker node images with package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.29_1533_openshift, released 3 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.29_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1532_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.6508205186}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":30.11615,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10642-6354-8294","score":28.188137,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":26.77624,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-10731-12253","score":24.10496,"text":"\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud oc worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\noc describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal12","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10284-1470-3569","score":23.789911,"text":"\n* Image and version updates: Worker node updates, such as security patches to the image or Red Hat OpenShift versions, are provided by IBM for you. However, you choose when to apply the updates to the worker nodes. For more information, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update).\n* Temporary modifications: If you log in to a pod or use some other process to modify a worker node setting, the modifications are temporary. Worker node lifecycle operations, such as autorecovery, reloading, updating, or replacing a worker node, change any modifications back to the default settings.\n* Persistent modifications: For modifications to persist across worker node lifecycle operations, create a daemon set that uses an init container. For more information, see [Modifying default worker node settings to optimize performance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelworker).\n\n\n\nModifications to the operating system are not supported. If you modify the default settings, you are responsible for debugging and resolving the issues that might occur.\n\n\n\n\n\n Hardware changes \n\nTo change the compute hardware, such as the CPU and memory per worker node, choose among the following options.\n\n\n\n* [Create a worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers). The instructions vary depending on the type of infrastructure for the cluster, such as classic, VPC, Satellite, or gateway clusters.\n* [Update the flavor](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type) in your cluster by creating a worker pool and removing the previous worker pool.\n\n\n\n\n\n\n\n\n\n Modifying worker node settings to optimize performance \n\n\n\n Modifying worker node settings by using the Node Tuning Operator \n\nYou can use the node tuning operator to tune worker node performance by creating custom profiles. For more information, see the Red Hat [Node Tuning Operator](https:\/\/docs.openshift.com\/container-platform\/4.7\/scalability_and_performance\/using-node-tuning-operator.html) docs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernel"},{"document_id":"ibmcld_06209-11131-12823","score":23.773762,"text":"\nIf applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* [Update the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster). The worker node version can't be higher than the API server version that runs in your Kubernetes master.\n* Make any changes that are marked with Update after master in the [Kubernetes version preparation guide](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n* If you want to apply a patch update, review the [Kubernetes version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud ks worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\nkubectl describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05598-24740-26499","score":23.026913,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1562\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1562, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1562. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.15_1561\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change logs](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.15_1561, released 27 September 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.19.15_1561. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.14_1559\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_05599-40319-41968","score":22.940609,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.11_1555\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.20.11_1555, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.20.11_1555. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.11_1554\n\n Component Previous Current Description \n\n Containerd v1.4.9 v1.4.11 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change logs](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.4.11). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for master fix pack 1.20.11_1553, released 28 September 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.21.1_1553. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.20.10_1550\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_120"},{"document_id":"ibmcld_06010-6040-7693","score":22.395153,"text":"\nTo update the version of the operating system that a worker node uses, such as from Ubuntu 16 to 18, you can [replace the flavor of the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type).\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\nkubectl get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\nkubectl describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>\nLabels: arch=amd64\n...\nibm-cloud.kubernetes.io\/os=UBUNTU_18_64\n...\nkubernetes.io\/arch=amd64\nkubernetes.io\/hostname=10.189.33.198\nkubernetes.io\/os=linux\n...\nSystem Info:\nOS Image: Ubuntu 18.04.5 LTS\nOperating System: linux\nArchitecture: amd64\n...\n\n\n\n\n\n\n\n\n\n Virtual machines \n\nWith VMs, you get greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price. You can use VMs for most general-purpose use cases such as testing and development environments, staging, and prod environments, microservices, and business apps. However, there is a tradeoff in performance. If you need high-performance computing for data- or RAM-intensive workloads, consider creating classic clusters with [bare metal](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes"},{"document_id":"ibmcld_05601-80075-81768","score":22.363651,"text":"\nThe following table shows the changes that are in the worker node fix pack patch update 1.22.2_1527. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.22.2_1524\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A Updated worker node images with package updates. Contains fix for cloud-init performance problem. \n Worker-pool taint automation N\/A N\/A Fixes known issue related to worker-pool taint automation that prevents workers from getting providerID. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.22.2_1524, released 11 October 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.22.2_1524. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.22.2_1523\n\n Component Previous Current Description \n\n Containerd v1.5.5 v1.5.7 See the [security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6501867) and the [change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.5.7). \n Ubuntu 18.04 packages 4.15.0-158 4.15.0-159 Updated worker node images and kernel with package updates [CVE-2021-3778](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3778) and [CVE-2021-3796](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-3796). \n\n\n\n\n\n\n\n Change log for master fix pack 1.22.2_1522 and worker node fix pack 1.22.2_1523, released 29 September 2021 \n\nThe following table shows the changes that are in the master fix pack 1.22.2_1522 and the worker node fix pack patch update 1.22.2_1523.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_122"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09410-3448-5457","score":16.312183,"text":"\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.\n* [hash] represents the digest (manifest) of the container image. It is a unique SHA-256 hash.\n\n\n\nThe following table outlines the tagging convention adopted and the agent update behavior:\n\n\n\nTable 1. logging agent tags explained\n\n Tag Logging agent auto-update enabled More info \n\n X YES The logging agent auto-updates when a new minor version releases. <br>The logging agent does not update to a new major version, as these updates may require configuration changes. \n X.Y YES The logging agent auto-updates when a new patch version is released. \n X.Y.Z YES The logging agent auto-updates when a new vulnerability fix is released. The agent code does not change, but the included libraries have vulnerability fixes. \n X.Y.Z-<date>.[hash] NO The logging agent never updates. If you use this tag, make sure you are watching for new agent releases that have vulnerability fixes. \n\n\n\nDepending on the tag that you use, you must consider upgrading the logging agent image in your DevOps maintenance plan, to resolve vulnerabilities and apply agent enhancements and agent bug fixes. For example:\n\n\n\n* In a development environment, you can use a tag X and let auto-updates happen as new minor versions are released.\n* In a staging environment, you might consider using a tag X.Y so auto-updates happen when a new patch is released.\n* In a production environment, you can use the tag X.Y.Z so that auto-updates happen when a new vulnerability fix is released.\n* For highly regulated environments, you should use the tag X.Y.Z-<date>.[hash]. Notice that you will have to check periodically for vulnerability fixes, patches, and minor version releases to keep the agent free of issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_16471-74601-76664","score":14.30892,"text":"\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_09275-13854-15898","score":13.68122,"text":"\nTags are case-sensitive, and the maximum length of a tag is 128 characters.\n\n\n\n* The characters that are permitted to name tags are A-Z, 0-9, spaces, underscore, hyphen, period, and colon.\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the log ingestion strategy \n\nFor non-IBM Cloud enabled services, you must decide the method to collect and forward logs from a log source that you want to monitor to a logging instance.\n\nIn IBM Log Analysis, you can collect and forward data to a logging instance by using any of the following methods:\n\n\n\n* logging agent: Logging agent that automatically collects and forwards logs to 1 logging instance in your account.\n* Syslog: Logging daemon that collects information across multiple devices and system-services, and forwards logs to 1 logging instance in your account.\n* REST API: API that you can use to send log data and custom metadata to 1 logging instance in your account.\n* Code libraries: Libraries that you can use to code ingestion of logs from your apps and services to 1 logging instance. logging offer libraries for Node.JS, Python, Rails, Ruby, Go, iOS, Java, and PHP.\n\n\n\nFor any method that you adopt, you have the flexibility to choose the logging instance where you want to send data per log source. Decide how many instances you might need to collect data from all your log sources based on who can see the data and the type of data that is collected. Avoid sending data to a logging instance that has the platform logs flag enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_16471-73103-74976","score":13.6164055,"text":"\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_05074-7-1939","score":13.247848,"text":"\nTagging objects in IBM Cloud Object Storage \n\nYour data can be expressly defined, categorized, and classified in IBM Cloud\u00ae Object Storage using associated metadata, called \"tags.\" This document will show you how to take full control in \"tagging\" the objects representing your data.\n\n\n\n Objects and metadata \n\nOrganizing your data can be a complex task. Basic methods, such as using key prefixes like organizational \"folders\" are a great start to hierarchical structures. But for more complex organization, you will need custom \"\n\ntags.\" Your metadata can describe the relationships inherent to your data, and provide more organization than titles or folders. Unlike mere labels, there are two parts to a tag: a key and a value, defined individually according to your needs.\n\n\n\n Tagging Objects \n\nManaging tags describing your objects can be performed through various interfaces and architectures. Using the [Console](https:\/\/cloud.ibm.com) provides a graphical user interface. Using the command line requires tools like [curl](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-curl) and the knowledge of how it interacts with Object Storage.\n\n\n\n\n\n Before you begin \n\nYou need:\n\n\n\n* An [IBM Cloud\u00ae Platform account](https:\/\/cloud.ibm.com\/login)\n* An [instance of IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-provision) and a bucket created for this purpose\n* An [IAM API key](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-overview) with Writer access to your Object Storage bucket or instance\n* Either existing or new objects that will have tags applied to them.\n\n\n\n\n\n\n\n Reading tags \n\nTags are accessible throughout an instance with the proper permissions. While the true organizational power of using tags as an organizational principle scales with you, you can access tags on an individual basis as well.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-object-tagging"},{"document_id":"ibmcld_02237-4-2121","score":12.272211,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Working with tags \n\nUse tags to organize, track usage costs, and even manage access to your resources and service IDs. You can tag related resources and view them throughout your account by filtering by tags from your resource list.\n\nTo see a full list of tags in your account, go to Manage > Account in the IBM Cloud\u00ae console, and select Tags.\n\nYou can apply user tags to organize your resources and service IDs and easily find them later. User tags can also help you with identifying specific team usage or cost allocation. By creating access management tags, you can control access to your resources and service IDs without requiring updates to your IAM policies.\n\n\n\n Tagging rules \n\nTags are not case-sensitive, and the maximum length of a tag is 128 characters. The permitted characters are A-Z, 0-9, spaces, underscore, hyphen, period, and colon. The only supported format for access management tags is key:value. The use of a colon formats the tag into a string that isolates two logical parts, like a env:dev pair. A comma separates multiple tags and can't be used within the tag name itself.\n\nTags are visible account-wide and can be replicated across geographic regions. Since tags are not regulated information, avoid creating tags that use personal information, such as your name, address, phone number, email address, or other identifying or proprietary information.\n\n\n\n Sample tags and syntax \n\nYou can apply tags to help you organize and manage your resources, service IDs, and access policies. Consider writing tags as key:value pairs to help coordinate your development environments, projects, compliance, and optimization throughout your organization. See the following table for some examples of tags that you might want to use.\n\n\n\nTable 1. Tag syntax\n\n Tag Description \n\n env:dev, env:test, env:stage, env:prod Use to identify or even manage access to your development environment \n project:lw-wizard, app:poc-app Use to identify or even manage access to a project \n dataresidency:germany, compliance:hipaa, compliance:pii Use to define compliance requirements","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-tag&interface=ui"},{"document_id":"ibmcld_16471-71623-73502","score":12.119891,"text":"\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_02361-12527-14703","score":11.761012,"text":"\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the IAM strategy \n\nUse IBM Cloud\u00ae Identity and Access Management (IAM) to securely authenticate users and service IDs, and to control access to all cloud resources and data consistently in the IBM Cloud.\n\nIf you add PII information in the name or description of IAM resources, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your IAM resources, do not add sensitive information in their names and descriptions.\n\n\n\n Access groups \n\nYou can assign permissions to work with the IBM Cloud Activity Tracker service within the context of the service, a resource group, or an access group.\n\nUse access groups to organize a set of users and service IDs into a single entity that makes it easy for you to manage IAM permissions.\n\nYou can create multiple access groups.\n\nDefine a minimum of 4 access groups:\n\n\n\nTable 2. List of access groups\n\n Access group Description \n\n Administrators Users in this group should have permissions to fully manage the service and grant other users in the account permissions to work with the service in the IBM Cloud. \n Managers Users in this group should have permissions to fully manage the service in the IBM Cloud. \n Advanced service users Users in this group should have permissions to run advanced service tasks. \n Users Users in this group should have permissions to run basic tasks. \n\n\n\n\n\n\n\n Policies \n\nA policy determines the full set of actions that a user or service ID can perform.\n\nFor each access group, define a policy for each resource group that defines the level of access to that resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_07043-1723-3942","score":11.48592,"text":"\nDomain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant. For example, when you apply the Entity enrichment, terms that mention city names or famous people are tagged as locations or people of interest. \n Facet A category by which you can filter search query results. Automatically, facets based on entity types are applied to the query results for Document Retrieval projects and facets based on the parts of speech are applied to Content Mining projects. You can define your own facet categories based on document fields, including fields generated by enrichments, or based on dictionaries or patterns. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-facets) \n Index As you upload data or connect to data that is stored in an external repository, the data is crawled and ingested. As part of the processing, an index is created to keep track of important information that is recognized from the source. The main difference between a data source and a collection is that content in the data source is crawled, normalized, and indexed as it is added to a collection. \n Project A container for the collections of data that fuel your research or search applications. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects). \n Regular expression A regular expression, also known as a regex, is a standardized format for defining search patterns. You can define patterns with special significance to your application. For example, the bill of materials (BOM) numbers for parts that you manufacture might have a standard syntax of two uppercase letters followed by four numbers (GT2345). You can teach Discovery to recognize BOM mentions by adding a regular expression that can recognize and tag occurrences of the pattern in text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-glossary"},{"document_id":"ibmcld_05256-31524-33025","score":11.469776,"text":"\n--__.. 0-128 (NOT start with periodOrDash) \n IMAGEID a-z 0-9 : (startwith sha256: noOtherColon) \n\n\n\nThe parts of the image name must meet the following criteria.\n\n\n\n* REGISTRY must be 253 characters or fewer and can contain lowercase or uppercase letters, numbers, periods (.), hyphens (-), and underscores (_). Do not use a dash (.) as the last character. Do not use more than 127 periods (.) and the labels between them can be between 1 and 63 characters long.\n* NAMESPACE must be between 4 and 30 characters and must begin and end with a lowercase letter or number. NAMESPACE can contain lowercase alphanumeric characters, hyphens (-), and underscores (_).\n* DOCKERUSERorDOCKERORG can be used for Docker registries instead of NAMESPACE. Specify your Docker username or Docker organization. Your Docker username and organization must be between 4 and 30 characters and contains only lowercase alphanumeric characters or numbers.\n* REPOSITORY must be between 2 and 255 characters and must begin and end with a lowercase letter or number. REPOSITORY can contain lowercase alphanumeric characters, forward slashes (\/), periods (.), hyphens (-), and underscores (_).\n* TAG must be between 0 and 128 characters and can contain lowercase or uppercase letters, numbers, periods (.), hyphens (-), and underscores (_). The TAG must not begin with a period or dash. If you do not include a TAG, do not include the colon either.\n* IMAGEID is prefixed with sha256: and can contain lowercase letters and numbers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.7365896932,"ndcg_cut_10":0.8756458727}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03970-6841-9069","score":20.283216,"text":"\nIf you import a bulk data transfer of nodes and do not also import identities, you will have to perform the separate step of associating identities with the nodes. There are a few ways to procure an identity that can operate a node. For more information about, see [Gathering certificates or credentials](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodesibp-console-import-start-here). Regardless of the process used to acquire the identity, after the bulk import has been completed you will need to click on each imported node. For peers and ordering nodes, a box on the left of the screen will say Identity not associated with (peer or ordering node), depending on the node in question. After clicking on this box, you will be able to associate the relevant identity by selecting it from your Wallet. Note that this process is distinctly different than the process for importing individual nodes, where you will be asked to associate an identity as part of the import process.\n\nYou will also need to associate an admin identity for the CA. This process is similar to the peer and ordering node process except that after you click on the imported CA you will see a separate screen asking you to associate an identity rather than a box on the left.\n\nFor cases where bulk data transfers are impractical or inadvisable, you can follow the steps below to export and import components and identities one at a time.\n\n\n\n\n\n Gathering certificates or credentials \n\nBecause identities contain private keys, be careful when exporting them to ensure they are handled securely. If a private key is compromised, it can be used to perform malicious actions.\n\nEach IBM Blockchain Platform component is deployed with the signing certificate of an administrator inside. When actions requiring the permission level of an admin are performed against the component, the signing certificate of the entity attempting the action is checked against the signing certificate inside the node. If they don't match, the action is denied. In this way, these certificates, which are also known as \"keys\", allow the administrator to operate their components.\n\nIf you intend to operate an imported node, you have two options:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodes"},{"document_id":"ibmcld_06160-11142-12906","score":19.669508,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_03406-34893-35432","score":19.612806,"text":"\nIn this tutorial you tested a node with slots and made changes that optimize how it interacts with real users. For more information about this subject, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots).\n\n\n\n\n\n\n\n Next steps \n\nDeploy your dialog skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"},{"document_id":"ibmcld_10596-11475-13230","score":18.941868,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":18.883394,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-581893-583377","score":18.661098,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_03071-3000-4820","score":17.421377,"text":"\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_02961-7-1871","score":17.33522,"text":"\nDialog building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nYou currently know what the node does, but months from now you might not. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_10596-5350-7330","score":17.02862,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":16.601303,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":17.986118,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-4083-5561","score":13.284929,"text":"\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https:\/\/docs.datastax.com\/en\/dsbulk\/doc\/dsbulk\/reference\/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https:\/\/docs.datastax.com\/en\/dse\/6.0\/cql\/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https:\/\/docs.datastax.com\/en\/astra\/docs\/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_06320-1330-3318","score":12.613852,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04489-112645-114324","score":20.789354,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud ks worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-112012-113705","score":20.781925,"text":"\nTo reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reboot command \n\nibmcloud ks worker reboot --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker reload \n\nClassic infrastructure\n\nReload the configurations for a Classic worker node. To reload a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_worker_replace) instead.\n\nA reload can be useful if your worker node experiences problems, such as slow performance or if your worker node is stuck in an unhealthy state. During the reload, your worker node machine is updated with the latest image and data is deleted if not [stored outside the worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). The worker node public and private IP address remain the same after the reload operation.\n\nReloading a worker node applies patch version updates to your worker node, but not major or minor updates. To see the changes from one patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) documentation.\n\nBefore you reload your worker node, make sure that you have enough capacity in other worker nodes to reschedule the pods on the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_06209-8154-10055","score":20.631565,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-21345-23408","score":20.504698,"text":"\nThis type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node. However, the replacement worker node is assigned a new private IP address, and loses any custom labels or taints that you applied to the old worker node (worker pool labels and taints are still applied to the replacement worker node).\n\nWhat if I replace multiple worker nodes at the same time?\n: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.\n\nWhat if a replacement worker node is not created?\n: A replacement worker node is not created if the worker pool does not have [automatic rebalancing enabled](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-off).\n\n\n\n Prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06128-11467-13651","score":20.35231,"text":"\nHow many worker nodes do I need to handle my workload? \n\nNow that you have a good idea of what your workload looks like, let's map the estimated usage onto your available cluster configurations.\n\n\n\n1. Estimate the max worker node capacity, which depends on what type of cluster you have. You don't want to max out worker node capacity in case a surge or other temporary event happens.\n\n\n\n* Single zone clusters: Plan to have at least three worker nodes in your cluster. Further, you want one extra node's worth of CPU and memory capacity available within the cluster.\n* Multizone clusters: Plan to have at least two worker nodes per zone, so six nodes across three zones in total. Additionally, plan for the total capacity of your cluster to be at least 150% of your total workload's required capacity, so that if one zone goes down, you have resources available to maintain the workload.\n\n\n\n2. Align the app size and worker node capacity with one of the [available worker node flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes). To see available flavors in a zone, run ibmcloud ks flavors --zone <zone>.\n\n\n\n* Don't overload worker nodes: To avoid your pods competing for CPU or running inefficiently, you must know what resources your apps require so that you can plan the number of worker nodes that you need. For example, if your apps require less resources than the resources that are available on the worker node, you can limit the number of pods that you deploy to one worker node. Keep your worker node at around 75% capacity to leave space for other pods that might need to be scheduled. If your apps require more resources than you have available on your worker node, use a different worker node flavor that can fulfill these requirements. You know that your worker nodes are overloaded when they frequently report back a status of NotReady or evict pods due to the lack of memory or other resources.\n* Larger versus smaller worker node flavors: Larger nodes can be more cost efficient than smaller nodes, particularly for workloads that are designed to gain efficiency when they process on a high-performance machine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_10568-11152-13334","score":20.340158,"text":"\nHow many worker nodes do I need to handle my workload? \n\nNow that you have a good idea of what your workload looks like, let's map the estimated usage onto your available cluster configurations.\n\n\n\n1. Estimate the max worker node capacity, which depends on what type of cluster you have. You don't want to max out worker node capacity in case a surge or other temporary event happens.\n\n\n\n* Single zone clusters: Plan to have at least three worker nodes in your cluster. Further, you want one extra node's worth of CPU and memory capacity available within the cluster.\n* Multizone clusters: Plan to have at least two worker nodes per zone, so six nodes across three zones in total. Additionally, plan for the total capacity of your cluster to be at least 150% of your total workload's required capacity, so that if one zone goes down, you have resources available to maintain the workload.\n\n\n\n2. Align the app size and worker node capacity with one of the [available worker node flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes). To see available flavors in a zone, run ibmcloud oc flavors --zone <zone>.\n\n\n\n* Don't overload worker nodes: To avoid your pods competing for CPU or running inefficiently, you must know what resources your apps require so that you can plan the number of worker nodes that you need. For example, if your apps require less resources than the resources that are available on the worker node, you can limit the number of pods that you deploy to one worker node. Keep your worker node at around 75% capacity to leave space for other pods that might need to be scheduled. If your apps require more resources than you have available on your worker node, use a different worker node flavor that can fulfill these requirements. You know that your worker nodes are overloaded when they frequently report back a status of NotReady or evict pods due to the lack of memory or other resources.\n* Larger versus smaller worker node flavors: Larger nodes can be more cost efficient than smaller nodes, particularly for workloads that are designed to gain efficiency when they process on a high-performance machine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategy"},{"document_id":"ibmcld_10035-7-2089","score":20.252413,"text":"\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers"},{"document_id":"ibmcld_05558-7-2091","score":20.208387,"text":"\nAdding worker nodes and zones to clusters \n\nTo increase the availability of your apps, you can add worker nodes to an existing zone or multiple existing zones in your cluster. To help protect your apps from zone failures, you can add zones to your cluster.\n\nWhen you create a cluster, the worker nodes are provisioned in a worker pool. After cluster creation, you can add more worker nodes to a pool by resizing it or by adding more worker pools. By default, the worker pool exists in one zone. Clusters that have a worker pool in only one zone are called single zone clusters. When you add more zones to the cluster, the worker pool exists across the zones. Clusters that have a worker pool that is spread across more than one zone are called multizone clusters.\n\nIf you have a multizone cluster, keep its worker node resources balanced. Make sure that all the worker pools are spread across the same zones, and add or remove workers by resizing the pools instead of adding individual nodes. After you set up your worker pool, you can [set up the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-classic-vpc) to automatically add or remove worker nodes from your worker pools based on your workload resource requests.\n\n\n\n Adding worker nodes by resizing an existing worker pool \n\nYou can add or reduce the number of worker nodes in your cluster by resizing an existing worker pool, regardless of whether the worker pool is in one zone or spread across multiple zones.\n\nFor example, consider a cluster with one worker pool that has three worker nodes per zone.\n\n\n\n* If the cluster is single zone and exists in dal10, then the worker pool has three worker nodes in dal10. The cluster has a total of three worker nodes.\n* If the cluster is multizone and exists in dal10 and dal12, then the worker pool has three worker nodes in dal10 and three worker nodes in dal12. The cluster has a total of six worker nodes.\n\n\n\nFor bare metal worker pools, keep in mind that billing is monthly. If you resize up or down, it impacts your costs for the month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers"},{"document_id":"ibmcld_10290-116392-118025","score":20.138157,"text":"\nYou can find more information about your worker node when you run the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command and look for the worker node with the same Private IP address.\n2. Replace the worker node. As part of the replace process, the pods that run on the worker node are drained and rescheduled onto remaining worker nodes in the cluster. The worker node is also cordoned, or marked as unavailable for future pod scheduling. Use the worker node ID that is returned from the ibmcloud oc worker ls --cluster <cluster_name_or_ID> command.\n\nibmcloud oc worker replace --cluster <cluster_name_or_ID> --worker <worker_node_ID>\n3. Verify that the worker node is replaced.\n\nibmcloud oc worker ls --cluster <cluster_name_or_ID>\n\n\n\nibmcloud oc worker replace --cluster CLUSTER_NAME_OR_ID --worker WORKER_ID [--update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service.\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--worker WORKER\n: Required: The name or ID of a worker node.\n\n--update\n: Include this option to update the worker node to the same major and minor version of the master and the latest patch.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker replace command \n\nibmcloud oc worker replace --cluster my_cluster --worker kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1\n\n\n\n\n\n\n\n ibmcloud oc worker rm \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRemove one or more worker nodes from a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_06160-7-2098","score":20.10748,"text":"\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud ks worker commands, and as NotReady in the Kubernetes dashboards and when you run kubectl get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10228-4-1670","score":25.69804,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started"},{"document_id":"ibmcld_10229-4-1670","score":25.69804,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started&interface=ui"},{"document_id":"ibmcld_10489-7-1763","score":25.487062,"text":"\nSetting up the Red Hat Marketplace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nWith [Red Hat\u00ae Marketplace](https:\/\/marketplace.redhat.com\/en-us), you can deploy certified Red Hat software from an operator-based catalog to your OpenShift Container Platform clusters, including Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nRequired permissions:\n\n\n\n* The IAM Operator platform access role for the cluster in Kubernetes Service.\n* The IAM Manager service access role in all namespaces (cluster-admin RBAC) for the cluster in Kubernetes Service.\n\n\n\nRed Hat Marketplace is available for clusters that run Red Hat OpenShift version 4 only.\n\nBefore you begin:\n\n\n\n* Register for a [Red Hat Marketplace account](https:\/\/marketplace.redhat.com\/en-us\/registration\/redhat-marketplace).\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that the Operator Lifecycle Manager (OLM) pods in the openshift-operator-lifecycle-manager project and marketplace pods in the openshift-marketplace project are ready and running. You might have to restart a pod to return the pod to a healthy state.\n\noc get pods -n openshift-operator-lifecycle-manager\n\noc get pods -n openshift-marketplace\n\n\n\nTo set up your cluster with Red Hat Marketplace:\n\n\n\n1. Follow the [Red Hat Marketplace instructions](https:\/\/marketplace.redhat.com\/en-us\/workspace\/clusters\/add\/register) to create a namespace, operator, and global pull secret for the Red Hat Marketplace.\n2. Verify that the global pull secret for the cluster is updated with the registry.marketplace.redhat.com secret.\n\noc get secret pull-secret -n openshift-config --output=\"jsonpath={.data..dockerconfigjson}\" | base64 --decode | grep \"marketplace\" -A4\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rh-marketplace"},{"document_id":"ibmcld_07578-396975-399135","score":25.404139,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-396949-399109","score":25.404139,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10214-4313-6479","score":25.24973,"text":"\nTo get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\n\n\n\n\n Does the service come with a managed Red Hat OpenShift master and worker nodes? \n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches. Security updates and patches are made available by IBM Site Reliability Engineers (SREs) who continuously monitor the Linux image that is installed on your worker nodes to detect vulnerabilities and security compliance issues. For more information, see [Updating worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n\n\n\n\n\n Are the master and worker nodes highly available? \n\nThe Red Hat OpenShift on IBM Cloud architecture and infrastructure is designed to ensure reliability, low processing latency, and a maximum uptime of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10702-7-1940","score":25.085337,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10402-31261-32288","score":24.913597,"text":"\nRed Hat OpenShift 4.6.48 4.6.56 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.6\/release_notes\/ocp-4-6-release-notes.htmlocp-4-6-56). \n Red Hat OpenShift Control Plane Operator v4.6.0-20220222 v4.6.0-20220308 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.6.0+20220308). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.6.0-20220222 v4.6.0-20220308 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.6.0+20220308). \n Red Hat OpenShift on IBM Cloud toolkit 4.6.0+20220222 4.6.0+20220308 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.6.0+20220308). \n\n\n\n\n\n\n\n Change log for worker node pack 4.6.56_1577_openshift, released 28 March 2022 \n\n\n\nChanges since version 4.6.55_1575_openshift\n\n Component Previous Current Description \n\n RHEL Packages N\/A N\/A N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_46"},{"document_id":"ibmcld_10422-1393-2886","score":24.763824,"text":"\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.13\/release_notes\/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.10\/release_notes\/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https:\/\/github.com\/kubernetes\/kubernetes\/tree\/master\/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions"},{"document_id":"ibmcld_10399-53696-54849","score":24.757835,"text":"\nRed Hat OpenShift on IBM Cloud 4.11.0 4.11.4 See the [Red Hat OpenShift on IBM Cloud Release Notes](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-4). \n OpenVPN Operator image v1.4.8 v1.4.9 Updated ansible operator base image to v1.23.0 to resolve CVEs. \n Red Hat OpenShift on IBM Cloud Control Plane Operator v4.11.0-20220829 v4.11.0-20220920 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.11.0+20220920). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.11.0-20220829 v4.11.0-20220920 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.11.0+20220920). \n Red Hat OpenShift on IBM Cloud toolkit 4.11.0+20220829 4.11.0+20220920 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.11.0+20220920). \n\n\n\n\n\n\n\n Change log for master fix pack 4.11.0_1521_openshift, released 1 September 2022 \n\n\n\nChanges since version 4.11.0_1519_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_411"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14913-0-1238","score":24.802374,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_16026-0-358","score":18.847733,"text":"\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vnf-limitations"},{"document_id":"ibmcld_14282-1986-4283","score":16.501604,"text":"\n* Isolation of development, test, and production environments on the same bare metal infrastructure\n* Single Account multi-tenant clouds\n\n\n\nNSX can be configured through the vSphere Web Client, a command line interface (CLI), and REST API. The core network services that are offered by NSX are:\n\n\n\n Logical switches \n\nA cloud deployment or a virtual data center might have various applications across multiple tenants. These applications and tenants require isolation from each other for security, fault isolation, and avoiding overlapping IP addressing issues. The NSX logical switch creates logical broadcast domains or segments (VXLAN vWires) to which an application or tenant virtual machine can be logically wired. This feature allows for flexibility and speed of deployment while still providing all the characteristics of a physical network's broadcast domains (VLANs) without physical Layer 2 sprawl. Logical switches allow for thousands of tenant networks to be provisioned onto a single IBM Cloud private network (VLAN). A logical switch is distributed and can span arbitrarily large compute clusters, even across pods within the same data center. This distribution allows for virtual machine mobility within the data center without limitations of physical Layer 2 (VLAN) boundaries across pods.\n\n\n\n\n\n Logical routers \n\nDynamic routing provides the necessary forwarding information between Layer 2 broadcast domains (VXLAN, vWires, Logical Switches). This routing decreases Layer 2 broadcast domains and improve network efficiency and scale. NSX extends this intelligence where the workloads reside for providing East-West routing functions. This extension allows more direct virtual machine to virtual machine communication without the costly or timely need to extend hops. NSX also provides North-South connectivity inbound and outbound of IBM Cloud data centers, thus enabling tenants to access public networks securely and efficiently.\n\n\n\n\n\n Logical firewall \n\nLogical firewall provides security mechanisms for dynamic virtual data centers. The Distributed Firewall component of an NSX Logical Firewall allows users to segment virtual data center entities (virtual servers), vCenter objects (data centers and hosts), and traditional networking attributes like IP addresses and VLANs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_16030-7-2126","score":16.289114,"text":"\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"},{"document_id":"ibmcld_14398-1360-3493","score":16.252827,"text":"\nFor more information about the IBM Cloud network design, see [Physical network design](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-design_physicalinfrastructure).\n\n\n\n IBM Cloud edge services \n\nYou can deploy a VMware ESXi\u2122 gateway cluster as part of your vCenter Server instance. This cluster is configured to peer with the IBM Cloud customer routers to provide firewall and gateway services for IBM Cloud public and private VLANs of your choice. While you can deploy any virtual firewall technology of your choice to this gateway cluster, IBM Cloud features FortiGate VM as an option for these firewall and gateway services. Using this approach, your FortiGate VM appliances can provide services such as:\n\n\n\n* The firewall between public and private networks.\n* The firewall between your private VLANs and the subnets within them. For example, you can deploy separate clusters for workload and management on to separate VLANs and use the edge to limit connectivity between management and workload.\n* Network peering between your private environment (including your NSX edges and networks) and external environments (such as your on\u2013premises networks).\n* Advanced firewall services such as VPN and IPS for these networks.\n\n\n\nIn the previous figure, this topology is illustrated by the FortiGate-VM Edge component.\n\n\n\n\n\n Virtual firewall appliance \n\nYou can also deploy FortiGate VM as a virtual firewall appliance directly within your management and workload networks. With this approach, your FortiGate VM appliances can achieve the following functions:\n\n\n\n* Gateway firewall between public and private networks such as NAT, firewall, and VPN\n* Gateway firewall between the private network and NSX overlays\n* Gateway firewall between different workload tiers within your NSX overlay networks\n\n\n\nAdditionally, FortiGate VM can use service chaining to integrate directly with NSX\u2013T.\n\nIn the previous figure, these topologies are illustrated by the FortiGate-VM Internal component.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Solution overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortigate-overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortigate-design"},{"document_id":"ibmcld_14282-9296-10826","score":16.140375,"text":"\nThe NSX Controller uses Unicast mode with virtual tunnel endpoints (VTEPS) to provide MAC learning and other functions to allow VXLAN Broadcast, Unknown unicast, and Multicast (BUM) traffic within a logical switch. The unicast mode replicates all the BUM traffic locally on the host and requires no physical network configuration outside of Layer 3 connectivity between VTEPS. NSX Controllers are deployed by the NSX Manager as a minimum set of three controller nodes, and various other nodes to support (distributed) Layer 3 routing services. All of the nodes are deployed as virtual machines and are managed by the NSX Manager on an ESX Management Cluster at IBM Cloud.\n\n\n\n\n\n NSX Edge \n\nNSX Edge provides network edge security and gateway services to isolate a virtualized network. You can install an NSX Edge either as a logical (distributed) router or as a services gateway. The NSX Edge logical (distributed) router provides East-West distributed routing with tenant IP address space and data path isolation. Virtual machines or workloads that reside on the same host on different subnets can communicate with one another without having to traverse a traditional routing interface. The NSX Edge Gateway connects isolated stub networks to shared (uplink) networks by providing common gateway services such as DHCP, VPN, NAT, dynamic routing, and Load Balancing. Common deployments of NSX Edge include in the DMZ, VPN extranets, and multi-tenant cloud environments where the NSX Edge creates virtual boundaries for each tenant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_14282-5653-8041","score":16.122694,"text":"\nLoad balancing thus helps in achieving optimal resource utilization, maximizing throughput, minimizing response time, and avoiding overload. NSX Edge provides load balancing up to Layer 7.\n\n\n\n\n\n Service composer \n\nService composer helps you provision and assign network and security services to applications in a virtual infrastructure. These services can be mapped and applied to virtual machines in the security groups. Data security provides visibility into sensitive data that is stored within your organization's virtualized and cloud environments that include IBM Cloud. Based on the violations reported by NSX Data Security, you can make sure that sensitive data is adequately protected and assess compliance with regulations around the world.\n\n\n\n\n\n NSX extensibility \n\nVMware partners can integrate their network service solutions with the NSX platform, which enables customers to have an integrated experience across VMware products. Data center operators can provision complex, multi-tier virtual networks in seconds, independent of the underlying network topology or components from IBM Cloud.\n\n\n\n\n\n NSX core components \n\nYou can configure and manage these components through the vSphere Web Client, a command line interface (CLI), and REST API. VMware NSX requires a functional IBM Cloud environment with at least vSphere and vCenter version 6. The components are deployed as VMware Appliance VMs that run on IBM Cloud. NSX components are not supported as virtual server instances. It is recommended that the instructions are followed to create a dedicated ESX Management Cluster. Additionally an Edge Services Cluster might also be required.\n\n\n\n\n\n NSX manager \n\nThe NSX manager is the centralized network management component of NSX, and is installed as a virtual appliance on an ESX host in your vCenter Server environment. IBM Cloud Architecture recommends that this VM deploys on a dedicated Management ESX Cluster. One NSX Manager maps to a single vCenter Server environment and multiple NSX Edge, vShield Endpoint, and NSX Data Security instances.\n\n\n\n\n\n NSX vSwitch \n\nNSX vSwitch is the software that operates on IBM Cloud ESX hosts to form a software abstraction layer between servers and the physical network. As the demands on data centers continue to grow and accelerate, requirements that are related to speed and access to the data itself continue to grow as well.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_14480-2803-4773","score":15.800406,"text":"\nService Router Provides gateway services<br><br><br><br> * NAT<br> * Load Balancer<br> * Gateway firewall<br> * North-south routing<br> * VPN<br> * DNS Forwarding<br> * DHCP<br><br><br> \n\n\n\nSome key NSX-T concepts do not correspond to NSX-V functions. You need to review the following concepts so you can understand the NSX-T design implementation.\n\n\n\n* A gateway cluster is one or more VMs or physical machines that participate in an NSX-T virtual fabric. They are endpoints for the overlay network transport zones and VLAN backed transport zones. A gateway cluster can support a single T0 gateway instance.\n* A T0 gateway is a virtual router instance, but not a VM. Multiple T0 gateway instances can run within a gateway cluster each with its own routing table and functions. A gateway cluster must exist before you can create a T0 router instance.\n* A transport zone can span endpoints across different platforms and multiple vSphere vCenter instances. No cross-vCenter linked NSX is required. Transport zones can be excluded from specific endpoints.\n* Uplink failover order is created independent of a particular logical switch as they are created in profiles as \u201cUplink Profiles\u201d and are applied to a particular logical switch based on VLAN. It's possible to need a differing failover order or load balancing of physical uplinks for the same VLAN. Therefore, the uplink profile for a particular VLAN can contain multiple entries for \u201cTeaming\u201d with different a failover order and load balancing. When you assign the uplink profile to a logical switch, the specific teaming profile is chosen.\n* The manager VM and the controller VM function are combined, which results in three NSX-T manager VMs being deployed. If on the same subnet, they use an internal network load balancer. If across different subnets, an external load balancer is required.\n\n\n\n\n\n\n\n Resource requirements \n\nIn this design, the NSX-T controller Manager VMs are deployed on the management cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-nsx-t-design"},{"document_id":"ibmcld_15742-4-1884","score":15.679412,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Creating a network load balancer for VPC with routing mode \n\nVirtual Network Function (VNF) devices are virtualized network services (such as routers and firewalls) running on virtual machines. With IBM Cloud VPC, you can provision VNF devices to gain better and more affordable scalability than you would by purchasing physical network devices.\n\nTraffic destined for servers in IBM Cloud VPC must be delivered to healthy VNF devices; otherwise, traffic disruption occurs. You can use network load balancers with routing mode to perform health checks and to ensure that workloads only travel through healthy VNF devices. Because of this, network load balancers with routing mode support only VNF devices as back-end targets.\n\nFor detailed examples of various ways you can deploy your NLB with routing mode, refer to [HA VNF deployments](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf-ha&interface=ui).\n\n\n\n Prerequisites for NLB with routing mode \n\nTo support routing mode, you must first create a service-to-service authentication policy for your NLB. To do, follow these steps:\n\n\n\n1. From your browser, log in to [IBM Access Management](https:\/\/cloud.ibm.com\/iam\/authorizations\/grant).\n2. Click Authorizations, then click Create.\n3. For the source service, select VPC Infrastructure Services. For scope access, select Resources based on selected attributes > Resource Type > Load Balancer for VPC.\n4. For the target service, select VPC Infrastructure Services. For scope access, select Resources based on selected attributes > Resource Type > Virtual Private Cloud.\n5. Select the Editor checkbox to give yourself Editor access, then click Authorize.\n\n\n\n\n\n\n\n Creating a network load balancer with routing mode using the UI \n\nTo create and configure Network Load Balancer for VPC with routing mode using the IBM Cloud console, follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb-vnf&interface=cli"},{"document_id":"ibmcld_14870-7-1912","score":15.53416,"text":"\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-overview"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16662-0-1981","score":14.33641,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_05152-4777-6005","score":14.151511,"text":"\n[SQL Query Window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https:\/\/www.ibm.com\/cloud\/blog\/analyzing-data-with-ibm-cloud-sql-query).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sql-query"},{"document_id":"ibmcld_16666-11924-13606","score":13.366434,"text":"\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_13493-2289-4276","score":12.797178,"text":"\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos:\/\/us-geo\/sql\/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_09437-8631-10180","score":12.607532,"text":"\nIdentify the file that you want to query.\n\nNotice that the file name has the ID of your Log Analysis instance and the date, in UTC format.\n6. For that file, copy the Object Data Engine URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file \n\nComplete the following steps to run the query to transform content from JSON into partitioned JSON objects:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT , date_format(from_unixtime(_source._ts \/ 1000, 'yyyy-MM-dd HH:mm:ss'), 'yyyy') AS _year,\ndayofyear(from_unixtime(_source._ts \/ 1000, 'yyyy-MM-dd HH:mm:ss')) AS _dayofyear,\ndate_format(from_unixtime(_source._ts \/ 1000, 'yyyy-MM-dd HH:mm:ss'), 'HH') AS _hour\nFROM SQL_URL STORED AS JSON\nINTO RESULTS_BUCKET STORED AS JSON PARTITIONED BY (_year, _dayofyear, _hour)\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nIn the statement, the timestamp information is captured in the _ts entry of each row and is used to generate the year, day of year, and hour information. The result reflects the specified partitioning as Hive style partitioning.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-sqlquery"},{"document_id":"ibmcld_16666-10416-12326","score":12.4058,"text":"\n* Add the metadata catalogs to manage your table schemas.\n* Select the query engine to work with your data.\n\n\n\nComplete the following steps:\n\n\n\n1. In the Bucket configuration page, select Provision new IBM-managed bucket.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select a catalog.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the Presto engine and smallest starter (1 coordinator node 1 worker node memory optimized).\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nAlthough you can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to, this would change the consumption rate of your promo code. When you add items in the Infrastructure manager, you can see the resource unit consumption per hour.\n\nThe promotion credits consumption begins immediately after you configure and the support services are created for your metadata. Ensure that you pause the Presto engine when it is not used. This helps in optimizing the usage credit.\n\n\n\n\n\n Step 6: Ingesting data \n\nThe data files are ingested into watsonx.data using CLI. For the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_02522-8519-10234","score":12.399025,"text":"\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format \n\nWhen you query an archive file, the format of the data is JSON. You must transform the format to PARQUET to query successfully the data.\n\nParquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n\nThe Data Engine UI is an editor that lets you immediately start composing SQL queries. Since SQL Query uses Spark SQL, you can use Spark SQL functions and ANSI SQL to compose both simple and complex queries that involve large amounts of data.\n\nComplete the following steps to run the query to transform content from JSON into PARQUET:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT * FROM cleancols(SQL_URL STORED AS JSON)\nINTO RESULTS_BUCKET STORED AS PARQUET\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n* Use [cleancols](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference) to avoid transformation problems into PARQUET format when the name of the columns include special characters or blanks.\n\n\n\nFor example, the following query is used to transform an archive file:\n\nSELECT * FROM cleancols(cos:\/\/ams03\/at-eu-de\/999999d8f1f.2019-06-03.62.json.gz STORED AS JSON)\nINTO cos:\/\/eu-de\/results-at STORED AS PARQUET\n2. Click Run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_16670-5968-7639","score":12.081077,"text":"\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_join_data"},{"document_id":"ibmcld_12114-4110-6128","score":11.94124,"text":"\n4. Click Create host group.\n5. Enter a name for your host group and select the Schematics Workspaces that provisioned the target hosts that you want to add to your host group.\n6. Optional: Click Add query to add another condition to your query and limit the number of target hosts that are added to your host group. You can choose to identify your hosts by using the resource name or a tag. For more information, see [supported resource queries](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setupsupported-queries).\n7. Repeat step 4-6 to add more host groups.\n8. From the table list, select the host groups that you want to include in your resource inventory.\n9. Click Create inventory.\n10. Follow the [steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-action-workingcreate-action) to create the Schematics Actions and use the resource inventory that you created.\n\n\n\n\n\n Supported resource queries \n\n\n\nResource query\n\n Supported query Description \n\n Workspace name Select all the IBM Cloud resources from a specific workspace. \n Workspace name AND resource name Select a specific resource from a specific workspace by using the resource name. To select multiple resources from the same workspace, you can add multiple queries of this type. \n Workspace name AND tag Select a specific resource from a specific workspace by using tags. Tags are added to the resource when you create the workspace and provision your resource. To select multiple resources with different tags from the same workspace, you can add multiple queries of this type. \n\n\n\n\n\n\n\n Limitations \n\nReview the following limitations of dynamic inventories in Schematics:\n\n\n\n* You can choose among the [supported queries](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setupsupported-queries) to select the target virtual server instances to include in your resource inventory.\n* Schematics retrieves the IP address of a target Virtual Servers for VPCs and adds the IP address to the resource inventory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setup"},{"document_id":"ibmcld_02522-13463-15240","score":11.914018,"text":"\nFor example, to get the list of actions for a user, you can run the following query:\n\nSELECT _source.eventTime, _source.action, _source.o_target.name\nFROM cos:\/\/eu-gb\/sql-results\/jobid=3aa9e732-ba88-4ffe-b9fc-b8a265876467 STORED AS PARQUET\nWHERE _source.o_initiator.name = \"xxx@ibm.com\"\nORDER BY _source.eventTime\nINTO cos:\/\/eu-gb\/sql-results STORED AS CSV\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.7. Run a query to get a subset of the event fields ordered by the event time \n\nTo see information about each event, run the following query:\n\nSELECT FIELDS FROM PARQUET_FILE STORED AS PARQUET\nORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\nWhere\n\n\n\n* FIELDS is the list of fields that you want to get information on for the different records. For example, you can enter _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME\n* PARQUET_FILE is the Result location URL that you get when you transform the archive file from JSON to PARQUET\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET ORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02628-4002-5694","score":9.611706,"text":"\nWith your query parameters defined in the previous step, you are ready to define the response object, which is returned when you invoke the weather API. Scroll to the Definitions panel.\n\n\n\n1. Add a new definition.\n2. Name the new definition Current.\n3. Set the Type of Object.\n4. Add new properties for the Current definition as shown in Table 1.\n\n\n\nTable 1. Properties for the Current definition\n\n Name Type \n\n zip string \n temperature integer \n humidity integer \n city string \n state string \n\n\n\n\n\n![definition-current-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/definition-current-1.png)\n\n\n\n5. Save your API.\n\n\n\n12. In the previous step, you defined the response object. Next you'll need to ensure the response object is associated with the get \/current path. In the navigation, scroll back up to the Paths panel. a. Open the GET \/current operation, and scroll to the Responses section. b. Change the schema of the 200OK response from \"object\" to \"Current\". c. Save your API.\n13. The GET \/current path and operation get the current weather data. Now you'll need to create a similar path and operation to get today's weather data. Similar to how you created the \/current path in step 11, create a new path: \/today.\n14. Add a Parameter to the GET \/today operation.\n\n\n\n* Parameter Name: zipcode\n* Located in: Query\n* Required: Yes\n* Type: string\n\n\n\n15. Create a new definition: Today.\n16. Add new properties for the Today definition as shown in Table 2.\n\n\n\nTable 2. Properties for the Today definition\n\n Name Type \n\n zip string \n hi integer \n lowe integer \n nighthumidity integer \n dayhumidity integer \n city string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_add_openapi_rest_tk"},{"document_id":"ibmcld_09994-7-1823","score":9.346515,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_00644-7-2122","score":9.283792,"text":"\nUsing Views \n\nUse views to search for content within a database that matches specific criteria. The criteria are specified within the view definition.\n\nCriteria can also be supplied as arguments when you use the view.\n\n\n\n Querying a view \n\nTo query a view, submit a GET request with the following format:\n\nMethod\n: Issue a partition query by using the following command, GET $SERVICE_URL\/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_view\/$VIEW_NAME. Or issue a global query by using the following command, GET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME.\n\nRequest\n: None\n\nResponse\n: JSON of the documents that are returned by the view.\n\nRoles permitted\n: _reader\n\nThe request runs either:\n\n\n\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database, which is constrained to results within the specified $PARTITION_KEY data partition.\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database.\n\n\n\nThe examples in this document vary between partition and global queries for illustrative purposes. Unless otherwise noted, modifying the path to embed or remove the partition name works for any view query type.\n\n\n\n Query and JSON Body Arguments \n\nGlobal queries can use all query and JSON body arguments. Partition queries can use only the subset that is indicated in the table.\n\n\n\nTable 1. Subset of query and JSON body arguments available for partitioned queries\n\n Argument Description Optional Type Default Supported values Partition query \n\n conflicts Specify whether to include a list of conflicted revisions in the _conflicts property of the returned document. Ignored if include_docs isn't set to true. Yes Boolean False Yes \n descending Return the documents in descending by key order. Yes Boolean False Yes \n end_key Stop returning records when the specified key is reached. Yes String or JSON array Yes \n end_key_docid Stop returning records when the specified document ID is reached. Yes String Yes \n group Specify whether to group reduced results by key. Valid only if a reduce function is defined in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00512-13573-14952","score":8.942547,"text":"\nTo return the readings for a specific device from a partition, you can use an IBM Cloudant Query index. For this document, use POST to _index with an index definition that includes the partitioned field set to true.\n\nFor Query index definitions, the partitioned field isn't nested inside an options object.\n\nFor these queries, you need two partitioned indexes:\n\n\n\n1. By timestamp\n2. By device ID and timestamp\n\n\n\n\n\n Uploading partitioned index by timestamp \n\nUpload the index by timestamp to the database by using this command:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/readings\/_index\" -H 'Content-Type: application\/json' --data '{\n\"index\": {\n\"fields\": [\n{\"ts\": \"asc\"}\n]\n},\n\"name\": \"timestamped-readings\",\n\"type\": \"json\",\n\"partitioned\": true\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.IndexDefinition;\nimport com.ibm.cloud.cloudant.v1.model.IndexField;\nimport com.ibm.cloud.cloudant.v1.model.IndexResult;\nimport com.ibm.cloud.cloudant.v1.model.PostIndexOptions;\n\nCloudant service = Cloudant.newInstance();\n\nIndexField indexField = new IndexField.Builder()\n.add(\"ts\", \"asc\")\n.build();\n\nIndexDefinition index = new IndexDefinition.Builder()\n.addFields(indexField)\n.build();\n\nPostIndexOptions indexOptions = new PostIndexOptions.Builder()\n.db(\"readings\")\n.index(index)\n.name(\"timestamped-readings\")\n.type(\"json\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00512-12262-14029","score":8.698514,"text":"\nFor the queries described previously, you need two indexes:\n\n\n\n1. A global index-mapping device ID to infrastructure ID\n2. A partitioned index-mapping device ID to reading\n\n\n\n\n\n Creating a global view index \n\nA view index is the most efficient way to do the simple device ID to infrastructure ID mapping. To define it, upload a design document with options.partitioned set to false as this index is global. While in a real map function you'd want to be more defensive around field existence, this document would look something like this:\n\n{\n\"options\": {\n\"partitioned\": false\n},\n\"views\": {\n\"by-device\": {\n\"map\": \"function(doc) { emit(doc.deviceID, doc.infrastructureID) }\"\n}\n}\n}\n\nAssuming the previous document in .\/view.json, this document is uploaded to the database by using the following command:\n\ncurl -X PUT \"$SERVICE_URL\/readings\/_design\/infrastructure-mapping\" -H 'Content-Type: application\/json' --data @view.json\n\nFor more language examples that show creating a global view, see the [Storing the view definition](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreducestoring-the-view-definition) guide, or [the Create or modify a design document section in API Docs](https:\/\/cloud.ibm.com\/apidocs\/cloudantputdesigndocument).\n\n\n\n\n\n Creating a partitioned IBM Cloudant Query index \n\nTo return the readings for a specific device from a partition, you can use an IBM Cloudant Query index. For this document, use POST to _index with an index definition that includes the partitioned field set to true.\n\nFor Query index definitions, the partitioned field isn't nested inside an options object.\n\nFor these queries, you need two partitioned indexes:\n\n\n\n1. By timestamp\n2. By device ID and timestamp\n\n\n\n\n\n Uploading partitioned index by timestamp","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_13498-101780-103603","score":8.668169,"text":"\nFor more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.\n\nThe column and partition definitions are optional. If they are not provided, the table schema and partitioning is detected from the structure of the data at the indicated location. If you explicitly provide these definitions, ensure that they match the objects that are stored in Object Storage. See [data types](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencedataType) for details on the supported column types.\n\n-- create a definition for the table customer\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nlocation cos:\/\/us-geo\/sql\/customers.csv\nShow more\n\nBefore you can use a newly created partitioned table, you must call ALTER TABLE tablename RECOVER PARTITIONS. Otherwise, querying the table returns an empty result.\n\n-- create a definition for the table customers_partitioned\nCREATE TABLE customers_partitioned (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (COUNTRY)\nlocation cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\n-- attach table partitions by scanning the location of the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_00522-3956-5681","score":8.58918,"text":"\nCopy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard2.png)\n\nFigure 2. Window for creating indexes\n\n\n\nThe fields array contains a list of fields that we want IBM Cloudant to index.\n\nIf we repeat our query, it is faster and remains quick even as the database size reaches millions of documents.\n\nIndexing instructs IBM Cloudant to create a secondary data structure that allows it to find the slice of data you need much faster than looking over every document in turn. IBM Cloudant Query is best for fixed queries based on the same fields in the same order.\n\nFor more information, see the following details in IBM Cloudant documentation:\n\n\n\n* [Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html)\n* [IBM Cloudant Query documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n\n\n\nThis index is useful for queries that involve both the publisher and the year, but if we introduce another field or make the query more complex (for example, by using the $or operator), then the index doesn't get used. We are back to a full database scan.\n\nFor a general-purpose search facility, we need IBM Cloudant Search, which is described in the next section.\n\n\n\n\n\n\n\n Step 3. Creating a search engine - IBM Cloudant Search \n\nIBM Cloudant Search is based on Apache Lucene and has its own query language that allows rich queries to be constructed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_00522-2652-4218","score":8.543662,"text":"\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_09991-7-1416","score":8.499496,"text":"\nQuerying historical data \n\nYou can run the queries by using the command-line or the [query editor inside the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor).\n\nThe following table definition is used for the example queries.\n\nCREATE TABLE PRODUCT (PRODUCTID INTEGER, DESC VARCHAR (100), PRICE DECIMAL) DATA_VERSION_RETENTION_TIME 30;\n\nThe following rows are inserted at different times. The commit times of the inserts (the insert timestamps or _SYS_START values) are indicated in SQL comments.\n\nINSERT INTO PRODUCT VALUES(1001, 'Jacket', 102.00); -- 2020-10-23 16:00:00\nINSERT INTO PRODUCT VALUES(1002, 'Gloves', 20.50); -- 2020-10-23 16:05:00\nINSERT INTO PRODUCT VALUES(1003, 'Hat', 18.99); -- 2020-10-23 16:10:00\nINSERT INTO PRODUCT VALUES(1004, 'Shoes', 125.25); -- 2020-10-23 16:15:00\n\n\n\n Showing data with the insert and delete timestamps \n\nThis SELECT command shows the table data with the associated insert and delete timestamp values at that instant when the query was issued. The _SYS_START and _SYS_END timestamps are available only in time travel queries, hence the use of AS OF NOW().\n\nSELECT , _SYS_START, _SYS_END FROM <table_name> FOR SYSTEM_TIME AS OF NOW();\n\nExample:\n\nSELECT , _SYS_START, _SYS_END FROM PRODUCT FOR SYSTEM_TIME AS OF NOW();\nPRODUCTID | DESCRIPTION | PRICE | _SYS_START | _SYS_END\n----------+-------------+---------+---------------------+-----------","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queryingdata_tt"},{"document_id":"ibmcld_07086-6808-9095","score":8.47654,"text":"\nFor relevancy training to be used, you must successfully train the project either programmatically ([Create training query method](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreatetrainingquery)) or by using the product user interface.\n\nQPP\n: A Query Performance Prediction algorithm that, given a query and a list of top results, produces a score that determines how relevant a document is. Used only if no Relevancy training ranker is available.\n\nfilter\n: The filter parameter can be passed along with query and natural_language_query requests to remove documents that don't meet certain criteria from the result set. The filter is shown as the last step within the document retrieval phase. However, it is used at different times in the flow. Its placement in the diagram is chosen to emphasize the fact that any documents that don't match the filter definition are excluded from the result set. The exclusion applies even to documents that might be specified in a curation.\n\nPassage retrieval\n: Returns passages from documents when the passages.enabled=true parameter is included with a natural language query request.\n\nAnswer finding\n: When the passages.find_answers=true parameter is included with a natural language query request, returns succinct answers from passages along with the passages that are extracted from documents. If answer finding is enabled, then the final confidence score for each search result is a combination of the confidence scores from answer finding, passage retrieval, and QPP or Reranked search, whichever method is used.\n\nTable retrieval\n: Returns information from tables in documents when the table_results.enabled=true parameter is included with a natural language query request.\n\n\n\n\n\n Query limits \n\nA query is any operation that submits a POST request to the \/query endpoint of the API. Such operations include queries that are submitted by using the API. It does not include queries that are submitted from the search bar on the Improve and customize page of the product user interface.\n\nA query is counted only if the request is successful, meaning it returns a response (with message code 200).\n\nThe number of search queries that you can submit per month per service instance depends on your Discovery plan type.\n\n\n\nNumber of queries per month","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07045-7-2118","score":15.116391,"text":"\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_07108-7-1958","score":14.292431,"text":"\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_07108-2897-3942","score":14.114465,"text":"\nYou can use the [expansions.json](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/discovery\/expansions.json) file as a starting point when you build a query expansion list.\n2. From the navigation pane, open the Improve and customize page.\n3. Expand Improve relevance from the Improvement tools pane.\n4. Click Synonyms, and then click Upload synonyms for the collection.\n\nDo not upload a synonyms file while documents are being added to your collection. The ingestion processing that occurs when documents are added can cause the index to be unavailable.\n\nOnly one synonyms list can be uploaded per collection. If a second expansion list is uploaded, the second list replaces the first.\n5. Run a test query to verify that the query expansion is working as expected.\n\nQuery expansions are applied at query time, not during indexing, so you can add synonyms without reprocessing your collection.\n\n\n\nTo disable query expansion, delete the synonyms file. However, do not delete a synonyms file while new documents are being processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_07115-7009-9068","score":14.028847,"text":"\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_07163-7-1995","score":13.662223,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_13075-7-2200","score":13.619926,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07175-1564-2340","score":13.600458,"text":"\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_07120-21369-22998","score":13.452264,"text":"\nFor more information about splitting documents, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\n\n\n\n\n Step 8: Test the project again \n\nLet's find out whether we improved the search function by adding a user-trained SDU model for the document. To do so, let's retest the project.\n\n\n\n1. From the navigation panel, click Improve and customize to open the Improve and customize page.\n2. First, to make sure that we didn't degrade the quality of the search, let's ask one of the questions that returned a good response when we tested earlier.\n\nIn the Search field, enter What is the purpose of Rule 15c3-5?\n\nZoom\n\n![Shows a query that is being entered into the Improve and customize page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-retest-query.png)\n\nFigure 25. Query added to the Improve and customize page\n\nMultiple responses are returned this time. The following response contains the exact answer to the question without any extraneous text:\n\nIn November 2011, the SEC implemented the final provision of Rule 15c3-5 curbing unfiltered market access. The provision mandated that brokers verify their clients\u2019 order flow for compliance with credit and capital thresholds before routing to market centers.\n\nZoom\n\n![Shows that multiple responses are returned for the query.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-rule-response.png)\n\nFigure 26. Multiple responses are returned for the query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_00460-34449-36370","score":13.442284,"text":"\nQuery (_find endpoint) improved\n: IBM Cloudant Query now uses a new method to select an index. Learn more about [IBM Cloudant Query index selection](https:\/\/www.ibm.com\/support\/pages\/improving-cloudant-query-index-selection).\n\nIndex validation\n: The logic for determining whether a specific index is valid for a query that changed, addressing a bug that might lead to incorrect results.\n\nText indexes\n: Queries that use text indexes no longer fail when $exists: false is used.\n\nPartial indexes\n: Partial indexes are now supported for both JSON and text indexes. For more information, see [Creating a partial index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) to learn about the partial_filter_selector parameter.\n\nExecution statistics\n: Execution statistics about a query can now be generated. These statistics are enabled by using the execution_stats=true parameter. For more information, see [querying an index by using selector syntax](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) to learn more about execution_stats=true parameter.\n\nPagination\n: [Pagination](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks) is supported by using the bookmark field. Bookmarks are enabled for all index types.\n\nuse_index field invalid\n: _find now falls back to any valid index if the value specified in the use_index field is invalid for the current query. When find falls back, the warning field is populated in the query response.\n\n\n\n\n\n 9 October 2017 \n\nError handling\n: If you rely on 500 replies for your application, you might have issues. To fix the problem, update your application to rely on 400 responses.\n: If you don't take care of reduce overflow errors as part of a row in the response body, issues occur. To fix this problem, change the application to handle the errors from view requests.\n\n\n\n\n\n\n\n August 2017 \n\n\n\n 17 August 2017 \n\nThe following changes were made in build 6365:\n\nNew!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-classic-release-notes"},{"document_id":"ibmcld_13075-1823-3835","score":13.304298,"text":"\nFor more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.6,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.6739577727}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07214-74576-76512","score":14.547114,"text":"\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_00580-64080-66194","score":14.113815,"text":"\nTo summarize, IBM Cloudant Search indexes are defined with a supplied JavaScript function. They are built on Apache Lucene and are primarily used for free-text search matching, but the query language is useful for building flexible queries on a fixed set of indexed fields. It also has some powerful counting aggregations suitable for drill-down user interfaces.\n\nIBM Cloudant Search also powers type=text IBM Cloudant Query indexes, so a subset of its capabilities is surfaced by using the _find API.\n\nThat's the end of this part. The next part is called Under the hood.\n\n\n\n\n\n\n\n Under the hood video \n\nLearn how the IBM Cloudant service is organized.\n\n\n\n* Under the hood video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 17 - Under the hood.\n\nLet's look at how an IBM Cloudant service is organized: This overview applies to the IBM Cloudant services that map to CouchDB 2 and 3. CouchDB 4 is built on different technology.\n\nIBM Cloudant is a distributed database with data that is stored around a cluster of storage nodes. Picture the IBM Cloudant service as ring of nodes, in this case twelve. Every node can deal with incoming API calls and every node has responsibility for storing some of the data: shards and associated secondary indexes of databases that exist in the cluster.\n\nWhen data is written to IBM Cloudant, one of the nodes in the ring handles the request: Its job is to instruct three copies of the data to be stored in three storage nodes. Data is stored in triplicate in IBM Cloudant, so each shard of a database is stored multiple times, often across a region's availability zones.\n\nWhen you make an API call to write data and get a response back, we write the data to at least two of the three storage nodes. Data is flushed to disk - it isn't cached in memory to be flushed data. We consider that technique too risky and prone to data loss.\n\nWhen you create a database, a number of database shards are created (16 by default) which are spread around the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07163-7-1995","score":13.997052,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07214-41790-43719","score":13.813079,"text":"\nImproved query limits for Advanced and Premium plans : [Query expansion](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion) limits are increased for Advanced and Premium plans to 5,000 query expansions and 25,000 total terms. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\n\n\n\n\n 28 February 2018 \n\nDeprecated AlchemyLanguage enrichments : AlchemyLanguage enrichments are deprecated, effective 1 March 2018.\n\n\n\n\n\n 23 February 2018 \n\nNew document similarity query feature : Added the ability to query by document similarity. You can query for similar documents by document ids, and optionally further refine the similarity by specifying fields. See [Document similarity](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsdoc-similarity) for more information.\n\nImproved highlight parameter : The [highlight parameter](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) in query results is enhanced. Query results return complete sentences, ordered by their score.\n\n\n\n\n\n 21 February 2018 \n\nFixed PDF file type : Previously, when ingesting PDF documents, the file_type returned when ingestion notices were queried, in the extracted_metadata object, and from the document details API was html. This is no longer the case. The file_type returned is now pdf.\n\n\n\n\n\n 26 January 2018 \n\nNew Korean and Spanish accessibility in Discovery News : Added the ability to access Korean and Spanish collections to the [IBM Watson\u2122 Discovery News](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news) tile in the tooling. Previously, these collections could only be queried via the API.\n\n\n\n\n\n 23 January 2018 \n\nNew query expansion : Added the ability to expand the scope of a query - for example, you can expand a query for \"car\" to include \"automobile\" and \"motor vehicle\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07096-7-1899","score":13.7917795,"text":"\nQuery operators \n\nYou can use operators when you write queries to submit to Discovery by using the Query API.\n\nThe types of operators that are supported differ by query type:\n\n\n\n* [Natural language queries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsnlq-operator)\n* [Discovery Query Language (DQL) queries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsdql-operators)\n\n\n\n\n\n Natural Language Query (NLQ) operator \n\nThe natural_language_query parameter accepts a string value.\n\n\n\n \"\" (Phrase query) \n\nUse quotation marks to emphasize a single word or phrase in the query that is most important to match. For example, the following request boosts documents that contain the term \u201cnomination\u201d in them.\n\n{\n\"natural_language_query\":\"What is the process for \"nomination\" of bonds?\"\n}\n\nSpecifying a quoted phrase does not prevent documents without the phrase from being returned. It merely gives more weight to documents with the phrase than those without it. For example, the query results might also contain documents that mention \u201cbonds\u201d or \u201cprocess\u201d and do not contain the word \u201cnomination\u201d.\n\nThe following request boosts the phrase \u201cchange in monetary policy\u201d and also matches \u201cchange\u201d or \u201cmonetary\u201d or \u201cpolicy\u201d.\n\n{\n\"natural_language_query\":\"\"change in monetary policy\"\"\n}\n\nSingle quotation marks (') are not supported. You cannot use wildcards (*) in phrase queries.\n\n\n\n\n\n\n\n Discovery Query Language (DQL) operators \n\nOperators are the separators between different parts of a query.\n\n\n\n . (JSON delimiter) \n\nThis delimiter separates the levels of hierarchy in the JSON schema\n\nFor example, the following query argument identifies the section of the enriched_text object that contains entities and the text recognized as an entity.\n\nenriched_text.entities.text\n\nThe JSON representation of this section looks as follows:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"},{"document_id":"ibmcld_07242-7-2087","score":13.476045,"text":"\nUsage monitoring \n\nYou can monitor and track usage of your Discovery instance and use this data to help you understand and improve your applications. The [Events API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) can be used to create log entries that are associated with specific natural language queries and actions. For example, you can record which documents in a results set were \"clicked\" by a user, and when that click occurred.\n\nLogs and events are monitored only for natural language queries on private data collections. No logs are gathered on IBM Watson\u2122 Discovery News.\n\nDiscovery can log the following information:\n\n\n\n* Queries - Natural language queries run against collections in your environment\n* Impressions (or Results) - The results returned for a particular query, usually documents or passages\n* Events - Interactions a user performs on a result or set of results in Discovery (for example, a click on a document result)\n\n\n\nQueries and Impressions are logged automatically; Events logging can be integrated into your application via the API.\n\n\n\n Viewing the logs \n\nYou can search the query and event log to find query sessions that match the specified criteria. Searching the logs endpoint uses the standard Discovery query syntax for the parameters that are supported. The endpoint provides basic query functionality for viewing and searching through the recorded data.\n\nThe \/api\/v1\/logs endpoint supports the following Discovery query parameters.\n\n\n\n* query\n* filter\n* sort\n* count\n* offset\n* version\n\n\n\nFor additional details on the function and syntax for the parameters see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters).\n\nExample of searching logs for a natural language query that contains the term \u201ctrain\u201d:\n\n{url}\/v1\/logs?version=2019-04-30&query=train\n\nReplace {url} with your URL.\n\nThe response of a logs query includes results that appear similar to Discovery document results. Each result is either a query or event, specified in the document type field.\n\nExample query log:\n\n{\n\"customer_id\": \"\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage"},{"document_id":"ibmcld_07213-3538-5222","score":13.358629,"text":"\nTo extract the training data, use the API to download the queries and the ratings from Discovery.\n\n\n\n1. [List the training data](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n2. [List the examples](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-examples-for-a-training-data-query) for each query.\n3. [Get the details](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-details-for-training-data-example) for a training data examples.\n\n\n\nThe document IDs that you use in your training data point to the documents in your current collection. Use the same IDs in your new collections to ensure that the correct documents are referenced. If the IDs do not match, your restored relevancy training will not work.\n\n\n\n\n\n Queries \n\nBy default, Discovery stores the queries that you send to it, unless you opt out.\n\nIf you want to be able to restore your queries for [statistical purposes](https:\/\/cloud.ibm.com\/apidocs\/discoverynumber-of-queries-over-time), it is recommended that you store those queries separately.\n\nYou can [extract queries](https:\/\/cloud.ibm.com\/apidocs\/discoverysearch-the-query-and-event-log) from Discovery, however a maximum of 10,000 queries are stored. There is no paging API. Restoring queries is not recommended; we recommend starting from scratch.\n\n\n\n\n\n Feedback\/clicks \n\nIf you are storing clicks in the form of feedback events, there is currently no easy way to back up and restore this information. The recommendation is to start from scratch with the [clicks\/feedback data](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) API.\n\n\n\n\n\n Expansion lists \n\nIf you are using expansions for query modification, back up your expansion list, and store it locally.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-recovery"},{"document_id":"ibmcld_07214-57536-59639","score":13.241608,"text":"\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07163-14976-16332","score":13.071643,"text":"\nFor additional training guidance, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Performing other training-data query operations \n\nYou can administer and maintain training-data queries by using other API methods as described in the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery):\n\n\n\n* [List the training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n* [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data)\n* [Display the contents of a specified training-data query](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-details-about-a-query)\n* [Delete a training-data query from the collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-example-for-training-data-query)\n* [Change a training-data query example's relevance label or cross reference](https:\/\/cloud.ibm.com\/apidocs\/discoverychange-label-or-cross-reference-for-example)\n* [Delete an example document from a training-data query](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n\nError monitoring: Training-data errors appear in the notices, which you can monitor using the [query notices API](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-system-notices) ( GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/notices).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07068-18922-20116","score":13.061547,"text":"\nAction v1 API v2 API \n\n List training data [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data](https:\/\/cloud.ibm.com\/apidocs\/discoverylisttrainingdata) [GET \/v2\/projects\/{project_id}\/training_data \/queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalisttrainingqueries) \n Add query to training data [POST \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data](https:\/\/cloud.ibm.com\/apidocs\/discoveryaddtrainingdata) [POST \/v2\/projects\/{project_id}\/training_data \/queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreatetrainingquery) \n Delete all training data [DELETE \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data](https:\/\/cloud.ibm.com\/apidocs\/discoverydeletealltrainingdata) [DELETE \/v2\/projects\/{project_id}\/training_data \/queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datadeletetrainingqueries) \n Get details about a query [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygettrainingdata) [GET \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagettrainingquery)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":21.820583,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_01241-14983-16623","score":19.819256,"text":"\nslcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host.\n\nFor more information about mounting and unmounting storage, see [connecting your new storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mountingLinux).\n2. Go to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/login). From the menu, select Classic Infrastructure![Classic icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/classic.svg).\n3. Click Storage, File Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to the snapshot to be used and click Restore.\n\nCompleting the restore results in the loss of the data that was created or modified after the snapshot was taken. This data loss occurs because your storage volume returns to the same state that it was in of the time of the snapshot.\n6. Click Yes to start the restore.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-13788-15540","score":18.22864,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_00241-15158-16579","score":17.974808,"text":"\nslcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host to ensure the host is not connecting to the volume during the restore for any reason.\n\n\n\n* [Unmounting Block Storage for Classic volumes on Linux\u00ae server](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-mountingLinuxunmountingLin)\n* [Unmounting Block Storage for Classic volumes on Microsoft\u00ae server](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-mountingWindowsunmountingWin)\n\n\n\n2. Go to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/login). From the menu, select Classic Infrastructure![Classic icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/classic.svg).\n3. Click Storage, Block Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_01241-13660-15370","score":17.846804,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-5761-7733","score":17.535416,"text":"\nIts schedule appears Manual.\n\n\n\n\n\n Taking a manual Snapshot from the SLCLI \n\nYou can use the following command to create a snapshot from the SLCLI.\n\n slcli block snapshot-create --help\nUsage: slcli block snapshot-create [OPTIONS] VOLUME_ID\n\nOptions:\n-n, --notes TEXT Notes to set on the new snapshot\n-h, --help Show this message and exit.\n\n\n\n\n\n Listing all Snapshots with Space Used Information and Management functions in the UI \n\nA list of retained snapshots and space that is used can be seen on the Block Storage for Classic Detail page. Management functions (editing schedules and adding more space) are conducted on the Block Storage for Classic Detail page by using the Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) menu or links in the various sections on the page. The Snapshot page displays how much capacity the volume has and how much of it is used.\n\nYou receive notifications when you reach space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_01241-5726-7749","score":17.094902,"text":"\nThe snapshot is taken and displayed in the Snapshots section of the Detail page. Its schedule appears Manual.\n\n\n\n\n\n Taking a manual Snapshot from the SLCLI \n\nYou can use the following command to create a snapshot from the SLCLI.\n\n slcli file snapshot-create --help\nUsage: slcli file snapshot-create [OPTIONS] VOLUME_ID\n\nOptions:\n-n, --notes TEXT Notes to set on the new snapshot\n-h, --help Show this message and exit.\n\n\n\n\n\n Listing all Snapshots with Space Used Information and Management functions in the UI \n\nA list of retained snapshots and space that is used can be seen on the File Storage for Classic Detail page. Management functions (editing schedules and adding more space) are conducted on the File Storage for Classic Detail page by using the Actions menu or links in the various sections on the page. The Snapshot page displays how much capacity the volume has and how much of it is used.\n\nYou receive notifications when you reach space thresholds \u2013 75 percent, 90 percent, and 95 percent.\n\n\n\n* At 75 percent capacity, a warning is sent that snapshot space usage exceeded 75 percent. To remediate, you can manually add space, or delete retained unnecessary snapshots. You can reduce the number of retained snapshots in the schedule. If you reduce the snapshot data or increase the space, the warning system is reset, and no autodeletion occurs.\n* At 90 percent capacity, a second warning is sent when snapshot space usage exceeded 90 percent. Like with reaching 75 percent capacity, if you take the necessary actions to decrease the snapshot data or increase the space, the warning system is reset and no autodeletion occurs.\n* At 95 percent capacity, a final warning is sent. If no action is taken to bring your space usage under the threshold, automatic deletion starts so that future snapshots can be created. Scheduled snapshots are deleted, starting with the oldest, until usage drops under 95 percent. Snapshots continue to be deleted each time usage exceeds 95 percent until it drops under the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-4-1958","score":15.735664,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Managing Snapshots \n\nSnapshots are a feature of IBM Cloud\u00ae Block Storage for Classic. A snapshot represents a volume's contents at a particular point in time. With snapshots, you can protect your data with no performance impact and minimal consumption of space. Learn more about how to manage snapshots by reading the following instructions.\n\n\n\n Adding a Snapshot schedule in the UI \n\nYou decide how often and when you want to create a point in time reference of your storage volume with Snapshot schedules. You can have a maximum of 50 snapshots per storage volume. Schedules are managed through the Storage > Block Storage for Classic tab of the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/classic-gen1).\n\nBefore you can set up your initial schedule, you must first purchase snapshot space if you didn't purchase it during the initial provisioning of the storage volume. For more information, see [Ordering Snapshots](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-orderingsnapshots).\n\nSnapshots schedules can be set up for hourly, daily, and weekly intervals, each with a distinct retention cycle. The maximum limit of snapshots is 50 per storage volume, which can be a mix of hourly, daily, and weekly schedules, and manual snapshots.\n\n\n\n1. Click your storage volume, click Actions, and click Edit Snapshot Schedule.\n2. In the Snapshot Schedule window, you can select from three different snapshot frequencies. Use any combination of the three to create a comprehensive snapshot schedule.\n\n\n\n* Hourly\n\n\n\n* Specify the minute each hour that a snapshot is to be taken. The default is the current minute.\n* Specify the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Daily\n\n\n\n* Specify the hour and minute that a snapshot is to be taken. The default is the current hour and minute.\n* Select the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Weekly","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_14348-7-1986","score":15.5214,"text":"\nAdding and deleting clusters \n\nYou can increase or decrease the capacity of your deployment by adding clusters to or deleting clusters from an instance. VMware vCenter clusters are the building blocks of VMware Cloud Director provider virtual data centers (PVDCs) and are added to existing PVDCs or are added as part of a PVDC creation.\n\n\n\n Procedure to add clusters to VMware as a Service instances \n\n\n\n1. In the VMware Solutions console, click Resources > VMware as a Service from the left navigation pane.\n2. In the VMware as a Service table, click the Cloud director sites tab, then click an instance name.\n3. Click the Infrastructure tab.\n4. On the Clusters tab, click Add cluster +.\n5. On the Add cluster window, specify the settings for the new cluster.\n\n\n\n1. Specify the cluster name.\n2. Select the profile storage type.\n3. Select the host profile.\n4. Select the host quantity.\n\n\n\n* For NFS only storage, select a minimum of 2.\n* For vSAN\u2122 storage, select a minimum of 6.\n\n\n\n5. Click Next.\n\n\n\n6. Specify the attached NFS storage settings.\n7. Review the new cost, select the confirmation checkbox, and click Order to confirm.\n\n\n\n\n\n\n\n Before you delete clusters \n\nWorkload virtual machines (VMs) are deployed in virtual data centers (VDCs) that logically exist in the scope of a PVDC. PVDCs physically consist of one or more VMware vCenter clusters. When the PVDC contains multiple clusters and one cluster is deleted, all VMs running in that cluster are migrated to other clusters in the same PVDC.\n\nVMs deployed to a specific storage performance tier are only migrated to the same performance tier of storage in the remaining clusters. You must ensure that the remaining clusters have compatible storage performance layers of the deleted cluster. The remaining clusters must also have enough CPU and memory to contain the VMs of the deleted cluster.\n\nIf not enough CPU, RAM, or equivalent storage performance for the cluster exists, the delete operation does not succeed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-cluster-adding-deleting"},{"document_id":"ibmcld_14580-1471-2689","score":14.761103,"text":"\n4. Select the host quantity.\n\n\n\n* For NFS only storage, select a minimum of 2.\n* For vSAN\u2122 storage, select a minimum of 6.\n\n\n\n5. For vSAN, optionally select the Enable vSAN de-duplication & compression checkbox to save storage space.\n6. Select the sizings for one or more IOPS\/GB performance tiers for attached NFS storage.\n\n\n\n7. Review the add-on service option to deploy the Veeam\u00ae Backup and Replication service. Toggle the service off if you do not want to include it in your order.\n8. On the Summary pane, review the instance settings and the estimated price.\n9. To place the order, ensure that the account to be charged is correct, review and accept the terms, and then click Create.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware as a Service overview](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-vmware-aas-overview)\n* [Viewing VMware as a Service instances](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-tenant-viewing)\n* [Visualizing your site with IBM Cloud\u00ae Monitoring](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-single-tenant-monitoring)\n* [Deleting VMware as a Service instances](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-tenant-deleting)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-tenant-ordering"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09984-0-1283","score":19.826094,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_16728-6533-8457","score":19.355572,"text":"\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_16729-11586-13439","score":17.915478,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_13162-7-1878","score":16.411194,"text":"\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-12751-14416","score":16.071909,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16728-5097-7108","score":15.611758,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_13162-11690-13171","score":15.001968,"text":"\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-326786-328759","score":14.255239,"text":"\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine\n\nIn this tutorial, you will create a serverless web application using a bucket in Object Storage and implementing the application backend using IBM Cloud Code Engine and IBM Cloudant as JSON document database.\n\nCode Engine Cloudant\n\n+1\n\nObject Storage\n\n\n\n* 1 hour\n* 2023-06-16\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\nContent Delivery Network (CDN) Object Storage\n\n\n\n* 2 hours","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_13162-2830-4436","score":13.888474,"text":"\nCreate an instance of [Object Storage](https:\/\/cloud.ibm.com\/catalog\/services\/cloud-object-storage). If you already have Object Storage instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-cos cloud-object-storage lite global\n4. Create an instance of [Data Engine](https:\/\/cloud.ibm.com\/catalog\/services\/sql-query). Replace us-south by your region, if needed. If you already have Data Engine instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-sql sql-query lite us-south\n5. Create an instance of [Watson Studio](https:\/\/cloud.ibm.com\/catalog\/services\/watson-studio).\n\nibmcloud resource service-instance-create data-lake-studio data-science-experience free-v1 us-south\n6. Create an API key for service access. Copy the output to a secure, permanent location for later use.\n\nibmcloud iam api-key-create data-lake-cos-key --output json\n\n\n\n\n\n\n\n Step 2: Uploading data \n\nIn this section, you will upload data to an Object Storage bucket. You can do this using regular http upload or by utilising the built-in Cloud High-Speed Transfer Service. Cloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles \/ Traffic Collision Data from 2010](https:\/\/data.lacity.org\/api\/views\/d5tf-ez2w\/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-6697-8604","score":13.195734,"text":"\nThe intermediate dataset is displayed below the query on the Results tab associated with the Job\n\n\n\n\n\n\n\n Step 4: Combine Jupyter Notebooks with Data Engine \n\nIn this section, you will use the Data Engine client within a Jupyter Notebook. This re-uses the data stored on Object Storage in a data analysis tool. The combination also creates datasets that are automatically stored in Object Storage that can then be accessed by applications and tools serving line of business users.\n\nFirst, create a new Jupyter Notebook and service connections in Watson Studio.\n\n\n\n1. Access the data-lake-studio Watson Studio service instance from the [Resource List](https:\/\/cloud.ibm.com\/resources) under the AI \/ Machine Learning section.\n\n\n\n* Click Launch in IBM Cloud Pak for Data.\n* Click Create a Project followed by Create an empty project.\n* Use Data lake project as Name.\n* Under Define storage select data-lake-cos.\n* Click Create.\n\n\n\n2. In the resulting project, add an access token to the project.\n\n\n\n* Click the Manage tab.\n* Click Access control on the left.\n* Click the Access tokens tab.\n* Click New access token.\n* Enter a name and select Editor for access role and click Create.\n\n\n\n3. Click the Assets tab and then click New asset and Connection.\n\n\n\n* From the list of services select IBM Cloud Data Engine.\n* In the dialog enter SQLQuery as Name.\n* As CRN copy in the Data Engine instance CRN. You can obtain it by clicking in the [Resource List](https:\/\/cloud.ibm.com\/resources) right to the service name. data-lake-sql. The pop-up has the CRN and a copy button.\n* Fill in cos:\/\/us-south\/<your-bucket-name> as Target. Replace us-south and <your-bucket-name> similar to how you did it earlier.\n* As Password under Credentials use the API key which you created earlier. The value is from the field apikey.\n* Finally, click Create.\n\n\n\n4. Now create the notebook. Click New asset and Jupyter notebook editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16638-0-764","score":19.165998,"text":"\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-import_data"},{"document_id":"ibmcld_13480-3420-5386","score":16.83226,"text":"\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogpartitioned).\n\nYou can then query the table by name instead of specifying the Object Storage URI directly in the SQL statement:\n\nSELECT * FROM employees LIMIT 10\n\nIf you want to use more specific data types than the data types inferred by automatic schema detection, you can also specify the table schema explicitly:\n\nCREATE TABLE employees (\nemployeeID int,\nlastName string,\nfirstName string,\ntitle string,\ntitleOfCourtesy string,\nbirthDate timestamp,\nhireDate timestamp,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nhomePhone string,\nextension int,\nphoto string,\nnotes string,\nreportsTo string,\nphotoPath string\n)\nUSING PARQUET\nLOCATION cos:\/\/us-geo\/sql\/employees.parquet\nShow more\n\nIf accessing the table in a SELECT statement does not work as expected, it is possibly caused by improper specification of the table schema in the CREATE TABLE statement. The column names and their data types in your CREATE TABLE statement must match the result of the following query:\n\nSELECT * FROM describe (<data-location> stored as <storage-format>)\n\nColumn names are case-sensitive. Incorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_09958-9644-11401","score":15.819205,"text":"\nUnlike the CREATE TABLE command, which does not have any existing rows, existing visible rows in the table are treated as if they were inserted by this ALTER TABLE transaction. The existing visible rows receive virtual insert timestamps that are equal to the retention start time. With these timestamps, the rows are potentially visible to time travel queries.\n\n\n\n\n\n Altering temporal schemas to nontemporal with the command-line \n\nTo alter a temporal schema to nontemporal, set DATA_VERSION_RETENTION_TIME to 0.\n\nFor detailed syntax, the necessary privileges, and the CASCADE option, see [the ALTER SCHEMA command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-schema-2).\n\nALTER SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\nExample:\n\nALTER SCHEMA SCHEMA DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\n\n\n\n\n Altering nontemporal schemas to temporal with the command-line \n\nTo alter a nontemporal schema to temporal, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax, the necessary privileges, and the CASCADE option, see [the ALTER SCHEMA command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-schema-2).\n\nALTER SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME <number-of-days> NOCASCADE;\n\nExample:\n\nALTER SCHEMA DB1 DATA_VERSION_RETENTION_TIME 30 NOCASCADE;\n\n\n\n\n\n Altering temporal databases to nontemporal with the command-line \n\nTo alter a temporal database to nontemporal, set DATA_VERSION_RETENTION_TIME to 0.\n\nFor detailed syntax and the necessary privileges, see [the ALTER DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-database-2).\n\nALTER DATABASE <db_name> DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\nExample:\n\nALTER DATABASE DB1 DATA_VERSION_RETENTION_TIME 0 NOCASCADE;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_13498-108109-110305","score":15.462699,"text":"\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_16627-0-1141","score":15.395021,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"},{"document_id":"ibmcld_16669-1692-3354","score":15.278341,"text":"\nAlternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1. Run the following command to create schema for the data you want to access.\n\nCREATE SCHEMA <SCHEMA_NAME> WITH ( location = '<SCHEMA_LOCATION>' );\n\nFor example:\n\nCREATE SCHEMA hive.gosales WITH ( location = 's3a:\/\/lhbeta\/gosales' );\n2. Run the following command to create table by using an external location by pointing to an existing table.\n\nCREATE TABLE IF NOT EXISTS <TABLE_NAME> (\"<COLUMN_NAMES>\" <DATA_TYPE>) WITH ( format = '<DATA_FORMAT>', external_location = '<TABLE_LOCATION>' );\n\nFor example:\n\nCREATE TABLE IF NOT EXISTS hive.gosales.branch (\"BRANCH_CODE\" int, \"ADDRESS1\" varchar, \"ADDRESS1_MB\" varchar, \"ADDRESS2\" varchar, \"ADDRESS2_MB\" varchar, \"CITY\" varchar, \"CITY_MB\" varchar, \"PROV_STATE\" varchar, \"PROV_STATE_MB\" varchar, \"POSTAL_ZONE\" varchar, \"COUNTRY_CODE\" int, \"ORGANIZATION_CODE\" varchar, \"WAREHOUSE_BRANCH_CODE\" int) WITH ( format = 'CSV', external_location = 's3a:\/\/lhbeta\/gosales\/branch' );\n\n\n\n\n\n\n\n Step 3: Generate statistics with analyze table \n\nIf you want to use the data without creating a new copy for a different table format or more table optimizations, you can generate statistics alone with analyze table.\n\n\n\n1. To generate statistics with analyze table, run the following command:\n\nanalyze <TABLE_NAME>;\n\nFor example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"},{"document_id":"ibmcld_09958-5588-7326","score":14.792251,"text":"\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Create a temporal table as described in [Creating tables](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-tablescreating-tables).\n\n\n\nYou must set retention time interval to a nonzero value.\n\nDatabases, schemas, and table names containing a dot character (\".\") do not show in the time travel statistics and graphs when you set the retention time interval to a nonzero value. When you do not set the retention time interval, all special characters are supported.\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the web console \n\nTo create a temporal schema, set retention time interval to a nonzero value.\n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Create a temporal schema as described in [Creating schemas](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemas).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_09958-4322-5978","score":14.7125435,"text":"\nTo create a temporal table, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE TABLE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-table-2).\n\nCREATE TABLE <tablename> ( <col>[, <col>\u2026 ] ) DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE TABLE PRODUCT (prodid int, proddesc char(100)) DATA_VERSION_RETENTION_TIME 30;\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the command-line \n\nTo create a temporal schema, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE SCHEMA](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-schema-2) command.\n\nCREATE SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE SCHEMA SCHEMA1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n Creating temporal databases with the command-line \n\nTo create a temporal database, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_16640-7-2035","score":14.538885,"text":"\nKnown issues (Limitations) \n\nThe following limitations and known issues, apply to IBM\u00ae watsonx.data.\n\n\n\n Issue: Unable to view created schema \n\nWhen a user with the User role and the Create access (the user only has the Create access) is added to an external database, they cannot see the schemas that they created. Though the user can create schemas, they cannot view them. Following is the system response:\n\npresto:default> show schemas;\nSchema\n--------\n(0 rows)\n\nWorkaround: Provide select privilege for the schema the user created.\n\n\n\n\n\n Issue: Access denied message occurs when querying an external database \n\nWhen a user with the User role and Create access (the user only has Create access), is added to an external database, they cannot run the select query from the table they have created. Though the user can connect to the Presto engine and create tables and schemas, they cannot query from the table. The system displays an Access Denied message.\n\nQuery 20230608_132213_00042_wpmk2 failed: Access Denied: Cannot select from columns [id] in table or view tab_appiduser_01\n\nWorkaround: Provide select privilege for the table the user created.\n\n\n\n\n\n Issue: Schema created under different catalog \n\nSchemas are available across Iceberg and Hive catalogs. When a schema is created under Iceberg catalog, it is listed under Hive catalog and vice versa.\n\n\n\n\n\n Issue: Presto does not support deletion of Iceberg tables \n\n\n\n\n\n Issue: DROP SCHEMA in Db2 \n\nIn Db2, the schema can be dropped only if it is empty. Initiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-known_issues"},{"document_id":"ibmcld_13472-4479-5403","score":14.043135,"text":"\nIf you don't use Hive-style partitioning or catalog tables, all objects in the source location must be listed as part of the query execution, even if only a single row from a single object is required for the query.\n\nTo successfully query the source location, use the following best practices.\n\n\n\n* Create a table with the correct schema specified. If you don't specify the schema, schema inference causes the same error to be returned.\n* If you use more than 10 UNION\/JOIN constructs for different source URIs, try to lower the number of different sources.\n* Depending on the number of table partitions, you can either add the partition manually one by one, or use the ALTER TABLE \u2026 RECOVER PARTITION command. Although the limit is 20,000 partitions per table by default, stay below 10,000 partitions for a single table.\n* Lay your data out by using Hive-style partitioning and aim for an object size of 128 MB if possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00522-2652-4218","score":22.550165,"text":"\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_00580-39512-41555","score":22.371136,"text":"\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00522-7-1725","score":22.273191,"text":"\nDigging deeper into IBM Cloudant Dashboard \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard gives new and experienced IBM Cloudant users the opportunity to add, edit, and delete documents. The IBM Cloudant users can refine the indexing and querying options that best suit their application's use-cases.\n\n\n\n Objectives \n\nSet up some basic indexes using the Dashboard to see how each of IBM Cloudant's querying mechanisms works.\n\n\n\n\n\n Before you begin \n\nYou need to create a service instance in IBM Cloudant before you start this tutorial. You can follow the instructions in the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial to create one.\n\n\n\n\n\n Step 1. The data set \n\n\n\n1. Create a database called books.\n2. Create some sample data that represents a book in a library as shown in the following example:\n\n{\n\"_id\": \"BXP9G5ZQY9Q4EA13\",\n\"author\": \"Dickens\",\n\"title\": \"David Copperfield\",\n\"year\": 1840,\n\"pages\": 723,\n\"publisher\": \"Penguin\",\n\"url\": \"https:\/\/www.somurl.com\/dc\"\n}\n3. Continue to add some documents that match the pattern in the previous step by using the IBM Cloudant Dashboard.\n\nThe documents store simple key\/value pairs that hold metadata about each book: its author and its publisher. In this example, we address the following three use-cases:\n\n\n\n1. A query facility that allows a user to find a book by a known publisher and year.\n2. A general-purpose search engine that allows a user to find books by a combination of one or more of the following descriptors: author, title, year, and publisher.\n3. A report that details the number of books that are published by year.\n\n\n\n\n\n\n\n\n\n Step 2. Querying books by publisher and year - IBM Cloudant Query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_00539-7-1755","score":22.25603,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00580-60601-62822","score":22.064617,"text":"\nWhen you create a secondary index, you choose whether its purpose is for per-partition or global scope.\n\nThat's the end of this part. The next part is called IBM Cloudant Search.\n\n\n\n\n\n\n\n IBM Cloudant Search video \n\nLearn how to use IBM Cloudant Search, as well as Lucene query language and faceting.\n\n\n\n* IBM Cloudant Search video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 16 - IBM Cloudant Search.\n\nWe have another method of querying and indexing in IBM Cloudant called IBM Cloudant Search that we briefly explore in this part.\n\nIBM Cloudant Search is built on another open source project, Apache Lucene, which powers the search capabilities of many products that include Elasticsearch.\n\nIt is primarily designed for free text search, where blocks of text are pre-processed before they are indexed: removing case, punctuation, common noise words, and trimming common language-specfic word endings, for example, farmer becomes farm, and farms becomes farm.\n\nThis text-processing is performed by a choice of analyzers at query time, searching. Before this time, it also allows some aggregation functionality that uses a technique that is called faceting.\n\nAn IBM Cloudant Search index is created by supplying JavaScript function. It is not unlike MapReduce, except this time, the emit function is replaced by an index function, which expects the name of the field, the data itself, and some options.\n\nIn this example, the document's name and title are indexed with default options. The category is nominated for faceting (the aggregation functionality) and the ISBN is stored in the index but not indexed for search itself. Sometimes it is more efficient to store some items in the index rather than doing include_docs=true at query time.\n\nLucene has its own query language that creates queries that match combinations of clauses with logic, fuzzy matching, ranges, and term boosting.\n\nSee the following examples:\n\n\n\n* Find documents whose title matches gastby and whose author starts with fitz. Notice the asterisk wildcard.\n* Find documents whose author is in the range austen to dickens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00579-2977-4822","score":21.956936,"text":"\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00491-1283-3050","score":21.887848,"text":"\n(Optional) [Create an acurl alias](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"},{"document_id":"ibmcld_00472-16393-17597","score":21.80506,"text":"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nSee the following example that uses HTTP to query a global index:\n\nGET \/$DATABASE\/_design\/$DDOC\/_search\/$INDEX_NAME?include_docs=true&query=\":\"&limit=1 HTTP\/1.1\nContent-Type: application\/json\nHost: $ACCOUNT.cloudant.com\n\nSee the following example that uses the command line to query a global index:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_design\/$DDOC\/_search\/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostSearchOptions searchOptions = new PostSearchOptions.Builder()\n.db(\"<db-name>\")\n.ddoc(\"<ddoc>\")\n.index(\"<index-name>\")\n.query(\":\")\n.includeDocs(true)\n.limit(1)\n.build();\n\nSearchResult response =\nservice.postSearch(searchOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nimport { CloudantV1 } from '@ibm-cloud\/cloudant';\n\nconst service = CloudantV1.newInstance({});\n\nservice.postSearch({\ndb: '<db-name>',\nddoc: '<ddoc>',\nindex: '<index-name>',\nquery: ':',\nincludeDocs: true,\nlimit: 1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_00580-41116-43256","score":21.79447,"text":"\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00491-7-1604","score":21.666517,"text":"\nUsing IBM Cloudant Query \n\nIn this tutorial, we demonstrate how to create an index and use the index to query the database. You also learn to create different types of queries to more easily find data.\n\nHere you run the commands from the command line, but you can also complete these tasks with the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard, which gives you a visual example of each task. For more information about the dashboard, see [Using the IBM Cloudant Dashboard](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query) tutorial.\n\n\n\n Before you begin \n\nBefore you begin, follow these tutorials to create an instance, and then create and populate a database.\n\n\n\n1. [Create an IBM Cloudant instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-an-ibm-cloudant-instance-on-ibm-cloud).\n2. [Create a database](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudcreating-a-database-within-the-service-instance).\n3. [Populate the database](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-creating-and-populating-a-simple-ibm-cloudant-database-on-ibm-cloudstoring-a-small-collection-of-data-as-documents-within-the-database).\n4. (Optional) [Create an acurl alias](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\/databasedemo\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1681275363,"ndcg_cut_10":0.2982542196}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-2570-3569","score":15.062772,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":14.4942,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":12.564305,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16343-7-1927","score":11.498407,"text":"\nNeuralSeek extension setup \n\n[NeuralSeek](https:\/\/neuralseek.com) by [Cerebral Blue](https:\/\/cerebralblue.com\/) is a combined search and natural-language generation system that is designed to [make conversational AI feel more conversational](https:\/\/garrettrowe.medium.com\/making-conversational-ai-feel-more-conversational-8748009b3fda). It requires that you load all your content into [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Then, when a user asks a question, it has Discovery search for multiple relevant documents and then it generates a natural-language answer that uses the contents of those documents. In some cases, the answer might be taken directly from a single document, and in others, the answer can include information from multiple sources that are combined into a single coherent statement. For each query, NeuralSeek returns a single answer and a confidence score. In most cases, it also returns a URL of a document that influenced the answer, which might be one of several documents.\n\nTo set up the extension for NeuralSeek search:\n\n\n\n Set up IBM Watson\u00ae Discovery \n\n\n\n1. You need an instance of [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Because NeuralSeek can modify your data as needed to make it more effective, make sure it is not an instance with important data that you are using for other purposes.\n2. In Discovery, create a project and load the documents that you want to use.\n\n\n\n\n\n\n\n Get the NeuralSeek OpenAPI specification and API Key \n\n\n\n1. You also need an instance of [NeuralSeek on IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/neuralseek).\n2. In NeuralSeek, open the Configure page and enter your information in the Discovery instance details section.\n3. On the Integrate page, and click the OpenAPI file link to download the NeuralSeek.json OpenAPI specification file configured for your instance.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-neuralseek"},{"document_id":"ibmcld_03285-1272-3273","score":11.483954,"text":"\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same dialog node or step. For more information, see [Defining a sequence of phone actions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sequence).\n\nFor reference information about phone-specific repsonse types and related context variables, see [Phone context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context).\n\n\n\n Adding phone-specific responses to your dialog or actions \n\nTo initiate a voice-specific interaction from a dialog node or a step in an action, add a response within the output.generic array using the appropriate response type.\n\nAlthough many response types can be specified using the Watson Assistant user interface, phone-specific response types must currently be added using the JSON editor.\n\nFor more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from a dialog node or action step, you can dynamically change the Speech to Text configuration during a conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16364-36153-38148","score":11.461617,"text":"\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-32797-34928","score":11.046628,"text":"\n: On the Preview page, you can now upload an image of your organization's website as a background. For more information, see [Previewing and sharing your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share).\n\n\n\n\n\n 16 September 2022 \n\nSession ID information on Analyze page\n: Session ID information for conversations is now displayed on the Conversations tab of the Analyze page. You can also filter customer conversation data by the session ID. From the Conversations tab of the Analyze page, use the Keyword filter to search by session ID. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nThe ability to filter on session ID has limited support for conversations that occurred before this feature release. For all conversations that occurred before 16 September 2022, you can filter only by a single session ID at a time.\n\n\n\n\n\n 9 September 2022 \n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The options response type now has the is any of and is none of operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nCopy actions to other assistants\n: You can copy an action from one assistant to another. When you copy an action, references to other actions, variables, and saved responses are also copied. For more information, see [Copying an action to another assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-copy-action).\n\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03126-5596-6966","score":10.714621,"text":"\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_16259-1485-3642","score":10.495871,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_16364-34499-36597","score":10.38355,"text":"\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week. This feature is available with the date response type and the Current date built-in variable.\n\nFor example, you might [define a customer response](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infochoose-type) in step 1 with the date response type. When the customer responds to that step, they choose a date. You can then condition a later step on whether the date that the customer chose is Wednesday.\n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The free text response type now has the contains, does not contain, matches, and does not match operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nExtensions support for arrays\n: Custom extensions now support passing arrays as parameters and accessing arrays in response variables. For more information, see [Calling a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension).\n\n\n\n\n\n 26 August 2022 \n\nNew filter on the Analyze page\n: You can now filter customer conversation data by the Greet customer system action. From the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03042-2711-4616","score":19.967796,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03107-5127-7134","score":19.69141,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16252-3899-5971","score":16.030626,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03107-3801-5605","score":15.919732,"text":"\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16259-1485-3642","score":15.449665,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_03037-1358-3485","score":14.71894,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_16258-2570-3569","score":13.381846,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03042-1241-3131","score":12.812189,"text":"\n* [Skills](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-addskill-add-limits)\n* [Versions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versionsversions-limits)\n\n\n\n\n\n\n\n User information \n\nA unique user is recognized by the user ID that is associated with the person that interacts with your assistant. It is your responsibility to pass the user ID information to the service. Watson Assistant checks for the following information from API requests in this order:\n\n1. user_id: A property defined in the API that is sent in the context object of a \/message API call. Using this property is the best way to ensure that you accurately attribute \/message API calls to unique users. For more information about the user ID property, see the API reference documentation:\n\n- context.global.system.user_id: [v2 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message)\n- context.metadata.user_id: [v1 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1message)\n\n1. session_id (v2 only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes integration or after the inactivity time limit is reached.\n\nIf you use the stateless v2 \/message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_16258-1324-3123","score":12.802551,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03036-7103-8947","score":12.355987,"text":"\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter. See [Enabling user metrics](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resourceslogs-resources-user-id) for more information.\n\n\n\n\n\n\n\n Top Intents and Top Entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. For each entity you can select from the Values column to see a list of the most common values that were identified for this entity during the time period. You can also select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02734-1732-3794","score":17.207174,"text":"\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02734-3347-4762","score":17.19615,"text":"\nThe user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.\n5. The user might choose to sign in to access more features of your app.\n6. Your application notifies App ID that the user wants to interact with your app as an identified user.\n7. App ID returns the login widget to your app.\n8. The user selects their preferred identity provider and provides their credentials.\n9. Your application informs App ID that the user selected an identity provider.\n10. App ID authenticates the call with the identity provider.\n11. The identity provider confirms whether the login was successful.\n12. App ID uses the anonymous token to find the anonymous profile and attaches the user's identity to it.\n13. After App ID creates the new tokens, the service invalidates the user's anonymous token.\n14. App ID returns the new access and identity tokens. The new tokens contain the public information that is shared by the identity provider and the attributes of the user's formerly anonymous profile.\n15. The user is granted access to your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02798-4-2051","score":16.992184,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Managing profiles \n\nWith IBM Cloud\u00ae App ID, you can compile information about the individual users of your application into a profile. The information in the profile can be learned about your users by the way that they interact with your app or added by you on their behalf. By storing the information, you can access it to help create personalized experiences of your app for your users.\n\nLooking for information about your Cloud Directory users? Check out [managing users](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-users).\n\n\n\n Viewing user profiles with the UI \n\nTo see the data that is available for your app users, you can use the App ID UI.\n\n\n\n1. Navigate to the User Profiles > Profiles tab of your App ID instance.\n2. Look through the table or search by using an email address to find the user that you want to see the information for. The search term must be exact.\n3. In the overflow menu of the user's row, click View user profile. A page opens that contains the user's information. Check out the following table to see what information you can see.\n\n\n\nTable 1. User details as shown in the App ID dashboard\n\n Detail Description \n\n IdP identifier The IdP identifier is issued by the provider that your user chose to sign in to your application with. \n Email The primary email address that is attached to the user. \n Name Your user's first and surname as issued by the identity provider. \n Identity provider The provider that your user chose to sign in with. \n ID The ID that is assigned to the user by App ID. \n Custom attributes Custom attributes are additional information that is added to their profile or that is learned about the user's as they interact with your application. \n Summary All the information that is associated with that user shown as a JSON object. \n\n\n\n\n\n\n\n\n\n Viewing user profiles with the API \n\nYou can use the App ID API to view details about your app users.\n\n\n\n1. Obtain your tenant ID from your instance of the service. You can find the ID in your service or application credentials.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-user-admin"},{"document_id":"ibmcld_02734-7-2170","score":16.760355,"text":"\nAnonymous authentication \n\nWith IBM Cloud\u00ae App ID, you can allow users to anonymously browse your application under an anonymous user profile. If the user chooses to sign in, you can allow them to still access their anonymous attributes by attaching their anonymous profile to their user identity with App ID.\n\n\n\n Understanding progressive authentication \n\nWhen a user chooses not to sign in immediately, they are considered an anonymous user. For example, say you're an online retailer and you want to allow users to add objects to their shopping cart without signing in. However, you ask them to sign in to complete their purchase. If a user chooses to sign in, you can allow them to access the same objects that were in their shopping carts before they signed in.\n\nYou can use App ID to gather information about anonymous users into an anonymous user profile, which you can use to help personalize their experience of your application. If the user chooses to signs in, you can attach the user attributes that are part of the anonymous profile to their user identity that is stored in App ID. Anonymous profiles are temporarily valid. While you develop your app, you can [configure the lifetime](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idpidp-token-lifetime) of anonymous tokens.\n\nWhen a user signs in, they become an identified user. If an existing identified user profile does not exist, you can create a new identified user profile. After a user is identified, App ID issues new access and identity tokens and their anonymous token becomes invalid. However, an identified user can still access the attributes of their anonymous profile because they are accessible with the new access and identity tokens.\n\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_03042-2711-4616","score":16.528648,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_13878-14307-15983","score":16.524065,"text":"\n* [Service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids): Similar to how a user ID identifies a user, a service ID can identify a specific service or application, even a task. The service ID could be considered a \"technical user\". You can assign privileges to a service ID. Moreover, a service ID has its own IAM API keys to authenticate. Thus, a service ID can be used instead of a regular user ID, thereby simplifying resource management and increasing security. [To avoid deleting a service ID by mistake, you can lock them](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids&interface=uilock_serviceid).\n* [Access groups with access policies](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups): To simplify management of privileges (authorization), you can group user IDs and service IDs into access groups. You create an access group for a purpose, e.g., to administrate the application or a component. Then, you create access policies for that group to assign privileges and add the related user IDs and service IDs.\n* [Trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile): Using a trusted profile, you can automatically grant access to your account in a defined context and with a set of defined privileges. You can define such a context for either federated users based on properties in the enterprise directory, e.g., for users labeled as administrators or project members. Or you can allow access for [compute identities](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profilecreate-profile-compute-ui), i.e., specific computing resources like a virtual server instance (VSI).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-extended-app-security"},{"document_id":"ibmcld_16378-1689-3407","score":16.51536,"text":"\nThis example in this tutorial, which is based on an Express server for Node.js, shows how to start a session with an anonymous user ID and then authenticate the user during the session.\n\n\n\n1. Create a function called getOrSetAnonymousID() that generates a unique anonymous user ID for each customer and stores it in a cookie (or, if the cookie already exists, uses the stored user ID).\n\nUse a cookie that lasts for at least 45 days. If you do not store the user ID for more than 30 days, the same customer might be counted as multiple different users during the same billing period. (This can still happen if the same user deletes the cookie or uses a different browser.)\n\n\n\nfunction getOrSetAnonymousID(request, response) {\nlet anonymousID = request.cookies['ANONYMOUS-USER-ID'];\nif (!anonymousID) {\nanonymousID = anon-${uuid()};\n}\n\nresponse.cookie('ANONYMOUS-USER-ID', anonymousID, {\nexpires: new Date(Date.now() + 1000 * 60 * 60 * 24 * 45), \/\/ 45 days.\nhttpOnly: true,\n});\n\nreturn anonymousID;\n}\n\n\n\n1. In the function you use to create a JWT, use the anonymous ID returned from the getOrSetAnonymousID() function as the value of the sub claim. This sets the value of the user ID that will be used to uniquely identify the customer for billing purposes.\n\nIn addition, retrieve any value from the SESSION_INFO cookie, which we will use to store authenticated login information. If a value exists, store it in the user_payload private claim of the JWT. (If the user has not yet authenticated, this cookie does not yet exist.)\n\n\n\nconst jwtContent = {\nsub: anonymousUserID,\nuser_payload: {\nname: 'Anonymous',\ncustom_user_id: anonymousUserID,\n},\n};\n\nif (sessionInfo) {\njwtContent.user_payload.name = sessionInfo.userName;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security"},{"document_id":"ibmcld_03107-6652-8734","score":16.497215,"text":"\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use. You are billed for the user's interaction with each service instance separately.\n\n\n\n\n\n Test activity charges \n\nTest messages that you send from the Preview button are charged. For the preview, a random user_id is generated and stored in a cookie. The multiple interactions that a single tester has with the assistant embedded in the preview are recognized as coming from a single user and are charged accordingly. If you are doing your own test, running a scripted regression test for example, use a single user_id for all of the calls within your regression test. Other uses are flagged as abuse.\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\nIf an anonymous user logs in and later is identified as being the same person who submitted a request with a known ID, you are charged twice. Each message with a unique user ID is charged as an independent active user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_02732-7949-9378","score":16.31202,"text":"\n\"id\": \"123454231-1234-1234-3334-12345687012\",\n\"name\": \"developer\",\n\"description\": \"Can perform administrative tasks.\",\n\"access\":\n{\n\"application_id\": \"de33d272-f8a7-4406-8fe8-ab28fd457be5\",\n\"scopes\":\n\"write\",\n\"read\"\n]\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n Assigning roles to users with the UI \n\nAfter you create roles, you can assign them to your user's profile. You can also assign roles when you create a future user.\n\n\n\n1. Go to Profiles and roles > User profiles in your App ID dashboard.\n2. From the Actions menu in the row of the specific user you're assigning a role to, click Assign role.\n3. Select the role or roles that you want to add from the list of available roles.\n4. Optional: If you don't see the role that you're looking for, click Create role and provide the information to add another option.\n5. Click Save.\n\n\n\n\n\n\n\n Assigning roles to users with the API \n\nAfter you create roles, you can assign them to your user's profile. You can also assign roles when you create a future user.\n\n\n\n1. Get your user ID by searching your App ID users with an identifying query, such as an email address.\n\ncurl -X GET \"https:\/\/<region>.appid.cloud.ibm.com\/management\/v4\/<tenantID>\/Users?query=<identifyingSearchQuery>\" -H \"accept: application\/json\" -H \"authorization: Bearer <token>\"\n\nExample:\n\ncurl -X GET https:\/\/us-south.appid.cloud.ibm.com\/management\/v4\/e19a2778-3262-4986-8875-8khjafsdkhjsdafkjh\/cloud_directory\/Users?query=example@domain.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-access-control"},{"document_id":"ibmcld_11474-7-1764","score":16.280218,"text":"\nManage ID provider users with the ID provider \n\nApp ID creates an ID provider so you can add users directly in App ID or connect to other external ID providers. This tutorial describes how to set up your ID provider to work with users that do not have IBM Cloud accounts.\n\nTo manage users via IBM Cloud, see one of these topics:\n\n\n\n* [Manage IBM Cloud users](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-cloud-provider-org)\n* [Manage ID provider users with IBM Cloud](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-cloud-org)\n\n\n\n\n\n Step 1: Create an App ID instance \n\n\n\n1. [Open App ID from the IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/services\/app-id) and log in if necessary. Specify the following values:\n\n\n\n* For Select a location, it is recommended that you keep it in the same location as the Qiskit Runtime service, which is Washington DC (us-east).\n* Select a pricing plan:\n\n\n\n* The Lite plan is free of charge and is enough to get started. If needed, you can seamlessly upgrade to the graduated tier later.\n* The Graduated tier is paid per event and per user beyond the lite tier limits. This tier supports more features such as multi-factor authentication. The Cloud administrator as the owning account of the App ID instance is charged for any fees for the graduated tier instances.\n\n\n\n* Complete the values for Service name (the App ID instance name), Resource group (if one is being used), and any tags you want.\n\n\n\nZoom\n\n![Create App ID instance](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/includes\/images\/org-guide-create-appid.png)\n\nFigure 2. Create your APP ID instance\n2. Read and agree to the terms and click Create.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-org"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02746-7-1681","score":17.47728,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_07765-0-1628","score":15.611117,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_07761-2352-4487","score":11.823746,"text":"\nIA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br> \n IA-5 (f) <br><br> * Check whether App ID minimum period between password changes policy is set to greater than 0<br> * IBM Cloud IAM establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators, such as API keys<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * IBMid establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators<br> * Check whether App ID avoid password reuse policy is enabled<br><br><br> \n IA-5 (g) <br><br> * Check whether Secrets Manager user credentials are rotated at least every # days<br> * Check whether Secrets Manager arbitrary secrets are rotated at least every # days<br> * Check whether Hyper Protect Crypto Services encryption keys that are generated by the service are rotated automatically at least every # months<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nIndividual authenticators include, for example, passwords, tokens, biometrics, PKI certificates, and key cards. Initial authenticator content is the actual content (e.g., the initial password) as opposed to requirements about authenticator content (e.g., minimum password length).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"},{"document_id":"ibmcld_13992-1563-3789","score":11.138363,"text":"\nSSH provides better security solution than password authentication. See [Getting started with SSH keys](https:\/\/cloud.ibm.com\/docs\/ssh-keys?topic=ssh-keys-getting-started-tutorialgetting-started-tutorial).\n\n\n\n\n\n Record IP addresses and credentials \n\nKeep a log of IP addresses and credentials for the server in a safe location so that you can access them quickly without having to log in to the IBM Cloud console.\n\n\n\n* Individual device IP addresses can be viewed from the Device List.\n* Individual device root passwords can be viewed in the device\u2019s Snapshot View. Click the arrow next to the device name to expand the view.\n* Multiple device IP addresses can be viewed by using the Download CSV action within the Device List. Select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n\n\n\n\n Update software credentials \n\nAll software that was loaded onto your device during the provisioning process was assigned temporary credentials. These credentials are viewed and managed on the Passwords tab of each device in the IBM Cloud console. Use these temporary credentials to access your software for the first time. As a best practice, change the password to your software after you access it for the first time. Use a strong password that consists of a combination of letters, numbers, and symbols.\n\nOptionally, password updates can be stored on the Passwords tab for each device; however, understand that when you store passwords within the IBM Cloud console, any person with access to the account and appropriate permissions can view passwords that are stored on the Passwords screen.\n\nFor more information about viewing and managing your software credentials, see [Managing classic infrastructure access](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=account-mngclassicinfra).\n\n\n\n\n\n Access your server on the private network \n\nThe private network is the precursor to interacting with your devices through remote desktop (RDP) using SSH and KVM over IP. The VPN Access tool allows for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services that are offered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-configuring-virtual-servers"},{"document_id":"ibmcld_07761-1647-3208","score":10.76354,"text":"\n* [Handling and securing secrets](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-secrets)\n\n\n\n\n\n\n\n IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\nRules for IA-5 in IBM Cloud for Financial Services v1.2.0 profile\n\n Requirement ID Rules \n\n IA-5 (b) <br><br> * IBM Cloud IAM establishes initial authenticator content for authenticators that are defined by the organization (for example, API keys)<br><br><br> \n IA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"},{"document_id":"ibmcld_05278-229504-231143","score":10.082275,"text":"\nIf neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --pf\n: The path to a file containing the password to access the registry server. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-json-file, --pfj\n: The path to a JSON file containing the password to access the registry server. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--server, -s\n: The URL of the registry server. This value is optional. The default value is us.icr.io.\n\n--username, -u\n: The username to access the registry server. This value is optional. The default value is iamapikey.\n\n\n\n\n\n Example \n\nThe following example creates image registry access that is called myregistry to a Container Registry instance that is located at us.icr.io and uses a username of iamapikey and the IAM API key as a password.\n\nibmcloud ce registry create --name myregistry --server us.icr.io --username iamapikey --password API_KEY\n\n\n\n\n\n Example output \n\nCreating image registry access secret myregistry...\n\nOK\n\n\n\n\n\n\n\n ibmcloud ce registry delete \n\nDelete an image registry access secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_05278-270769-272483","score":9.528361,"text":"\nValid values are json, yaml, jsonpath=JSONPATH_EXPRESSION, and jsonpath-as-json=JSONPATH_EXPRESSION. Use jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--password, --pw\n: The password for a basic auth or registry secret. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --spf\n: The path to a file containing the password for a basic auth or registry secret. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--password-from-json-file, --spfj\n: The path to a JSON file containing the password for a basic auth or registry secret. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--private-key-file, --pkf\n: Specify a file containing the private key for a TLS secret that matches the specified certificate chain with the cert-chain-file option. You must provide the path to the file as a value. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--rm\n: Remove an individual key-value pair in a generic secret by specifying the name of the key. This option can be specified multiple times. This value is optional.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_04335-239254-240968","score":9.528361,"text":"\nValid values are json, yaml, jsonpath=JSONPATH_EXPRESSION, and jsonpath-as-json=JSONPATH_EXPRESSION. Use jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--password, --pw\n: The password for a basic auth or registry secret. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --spf\n: The path to a file containing the password for a basic auth or registry secret. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--password-from-json-file, --spfj\n: The path to a JSON file containing the password for a basic auth or registry secret. The apikey field is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. You must provide the path to the file as a value. This value is optional.\n\n--private-key-file, --pkf\n: Specify a file containing the private key for a TLS secret that matches the specified certificate chain with the cert-chain-file option. You must provide the path to the file as a value. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n--rm\n: Remove an individual key-value pair in a generic secret by specifying the name of the key. This option can be specified multiple times. This value is optional.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_04335-197002-198673","score":8.666405,"text":"\nibmcloud ce registry create \n\nCreate an image registry access secret.\n\nibmcloud ce registry create --name NAME (--password PASSWORD | --password-from-file PASSWORD_FILE | --password-from-json-file) [--email EMAIL] [--output OUTPUT] [--quiet] [--server SERVER] [--username USERNAME]\n\n\n\n Command Options \n\n-n, --name\n: The name of the image registry access secret. Use a name that is unique within the project.\n\n\n\n* The name must begin and end with a lowercase alphanumeric character.\n* The name must be 253 characters or fewer and can contain lowercase letters, numbers, periods (.), and hyphens (-).\n\n\n\nThis value is required.\n\n--email, -e\n: The email address to access the registry server. This value is optional.\n\n--output, -o\n: Specifies the format of the command output. Valid values are json, yaml, jsonpath=JSONPATH_EXPRESSION, and jsonpath-as-json=JSONPATH_EXPRESSION. Use jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--password, -p\n: The password to access the registry server. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-file, --pf\n: The path to a file containing the password to access the registry server. The first line of the file is used for the password. If neither --password, nor --password-from-file, nor --password-from-json-file option is specified, then you are prompted for the password. This value is optional.\n\n--password-from-json-file, --pfj\n: The path to a JSON file containing the password to access the registry server. The apikey field is used for the password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_00684-54925-56282","score":8.514415,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":13.571815,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_05070-25374-27355","score":13.454386,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_09956-3082-3744","score":13.237101,"text":"\nIdentify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a database:\n\n\n\n\n\n1. Go to Databases.\n2. Identify the database for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_09994-5971-8165","score":13.214917,"text":"\nThe retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date\/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.\n\nIf you want to query historical data as far back as possible, you can use the RETENTION_START_TIMESTAMP keyword in time travel queries. If you do this, you can avoid having to try to compute the right timestamp on your own. By extension, you eliminate the risk of running into an error if the value turns out to be too old (older than the retention start timestamp).\n* GROOM TABLE Historical rows that were deleted before the retention start timestamp are no longer needed for time travel queries and can be reclaimed.\n\n\n\n\n\n\n\n Row timestamps and validity \n\nThe insert timestamp of a current or historical row is the date\/time that the transaction inserting the row committed. It is not the time when a particular INSERT, UPDATE, or MERGE statement that inserted the row was run.\n\nIf the inserting transaction for a row committed before the retention start timestamp, the row is treated as having been inserted at the retention start timestamp. This generally applies only to existing rows at the time of altering a nontemporal table to a temporal table.\n\nAn inserted row whose transaction has not yet committed does not have an insert timestamp. Such a row will never be visible to a time travel query.\n\nIn a time travel query, you can select the insert timestamp by using the _SYS_START virtual column of a temporal table.\n\nThe delete timestamp of a historical row is the date\/time that the transaction deleting the row committed. It is not the time when a particular DELETE, UPDATE, MERGE, or TRUNCATE statement that deleted the row was run.\n\nIf a temporal table is truncated, the existing table rows are available to time travel queries and are treated as having been deleted as of the time the truncating transaction committed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_05044-62456-64487","score":13.1836195,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_04939-62476-64507","score":13.1836195,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_09955-1464-2581","score":13.149273,"text":"\nType a new name for the database.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n5. Click Rename.\n\n\n\n\n\n\n\n Updating retention time interval (time travel) for databases \n\n\n\n1. Go to Databases.\n2. Select the database for which you want to update the retention time interval.\n3. From the overflow menu, click Update interval.\n4. Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal database to nontemporal. For more information on retention time interval and time travel, see [Netezza Performance Server time travel](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt).\n5. Click Save.\n\n\n\n\n\n\n\n Viewing privileges for databases \n\n\n\n1. Go to Databases.\n2. Select the database which privileges you want to view.\n3. From the overflow menu, click Show privileges.\nA list of privileges is now displayed.\n\n\n\n\n\n\n\n Dropping databases \n\n\n\n1. Go to Databases.\n2. Select the database that you want to drop.\n3. From the overflow menu, click Drop.\n4. Confirm your choice by clicking Drop.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-databases"},{"document_id":"ibmcld_09994-4281-6432","score":12.83012,"text":"\nBETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2> Includes all the rows that were valid at any time between TIMESTAMP EXPRESSION 1 and TIMESTAMP EXPRESSION 2 (inclusive), whose insert timestamp is less than or equal to TIMESTAMP EXPRESSION 2 and whose delete timestamp is NULL or is greater than TIMESTAMP EXPRESSION 1. If TIMESTAMP EXPRESSION 1 or TIMESTAMP EXPRESSION 2 is less than the table\u2019s retention start timestamp, an error is returned. If TIMESTAMP EXPRESSION 1 is greater than TIMESTAMP EXPRESSION 2, the query produces no rows. \n\n\n\n\n\n\n\n\n\n Timestamps in time travel queries \n\n\n\n Retention time interval and retention time period \n\nA table\u2019s retention time interval defines the number of days past their delete timestamps that historical (deleted) rows are available for time travel queries. At any given time, the retention time period ends at the current timestamp (date and time) and extends back the given number of days. This is a sliding time window that advances as the current system time advances.\n\n\n\n\n\n Retention lower bound \n\nFor the most part, a table\u2019s retention lower bound is the date and time when the table was defined to be a temporal table. This could have been when you ran the CREATE TABLE command, or the last time you altered the table\u2019s DATA_VERSION_RETENTION_TIME from zero to non-zero.\n\n\n\n\n\n Retention start timestamp \n\nAt the time of defining a table to be temporal (when the retention lower bound is defined), there are no historical rows available over the retention time period. To capture the notion of how far back historical rows are actually available (visible to time travel queries), a table\u2019s retention start timestamp is defined. The retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date\/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_09947-0-947","score":12.706316,"text":"\n\n\n\n\n\n\n  Schemas \n\n\n\n  Creating schemas \n\n\n\n1.  Go to Databases.\n2.  Select the database in which you want to create a schema.\n3.  Click Create schema.\n4.  Type a name for the schema.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n5.  Specify the retention time interval (in days) for the schema.\n6.  Click Create.\n\n\n\n\n\n\n\n  Updating retention time interval (time travel) for schemas \n\n\n\n1.  Go to Databases.\n2.  Select the database in which the schema that you want to alter is.\n3.  From the overflow menu, click Update interval.\n4.  Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal schema to nontemporal.\nFor more information on retention time interval and time travel, see [Netezza Performance Server time travel](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt).\n5.  Click Save.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemas"},{"document_id":"ibmcld_09956-7-2100","score":12.563157,"text":"\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/docs\/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16481-3559-5682","score":16.150522,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-3559-5683","score":16.139776,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16464-13891-15856","score":14.862819,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16436-9264-11446","score":12.406711,"text":"\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"},{"document_id":"ibmcld_16493-8964-11146","score":12.406711,"text":"\nAn entity type exists independently and can be uniquely identified.\n\n\n\n\n\n\n\n F \n\n\n\n* F1 score\n\nA measure of a test's accuracy that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values. An F1 score reaches its best value at 1 and worst value at 0.\n* false negative\n\nAn answer or annotation that is correct, but was predicted to be incorrect.\n* false positive\n\nAn answer or annotation that is incorrect, but was predicted to be correct.\n* feature\n\nA data member or attribute of a type.\n* Fleiss Kappa score\n\nA measure of how consistently the same annotation was applied by multiple human annotators across overlapping documents. The Fleiss Kappa score reaches its best value at 1 and worst value at 0.\n\n\n\n\n\n\n\n G \n\n\n\n* ground truth\n\nThe set of vetted data, consisting of annotations added by human annotators, that is used to adapt a machine learning model to a particular domain. Ground truth is used to train machine learning models, measure model performance (precision and recall), and calculate headroom to decide where to focus development efforts for improving performance. Accuracy of ground truth is essential since inaccuracies in the ground truth will correlate to inaccuracies in the components that use it.\n\n\n\n\n\n\n\n H \n\n\n\n* headroom analysis\n\nThe process of determining how much improvement in accuracy, precision, or recall can be expected by addressing some class of problems that are identified while performing accuracy analysis.\n* human annotator\n\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"},{"document_id":"ibmcld_16417-5155-7505","score":12.35566,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":12.35566,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":12.219032,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":11.2779455,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":11.2779455,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-8324-10312","score":23.5354,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16481-3559-5682","score":22.825014,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-3559-5683","score":22.79298,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16417-5155-7505","score":22.666344,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":22.666344,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-13891-15856","score":21.634424,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16468-8522-10510","score":21.458735,"text":"\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16417-1764-4158","score":21.264725,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":21.264725,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":20.928844,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.7977228895}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15092-4396-6100","score":17.022812,"text":"\nAll volumes are assigned instance bandwidth proportional to their maximum bandwidth, where the sum of all volume bandwidth equals the overall \"volumes\" bandwidth.\n\nIn our [example](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-bandwidthvolume-adjust-bandwidth), the remaining bandwidth that is allocated on the instance for data volumes is 1,607 Mbps (2000 Mbps less 393 Mbps for the boot volume). After the data volume is attached to the instance, the volume optimally requires 640 Mbps. If this volume is the only attached volume, it gets the full bandwidth allocation. If you had two more volumes of greater capacity, the bandwidth allocation is less.\n\nUnattached volume bandwidth might not be the same as the actual bandwidth that you see after the volume is attached to an instance. The difference is due to the amount of bandwidth that is dedicated to the boot volume and all other attached data volumes.\n\n\n\n\n\n\n\n Estimating volume bandwidth \n\nThink about the type of data volume that your workloads require and select the right volume profile. Data intensive workloads might require the higher bandwidth performance of a 10 IOPS\/GB profile. For more information about the relationship of volume profiles to compute profiles, see [How virtual server profiles relate to storage profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles&interface=uivsi-profiles-relate-to-storage). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performance&interface=uihow-block-size-affects-performance).\n\n\n\n\n\n Next steps \n\nAllocate total volume bandwidth by using the API or CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-bandwidth"},{"document_id":"ibmcld_15111-1536-3423","score":15.820574,"text":"\nThe volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n\n\n\n\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_16436-3553-5570","score":14.549928,"text":"\nIn human annotation, a collection of documents that are extracted from the corpus that allow the workload to be shared by multiple human annotators. In machine-based annotation, a collection of documents that can be used as blind data, training data, or test data.\n* annotation process manager\n\nA role that is responsible for managing the full annotation lifecycle activities within a workspace. The project manager that is added to a workspace typically performs the activities of an annotation process manager.\n* annotator\n\nSee [human annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_H) and [machine learning annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_M).\n* attribute\n\nA characteristic or trait of an entity that describes the entity; for example, the telephone number of an employee is one of the employee attributes.\n\n\n\n\n\n\n\n B \n\n\n\n* blind data\n\nA set of documents annotated with the ground truth, such as question and answer pairs, semantic annotation, and passage judgment. Blind data is never released or seen by developers and is used to test the system periodically to evaluate performance on unseen data. Testing on blind data prevents accuracy from being tainted by over-fitting to known question sets or annotations. Reported results should only come from tests that are run on blind data. See also [testing data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_T) and [training data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_T).\n\n\n\n\n\n\n\n C \n\n\n\n* concordance\n\nProvides a way to ensure that the same mention is annotated with the same entity type throughout a document and across annotation sets. Concordance helps ensure consistency across multiple occurrences of a mention without requiring the human annotator to manually label each occurrence.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"},{"document_id":"ibmcld_16410-5205-7359","score":14.547424,"text":"\nAdjustments can be made repeatedly to improve performance until a satisfactory level of accuracy is achieved.\n\n\n\n\n\n Model deployment \n\nThis stage refers to exporting components that enable the model to run in machine learning runtime environments and making the model accessible to other Watson cognitive applications. For example, you can export the machine learning model for use by IBM Watson\u2122 Natural Language Understanding for IBM Cloud Pak\u00ae for Data or IBM Watson\u2122 Discovery for IBM Cloud Pak\u00ae for Data\n\n\n\n\n\n\n\n Creating an annotation task \n\nBefore human annotators begin adding annotations to documents, the annotation process manager can optionally create an annotation task.\n\nAdmins and project managers can annotate ground truth document sets directly. See [Annotating document sets directly](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotating-document-sets-directly).\n\n\n\n About this task \n\nThe annotation task specifies which documents are to be annotated. To compare how well the human annotators perform, and to see how consistently they apply the annotation guidelines, you must include at least two human annotators in the task. In addition, some percentage of documents must occur in all of the annotation sets that you add to the task (you specify the overlap percentage when you create the annotation sets).\n\n\n\n Important \n\n\n\n* An annotation task is a temporal concept that exists to allow human annotators to annotate text in isolated spaces. It also ensures that annotations must be approved before they are promoted to ground truth.\n* An annotation set can be included in one active task at a time. To add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16490-3348-5630","score":14.540236,"text":"\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_06109-20071-21928","score":14.433751,"text":"\n* false: Choose this option if you want to share an existing bucket across your stateful set replicas. Make sure to define the name of the bucket in the spec.volumeClaimTemplates.metadata.annotions.ibm.io\/bucket section of your stateful set YAML.\n\n\n\nibm.io\/auto-delete-bucket\n: In the spec volume claim templates metadata section, set an annotation to configure how buckets are deleted. Choose between the following options:\n\n\n\n* true: Your data, the bucket, and the PV is automatically removed when you delete the PVC. Your IBM Cloud Object Storage service instance remains and is not deleted. If you choose to set this option to true, then you must set ibm.io\/auto-create-bucket: true and ibm.io\/bucket: \"\"so that your bucket is automatically created with a name with the format tmp-s3fs-xxxx.\n* false: When you delete the PVC, the PV is deleted automatically, but your data and the bucket in your IBM Cloud Object Storage service instance remain. To access your data, you must create a new PVC with the name of your existing bucket.\n\n\n\nibm.io\/bucket\n: In the spec volume claim templates metadata section, set an annotation for the bucket details. Choose between the following options:\n\n\n\n* If ibm.io\/auto-create-bucket is set to true: Enter the name of the bucket that you want to create in IBM Cloud Object Storage. If in addition ibm.io\/auto-delete-bucket is set to true, you must leave this field blank to automatically assign your bucket a name with the format tmp-s3fs-xxxx. The name must be unique in IBM Cloud Object Storage.\n* If ibm.io\/auto-create-bucket is set to false: Enter the name of the existing bucket that you want to access in the cluster.\n\n\n\nibm.io\/secret-name\n: In the spec volume claim templates metadata annotations section, enter the name of the secret that holds the IBM Cloud Object Storage credentials that you created earlier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_cos_apps"},{"document_id":"ibmcld_16493-3353-5349","score":14.397362,"text":"\nIn human annotation, a collection of documents that are extracted from the corpus that allow the workload to be shared by multiple human annotators. In machine-based annotation, a collection of documents that can be used as blind data, training data, or test data.\n* annotation process manager\n\nA role that is responsible for managing the full annotation lifecycle activities within a workspace. The project manager that is added to a workspace typically performs the activities of an annotation process manager.\n* annotator\n\nSee [human annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_H) and [machine learning annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_M).\n* attribute\n\nA characteristic or trait of an entity that describes the entity; for example, the telephone number of an employee is one of the employee attributes.\n\n\n\n\n\n\n\n B \n\n\n\n* blind data\n\nA set of documents annotated with the ground truth, such as question and answer pairs, semantic annotation, and passage judgment. Blind data is never released or seen by developers and is used to test the system periodically to evaluate performance on unseen data. Testing on blind data prevents accuracy from being tainted by over-fitting to known question sets or annotations. Reported results should only come from tests that are run on blind data. See also [testing data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_T) and [training data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_T).\n\n\n\n\n\n\n\n C \n\n\n\n* concordance\n\nProvides a way to ensure that the same mention is annotated with the same entity type throughout a document and across annotation sets. Concordance helps ensure consistency across multiple occurrences of a mention without requiring the human annotator to manually label each occurrence.\n* confusion matrix","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"},{"document_id":"ibmcld_01232-15963-18009","score":14.207497,"text":"\nYes, you can use this setup because NFS is a file-aware protocol.\n\n\n\n\n\n Can I increase inodes for my NFS volume? \n\nTypically, when volumes are provisioned, they are allotted the maximum inode count for the size that you ordered. Maximum inode count grows automatically as the volume grows. If the inodes count does not increase after you expanded a volume, submit a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\n\n\n\n\n I am unable to upgrade storage. What can affect the ability to upgrade or expand storage? \n\nThe following situations can affect the ability to upgrade or expand storage.\n\n\n\n* If the original volume is the Endurance 0.25 tier, then the IOPS tier can\u2019t be updated.\n* Older storage types can't be upgraded. Ensure that the storage was ordered in an upgraded Data Center that allows for [Expandable storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacity).\n* The permissions that you have in the Cloud console can be a factor. For more information, see the topics within [User roles and permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\n\n\n\n\n\n\n Are File Storage for Classic volumes thin or thick provisioned? \n\nAll Block and File Storage for Classic services are thin-provisioned. This method is not modifiable.\n\n\n\n\n\n My billing ID changed, what does this mean? \n\nYou might notice that your Storage volumes are now billed as \"Endurance Storage Service\u201d or \"Performance Storage Service\" instead of \"Enterprise Storage\". You might also have new options in the console, such as the ability to adjust IOPS or increase capacity. IBM Cloud\u00ae strives to continuously improve storage capabilities. As hardware gets upgraded in the data centers, storage volumes that reside in those data centers are also upgraded to use all enhanced features. The price that you pay for your Storage volume does not change with this upgrade.\n\n\n\n\n\n How durable is File Storage for Classic? \n\nWhen you store your data in File Storage for Classic, it's durable, highly available, and encrypted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-file-storage-faqs"},{"document_id":"ibmcld_16425-1845-4030","score":14.110682,"text":"\nSee [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents. Recall is determined by the number of correctly labeled annotations divided by the number of annotations that should have been created. A recall score of 1.0 means that every mention that should have been labeled as entity type A was labeled correctly. A low recall score helps you identify places where the machine learning model failed to create an annotation that it should have. The score says nothing about how many other mentions were also labeled as entity type A, but should not have been; the precision score reflects that information. See [Analyzing low recall scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowr).\n* Percentage of total annotations\n\nA measurement of ground truth that shows how many words were annotated with a given entity type or relation type out of the total number of words that were annotated as any entity type or relation type in the test document set. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of one type are compared to the other types in your ground truth.\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16425-3435-5660","score":13.852482,"text":"\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-7-2064","score":19.65768,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-7-2044","score":19.346489,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":19.121449,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-1600-3658","score":19.056814,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-9193-11335","score":18.791779,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7346-9136","score":18.652966,"text":"\nHuman annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n[Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries)\n\n[Getting Started > Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in a production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16463-4148-5042","score":18.619997,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16507-4382-6307","score":18.593767,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":18.536827,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16507-12419-14261","score":18.33,"text":"\nAdd entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n\n\n* [Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Getting Started > Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16507-1455-3632","score":16.939732,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_06981-1673-3761","score":16.72468,"text":"\nLater, you can limit the search to return content from only the tips field.\n\nOr maybe you have extra large documents that contain subsections. You can teach the SDU model to recognize these subsections, and then split the large document into multiple, smaller, and easier-to-manage documents that begin with one of these subsections.\n* The best way to prepare a collection for use in Conversational Search projects is to identify discrete question-and-answer pairs. You can use the SDU tool to find and annotate them. If you configure the project to contain answers in an answer field, you must update the search configuration in Watson Assistant to get the body of the response from the custom answer field.\n* A pretrained SDU model is applied to Document Retrieval for Contracts projects automatically. The pretrained SDU model knows how to recognize terms and concepts that are significant to contracts. As a result, you cannot apply a user-trained SDU model to this project type, but you also don't need to.\n* The SDU tool is rarely used with Content Mining projects.\n\n\n\nYou can use the SDU tool to annotate the following file types only:\n\n\n\n* Image files (PNG, TIFF, JPG)\n* Microsoft PowerPoint\n* Microsoft Word\n* PDF\n\n\n\nFor a complete list of file types that Discovery supports, see [Supported file types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n\nThe Smart Document Understanding tool uses optical character recognition (OCR) to extract text from images in the files that it analyzes. Images must meet the minimum quality requirements that are supported by OCR. For more information, see [Optical character recognition](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionsocr).\n\nThe tool cannot read documents with the following characteristics; remove them from your collection before you begin:\n\n\n\n* Documents that appear to have text that overlays other text are considered double overlaid and cannot be annotated.\n* Documents that contain multiple columns of text on a single page cannot be annotated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_16507-9193-11335","score":16.601164,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-1600-3658","score":16.549973,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16468-3297-5708","score":16.437641,"text":"\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16507-3099-4772","score":16.324188,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-3168-4952","score":15.924386,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16456-13093-15345","score":15.778225,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-13093-15345","score":15.778225,"text":"\nIf so, select a mention and click Attribute View.\n8. Click Save at any time to save your work.\n\n\n\n\n\n\n\n What to do next \n\nAfter you finish annotating all entity mentions, relation mentions, and coreferences in the document, as applicable, change the document status from In Progress to Completed, click Save, and then close the document.\n\nAfter you finish annotating all documents and mark them Completed, the status of the annotation set changes to Submitted. That is how project managers know that they can start to evaluate the documents for inter-annotator agreement, reject or accept documents, and promote them to ground truth.\n\n\n\n\n\n\n\n Annotating repeating mentions \n\nYou can optionally use the concordance tool to label multiple occurrences of a mention at once. The tool enables you to annotate the same text with the same entity type throughout a document and across annotation sets. Using the tool helps to ensure consistency in annotation across multiple documents. For example, you can label each occurrence of the mention encryption individually in mention mode, or you can label all occurrences of the mention encryption by using the concordance tool. Either way, the model learns from the entity type that you apply to the mention.\n\n\n\n About this task \n\nAlthough the concordance tool is optional, a good practice is to use the concordance tool to annotate mentions within a document or across documents before you start annotating mentions in individual documents. When you apply an entity type to a mention with the concordance tool, the system applies the entity type to all matching mentions, overriding any existing entity types that are assigned to a matching mention. To avoid conflicts, attributes (such as roles or subtypes) are removed from existing entity types when a new entity type is applied by the concordance tool.\n\n\n\n\n\n Procedure \n\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"},{"document_id":"ibmcld_16563-9481-11146","score":15.539544,"text":"\nThis pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images\/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6. Annotate a mention:\n\n\n\n1. Click the Entity tab.\n2. In the document body, select the text Thomas Watson.\n3. In the list of entity types, click PERSON. The entity type PERSON is applied to the selected mention.\n\n![This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".](images\/wks_tut_annotatemention3.png \"This screen capture shows the \"PERSON\" entity type applied to the mention, \"Thomas Watson\".\")\n\n\n\n7. Annotate a relation:\n\n\n\n1. Click the Relation tab.\n2. Select the Thomas Watson and IBM mentions (in that order). To select a mention, click the entity type label above the text.\n3. In the list of relation types, click founderOf. The two mentions are connected with a founderOf relationship.\n\n![This screen capture shows two mentions connected by the relation type, \"founderOf\".](images\/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1301266833}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13464-7165-8908","score":11.08155,"text":"\nTS_CROSS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: DoubleArray\n: Use a [cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation) algorithm to return a measure of the similarity of two time series.\n\nTS_SEG_CROSS_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleArrayTimeSeries\n: Use a [cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation) algorithm to return a measure of the similarity of each pair of corresponding segments in the two input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_AVG(DoubleTimeSeries)\n: Output: Double\n: Returns the average of the values of the input time series.\n\nTS_SEG_AVG(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the average of the values of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_MIN(DoubleTimeSeries)\n: Output: Double\n: Returns the minimum value of the input time series.\n\nTS_SEG_MIN(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the minimum value of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_MAX(DoubleTimeSeries)\n: Output: Double\n: Returns the maximum value of the input time series.\n\nTS_SEG_MAX(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the maximum value of each segment of the input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_SUM(DoubleTimeSeries)\n: Output: Double\n: Returns the sum of the values of the input time series.\n\nTS_SEG_SUM(DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_09165-3941-4947","score":10.468294,"text":"\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n\n\n\nA successful GET api\/v2\/keys\/<key_ID_or_alias>\/metadata response returns details about your key. The following JSON object shows an example returned value for a standard key.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-standard-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"state\": 1,\n\"expirationDate\": \"2020-03-15T03:50:12Z\",\n\"extractable\": true,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-12T03:50:12Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"Deprecated\",\n\"algorithmMetadata\": {\n\"bitLength\": \"256\",\n\"mode\": \"Deprecated\"\n},\n\"algorithmBitSize\": 256,\n\"algorithmMode\": \"Deprecated\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key-metadata"},{"document_id":"ibmcld_09099-9914-10963","score":9.580843,"text":"\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n new_key_ring_ID Required. The unique identifier for the target key ring that you would like to move the key to. \n\n\n\nA successful PATCH api\/v2\/keys\/keyID_or_alias request returns the key's metadata, including the id of the key ring that the key is a part of.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-root-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"description\": \"A test root key\",\n\"state\": 1,\n\"extractable\": false,\n\"keyRingID\": \"new-key-ring\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-12T03:37:32Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"Deprecated\",\n\"algorithmMetadata\": {\n\"bitLength\": \"256\",\n\"mode\": \"Deprecated\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys"},{"document_id":"ibmcld_09920-7689-8996","score":9.464495,"text":"\nCorrelate documents from different sources \n\nCorrelate content across documents by using the Python NLTK and IBM Data Science Experience.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/watson-document-correlation\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-document-co-relation?cm_sp=Developer-_-watson-document-correlation-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/youtu.be\/vDCaBPhAr64?cm_sp=Developer-_-watson-document-correlation-_-View-the-Demo)\n\n\n\n\n\n\n\n Discover hidden Facebook usage insights \n\nHarness the power of cognitive data analysis in a Jupyter Notebook with PixieDust.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/discover-hidden-facebook-usage-insights\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/pixiedust-facebook-analysis?cm_sp=IBMCode-_-discover-hidden-facebook-usage-insights-_-Get-the-Code)\n* [View the Demo !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_08516-3998-5451","score":9.189152,"text":"\n-H 'correlation-id: <correlation_ID>' \n-H 'prefer: <return_preference>' \n-d '{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"name\": \"<key_alias>\",\n\"description\": \"<key_description>\",\n\"expirationDate\": \"<YYYY-MM-DDTHH:MM:SS.SSZ>\",\n\"payload\": \"<key_material>\",\n\"extractable\": <key_type>\n}\n]\n}'\n\nReplace the variables in the example request according to the following table.\n\n\n\n Variable Description \n\n region The region abbreviation, such as us-south or au-syd, that represents the geographic area where your Hyper Protect Crypto Services service instance resides. For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regionsservice-endpoints). \n port Required. The port number of the API endpoint. \n IAM_token Your IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID The unique identifier that is assigned to your Hyper Protect Crypto Services service instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n correlation_ID The unique identifier that is used to track and correlate transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-standard-keys"},{"document_id":"ibmcld_03037-8165-10458","score":9.022743,"text":"\nEarly in the development process, use the Dialog skill analysis for Watson Assistant notebook to help you get started. It offers the following types of insights:\n\n\n\n* Examines the terms that are correlated with each intent in your training data to find anomalies that might identify problems that you can investigate further.\n* Uses a blind test set that you provide to calculate performance on statistical metrics like Accuracy, Precision, Recall & F1.\n* Offers advanced features that you can use to find the causes of common issues such as why some sentences are often misidentified.\n\n\n\nTo learn more about how this notebook can help you improve your dialog, read this [Medium.com blog post](https:\/\/medium.com\/ibm-watson\/announcing-dialog-skill-analysis-for-watson-assistant-83cdfb968178).\n3. After you deploy a version of the assistant, and have some conversation log data collected, run the Measure Watson Assistant Performance notebook.\n4. Follow the step-by-step instructions provided with the notebooks to analyze a subset of the dialog exchanges from the logs.\n\nRun the following notebook first:\n\n\n\n* Measure: Gathers metrics that focus on coverage (how often the assistant is confident enough to respond to users) and effectiveness (when the assistant does respond, whether the responses are satisfying user needs).\n\n\n\nThe insights are visualized in ways that make it easier to understand areas for improvement in your assistant.\n5. Export a sample set of the logs from ineffective conversations, and then analyze and annotate them.\n\nFor example, indicate whether a response is correct. If correct, mark whether it is helpful. If a response is incorrect, then identify the root cause, the wrong intent or entity was detected, for example, or the wrong dialog node was triggered. After identifying the root cause, indicate what the correct choice would have been.\n6. Feed the annotated spreadsheet to the Analyze Watson Assistant Effectiveness notebook.\n\n\n\n* Effectiveness: Performs a deeper analysis of your logs to help you understand the steps you can take to improve your assistant.\n\n\n\n7. Use the Dialog Flow Analysis for Watson Assistant notebook to review your dialog. The notebook can help you pinpoint the dialog nodes where customers most frequently abandon the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_08661-4031-5327","score":8.593511,"text":"\nFor more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n correlation_ID The unique identifier that is used to track and correlate transactions. \n\n\n\nA successful GET api\/v2\/keys\/{id}\/policies response returns policy details that are associated with your key. The following JSON object shows an example response for a root key that has an existing rotation policy.\n\n{\n\"metadata\": {\n\"collectionTotal\": 1,\n\"collectionType\": \"application\/vnd.ibm.kms.policy+json\"\n},\n\"resources\": [\n{\n\"id\": \"a1769941-9805-4593-b6e6-290e42dd1cb5\",\n\"rotation\": {\n\"interval_month\": 1\n},\n\"createdby\": \"IBMid-503CKNRHR7\",\n\"createdat\": \"2019-03-06T16:31:05Z\",\n\"updatedby\": \"IBMid-503CKNRHR7\",\n\"updatedat\": \"2019-03-06T16:31:05Z\"\n}\n]\n}\n\nThe interval_month value indicates the key rotation frequency in months.\n\n\n\n\n\n\n\n Creating a rotation policy \n\nCreate a rotation policy for your root key by making a PUT call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/policies\n\n\n\n1. [Retrieve your service and authentication credentials](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n2. Create a rotation policy for a specified key by running the following cURL command.\n\ncurl -X PUT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-rotation-policy"},{"document_id":"ibmcld_13464-3036-4751","score":8.567538,"text":"\n: Calculates the Z-score of a time series with the specified mean (second parameter) and standard deviation (third parameter).\n\nTS_PEAK(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the peaks of the time series.\n\nTS_TROUGH(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the troughs of the time series.\n\nTS_DIFF(DoubleTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the difference of the time series.\n\nTS_CORRELATION(DoubleTimeSeries, DoubleTimeSeries)\n: Output: Double\n: Returns the correlation between two time series.\n\nTS_SEG_CORRELATION(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the correlation between each pair of corresponding segments in the two input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_MANHATTAN_DISTANCE()\n: Output: Double\n: Returns the [Manhattan distance](https:\/\/en.wikipedia.org\/wiki\/Taxicab_geometry) between two time series.\n\nTS_SEG_MANHATTAN_DISTANCE(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the [Manhattan distance](https:\/\/en.wikipedia.org\/wiki\/Taxicab_geometry) between each pair of corresponding segments in the two input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_SBD()\n: Output: Double\n: Returns the shape-based distance between two time series.\n\nTS_SEG_SBD(DoubleSegmentTimeSeries, DoubleSegmentTimeSeries)\n: Output: DoubleTimeSeries\n: Returns the shape-based distance between each pair of corresponding segments in the two input time series. Each timetick in the output time series is the timetick of the corresponding segment.\n\nTS_DTW()\n: Output: Double","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-data_processing_functions"},{"document_id":"ibmcld_08634-3797-5057","score":8.350325,"text":"\nIf unspecified, Hyper Protect Crypto Services will search for the key in every key ring that is associated with the specified instance. Therefore, it is suggested to specify the key ring ID for a more optimized request.<br><br>Note: The key ring ID of keys that are created without an x-kms-key-ring header is: default. For more information, see [Managing key rings](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-managing-key-rings). \n correlation_ID The unique identifier that is used to track and correlate transactions. \n encrypted_data_key Required. The ciphertext value that was returned by the original wrap operation. \n\n\n\nThe newly wrapped data encryption key, original key version (keyVersion) that is associated with the supplied ciphertext and latest key version (rewrappedKeyVersion) associated with the new ciphertext is returned in the response entity-body. The following JSON object shows an example returned value.\n\n{\n\"ciphertext\": \"eyJjaX ... h0Ijoi ... c1ZCJ9\",\n\"keyVersion\": {\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\"\n},\n\"rewrappedKeyVersion\": {\n\"id\": \"12e8c9c2-a162-472d-b7d6-8b9a86b815a6\"\n}\n}\n\nStore and use the new ciphertext value for future envelope encryption operations so that your data is protected by the latest root key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-rewrap-keys"},{"document_id":"ibmcld_16059-20962-22916","score":8.327328,"text":"\nDue to the sensitivity of the information, when an event is generated as a result of an API call to the KMS, the event doesn't include detailed information about the key. Instead, it includes a correlation ID that you can use to identify the key internally in your cloud environment. The correlation ID is a field that is returned as part of the correlationId field.\n\n\n\n Activity Tracker events for key rotation \n\nWhen you initiate activity in the KMS to rotate and manage your root keys, Activity Tracker events are generated. These events are particular to Key Protect, but similar events are generated for Hyper Protect Crypto Services, too.\n\n\n\n* When you list keys, a kms.secrets.list event is generated.\n* When you rotate a root key, a kms.secrets.rotate event is generated.\n* When you manually rewrap a data encryption key (DEK) with new key material, a kms.secrets.rewrap event is generated.\n* If you initially imported a root key by using an import token and use the import token to rotate a key, a kms.secrets.ack-rotate event is generated.\n* When you retrieve a key, the requestData.keyType field includes the type of key that was retrieved.\n* The responseData.keyState field includes the integer that correlates to the state of the key. The integers correlate with these key state values: Pre-activation = 0, Active = 1, Suspended = 2, Deactivated = 3, and Destroyed = 5. For more information about key states, see [Key states and transitions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-stateskey-transitions).\n* When you authorize the deletion of a key, a kms.secrets.setkeyfordeletion event is generated. The responseData.keyState field includes the integer that correlates to deleted state (5).\n* The responseData.totalResources field includes the total number of key versions that are associated with the key.\n* The responseData.eventAckData.newKeyVersionId field includes the unique identifier of the latest key version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09070-6713-7479","score":17.868795,"text":"\nFor a detailed description of the request, see the Key Protect [REST API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).\n\n\n\n\n\n What's next \n\nTo learn how to delete and purge a key using the UI, check out [Deleting keys using a single authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys). For information about how to do this using the API, click the API tab at the beginning of the topic.\n\nTo learn how to delete and purge a key that holds a dual-authorization deletion policy using the UI, check out [Deleting keys using dual authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys). For information about how to do this using the API, click the API tab at the beginning of the topic.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys"},{"document_id":"ibmcld_09061-4-1966","score":17.523815,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_16045-15510-17033","score":17.291098,"text":"\nDelete key [Deleting keys in the console (single authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-key-gui). [Deleting keys with the GUI (single authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui). \n [Deleting a key with dual authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-api). [Authorize deletion for a key with the GUI (dual authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-console). \n Restore key [Restoring a deleted key with the console](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keysrestore-ui). [Restoring a deleted key with the GUI](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keysrestore-ui). \n\n\n\n\n\n\n\n Manage root keys with the API \n\nYou can use the API to disable, enable, delete, or restore your root keys. Table 6 describes each action and links to detailed steps for the Key Protect or Hyper Protect Crypto Services API. For more information about the relationship of user actions and key states, see [Root key states and user actions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-root-key-states).\n\nBecause deleting a root key makes all resources that are protected by it unusable (status = unusable), program your applications to check the status of the resource (such as a volume, snapshot, or image) before it attempts to use it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_08987-28071-29358","score":16.979618,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_15666-15995-16585","score":16.74666,"text":"\nFor more information, see [ibmcloud is key-delete](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencekey-delete). Specify name of each SSH key that you delete by using the KEY variable.\n\nibmcloud is key-delete (KEY1 KEY2 ...)\n\n\n\n\n\n Deleting your SSH key by using the API \n\nTo delete one or more SSH keys by using the API, use [Delete a key](https:\/\/cloud.ibm.com\/apidocs\/vpc\/latestdelete-key).\n\nFor the $id variable, specify the name of the SSH key you want to delete.\n\ncurl -X DELETE \"$vpc_api_endpoint\/v1\/keys\/$id?version=2023-03-30&generation=2\" -H \"Authorization: Bearer $iam_token\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-ssh-keys&interface=ui"},{"document_id":"ibmcld_15665-15982-16572","score":16.74666,"text":"\nFor more information, see [ibmcloud is key-delete](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-referencekey-delete). Specify name of each SSH key that you delete by using the KEY variable.\n\nibmcloud is key-delete (KEY1 KEY2 ...)\n\n\n\n\n\n Deleting your SSH key by using the API \n\nTo delete one or more SSH keys by using the API, use [Delete a key](https:\/\/cloud.ibm.com\/apidocs\/vpc\/latestdelete-key).\n\nFor the $id variable, specify the name of the SSH key you want to delete.\n\ncurl -X DELETE \"$vpc_api_endpoint\/v1\/keys\/$id?version=2023-03-30&generation=2\" -H \"Authorization: Bearer $iam_token\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-ssh-keys"},{"document_id":"ibmcld_09120-29325-30645","score":16.741627,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-45768-46776","score":16.68488,"text":"\nThese are examples of kp key delete.\n\n\n\n Example 1 \n\nDelete a root key.\n\n create a root key\n$ ibmcloud kp key create my-root-key\n\nCreating key: 'my-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Name\n8635b804-9966-4918-a16b-d561fdbf181f my-root-key\n\n show key details\n$ ibmcloud kp key show 8635b804-9966-4918-a16b-d561fdbf181f\n\nGrabbing info for key id: 8635b804-9966-4918-a16b-d561fdbf181f...\nOK\nKey ID Key Name Description Creation Date Expiration Date\n8635b804-9966-4918-a16b-d561fdbf181f my-root-key 2020-05-05 19:58:02 +0000 UTC Key does not expire\n\n delete the key\n$ ibmcloud kp key delete 8635b804-9966-4918-a16b-d561fdbf181f\n\nDeleting key: 8635b804-9966-4918-a16b-d561fdbf181f, from instance: 390086ac-76fa-4094-8cf3-c0829bd69526...\nOK\nDeleted Key\n8635b804-9966-4918-a16b-d561fdbf181f\n\n\n\n\n\n Example 2 \n\nDelete a root key and show the JSON output.\n\n create a root key\n$ ibmcloud kp key create my-root-key --output json\n\n{\n\"id\": \"9cca88c9-019e-4f0a-9e76-8e657c6b9720\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09120-94597-96242","score":16.627169,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_13028-13559-15025","score":16.564114,"text":"\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n\n\n Deleting an API key \n\nIf you are using a key rotation strategy, you might want to delete an older key and replace it with a new key.\n\nTo delete an API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM) > API keys.\n2. Identify the row of the API key that you want to delete, and select Delete from the Actions![List of actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/814aeaf04800bb4f74ea1c057d4abb166a5f357a\/icons\/action-menu-icon.svg) menu.\n3. Confirm the deletion by clicking Delete.\n\n\n\nTo delete an API key that is not your own, but you have access to manage, go to the API keys page. Then, select the All user IBM Cloud API keys option from the View menu to find the API key.\n\n\n\n\n\n Deleting an API key by using the CLI \n\nTo delete an API key by using the CLI:\n\nEnter ibmcloud iam api-key-delete NAME in your command prompt, specifying the name of the key to delete.\n\n\n\n\n\n Deleting an API key by using the API \n\nTo delete an API key by using the API, call the [IAM Identity Service API](https:\/\/cloud.ibm.com\/apidocs\/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https:\/\/iam.cloud.ibm.com\/v1\/apikeys\/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application\/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/account?topic=account-userapikey"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09088-10880-12721","score":20.535194,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_09088-9397-11338","score":20.343363,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_07578-1211120-1213024","score":20.114172,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":20.114172,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16045-17715-19288","score":19.535116,"text":"\nDelete key [Deleting keys with the API (single authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-key-api) [Deleting keys with the API (single authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api) \n [Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api) [Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) \n Restore key [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keysrestore-api) [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keysrestore-api) \n\n\n\n\n\n\n\n Removing service authorization to a root key \n\nYou can make your data inaccessible but retain it on the cloud by removing IAM authorization to use that root key.\n\nWhen you [authorize use](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauthserviceauth) of your root key, you grant permission for IBM to use the key to encrypt your resource. Authorization is done at the key management service level through IAM, when you authorize service between your service (for example, Cloud Block Storage) and the key management service.\n\nYou can remove any authorization between services in your account when you have the Administrator role on the target service (in this case, the key management service).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09061-4-1966","score":19.30907,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-22025-23534","score":19.067707,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08695-7-1852","score":17.938736,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_08435-4-1684","score":17.634668,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_15994-4553-5739","score":16.597847,"text":"\nWhy it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service). For more information, see [Using authorizations to grant access between services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) to establish IAM service-to-service authorizations in the UI, CLI, or API.\n\n\n\n\n\n Resolving volume resize issues while a snapshot is taken \n\n What\u2019s happening \n\nIf you take a snapshot of a volume and resize the source volume while the snapshot is being created, you get an error.\n\n Why it\u2019s happening \n\nWhile the snapshot is in a pending state, a volume resize error displays with the message \"The resize validation failed.\" The correct message says, \"volume is locked.\"\n\n How to fix it \n\nWait until the snapshot is created and it is in an available state before you resize the source volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-block-storage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4752-6201","score":19.331253,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":18.465042,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":16.638859,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_02294-6247-7862","score":13.282742,"text":"\n[Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg)> Profile > Login settings. The user must set up the security questions and answers before an account owner or administrator can enable this setting on the User details page. Users with access to manage their own login settings by having the User-managed login setting that is turned on from their User details page can turn on and off this MFA setting.\n\nExternal authentication\n: Symantec is the only external, third-party authentication option that can be ordered for a monthly cost. An account owner or administrator must order this option for a user and enable it to be used from the User details page for the user. For Symantec, the administrator must work with the user to get that user's credential ID to complete the order. Users with access to manage their own login settings by having the User-managed login setting that is turned on from their User details page can turn on and off this MFA setting.\n\nPassword expiration\n: The password expiration is set to never by default. When you sign up for an account, you're never required to change your password. When you set a password expiration period, you're notified of your password expiration by email 14 days before, 7 days before, and the day the password is set to expire. This option is available only to users that log in with a SoftLayer ID. To update your password expiration, you must be an account owner or have the User-managed login setting that is turned on by your account administrator on your IAM User details page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-types"},{"document_id":"ibmcld_02363-8216-9547","score":12.94395,"text":"\nAn administrator sets an expiration timeout for sessions action:iam-identity.accountsettings.update AND requestData.request_body.old_session_expiration_in_seconds:NOT_SET AND requestData.request_body.new_session_invalidation_in_seconds:<SECONDS> \n An administrator sets the default expiration timeout for sessions action:iam-identity.accountsettings.update AND requestData.request_body.old_session_invalidation_in_seconds:<SECONDS> AND requestData.request_body.new_session_invalidation_in_seconds:NOT_SET \n An administrator restricts user list visibility in the account action:iam-identity.accountsettings.update AND requestData.team_directory_enabled:true \n An administrator allows users to see the list of users in the account action:iam-identity.accountsettings.update AND requestData.team_directory_enabled:false \n An administrator restricts access to resources in the account action:iam-identity.accountsettings.update AND requestData.public_access_enabled:true \n An administrator allows public access to resources in the account action:iam-identity.accountsettings.update AND requestData.public_access_enabled:false \n An administrator changes the MFA setting in the account. Valid MFA setting values are: NONE, TOTP, TOTP4ALL, LEVEL1, LEVEL2, LEVEL3 action:iam-identity.accountsettings.update AND new_mfa_traits:<MFA_SETTING>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-alerts_configuration"},{"document_id":"ibmcld_10601-1472-2161","score":12.893956,"text":"\n: Let's Encrypt refused to generate a new certificate for this domain. This usually happens when the cluster is deleted and recreated with the same name, or the ibmcloud oc nlb-dns secret regenerate command was invoked multiple times. The rate limit will expire after 7 days (there is no way to manually remove it). Certificate generation will be automatically attempted again after 7 days.\n3. Wait 10-15 minutes, then check if the warning is resolved.\n4. If the issue persists, contact support. Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-ingress-errdsiss"},{"document_id":"ibmcld_07456-3293-5378","score":12.881413,"text":"\n(Current fees for post-expiration renewal can be found here: [https:\/\/www.ibm.com\/cloud\/dns](https:\/\/www.ibm.com\/cloud\/dns)). If You signed up for any other services in conjunction with Your domain registration, these services may be automatically renewed when Your domain registration is renewed, and You may incur additional renewal fees unless You cancel in advance. IBM Cloud sends domain renewal reminders via email to the registered owner contact in accordance with the ICANN Expired Registration Recovery Policy. The notices are sent as follows:\n\n\n\n* IBM Cloud will send a first renewal reminder notice approximately 30 days before the domain registration expires, and a second notice approximately 1 week before expiration. Both of those notices will be sent to the email address on file for the owner of the domain registration.\n* IBM Cloud will send ONE more renewal reminder notice by email to the owner of the domain registration 3 days after expiration.\n\n\n\nIf You fail to renew Your domain name, You agree that IBM Cloud may choose to renew it on Your behalf, in which case You will have a grace period during which You may reimburse IBM Cloud for the renewal and keep Your domain name. The renewal grace period is currently 30 days but is subject to change under the terms of Section 2 of this Agreement.\n\nIf You do not reimburse IBM Cloud for the renewal during the renewal grace period, Your domain name will be placed on hold and flagged for deletion after which You will have a 30-day period during which You may pay IBM Cloud a redemption fee and redeem Your domain name. The current redemption fee, which is subject to change, can be found at [https:\/\/www.ibm.com\/cloud\/dns](https:\/\/www.ibm.com\/cloud\/dns). If You do not redeem Your domain name prior to the end of the redemption grace period IBM Cloud may, at its sole discretion, delete Your domain name or transfer it to another registrant on Your behalf.\n\n\n\n\n\n Term of Agreement; Modifications \n\nThis Agreement continues in full force and effect as long as You have any domain name registered through IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-domain-registration-agreement"},{"document_id":"ibmcld_08211-1158-3123","score":12.807136,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_05007-3201-4787","score":12.087105,"text":"\nThis could be a specific date in the future, or a period of time after new objects are written.\n\n\n\n\n\n NoncurrentVersionExpiration \n\nThe number of days after which non-current versions of objects are automatically deleted.\n\n\n\n\n\n Prefix \n\nAn optional string that will be matched to the prefix of the object name in the bucket. A rule with a prefix will only apply to the objects that match. You can use multiple rules for different expiration actions for different prefixes within the same bucket. For example, within the same lifecycle configuration, one rule could delete all objects that begin with logs\/ after 30 days, and a second rule could delete objects that begin with video\/ after 365 days.\n\n\n\n\n\n Status \n\nA rule can either be enabled or disabled. A rule is active only when enabled.\n\n\n\n\n\n\n\n Sample lifecycle configurations \n\nThis configuration expires any new objects after 30 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-after-30-days<\/ID>\n<Filter \/>\n<Status>Enabled<\/Status>\n<Expiration>\n<Days>30<\/Days>\n<\/Expiration>\n<\/Rule>\n<\/LifecycleConfiguration>\n\nThis configuration deletes any objects with the prefix foo\/ on June 1, 2020.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>delete-on-a-date<\/ID>\n<Filter>\n<Prefix>foo\/<\/Prefix>\n<\/Filter>\n<Status>Enabled<\/Status>\n<Expiration>\n<Date>2020-06-01T00:00:00.000Z<\/Date>\n<\/Expiration>\n<\/Rule>\n<\/LifecycleConfiguration>\n\nThis configuration expires any non-current versions of objects after 100 days.\n\n<LifecycleConfiguration>\n<Rule>\n<ID>DeleteAfterBecomingNonCurrent<\/ID>\n<Filter\/>\n<Status>Enabled<\/Status>\n<NoncurrentVersionExpiration>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry"},{"document_id":"ibmcld_08435-1255-3053","score":12.01569,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.8318724637}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":26.270914,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":20.287146,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08217-1687-3909","score":15.934489,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_00688-3697-4314","score":15.870615,"text":"\nresource-controller.instance.retrieve View a Continuous Delivery service instance in a resource group. Administrator, Editor, Operator, Viewer \n continuous-delivery.instance.add-auth-users Add entries to the Authorized Users list on the Manage tab within the Continuous Delivery service instance. Administrator, Writer, Manager \n continuous-delivery.instance.remove-auth-users Remove entries from the Authorized Users list on the Manage tab within the Continuous Delivery service instance. Administrator, Writer, Manager \n continuous-delivery.instance.config-auth-users Reserved for future use. Administrator, Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-iam-security"},{"document_id":"ibmcld_12570-2467-4288","score":15.25497,"text":"\nibmcloud catalog entry-visibility ID [--global]\n\n\n\n Command options \n\n--global\n: Operate in global scope\n\n\n\n\n\n Examples \n\nGet visibility of resource j402-dnf1i in global scope:\n\nibmcloud catalog entry-visibility 'j402-dnf1i' --global\n\n\n\n\n\n\n\n ibmcloud catalog entry-visibility-set \n\nUpdate the visibility of an existing catalog entry(catalog admin of an account only):\n\nibmcloud catalog entry-visibility-set ID [--includes-add LIST] [--includes-remove LIST] [--excludes-add LIST] [--excludes-remove LIST] [--owner ID or Email] [--restrict] [--unrestrict] [-c PARAMETERS_AS_JSON] [--global]\n\n\n\n Command options \n\n--includes-add\n: Adding an account (or list of comma-separated accounts) to the includes list, granting visibility to the entry. Email or Account GUIDs are acceptable.\n\n--includes-remove\n: Removing an account (or list of comma-separated accounts) from the includes list, revoking visibility to the entry. Email or Account GUIDs are acceptable.\n\n--excludes-add\n: Adding an account (or list of comma-separated accounts) to the excludes list. Email or Account GUIDs are acceptable.\n\n--excludes-remove\n: Removing an account (or list of comma-separated accounts) from the excludes list, revoking visibility to the entry. If the account was set by global admins, the account admins can't remove the account. Email or Account GUIDs are acceptable.\n\n--owner\n: Changing the owner of an object. Email or Account GUIDs are acceptable.\n\n--restrict\n: Changing the restriction of the visibility object to 'Private'.\n\n--unrestrict\n: Changing the restriction of the visibility object to 'Public'.\n\n-c\n: Valid JSON object that contains catalog-specific configuration parameters, provided either inline or in a file. For a list of supported configuration parameters, see documentation for the particular catalog entry.\n\n--global","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_catalog"},{"document_id":"ibmcld_09087-65885-67524","score":15.060459,"text":"\nUsing the CLI, create an import token, allow it to expire, then attempt to retrieve it.\n\n create an import token that expires in 5 minutes (300 seconds) and allows 2 retrievals\n$ ibmcloud kp import-token create -e 300 -m 2\n\nCreated Expires Max Retrievals Remaining Retrievals\n2020-08-18 19:39:06 +0000 UTC 2020-08-18 19:44:06 +0000 UTC 2 2\n\n sleep 300 seconds, which allows the import token to expire\n$ sleep 300\n\n show the import token\n$ ibmcloud kp import-token show\n\nFAILED\nkp.Error:\ncorrelation_id='fb677c6e-9bfa-422e-a14b-0e221bbad32b',\nmsg='Conflict:\nImport Token could not be retrieved.\nPlease see reasons for more details.',\nreasons='[IMPORT_TOKEN_EXPIRED_ERR:\nThe import token has expired. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\nShow more\n\n\n\n\n\n\n\n\n\n 24 - The key cannot be deleted because it's... \n\n\n\n Message \n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy: Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key\n\nReason code: PREV_KEY_DEL_ERR\n\n\n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict response status code indicates a request conflict with current state of the server.\n\nConflicts are most likely to occur in response to a PUT request. For example, you may get a 409 response when uploading a file which is older than the one already on the server resulting in a version control conflict.\n\n\n\n\n\n Context \n\nThis error occurs when a key, used for \"Registrations\", is deleted.\n\nIn most cases, a key with registrations can be deleted using the --force option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_00589-15623-17497","score":14.089437,"text":"\nEnsure that the IBM Cloudant instance has IAM authentication that is enabled. If the instance is deployed in a Cloud Foundry org and space, migrate it to a Resource Group by using the [Resource Groups FAQ](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-ibm-cloud-resource-groups).\n2. Update your application to use IAM authentication instead of IBM Cloudant legacy authentication.\n3. Generate [new service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) as needed.\n4. Open a new IBM Cloud support case that requests the removal of IBM Cloudant legacy credentials for your instance. Include the username of the instance as shown in the service credentials. For more information, see [Locating your service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-locating-your-service-credentials).\n5. After support replies that the legacy credentials were removed, any service credentials that were created before removal contain legacy username and password details that no longer work. It is recommended to remove any of these service credential entries.\n\n\n\n\n\n\n\n Making requests to instances by using IAM credentials \n\nNow, the following section describes how to use IBM Cloudant with service instances through IAM authentication. It uses the details from the [Service credential JSON examples for each option](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantservice-credential-json-examples-for-each-option-ai).\n\nIBM Cloud IAM requires that an IAM API key is exchanged for a time-limited access token before you make a request to a resource or service. The access token is then included in the Authorization HTTP header to the service. When the access token expires, the consuming application must handle getting a new one from the IAM token service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_02263-4-1911","score":14.007561,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Removing trusted profiles \n\nWhen you remove trusted profiles, compute resources and federated users are unlinked from the profile and can no longer apply the trusted profile identity.\n\nTo remove trusted profiles, you must be assigned the administrator or operator role within the account, or on the IAM Identity Service.\n\nWhen you remove trusted profiles, you revoke all active sessions. Users are immediately logged out and the removed profiles are no longer available to connect to the target account. API calls that use access tokens might be successful until the access token expires.\n\n\n\n Removing trusted profiles in the console \n\n\n\n1. To see the full list of trusted profiles in your account, go to Manage > Access (IAM) in the IBM Cloud console, and select Trusted profiles.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) next to the trusted profile you want to remove, and select Remove.\n\n\n\n\n\n\n\n Removing trusted profiles by using the CLI \n\nYou can remove a trusted profile from your account by using the CLI. For more information, see the [IBM Cloud CLI](https:\/\/github.com\/IBM-Cloud\/ibm-cloud-cli-release\/releases).\n\n\n\n1. Log in, and select the account.\n\nibmcloud login\n2. Check the list of trusted profiles for the current account and select the one that you want to remove. The following command shows the list of trusted profiles for your IBM Cloud account:\n\nibmcloud iam trusted-profiles\n3. Remove the trusted profile from your account by running the following command. Specify the ID or the name of the trusted profile that you would like to remove.\n\nibmcloud iam trusted-profile-delete <IDorName>\n\n\n\nFor example, the following command removes a trusted profile that is named Test trusted profile.\n\nibmcloud iam trusted-profile-delete <Test trusted profile>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-trusted-profile-remove"},{"document_id":"ibmcld_12602-4-1895","score":13.977808,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Removing trusted profiles \n\nWhen you remove trusted profiles, compute resources and federated users are unlinked from the profile and can no longer apply the trusted profile identity.\n\nTo remove trusted profiles, you must be assigned the administrator or operator role within the account, or on the IAM Identity Service.\n\nWhen you remove trusted profiles, you revoke all active sessions. Users are immediately logged out and the removed profiles are no longer available to connect to the target account. API calls that use access tokens might be successful until the access token expires.\n\n\n\n Removing trusted profiles in the console \n\n\n\n1. To see the full list of trusted profiles in your account, go to Manage > Access (IAM) in the IBM Cloud console, and select Trusted profiles.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/includes\/account\/includes\/icons\/action-menu-icon.svg) next to the trusted profile you want to remove, and select Remove.\n\n\n\n\n\n\n\n Removing trusted profiles by using the CLI \n\nYou can remove a trusted profile from your account by using the CLI. For more information, see the [IBM Cloud CLI](https:\/\/github.com\/IBM-Cloud\/ibm-cloud-cli-release\/releases).\n\n\n\n1. Log in, and select the account.\n\nibmcloud login\n2. Check the list of trusted profiles for the current account and select the one that you want to remove. The following command shows the list of trusted profiles for your IBM Cloud account:\n\nibmcloud iam trusted-profiles\n3. Remove the trusted profile from your account by running the following command. Specify the ID or the name of the trusted profile that you would like to remove.\n\nibmcloud iam trusted-profile-delete <IDorName>\n\n\n\nFor example, the following command removes a trusted profile that is named Test trusted profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-trusted-profile-remove"},{"document_id":"ibmcld_14622-7-2169","score":13.931501,"text":"\nDeleting services from vCenter Server instances \n\nYou can delete the services that were provisioned for your VMware vCenter Server\u00ae instances when you no longer need these services.\n\n\n\n Before you delete services from vCenter Server instances \n\n\n\n* Deleting services from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n* You are billed until the end of the IBM Cloud\u00ae infrastructure billing cycle for the deleted services.\n\n\n\n\n\n\n\n Procedure to delete services from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance for which you want to delete services.\n3. Click the Services tab.\n4. On the Services page, locate the service instance that you want to delete, click the vertical overflow menu next to the Status column, and then click Delete service.\n5. In the Remove service window, review the considerations or warnings if there are any and select I Understand. Click Delete.\n\n\n\n\n\n\n\n Results after you delete services from vCenter Server instances \n\nAfter your request to delete a service is accepted, the service status is changed to Removing.\n\nWhen the service deletion is completed successfully, you are notified by email, and the service is deleted from the Services page of the instance.\n\nYou are billed until the end of the IBM Cloud infrastructure billing cycle for the deleted services.\n\n\n\n\n\n Manually removing the DNS entries for specific services \n\nFor specific services, if you installed the service in a VMware Solutions release earlier than V4.0 and you delete that service, you must manually remove the DNS entries.\n\nAfter you delete the service, unused DNS entries remain in Active Directory\u2122. These entries do not cause any problems. However, in the future, they might create conflicts with reverse lookups. It is recommended that you remove the entries as soon as possible.\n\nThe following table shows the services that are affected. The table also shows the pattern for hostnames for various service offerings. The actual hostname might differ from the pattern in various ways.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingservices"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08414-28698-30846","score":20.565414,"text":"\nIf the delete key event has a reason.reasonCodeof 409, the key cannot be deleted because it is possibly protecting one or more cloud resources that have a retention policy. Make a GET request to \/keys\/{id}\/registrations to learn which resources this key is associated with. A registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event might also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see whether a dual authorization policy is associated with your key. If there is a policy set, contact the other authorized user to delete the key.\n\n\n\n\n\n Unable to authenticate while making a request \n\nIf the event has a reason.reasonCode of 401, you might not have the correct authorization to perform Hyper Protect Crypto Services actions in the specified service instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-access).\n\nCheck that you are using a valid token that is associated with an account that is authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a service instance \n\nYou can call GET api\/v2\/keys to list the keys that are available in your service instance. If responseData.totalResources is 0, query for keys in the deleted state by using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information about why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action cannot be completed due to the adopting service's key state conflicting with the key state that Hyper Protect Crypto Services has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events"},{"document_id":"ibmcld_09038-20413-22510","score":20.497105,"text":"\nA registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event could also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see if there is a dual authorization policy associated with your key. If there is a policy set, contact the other authorized user to schedule the key for deletion.\n\n\n\n\n\n Unable to authenticate while make a request \n\nIf the event has a reason.reasonCode of 401, you do not have the correct authorization to perform Key Protect actions in the specified Key Protect instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access).\n\nCheck that you are using a valid token that is associated with an account authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a Key Protect instance \n\nIf you make a call to GET api\/v2\/keys to list the keys that are available in your Key Protect instance and responseData.totalResources is 0, you may need to query for keys in the deleted state using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information on why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action could not be completed due to the adopting service's key state conflicting with the key state that Key Protect has.\n\nIf the event has a reason.reasonCode of 408, the action could not be completed because Key Protect was not notified that all appropriate actions were taken within 4 hours of the action request.\n\n\n\n\n\n\n\n Event Severity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events"},{"document_id":"ibmcld_09192-4150-5583","score":18.898455,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_09088-1516-3484","score":18.487371,"text":"\nNo user has access to the WIKEK or the IKEK, and even IBM does not have access to the IKEK. There is no direct or explicit access to the WIKEK by IBM, and it is encrypted by the master key.\n\n\n\n\n\n What is an active encryption key? \n\nWhen you import encryption keys into Key Protect, or when you use Key Protect to generate keys from its HSMs, those keys become Active keys. Pricing is based on all active keys within an IBM Cloud account.\n\n\n\n\n\n How should I group and manage my keys? \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to create a group of keys for a target group of users that require the same IAM access permissions by bundling your keys in your Key Protect service instance into groups called \"key rings\". A key ring is a collection of keys, within your service instance, that all require the same IAM access permissions. For example, if you have a group of team members who will need a particular type of access to a specific group of keys, you can create a key ring for those keys and assign the appropriate IAM access policy to the target user group. The users that are assigned access to the key ring can create and manage the resources that exist within the key ring.\n\nTo find out more about grouping keys, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n\n\n\n\n\n I am trying to delete an instance am getting a 409 error. How can I delete my instance? \n\nThis error indicates that keys are still in this instance. Before you can delete an instance, you must delete every key in that instance.\n\nBecause the Keys table in the console shows only Enabled keys by default, use the filters to show keys in all states. This can reveal keys that must be deleted to delete the instance which are not being displayed in the table.\n\nAfter all keys have been deleted, you can proceed with deletion of the instance.\n\n\n\n\n\n What is a root key? \n\nRoot keys are primary resources in Key Protect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_05001-10721-11815","score":17.977543,"text":"\n)\n\ndef get_bucket_contents(bucket_name, max_keys):\nprint(\"Retrieving bucket contents from: {0}\".format(bucket_name))\nreturnArray = []\ntry:\nfiles = cos.Bucket(bucket_name).objects.all()\nfor file in files:\nprint(\"Item: {0} ({1} bytes).\".format(file[\"Key\"], file[\"Size\"]))\nreturnArray.append(file[\"Key\"])\n\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to retrieve bucket contents: {0}\".format(e))\n\nreturn returnArray\n\ndef delete_item(bucket_name, item_name):\nprint(\"Deleting item: {0}\".format(item_name))\ntry:\ncos.Object(bucket_name, item_name).delete()\nprint(\"Item: {0} deleted!\".format(item_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to delete item: {0}\".format(e))\n\ndef main():\nbucket = \"<bucket_name>\"\ndeleteListArray = get_bucket_contents(bucket, 1000)\nfor item_name in deleteListArray:\ndelete_item(bucket, item_name)\n\nmain()\n\nimport (\n\"github.com\/IBM\/ibm-cos-sdk-go\/aws\/credentials\/ibmiam\"\n\"github.com\/IBM\/ibm-cos-sdk-go\/aws\"\n\"github.com\/IBM\/ibm-cos-sdk-go\/aws\/session\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-deleting-multiple-objects-patterns"},{"document_id":"ibmcld_05088-11823-12917","score":17.788492,"text":"\n{ \"Key\": \"deletetest\/testfile2.txt\" },\n{ \"Key\": \"deletetest\/testfile3.txt\" },\n{ \"Key\": \"deletetest\/testfile4.txt\" },\n{ \"Key\": \"deletetest\/testfile5.txt\" }\n]\n}\n\nresponse = cos.delete_objects(\nBucket=bucket_name,\nDelete=delete_request\n)\n\nprint(\"Deleted items for {0}n\".format(bucket_name))\nprint(json.dumps(response.get(\"Deleted\"), indent=4))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to copy item: {0}\".format(e))\nShow more\n\nSDK References\n\n\n\n* Classes\n\n\n\n* [S3.Client](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlclient)\n\n\n\n* Methods\n\n\n\n* [delete_objects](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlS3.Client.delete_objects)\n\n\n\n\n\n\n\n\n\n Delete a bucket \n\ndef delete_bucket(bucket_name):\nprint(\"Deleting bucket: {0}\".format(bucket_name))\ntry:\ncos.Bucket(bucket_name).delete()\nprint(\"Bucket: {0} deleted!\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to delete bucket: {0}\".format(e))\n\nSDK References\n\n\n\n* Classes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_05088-10756-12033","score":17.307867,"text":"\n* [get](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlS3.Object.get)\n\n\n\n\n\n\n\n\n\n Delete an item from a bucket \n\ndef delete_item(bucket_name, object_name):\ntry:\ncos.delete_object(Bucket=bucket_name, Key=object_name)\nprint(\"Item: {0} deleted!n\".format(object_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to delete object: {0}\".format(e))\n\nSDK References\n\n\n\n* Classes\n\n\n\n* [Object](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlobject)\n\n\n\n* Methods\n\n\n\n* [delete](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlS3.Object.delete)\n\n\n\n\n\n\n\n\n\n Delete multiple items from a bucket \n\nThe delete request can contain a maximum of 1000 keys that you want to delete. While this is useful in reducing the per-request performance hit, be mindful when deleting many keys. Also, take into account the sizes of the objects to ensure suitable performance.\n\ndef delete_items(bucket_name):\ntry:\ndelete_request = {\n\"Objects\": [\n{ \"Key\": \"deletetest\/testfile1.txt\" },\n{ \"Key\": \"deletetest\/testfile2.txt\" },\n{ \"Key\": \"deletetest\/testfile3.txt\" },\n{ \"Key\": \"deletetest\/testfile4.txt\" },\n{ \"Key\": \"deletetest\/testfile5.txt\" }\n]\n}\n\nresponse = cos.delete_objects(\nBucket=bucket_name,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_09192-2760-4563","score":17.14723,"text":"\nIf the instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to view or list specific keys \n\nWhen you call the Key Protect API, you're unable to list specific keys that you have access to.\n\n What\u2019s happening \n\nYou call GET api\/v2\/keys to list the keys that are available in your service instance.\n\nYou can see a list of keys, but you can't find a specific key that's stored in the instance. You verify with your administrator that you're assigned the applicable [level of access to the keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keys) that you're unable to view. You also verify with your admin that the key belongs to the Key Protect instance that you're targeting.\n\n Why it\u2019s happening \n\nThe Key Protect instance contains a large number of keys, and the specific keys that you're looking for aren't returned by default when you call GET api\/v2\/keys to list keys.\n\n How to fix it \n\nCheck with an admin to understand the total number of keys that are stored in the instance. By default, GET api\/v2\/keys returns the first 200 keys. If the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"},{"document_id":"ibmcld_08671-118434-119667","score":16.91977,"text":"\n(https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-create-keystroubleshoot-unable-to-create-keys)\n\n[Why can't I delete an initialized service instance?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-instancetroubleshoot-delete-instance)\n\n[Why can't I delete keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keystroubleshoot-unable-to-delete-keys)\n\n[Why can't I perform any actions by using the IBM Cloud console?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-ui-session-timeouttroubleshoot-ui-session-timeout)\n\n[Why can't I rotate root keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-rotate-root-keystroubleshoot-unable-to-rotate-root-keys)\n\n[Why can't I view or list keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-keys-apitroubleshoot-unable-to-list-keys-api)\n\n[Why can't I view or list specific keys?](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-list-specific-keystroubleshoot-unable-to-list-specific-keys)\n\n\n\n\n\n Troubleshooting master key rotation \n\n[Why can't I rotate master keys by using key part files?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-sitemap"},{"document_id":"ibmcld_07578-1202060-1204107","score":16.90688,"text":"\nEach Key Protect instance gets a randomly-generated \"instance key-encrypted-key\" (IKEK) which is wrapped by the HSM master key, producing a wrapped instance key (WIKEK). No user has access to the WIKEK or the IKEK, and even IBM does not have access to the IKEK. There is no direct or explicit access to the WIKEK by IBM, and it is encrypted by the master key.\n* What is an active encryption key?\n\nWhen you import encryption keys into Key Protect, or when you use Key Protect to generate keys from its HSMs, those keys become Active keys. Pricing is based on all active keys within an IBM Cloud account.\n* How should I group and manage my keys?\n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to create a group of keys for a target group of users that require the same IAM access permissions by bundling your keys in your Key Protect service instance into groups called \"key rings\". A key ring is a collection of keys, within your service instance, that all require the same IAM access permissions. For example, if you have a group of team members who will need a particular type of access to a specific group of keys, you can create a key ring for those keys and assign the appropriate IAM access policy to the target user group. The users that are assigned access to the key ring can create and manage the resources that exist within the key ring.\n\nTo find out more about grouping keys, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n* I am trying to delete an instance am getting a 409 error. How can I delete my instance?\n\nThis error indicates that keys are still in this instance. Before you can delete an instance, you must delete every key in that instance.\n\nBecause the Keys table in the console shows only Enabled keys by default, use the filters to show keys in all states. This can reveal keys that must be deleted to delete the instance which are not being displayed in the table.\n\nAfter all keys have been deleted, you can proceed with deletion of the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09064-8216-9792","score":23.94773,"text":"\n\"algorithmMode\": \"Deprecated\",\n\"lastUpdateDate\": \"2020-03-16T20:41:27Z\",\n\"dualAuthDelete\": {\n\"enabled\": false\n},\n\"deleted\": true,\n\"deletionDate\": \"2020-03-16T21:46:53Z\",\n\"deletedBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the available parameters, see the Key Protect [REST API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).\n\n\n\n Using the force query parameter \n\nKey Protect blocks the deletion of a key that's protecting a cloud resource, such as a Cloud Object Storage bucket. You can force delete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\n\nWhen you delete a key that has registrations associated with it, you immediately deactivate its key material and the data encrypted by the key. Any data that is encrypted by the key becomes inaccessible. Thirty days after a key is deleted, the key can no longer be restored and the key material will be destroyed after 90 days.\n\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_01019-1608-2449","score":23.702724,"text":"\nIf you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables. The physical pages that contain the data are not immediately erased and might still exist on the disk, but will be overwritten as needed. There is no ability to recover this data. The database provides the REORG and REDUCE MAX capability to reclaim this space for other activities or it will be reused when the database needs to store more data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_09064-9212-10938","score":22.563723,"text":"\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each registered IBM Cloud resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys\/ request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to force delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete keys with the Key Protect API.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_09087-30097-31549","score":21.929865,"text":"\nYou must use the force option to delete a root key that is registered with another cloud resource.\n\nRegistrations are associations between root keys and other cloud resources, such as Cloud Object Storage (COS) buckets or Cloud Databases deployments.\n\nFor more information about Registrations, see [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\n[See this explanation](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-delete) of deleting keys that are registered with another cloud resource (look at the force option).\n\n this CLI request fails because the registration was not deleted\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: 52a9d772-8982-4620-bfb4-b070dd812a0c, from instance: b0d84b32-09d0-4314-8049-da78e3b9ab6f...\nFAILED\nkp.Error:\ncorrelation_id='c27b7948-4a1f-4cbd-8770-cb3616888e27',\nmsg='Conflict:\nKey could not be deleted.\nPlease see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR:\nKey is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n this CLI request succeeds when using the --force option\n the registration between Key Protect and the cloud resource exists\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID --force --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_07578-1211120-1213024","score":21.92662,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":21.92662,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09088-9397-11338","score":21.849854,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_01019-7-2103","score":21.38652,"text":"\nDeleting a database \n\nWhen a service instance is deleted, the database that it provides is also removed. This will delete any online data and logs as well as database backups. The data will not be recoverable after this action.\n\n\n\n How is the data deleted \n\nAll data is encrypted at rest to ensure data is protected at all times using encryption keys stored in a key management service called Key Protect. When access to those keys is removed, the data is crypto-shredded and cannot be recovered. When the service instance is deleted, the block storage that is used for the database is wiped to ensure that all of the data is erased. Any data objects in cloud object storage are also deleted and not recoverable.\n\n\n\n\n\n When is the data deleted \n\n\n\n\n\n Using your own encryption keys to delete data \n\nYou can use your own encryption keys to delete data. This is called crypto-shredding. After the key is deleted, your data is unrecoverable and unreadable by anyone.\n\nKey Protect allows you to initiate a force delete of a key that is in use by various IBM Cloud\u00ae services, including your Db2 on Cloud service instances. Deleting a key that is in use on your deployment locks the disks containing your data when the key is requested again. You can have this occur right away by contacting IBM Support or by deleting your service instance. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete.\n\nIf you delete a deployment that is protected with your Key Protect key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_16727-1212381-1214315","score":21.362282,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":21.362282,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.570641719,"ndcg_cut_10":0.570641719}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01034-3831-4923","score":17.537132,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_06443-2410-3623","score":17.1643,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":17.1643,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":17.1643,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":17.1643,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":17.1643,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":16.764404,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06564-2541-3625","score":16.764404,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":16.764404,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_01041-3464-4855","score":16.070107,"text":"\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"}],"retriever_scores":{"recall_1":0.1666666667,"recall_3":0.3333333333,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.6548086578,"ndcg_cut_10":0.878569377}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06443-2410-3623","score":22.86971,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":22.86971,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":22.86971,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":22.86971,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":22.86971,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":22.03811,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06564-2541-3625","score":22.03811,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":22.03811,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06638-4935-6851","score":21.979567,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_09562-4925-6841","score":21.979567,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4752-6201","score":25.434074,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":25.346832,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":25.077326,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-7530-9143","score":23.622044,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":20.41739,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":19.508522,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09088-9397-11338","score":19.279436,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_08435-6973-8664","score":18.875315,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-12083-13778","score":18.35769,"text":"\nFor more information about deleting and purging keys, check out [About deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys).\n\nThe following table lists which APIs you can use to retrieve data related to a deleted key.\n\n\n\nTable 4. Lists the API that users can use to view details about a key and its registrations.\n\n API Description \n\n [Get key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key) Retrieve key details \n [Get key metadata](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key-metadata) Retrieve key metadata \n [Get registrations](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) Retrieve a list of registrations associated with the key \n\n\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the seven-day authorization period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Key Protect service actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08211-1158-3123","score":17.081161,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":25.91715,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10214-3003-4898","score":24.07757,"text":"\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system. With the [IBM Cloud Kubernetes Service version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionscs_versions), you get access to community Kubernetes API features that are considered beta or higher by the community. Kubernetes alpha features, which are subject to change, are generally not enabled by default. With Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\n\n\n\n\n Does the service come with a managed Red Hat OpenShift master and worker nodes? \n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_07578-396975-399135","score":23.193298,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-396949-399109","score":23.193298,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10489-7-1763","score":22.97704,"text":"\nSetting up the Red Hat Marketplace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nWith [Red Hat\u00ae Marketplace](https:\/\/marketplace.redhat.com\/en-us), you can deploy certified Red Hat software from an operator-based catalog to your OpenShift Container Platform clusters, including Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nRequired permissions:\n\n\n\n* The IAM Operator platform access role for the cluster in Kubernetes Service.\n* The IAM Manager service access role in all namespaces (cluster-admin RBAC) for the cluster in Kubernetes Service.\n\n\n\nRed Hat Marketplace is available for clusters that run Red Hat OpenShift version 4 only.\n\nBefore you begin:\n\n\n\n* Register for a [Red Hat Marketplace account](https:\/\/marketplace.redhat.com\/en-us\/registration\/redhat-marketplace).\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that the Operator Lifecycle Manager (OLM) pods in the openshift-operator-lifecycle-manager project and marketplace pods in the openshift-marketplace project are ready and running. You might have to restart a pod to return the pod to a healthy state.\n\noc get pods -n openshift-operator-lifecycle-manager\n\noc get pods -n openshift-marketplace\n\n\n\nTo set up your cluster with Red Hat Marketplace:\n\n\n\n1. Follow the [Red Hat Marketplace instructions](https:\/\/marketplace.redhat.com\/en-us\/workspace\/clusters\/add\/register) to create a namespace, operator, and global pull secret for the Red Hat Marketplace.\n2. Verify that the global pull secret for the cluster is updated with the registry.marketplace.redhat.com secret.\n\noc get secret pull-secret -n openshift-config --output=\"jsonpath={.data..dockerconfigjson}\" | base64 --decode | grep \"marketplace\" -A4\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rh-marketplace"},{"document_id":"ibmcld_10228-4-1670","score":22.886984,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started"},{"document_id":"ibmcld_10229-4-1670","score":22.886984,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started&interface=ui"},{"document_id":"ibmcld_14492-7-1792","score":22.629639,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10702-7-1940","score":22.598295,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_14501-7-1869","score":21.988756,"text":"\nPrerequisites for installation \n\nBefore you can start the build process to install the Red Hat\u00ae OpenShift\u00ae cluster, the following steps are required.\n\n\n\n* Order new subnets for the Red Hat OpenShift environment.\n\n\n\n* A private portable subnet for the Red Hat OpenShift cluster NSX ESG.\n* A public portable subnet for the Red Hat OpenShift cluster NSX ESG.\n\n\n\n* Download Red Hat OpenShift 4.7 - Access to a Red Hat\u00ae subscription to download the installer, pull secret and Red Hat Enterprise CoreOS OVA.\n* Download RHEL 8.0 ISO - Access to a Red Hat subscription to download the Red Hat Enterprise Linux\u00ae 8.x ISO for the bastion host.\n* IBM Cloud\u00ae environment details - Collect the following details for IBM Cloud for VMware\u00ae Solutions environment.\n\n\n\n* VMware vCenter Server\u00ae instance details and passwords\n* The additional private portable subnet information\n* The additional public portable subnet information\n\n\n\n* Download and install govc - govc is a VMware vSphere\u00ae CLI, an alternative to the GUI, and suited for automation tasks.\n\n\n\n\n\n Ordering new subnets for the Red Hat OpenShift environment \n\n\n\n1. Log in to the [IBM Cloud for VMware Solutions console](https:\/\/cloud.ibm.com\/vmware).\n2. Select Classic Infrastructure>Network>IP management>Subnets.\n3. Click Order IP Subnets.\n\n\n\nReview the following requirements.\n\n\n\n* 8 Public portable addresses assigned to the Public VLAN collected in the previous step.\n* 64 Private portable addresses assigned to the Private VLAN collected in the previous step.\n\n\n\n\n\n\n\n Downloading Red Hat OpenShift 4.7 \n\nAccess the [Red Hat OpenShift Infrastructure Providers page](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned).\n\n\n\n1. Download the installer.\n2. Download the Pull Secret.\n3. Download the Red Hat Enterprise Linux CoreOS (RHEL CoreOS) OVA image or download the OVA by using the following code.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-prereq-intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":30.851904,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10170-10609-12793","score":28.595621,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10170-12206-14575","score":28.018148,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10531-7-2246","score":26.857662,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10214-1438-3413","score":26.74518,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10170-14072-16125","score":26.097603,"text":"\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization \n\nWatson Assistant provides tools to quickly scaffold a chatbot that can provide the correct benefits information to users.\n\n\n\n\n\n Step 4: Deliver continuously across the globe \n\n\n\n* IBM Cloud\u00ae Continuous Delivery helps Developers to quickly provision an integrated toolchain, by using customizable, shareable templates with tools from IBM, third parties, and open source. Automate builds and tests, controlling quality with analytics.\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI\/CD toolchains to deploy apps into Production clusters across the globe.\n* Red Hat OpenShift on IBM Cloud provides easy rollout and roll-back of apps. Tailored apps are deployed to meet regional requirements through the intelligent routing and load balancing of Istio.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* With tools like the chatbot, the HR team proved to their workforce that innovation was part of the corporate culture, not just buzz words.\n* Authenticity with personalization in the site addressed the changing expectations of the airline\u2019s workforce today.\n* Last-minute updates to the HR site, including ones that driven by the employees chatbot conversations, went live quickly because Developers were pushing changes at least 10 times daily.\n* With infrastructure management taken care of by IBM, the Development team was freed up to deliver the site in only 3 weeks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_04815-7-2142","score":25.878193,"text":"\nDeployment Journey Overview \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nWelcome to the Deployment Journey for Cloud Native on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/b7b9235ce6abd45b66931867c388cf107d38e15b\/cloud-native-journey\/roks-on-vpc\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACLs rules, etc.).\n* When you create your cluster, you must choose a VPC networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* Worker-to-worker communication: All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* Worker-to-master and user-to-master communication: Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-native-journey?topic=cloud-native-journey-cloud-native-roks-overview"},{"document_id":"ibmcld_10166-12374-14395","score":25.458223,"text":"\n* Deploy the manifest and shipment apps to container that run in Red Hat OpenShift on IBM Cloud.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Ensure global availability \n\n\n\n* After Developers deploy the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains and Helm to deploy country-specific apps into clusters across the globe.\n* Workloads and data can then meet regional regulations.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n Step 3: Data sharing \n\n\n\n* IBM Cloudant is a modern NoSQL database suitable a range of data-driven use cases from key-value to complex document-oriented data storage and query.\n* To minimize queries to the regional databases, IBM Cloudant is used to cache the user's session data across apps.\n* This configuration improves the front-end app usability and performance across apps on Kubernetes Service.\n* While worker apps in Red Hat OpenShift on IBM Cloud analyze on-premises data and store results in IBM Cloudant, IBM Cloud\u00ae Functions reacts to changes and automatically sanitizes data on the incoming feeds of data.\n* Similarly, notifications of shipments in one region can be triggered through data uploads so that all down-stream consumers can access new data.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequently 10 times per week.\n* Shipping customers and government officials have access to manifest data and can share customs data, while they comply with local regulations.\n* The shipping company benefits from improved logistics management in the supply chain: reduced costs and faster clearance times.\n* 99% are digital declarations, and 90% of imports processed without human intervention.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_gov"},{"document_id":"ibmcld_16727-393979-396124","score":25.200764,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-394005-396150","score":25.200764,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-17039-18368","score":26.498028,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14682-7-2113","score":25.15618,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_11282-0-1290","score":25.080723,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_14497-7-1724","score":24.93174,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_11950-7-2002","score":24.430094,"text":"\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"},{"document_id":"ibmcld_10702-7-1940","score":23.841114,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10489-7-1763","score":23.669584,"text":"\nSetting up the Red Hat Marketplace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nWith [Red Hat\u00ae Marketplace](https:\/\/marketplace.redhat.com\/en-us), you can deploy certified Red Hat software from an operator-based catalog to your OpenShift Container Platform clusters, including Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\nRequired permissions:\n\n\n\n* The IAM Operator platform access role for the cluster in Kubernetes Service.\n* The IAM Manager service access role in all namespaces (cluster-admin RBAC) for the cluster in Kubernetes Service.\n\n\n\nRed Hat Marketplace is available for clusters that run Red Hat OpenShift version 4 only.\n\nBefore you begin:\n\n\n\n* Register for a [Red Hat Marketplace account](https:\/\/marketplace.redhat.com\/en-us\/registration\/redhat-marketplace).\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that the Operator Lifecycle Manager (OLM) pods in the openshift-operator-lifecycle-manager project and marketplace pods in the openshift-marketplace project are ready and running. You might have to restart a pod to return the pod to a healthy state.\n\noc get pods -n openshift-operator-lifecycle-manager\n\noc get pods -n openshift-marketplace\n\n\n\nTo set up your cluster with Red Hat Marketplace:\n\n\n\n1. Follow the [Red Hat Marketplace instructions](https:\/\/marketplace.redhat.com\/en-us\/workspace\/clusters\/add\/register) to create a namespace, operator, and global pull secret for the Red Hat Marketplace.\n2. Verify that the global pull secret for the cluster is updated with the registry.marketplace.redhat.com secret.\n\noc get secret pull-secret -n openshift-config --output=\"jsonpath={.data..dockerconfigjson}\" | base64 --decode | grep \"marketplace\" -A4\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-rh-marketplace"},{"document_id":"ibmcld_14683-7-2001","score":23.575464,"text":"\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"},{"document_id":"ibmcld_10228-4-1670","score":23.419252,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started"},{"document_id":"ibmcld_10229-4-1670","score":23.419252,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11617-8584-10460","score":20.621805,"text":"\n* [SAP Fundamental Library Styles component library](https:\/\/sap.github.io\/fundamental-styles) for UI Frameworks (Angular, React, Vue, and other frameworks)\n* [SAPUI5 Framework](https:\/\/sapui5.hana.ondemand.com) (and upstream project [OpenUI5](https:\/\/openui5.org))\n\n\n\n\n\n\n\n SAP's Software-as-a-Service (SaaS) offerings \n\nIBM Cloud is also available as an option underneath SAP's Software-as-a-Service (SaaS) products.\n\nIBM Cloud offerings for SAP's SaaS by request only:\n\n\n\n* SAP S\/4HANA Cloud SaaS, Extended Edition; using IBM Cloud SAP-certified IaaS (IBM Cloud is a strategic premier partner, requires PMC contract with a services partner)\n\n\n\n\n\n\n\n SAP Partner ecosystem solutions offerings \n\nIBM Cloud provides numerous solutions from SAP's Partner ecosystem. These solutions can reduce SAP implementation project timelines or increase the efficiency of SAP Systems that are running maintenance on IBM Cloud. IBM Cloud works closely with these SAP Partners (who are also IBM Business Partners) to offer their capabilities from the IBM Cloud catalog.\n\nThese solutions from SAP Patners may not apply to all SAP software or all Infrastructure within the IBM Cloud\u00ae for SAP portfolio; please see the individual sections under the SAP Partner certified solutions topic group.\n\nThis table summarises the available SAP Partner solutions:\n\n\n\nTable 1. Overview of SAP Partner solutions\n\n SAP Partner Solution name Solution description \n\n Actifio [Actifio Go for SAP HANA](https:\/\/www.actifio.com\/solutions\/application\/sap) Block-based backups for SAP HANA \n Veeam [Veeam Backup & Replication for SAP HANA](https:\/\/www.veeam.com\/backup-sap-hana-plugin.html) Backint backups from SAP HANA \n F5 [F5 BigIP for SAP NetWeaver](https:\/\/www.f5.com\/partners\/technology-alliances\/sap) Load balancing and traffic management for SAP \n\n\n\n\n\n\n\n Comparing the different SAP-certified IaaS offerings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-overview-sap-offerings"},{"document_id":"ibmcld_14566-1577-4027","score":20.123486,"text":"\nThen, you can access and manage the IBM-hosted environment through the native VMware clients, command-line interface (CLI), existing scripts, or other familiar vSphere API-compatible tools.\n\nPost deployment, you can add to (and remove from) VMware ESXi\u2122 servers for an instance, add and remove clusters, join additional vCenter Server instances to an existing instance, and add products and services by using the VMware Solutions console. It is your responsibility to monitor and manage the vCenter Server instances.\n\nYour responsibility includes backups, patching, configuration, and monitoring of the VMware software and the underlying hypervisor hardware. IBM Cloud for VMware Solutions offers automated solutions to help with the ongoing management and monitoring of the vCenter Server instance.\n\nIn addition, IBM Cloud Professional Services and Managed Services are also available to help accelerate your journey to the cloud with offerings like migration, implementation, and onboarding services.\n\nUnlike a managed service offering, vCenter Server gives you full and complete access to all components that allows for a greater flexibility than what a managed service might offer. However, certain constraints apply to allow the IBM Cloud for VMware Solutions automation to function, post vCenter Server deployment.\n\nThe VMware Solutions offerings bring the following benefits:\n\n\n\n* Accelerating delivery of IT projects for developers and lines of business. The time that it takes for procurement, architecture, implementation, and deployment of resources is reduced from weeks or even months, to hours.\n* Enhancing security with dedicated IBM Cloud bare metal servers in a hosted private cloud, including the encryption of data at rest. For vSAN storage, encryption of data at rest is optional by using either vSAN or vSphere encryption. For shared file\u2013level or block storage, service\u2013provider\u2013managed encryption at rest is available by default in select data centers or it is optional by using vSphere encryption. You must manage the necessary encryption keys.\n* Enabling consistent management and governance of the deployed hybrid cloud by providing full administrative access to virtualization management, thus preserving your existing VMware tools, scripts, and investments in training.\n* Using VMware expertise at global scale with IBM Professional and Managed Services spanning 40+ IBM Cloud data centers worldwide.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview"},{"document_id":"ibmcld_14611-7-1911","score":19.72872,"text":"\nTarget platforms in IBM Cloud \n\nIBM Cloud\u00ae for VMware Solutions has a number of offerings, deployment patterns, and options that can be used to create your target VMware NSX-T\u2122 environment:\n\n\n\n* Automated offerings - These offerings are available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console.\n* Regulated workload offerings - These offerings are available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console, the VMware Regulated Workloads card. They are suitable for clients that require a prescriptive reference architecture that matches the IBM Cloud Framework for Financial Services.\n* Automated offerings with manual customization tasks - These offerings are based on the offering available from the [VMware Solutions](https:\/\/cloud.ibm.com\/vmware) console. They require a number of post-deployment manual tasks to achieve the architectural pattern needed.\n\n\n\nBased on the assessment of your source NSX-V environment, you can identify the requirements for your target platform. After the analysis, do the following steps:\n\n\n\n1. Select the target platform that supports all your requirements from the information on the features that are shown in the following diagrams.\n2. Review [Getting started with VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-getting-started) to learn more about the offerings, deployment patterns, and services.\n\n\n\nA summary and key capabilities of the target VMware Solutions offerings in IBM Cloud is provided with architectural guidance to ease up the selection process.\n\n\n\n Automated offerings \n\nThe offerings are described in detail in the following documents:\n\n\n\n* [vCenter Server as a single site deployment](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverview) - This offering deploys a VMware\u00ae based platform in a single IBM Cloud data center automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-v2t-targets"},{"document_id":"ibmcld_14400-7-2130","score":18.74354,"text":"\nFortinet FortiGate virtual machine (VM) overview \n\nIBM Cloud\u00ae for VMware Solutions offers various solutions to meet your network security requirements. The base offering includes VMware NSX\u2013T\u2122 for integrated virtual networking and security. More network security features are available with the FortiGate\u00ae VM offering, which provides Fortinet\u00ae\u2019s next\u2013generation firewall (NGFW) capabilities in the form of a highly available pair of virtual FortiGate appliances. In addition to the architecture for FortiGate VM, IBM Cloud\u00ae also offers a [FortiGate Security Appliance](https:\/\/cloud.ibm.com\/docs\/fortigate-10g) offering, which provides a perimeter firewall, NAT, and VPN services in the form of a physical appliance.\n\nThe solution is considered to be an extra component and extension of the VMware vCenter Server\u00ae offering on IBM Cloud. As a result, this document doesn\u2019t cover the existing configuration of the foundation solutions on IBM Cloud. For more information about the foundation solution architecture, see [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview).\n\n\n\n Topologies \n\nYou can deploy FortiGate VM according to several different strategies:\n\n\n\n* FortiGate VM can be deployed as part of an ESXi\u2122 gateway cluster that is directly integrated with the IBM Cloud customer routers. It provides firewall and gateway functions for your private and public IBM Cloud network VLANs.\n* FortiGate VM can be deployed to your management and workload cluster. In this form, you can use FortiGate to provide firewall and gateway services between various networks. FortiGate VM provides controlled connectivity between:\n\n\n\n* Public and private networks\n* Private VLANs and NSX logical switches\n* Several VMware NSX\u00ae logical switches\n\n\n\n\n\nAdditionally, FortiGate VM offers direct integration with NSX\u2013T including service chaining and dynamic import of security groups.\n\n\n\n\n\n Key benefits \n\nSeveral licensing option bundles are available for FortiGate VM on IBM Cloud.\n\n\n\n* Standard FW - This bundle includes the following services.\n\n\n\n* Stateful packet inspection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-fortigate-overview"},{"document_id":"ibmcld_14439-7-1822","score":18.2702,"text":"\nInterconnectivity overview \n\nInterconnectivity consists of multiple services and offerings that enable customers to connect from their remote network locations to IBM Cloud\u00ae deployments and between workloads and services that run in IBM Cloud.\n\nIt can be divided into the following categories:\n\n\n\n* Interconnecting with on-premises networks.\n* Interconnecting VPCs and IBM Cloud services.\n\n\n\nThe following diagram shows an overview of the interconnectivity solutions.\n\nZoom\n\n![Interconnectivity solutions with VMware on VPC](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vpc-ryo-diagrams-xcon-vmw-arch.svg)\n\nFigure 1. Interconnectivity solutions with VMware\u00ae on VPC\n\n\n\n Interconnecting VMware workloads with on-premises networks \n\nInterconnecting VMware workloads on VPC with on-premises networks provides the capability to know how to interconnect workloads with on-premises network.\n\nThe solution consists of the following key offerings:\n\n\n\n* IBM Cloud Direct Link offerings provide low-latency, high-throughput connections between IBM Cloud VPC networks directly to a service provider-managed WAN, or a client-managed cloud backbone, or through a supported service provider.\n* IBM Cloud VPN for VPC can securely connect your virtual private cloud to another private network. This service offers two types of VPNs, such as Site-to-site gateways that connect your on-premises network to the IBM Cloud VPC network and Client-to-site servers that allows clients to connect to VPN servers on internet.\n\n\n\nSee the following sections for more detailed overview for these offerings for on-premises connectivity, and architectural considerations when used with VMware workloads on VPC.\n\n\n\n\n\n Interconnecting VMware workloads with VPCs and IBM Cloud services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-interconnectivity-overview"},{"document_id":"ibmcld_15214-23087-24489","score":16.835613,"text":"\nimage=$(ibmcloud is images | grep -i \"debian.available.amd64.public\" | cut -d\" \" -f1)\n\nSave the image ID as a variable, which is used later to provision an instance.\n\n\n\n* Select an image shared from a private catalog for the instance\n\n\n\nTo list all available images, run the following command.\n\nibmcloud is catalog-image-offerings\n\nThis command returns both the offering_crn and the offering_version_crn for the available images. When you create an instance, you can either provision an instance from the private catalog image at the latest version in a catalog product offering by using the offering_crn or from a specific version in the catalog product offering by using the offering_version_crn.\n\nSave the offering_crn and offering_version_crnin variables, which is used later to provision an instance.\n\noffering_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:offering:136559f6-4588-4af2-8585-f3c625eee09d\"\noffering_version_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:version:136559f6-4588-4af2-8585-f3c625eee09d\/8ae92879-e253-4a7c-b09f-8d30af12e518\"\n\n\n\nAfter you know these values, use them to run the instance-template-create command. In addition to the information that you gathered, you must specify a name for the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=cli"},{"document_id":"ibmcld_15206-23073-24475","score":16.835613,"text":"\nimage=$(ibmcloud is images | grep -i \"debian.available.amd64.public\" | cut -d\" \" -f1)\n\nSave the image ID as a variable, which is used later to provision an instance.\n\n\n\n* Select an image shared from a private catalog for the instance\n\n\n\nTo list all available images, run the following command.\n\nibmcloud is catalog-image-offerings\n\nThis command returns both the offering_crn and the offering_version_crn for the available images. When you create an instance, you can either provision an instance from the private catalog image at the latest version in a catalog product offering by using the offering_crn or from a specific version in the catalog product offering by using the offering_version_crn.\n\nSave the offering_crn and offering_version_crnin variables, which is used later to provision an instance.\n\noffering_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:offering:136559f6-4588-4af2-8585-f3c625eee09d\"\noffering_version_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:version:136559f6-4588-4af2-8585-f3c625eee09d\/8ae92879-e253-4a7c-b09f-8d30af12e518\"\n\n\n\nAfter you know these values, use them to run the instance-template-create command. In addition to the information that you gathered, you must specify a name for the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group"},{"document_id":"ibmcld_15215-23086-24488","score":16.835613,"text":"\nimage=$(ibmcloud is images | grep -i \"debian.available.amd64.public\" | cut -d\" \" -f1)\n\nSave the image ID as a variable, which is used later to provision an instance.\n\n\n\n* Select an image shared from a private catalog for the instance\n\n\n\nTo list all available images, run the following command.\n\nibmcloud is catalog-image-offerings\n\nThis command returns both the offering_crn and the offering_version_crn for the available images. When you create an instance, you can either provision an instance from the private catalog image at the latest version in a catalog product offering by using the offering_crn or from a specific version in the catalog product offering by using the offering_version_crn.\n\nSave the offering_crn and offering_version_crnin variables, which is used later to provision an instance.\n\noffering_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:offering:136559f6-4588-4af2-8585-f3c625eee09d\"\noffering_version_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:version:136559f6-4588-4af2-8585-f3c625eee09d\/8ae92879-e253-4a7c-b09f-8d30af12e518\"\n\n\n\nAfter you know these values, use them to run the instance-template-create command. In addition to the information that you gathered, you must specify a name for the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=ui"},{"document_id":"ibmcld_15244-22283-23790","score":15.992726,"text":"\n* To get the offering_crn for the offering and the offering_version_crn for each version in the offering, run the following command.\n\nibmcloud is catalog-image-offering $catalog_id $offering_id\n\n\n\nWhen you provision an instance, you can either provision the instance from the private catalog-managed image in the latest version in a catalog product offering by using the offering_crn value or from the specific version in the catalog product offering by using the offering_version_crn value.\n\nSave the offering_crn and offering_version_crnin variables, which are used later to provision an instance.\n\noffering_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:offering:136559f6-4588-4af2-8585-f3c625eee09d\"\noffering_version_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:version:136559f6-4588-4af2-8585-f3c625eee09d\/8ae92879-e253-4a7c-b09f-8d30af12e518\"\n\n\n\n7. List the available boot volumes for creating your instance. If you are creating an instance from an image, skip this step. To create an instance from an existing volume, you must use a volume compatible with the instance options chosen previously. A compatible volume is in the same zone as the instance that is being provisioned, in an unattached state, and has an OS compatible with the profile that is selected in step 5. Use the volumes subcommand to see the compatible volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers&interface=api"},{"document_id":"ibmcld_15245-22283-23790","score":15.992726,"text":"\n* To get the offering_crn for the offering and the offering_version_crn for each version in the offering, run the following command.\n\nibmcloud is catalog-image-offering $catalog_id $offering_id\n\n\n\nWhen you provision an instance, you can either provision the instance from the private catalog-managed image in the latest version in a catalog product offering by using the offering_crn value or from the specific version in the catalog product offering by using the offering_version_crn value.\n\nSave the offering_crn and offering_version_crnin variables, which are used later to provision an instance.\n\noffering_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:offering:136559f6-4588-4af2-8585-f3c625eee09d\"\noffering_version_crn=\"crn:v1:staging:public:globalcatalog-collection:global:a\/efe5afc483594adaa8325e2b4d1290df:0b322820-dafd-4b5e-b694-6465da6f008a:version:136559f6-4588-4af2-8585-f3c625eee09d\/8ae92879-e253-4a7c-b09f-8d30af12e518\"\n\n\n\n7. List the available boot volumes for creating your instance. If you are creating an instance from an image, skip this step. To create an instance from an existing volume, you must use a volume compatible with the instance options chosen previously. A compatible volume is in the same zone as the instance that is being provisioned, in an unattached state, and has an OS compatible with the profile that is selected in step 5. Use the volumes subcommand to see the compatible volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10165-7-2413","score":27.33484,"text":"\nFinancial services use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae can take advantage of high availability, high-performance compute, easy spin-up of clusters for faster development, and AI from IBM Watson\u00ae.\n\n\n\n Mortgage company trims costs and accelerates regulatory compliance \n\nA Risk Management VP for a residential mortgage company processes 70 million records a day, but the on-premises system was slow and also inaccurate. IT expenses soared because hardware quickly went out of date and wasn't utilized fully. While they waited for hardware provisioning, their regulatory compliance slowed.\n\n\n\n Context \n\nTo improve risk analysis, the company looked to Red Hat OpenShift on IBM Cloud and IBM Cloud Analytic services to reduce costs, increase worldwide availability, and ultimately accelerate regulatory compliance. With Red Hat OpenShift on IBM Cloud in multiple regions, their analysis apps can be containerized and deployed across the globe, improving availability and addressing local regulations. Those deployments are accelerated with familiar open source tools, already part of Red Hat OpenShift on IBM Cloud.\n\nThey started by containerizing the analysis apps and putting them in the cloud. In a flash, their hardware headaches went away. They were able to easily design Kubernetes clusters to fit their high-performance CPU, RAM, storage, and security needs. And when their analysis apps change, they can add or shrink compute without huge hardware investments. With the Red Hat OpenShift on IBM Cloud horizontal scaling, their apps scale with the growing number of records, resulting in faster regulatory reports. Red Hat OpenShift on IBM Cloud provides elastic compute resources around the world that are secure and capable.\n\nNow those apps receive high-volume data from a data warehouse on IBM Cloudant. Cloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_finance"},{"document_id":"ibmcld_10169-7-2057","score":26.576664,"text":"\nRetail use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae can take advantage of analytics for market insights, multi-region deployments across the globe, and inventory management with IBM\u00ae Event Streams for IBM Cloud\u00ae and object storage.\n\n\n\n Brick-and-mortar retailer shares data, by using APIs with global business partners to drive omnichannel sales \n\nA Line-of-Business (LOB) Exec needs to increase sales channels, but the retail system is closed off in an on-premises data center. The competition has global business partners to cross-sell and up sell permutations of their goods: across brick-and-mortar and online sites.\n\nRed Hat OpenShift on IBM Cloud provides a public-cloud ecosystem, where containers enable new business partners and other external players to co-develop apps and data, through APIs. Now that the retail system is on the public cloud, APIs also streamline data sharing and jump-start new app development. App deployments increase when Developers experiment easily, pushing changes to Development and Test systems quickly with toolchains.\n\nRed Hat OpenShift on IBM Cloud and key technologies:\n\n\n\n* [Clusters that fit varied CPU, RAM, storage needs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n* [IBM Cloud\u00ae Object Storage to persist and sync data across apps](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage)\n* [DevOps native tools, including open toolchains in IBM Cloud\u00ae Continuous Delivery](https:\/\/www.ibm.com\/cloud\/architecture\/toolchains\/)\n\n\n\n\n\n Context \n\n\n\n* The retailer is faced with strong competitive pressures. First, they need to mask the complexity of crossing into new products and new channels. For example, they need to expand product sophistication. At the same time, it needs to be simpler for their customers to jump across brands.\n* That ability to jump brand means that the retail ecosystem requires connectivity to business partners.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_retail"},{"document_id":"ibmcld_10392-250715-251723","score":25.5851,"text":"\n: Updated the [CLI reference page](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli) to reflect multiple changes for the release of version [0.3.34](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog) of the IBM Cloud Kubernetes Service CLI plug-in.\n\nNew! Red Hat OpenShift on IBM Cloud clusters\n: With the Red Hat OpenShift on IBM Cloud beta, you can create IBM Cloud Kubernetes Service clusters with worker nodes that come installed with the Red Hat OpenShift container orchestration platform software. You get all the advantages of managed IBM Cloud Kubernetes Service for your cluster infrastructure environment, along with the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/3.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments. To get started, see [Tutorial: Creating a Red Hat OpenShift on IBM Cloud cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_13150-7-1859","score":25.53854,"text":"\nScalable web application on Red Hat OpenShift on IBM Cloud \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through how to deploy an application to a [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/openshiftcluster) cluster from a remote Git repository, expose the app on an Red Hat OpenShift on IBM Cloud route, monitor the health of the environment, and scale the application. Additionally, you will learn how to use a private container registry, deploy an application from a private Git repository and bind a custom domain to your application.\n\nWith Red Hat OpenShift on IBM Cloud, you can create IBM Cloud Kubernetes Service clusters with worker nodes that come installed with the Red Hat OpenShift on IBM Cloud Container Platform orchestration software. You get all the [advantages of managed IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for your cluster infrastructure environment, while using the [Red Hat OpenShift on IBM Cloud tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.12\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n\n\n\n Objectives \n\n\n\n* Deploy a web application to the Red Hat OpenShift on IBM Cloud cluster.\n* Bind a custom domain.\n* Monitor the logs and health of the cluster.\n* Scale Red Hat OpenShift on IBM Cloud pods.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution50-scalable-webapp-openshift\/Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The developer deploys a web application using the code from a remote Git repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-openshift"},{"document_id":"ibmcld_10167-15831-18105","score":25.374334,"text":"\n* Use IBM\u00ae Secure Gateway for IBM Cloud\u00ae to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Use secure and performance driven compute \n\n\n\n* ML apps that require higher-performing compute are hosted on Red Hat OpenShift on IBM Cloud on Bare Metal. This ML cluster is centralized, so each regional cluster doesn't have the expense of bare metal workers; Kubernetes deployments are easier too.\n* Vulnerability Advisor provides image, policy, container, and packaging scanning vulnerability scanning.\n\n\n\n\n\n\n\n Step 3: Ensure global availability \n\n\n\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI\/CD toolchains to deploy apps into clusters across the globe.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n* With the toolchains and Helm deployment tools, the apps are also deployed to clusters across the globe, so workloads and data meet regional regulations.\n\n\n\n\n\n\n\n Step 4: Data sharing \n\n\n\n* IBM Cloudant is a modern NoSQL database suitable a range of data-driven use cases from key-value to complex document-oriented data storage and query.\n* To minimize queries to the regional databases, IBM Cloudant is used to cache the user's session data across apps.\n* This choice improves the front-end app usability and performance across apps on Red Hat OpenShift on IBM Cloud.\n* While worker apps in Red Hat OpenShift on IBM Cloud analyze on-premises data and store results in IBM Cloudant, IBM Cloud\u00ae Functions reacts to changes and automatically sanitizes data on the incoming feeds of data.\n* Similarly, notifications of research breakthroughs in one region can be triggered through data uploads so that all researchers can take advantage of new data.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Researchers have access to clinical data and can share clinical data, while they comply with local regulations.\n* Patients who participate in disease research feel confident that their data is secure and making a difference, when it is shared with large research teams.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_health"},{"document_id":"ibmcld_07578-396975-399135","score":25.273367,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-396949-399109","score":25.273367,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05207-7-2050","score":25.14217,"text":"\nGetting started with IBM Cloud Pak for Multicloud Management V1.3 \n\nThe IBM Cloud Pak for Multicloud Management, running on Red Hat OpenShift, provides consistent visibility, governance, and automation from on-premises to the edge. Enterprises gain capabilities such as multicluster management, event management, application management, and infrastructure management. Enterprises can use this Cloud Pak to help increase operational efficiency that is driven by intelligent data, analysis, and predictive golden signals, and gain built-in support for their compliance management. For more details, see the [documentation](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSFC4F\/product_welcome_cloud_pak.html).\n\n\n\n What's inside this Cloud Pak \n\nIn addition to the default features for managing multicloud environments, the IBM Cloud Pak for Multicloud Management includes the following installable modules that you can add to your cluster to manage applications and infrastructure, and to automate tasks:\n\n\n\n* Monitoring Module for monitoring the performance and availability of cloud applications in hybrid cloud environments.\n* Terraform & Service Automation Module for cluster security, operating efficiency, and appropriate service level delivery.\n* CloudForms for controlling and managing cloud infrastructures.\n* Red Hat Ansible Tower for running your automation tasks.\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* Before you can install the Cloud Pak, you must purchase a license through [IBM Passport Advantage](https:\/\/www.ibm.com\/software\/passportadvantage\/index.html). For part numbers, see [Passport Advantage part numbers](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFC4F_1.3.0\/about\/part_numbers.html).\n* You must have a supported version of OpenShift Container Platform installed by using IBM Cloud Kubernetes Service so that the managed OpenShift service is supported. For the list of supported versions, see [Supported OpenShift versions and platforms](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFC4F_1.3.0\/install\/supported_os.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-multicloud-management?topic=cloud-pak-multicloud-management-getting-started-13"},{"document_id":"ibmcld_10116-5684-7668","score":24.856817,"text":"\n[Migrate](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand-migrate) your existing worker nodes to take advantage of the new OCP licenses.\n\n\n\n\n\n New OCP licenses with reduced pricing, available 9 November 2020 \n\nNew OCP licenses include reduced pricing from Red Hat. a Red Hat OpenShift license is billed for every two virtual cores (or one physical cores) of the worker node flavor. Charges vary by the type of worker node that you have, for as long as you have the worker node. For more information, see the [IBM Cloud blog](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/run-workloads-by-the-hour-with-red-hat-openshift-on-ibm-cloud).\n\n\n\n* Virtual machines (VMs): The OCP licenses are billed hourly. For example, you create a worker pool with VMs, test an app for 3 days, and then delete the worker pool. You are billed for only the hours that your worker nodes were deployed.\n* Physical machines (bare metal): The OCP licenses are prorated for the first month that you create the worker nodes in, and then billed monthly for the remaining lifecycle of the worker node. For example, you create a cluster with bare metal worker nodes on 15 August and delete the cluster on 14 September. You are charged a prorated monthly cost for the first month of August, but the full monthly cost for September.\n\n\n\nWhen you estimate the cost of a new cluster or worker node, the OCP licenses are included as part of the worker node cost. The OCP licenses are also part of the worker node plan and listed as a sub-item of the worker nodes in your IBM Cloud bill.\n\n\n\n\n\n Deprecated: Old OCP licenses for existing worker nodes before 9 November 2020 or deprecated bare metal flavors \n\na Red Hat OpenShift license is billed for every four virtual cores (or two physical cores) of the worker node flavor. You are charged for the entire license for each month that you have worker nodes in a deployed state. The monthly charge applies to both virtual and physical worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10702-7-1940","score":24.740705,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-139037-140928","score":27.350344,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-246841-248669","score":27.31621,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Reconciling usage for nonsubscription multi-year account invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice)Reconciling usage for nonsubscription multi-year account invoices\n\nAs an IBM Cloud\u00ae customer with a nonsubscription multi-year account, understanding the different invoices that are available to you can help you understand your monthly cost breakdown.\n\nManaging billing and usage\n\n\n\n* 15 minutes\n* 2022-08-30\n\n\n\n[Getting started with the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started)Getting started with the IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10392-235456-236884","score":26.966316,"text":"\n* [Using the internal registry in Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry).\n\n\n\nEntitled software\n: If you have licensed products from your [MyIBM.com](https:\/\/myibm.ibm.com) container software library, you can [set up your cluster to pull images from the entitled registry](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrysecret_entitled_software).\n\nscript update command\n: Added [steps for using the script update command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliscript_update) to prepare your automation scripts for the release of version 1.0 of the Red Hat OpenShift on IBM Cloud plug-in.\n\n\n\n\n\n 12 September 2019 \n\nIngress ALB change log\n: Updated the ALB [nginx-ingress image to build 552](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog).\n\n\n\n\n\n 6 September 2019 \n\nNew! Chennai, India che01 single zone location for Red Hat OpenShift clusters\n: For more locations, see [Single and multizone locations in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zones).\n\n\n\n\n\n 5 September 2019 \n\nIngress ALB change log\n: Updated the ALB [ingress-auth image to build 340](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog).\n\n\n\n\n\n 4 September 2019 \n\nCLI change log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_10404-74695-75915","score":26.37115,"text":"\nRed Hat OpenShift Control Plane Operator v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift 4.8.21 4.8.26 Changed the duration of worker node certificates from 3 years to 2 years. See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.8\/release_notes\/ocp-4-8-release-notes.htmlocp-4-8-26). \n Red Hat OpenShift on IBM Cloud toolkit 4.8.0+20211201 4.8.0+20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n OpenVPN client 2.4.6-r3-IKS-463 2.5.4-r0-IKS-556 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts. \n OpenVPN server 2.4.6-r3-IKS-462 2.5.4-r0-IKS-555 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_48"},{"document_id":"ibmcld_16729-86110-87974","score":25.596542,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Node.js Express application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Deploy a Java Spring app by using IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-spring-webapp)Deploy a Java Spring app by using IBM Cloud Schematics\n\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_05173-7408-9438","score":25.326233,"text":"\n2. Enter or select the Red Hat OpenShift on IBM Cloud project where you want to deploy IBM Cloud Pak for Data.\n\n\n\n\n\n\n\n Step 3. Configure your workspace \n\nSpecify how you will track and manage your installation:\n\n\n\n1. Enter or select a name for the installation.\n2. Consider changing the default resource group.\n3. Specify any tags that you want to use for the installation. Specify multiple tags as a comma-separated list.\n\n\n\n\n\n\n\n Step 4. Complete the preinstallation task \n\nA Red Hat OpenShift on IBM Cloud cluster administrator must complete this step. Specifically, the administrator must have an [access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users) policy in IBM Cloud Identity and Access Management that has an Operator role or higher.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the preinstallation set up on your cluster.\n\n\n\nThe preinstallation script makes the following changes to your Red Hat OpenShift on IBM Cloud cluster:\n\n\n\n* Increases the size of the Docker registry to 200 GB. This change increases the cost of your Red Hat OpenShift on IBM Cloud cluster.\n* Creates the security context constraints that are required for IBM Cloud Pak\u00ae for Data.\n* Grants access to the security context constraints to the service accounts that are required for IBM Cloud Pak\u00ae for Data.\n\n\n\nConfirm that the script completes successfully before you proceed.\n\nIf the cluster administrator is not allowed to modify the storage, or the infrastructure account is not the same as the current account, a storage administrator can manually execute the script that is provided in [Complete the preinstallation section](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global).\n\n\n\n\n\n Step 5. Set the deployment values \n\nChoose a storage class:\n\n\n\n* EnduranceFileStorage - This option uses the storage class ibmc-file-gold-gid to install Cloud Pak for Data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data"},{"document_id":"ibmcld_13144-1354-3173","score":25.289766,"text":"\n3. Users access the frontend application.\n4. The IBM Cloudant database instance is provisioned through an IBM Cloud Operator Service.\n5. The backend application is connected to the database with an IBM Cloud Operator Binding.\n6. Log Analysis is provisioned and agent deployed.\n7. Monitoring is provisioned and agent deployed.\n8. An Administrator monitors the app with Log Analysis and Monitoring.\n\n\n\nThere are [scripts](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend\/tree\/master\/scripts) that will perform some of the steps below. It is described in the [README.md](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend). If you run into trouble and want to start over just execute the destroy.sh script and sequentially go through the scripts that correspond to the steps to recover.\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* oc to interact with OpenShift.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\n\n\n\n\n Step 1: Create a Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_05210-8096-10006","score":25.049719,"text":"\nUsing a CLI that has access to your cluster, create the open-cluster-management namespace by running the following command: oc create namespace open-cluster-management\n2. Download your Openshift Container Platform pull secret file from https:\/\/cloud.redhat.com\/openshift\/install\/pull-secret by selecting Download pull secret; save the pull secret to a filepath you have read and write access to, like \/root\/rhacm-pull-secret.\n3. Run the following command to create your secret, substituting in the filepath to the pull-secret: oc create secret generic rhacm-pull-secret -n open-cluster-management --from-file=.dockerconfigjson=\/root\/rhacm-pull-secret --type=kubernetes.io\/dockerconfigjson\n\nFor additional information, see the Red Hat Advanced Cluster Management documention [here](https:\/\/access.redhat.com\/documentation\/en-us\/red_hat_advanced_cluster_management_for_kubernetes\/2.2\/html\/install\/installinginstalling-red-hat-advanced-cluster-management-from-the-cli).\n\n\n\n\n\n Step 4. Complete the pre-installation check \n\nA Red Hat OpenShift cluster administrator must complete this step.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the pre-installation check. Confirm that the script completes successfully.\n\n\n\n\n\n\n\n Step 5. Install IBM Cloud Pak for Multicloud Management \n\n\n\n1. Ensure that you assigned a license for IBM Cloud Pak for Multicloud Management to the deployment.\n2. Confirm that you read and agree to the license agreements.\n3. Click Install.\n\n\n\n\n\n\n\n\n\n Next steps \n\nWhen the installation completes, you can access your IBM Cloud Pak for Multicloud Management deployment with the provided URL.\n\n\n\n1. Log in the IBM Cloud Pak for Multicloud Management management console by using the administrator username and password which were generated when the workspace was created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-multicloud-management?topic=cloud-pak-multicloud-management-getting-started-23"},{"document_id":"ibmcld_06835-3900-5573","score":24.068941,"text":"\n* This toolchain uses [Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-cluster-config) to deploy an application to a group of clusters.\n* This toolchain assumes that you have a [Satellite cluster group](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig) with the required clusters.\n* This toolchain supports a Satellite cluster group that contains only one type of cluster (Red Hat\u00ae OpenShift\u00ae).\n\n\n\n\n\n\n\n Deployment \n\nDevSecOps provides out of the box scripts to deploy your application on the group of clusters. You might need to customize these scripts according to your application and cluster group requirements.\n\nThese scripts are located in the deployment repository and are specified in the pipeline-config.yml file.\n\ndeploy:\nimage: icr.io\/continuous-delivery\/pipeline\/pipeline-base-image:2.12@sha256:ff4053b0bca784d6d105fee1d008cfb20db206011453071e86b69ca3fde706a4\nscript: \n!\/usr\/bin\/env bash\n\nif [ \"$PIPELINE_DEBUG\" == 1 ]]; then\ntrap env EXIT\nenv\nset -x\nfi\n\nsource scripts\/deploy_setup.sh\nsource scripts\/deploy.sh\nexport DEPLOY_EXIT=$?\nsource scripts\/doi-publish-deploy.sh\nShow more\n\n\n\n\n\n\n\n Deploying to a custom target \n\nDeploy to a custom target if you want to:\n\n\n\n* Deploy your application on your own choice of infrastructure, such as Virtual Server Instances (VSI).\n* Perform custom tasks, such as updating some configurations in a Red Hat\u00ae OpenShift\u00ae cluster.\n\n\n\nIn these cases, select \"custom\" as a deployment target.\n\n\n\n Performing a custom deployment \n\n\n\n* DevSecOps templates are fully customizable. You can provide your own stages and steps in the pipeline-config.yml file of the deployment repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-deployment-target"},{"document_id":"ibmcld_14490-7-2135","score":24.068583,"text":"\nManaging Red Hat OpenShift for VMware \n\nReview the following information to manage your Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service after deployment.\n\n\n\n Rotating the Red Hat OpenShift certificates (required) \n\nRed Hat OpenShift for VMware uses kubelet client certificates that must be rotated periodically for security purposes. Red Hat OpenShift mainly automates the rotation process, but requires manual approval of certificate signing requests (CSRs). Therefore, it is important that you understand the Red Hat OpenShift certificate rotation schedule to avoid expired certificates.\n\nThe initial certificates that are created during installation expire 24 hours after they are created. IBM's automation process, which installs Red Hat OpenShift, handles the approval of the CSRs for this initial rotation, which is done by running a script on the bastion for the first 30 hours. The script is named \/root\/approve-csr.sh and its log file is named \/root\/approve-csr.log.\n\nFor the script to run successfully, the initial kubeadmin credentials must be the same until the initial certificate rotation is complete. Do not change the kubeadmin credentials for the first 24 hours. If the credentials are changed, you must monitor and approve the CSRs for the initial certificate rotation. For more information, see [Approving the CSRs for your machines](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlinstallation-approve-csrs_installing-vsphere).\n\nDo not restart any of the Red Hat OpenShift cluster virtual machines (VMs) or the bastion VM until the first certificate rotation is done.\n\nAfter the initial certificate rotation, certificates are renewed every 30 days. You must establish a process to approve the CSRs for every certificate rotation. According to Red Hat\u00ae, you can approve CSRs when they reach 80% of their expiration period, which is approximately 25 days into the lifespan of the CSRs.\n\nIf you do not approve CSRs in time and the certificates expire, you can recover from expired control plane certificates and get the Red Hat OpenShift cluster operational again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_managing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07705-0-1395","score":9.78305,"text":"\n\n\n\n\n\n\n  CM-11 - User-installed Software \n\n\n\n  Control requirements \n\nThe organization:\n\nCM-11 (a)\n:   Establishes [Assignment: organization-defined policies] governing the installation of software by users;\n\nCM-11 (b)\n:   Enforces software installation policies through [Assignment: organization-defined methods]; and\n\nCM-11 (c)\n:   Monitors policy compliance at [IBM Assignment: continuously].\n\n\n\n\n\n  NIST supplemental guidance \n\nIf provided the necessary privileges, users have the ability to install software in organizational information systems. To maintain control over the types of software installed, organizations identify permitted and prohibited actions regarding software installation. Permitted software installations may include, for example, updates and security patches to existing software and downloading applications from organization-approved \u201capp stores\u201d Prohibited software installations may include, for example, software with unknown or suspect pedigrees or software that organizations consider potentially malicious. The policies organizations select governing user-installed software may be organization-developed or provided by some external entity. Policy enforcement methods include procedural methods (e.g., periodic examination of user accounts), automated methods (e.g., configuration settings implemented on organizational information systems), or both.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-11"},{"document_id":"ibmcld_05187-7-1663","score":9.500487,"text":"\nInstalling services \n\nIf you deploy IBM Cloud Pak for Data on IBM Cloud, you can install a subset of the services that are available in the Cloud Pak for Data services catalog.\n\nYou can install services by using two different methods. The supported methods depend on the services that you want to install:\n\n\n\n* Some services can be installed from the [Cloud Pak for Data installation page](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global) in the IBM Cloud catalog.\n* Some services can be installed by creating a catalog source and an operator subscription for each service. For general information and prerequisites, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html). To use this method, you must:\n\n\n\n* Use the Red Hat OpenShift command-line interface (oc CLI) to connect to the cluster. For more information, see [Connecting to the cluster from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_oc_cli).\n* Create an operator subscription for each service that you plan to install. For more information, see [Creating OLM objects for an express installation](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install-platform-express-olm.html).\n\n\n\n\n\nUse the links in the following table to learn how to install each of these services.\n\n\n\n Service Install from the Cloud Pak for Data installation page Install by using the CLI \n\n [Analytics Engine Powered by Apache Spark](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/spark.html) \u2713 \u2713 \n [Cognos Analytics](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/ca.html) \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-install-services"},{"document_id":"ibmcld_00133-1680-3358","score":9.37229,"text":"\nRun the Agent installation package.\n2. At the language screen, click OK.\n3. At the welcome screen, click Next.\n4. Select the Modify installation, and click Next.\n5. Select the Leave Unchanged, and click Next.\n6. At the custom setup screen, select each plug-in that you purchased, and select This feature will be installed on ..., then click Next.\n7. Select Keep my current registration, and click Next.\n8. Click Install.\n9. When the installation is complete, check to ensure that both services are enabled and running.\n10. If Cloud Backup Portal is able to access or view the database, then the installation was successful.\n\n\n\n\n\n\n\n Installing the plug-in for Linux \n\nThe Oracle plug-in is an add-on to the Linux\u00ae Agent and is installed with the Agent on the database host. The Linux\u00ae Agent application must be installed before the plug-in installation occurs. The agent is available as a 32-bit application and a 64-bit application. For more information, see [Installing the IBM Cloud Backup for Classic Client in Linux\u00ae](https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-InstallinLinux).\n\nThe Oracle plug-in installation kit is available in a tar.gz file.\n\n\n\n1. On the host, download the installation package.\n\nhttp:\/\/downloads.softlayer.com\/evault\/Oracle-Plugin-Linux-x64-8.10.5249.tar.gz\n2. Extract the files from the package.\n\n cd \/tmp\n tar xvf Oracle-Plugin-Linux-x64-8.10.5249.tar\n3. Go to the folder.\n\n cd Oracle-Plugin-Linux-x64-8.10.5249.xxxx\n4. Run the installation script.\n\n .\/install.sh\n5. Follow the installation instructions on the screen.\n\n\n\nThe Oracle plug-in performs an \"inconsistent\" whole database backup that requires that the database runs in ARCHIVELOG mode.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-Oracleplugin"},{"document_id":"ibmcld_07578-537610-538960","score":9.073235,"text":"\nRun the following command to install the private worker by using the specific container registry: kubectl apply \u2013filename updated_deployment.yaml.\n6. Continue the [installation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui).\n\n\n\n* How do I provision and update the private worker installation file for IBM Cloud\u00ae Private?\n\nIf your pipeline worker is installed on IBM Cloud Private, you can use the following script to provision and update the private worker installation file.\n\n#!\/bin\/bash\nregion=${region:-\"us-south\"}\ntarget_cr=\"mycluster.icp:8500\"\ninstall_filename=\"updated-private-worker-install.yaml\"\ncurl -o $install_filename\nhttps:\/\/private-worker-service.$region.devops.cloud.ibm.com\/install\ncat $install_filename | grep -e\n'gcr.io\/tekton-releases\/github.com\/tektoncd\/pipeline\/cmd' -e 'image:' \\\n| sed 's\/- gcr.io\/gcr.io\/g' \\\n| sed 's\/- image: gcr.io\/gcr.io\/g' \\\n| sed 's\/image: gcr.io\/gcr.io\/g' \\\n| sed 's\/image:\/\/g' \\\n| awk '{$1=$1;print}' \\\n| while read -r image ; do\n\necho \"Processing $image\"\ndocker pull $image\nnew_image_tag=$image\n if $image only have a single slash it is coming from dockerhub\nnumber_of_slashes=$(echo $image | tr -cd '\/' | wc -c)\nif [ \"$number_of_slashes\" == \"1\" ]; then\nnew_image_tag=\"$target_cr\/$image\"\nfi\n\n replace the sha id reference in the tag if any","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-537564-538914","score":9.073235,"text":"\nRun the following command to install the private worker by using the specific container registry: kubectl apply \u2013filename updated_deployment.yaml.\n6. Continue the [installation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-install-private-workers&interface=ui).\n\n\n\n* How do I provision and update the private worker installation file for IBM Cloud\u00ae Private?\n\nIf your pipeline worker is installed on IBM Cloud Private, you can use the following script to provision and update the private worker installation file.\n\n#!\/bin\/bash\nregion=${region:-\"us-south\"}\ntarget_cr=\"mycluster.icp:8500\"\ninstall_filename=\"updated-private-worker-install.yaml\"\ncurl -o $install_filename\nhttps:\/\/private-worker-service.$region.devops.cloud.ibm.com\/install\ncat $install_filename | grep -e\n'gcr.io\/tekton-releases\/github.com\/tektoncd\/pipeline\/cmd' -e 'image:' \\\n| sed 's\/- gcr.io\/gcr.io\/g' \\\n| sed 's\/- image: gcr.io\/gcr.io\/g' \\\n| sed 's\/image: gcr.io\/gcr.io\/g' \\\n| sed 's\/image:\/\/g' \\\n| awk '{$1=$1;print}' \\\n| while read -r image ; do\n\necho \"Processing $image\"\ndocker pull $image\nnew_image_tag=$image\n if $image only have a single slash it is coming from dockerhub\nnumber_of_slashes=$(echo $image | tr -cd '\/' | wc -c)\nif [ \"$number_of_slashes\" == \"1\" ]; then\nnew_image_tag=\"$target_cr\/$image\"\nfi\n\n replace the sha id reference in the tag if any","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11636-15230-16963","score":9.025368,"text":"\nIn this tutorial that installs a prototypical SAP System, we do not specify a Windows domain. Usually, if you configure a server for your company's access, you would specify the domain in the hosts file. During the SAP installation, you turn off the FQDNoption and leave the domain name blank.\n{: note}\n\nThe following example is for the server instance sap-wdb.\n\nShow more\n\n10.243.128.9 sap-wdb 10.243.129.6 sap-wdb-priv 10.243.128.7 sap-wapp-win 10.243.129.4 sap-wapp-priv\n\nYour VSIs are now prepared to host the components of a distributed SAP installation. For more information about more installation preparations, see [!Downloading and installing SAP software and applications](\/docs\/sap?topic=sap-download-install-media).\n\n Installing your SAP landscape {: install-sap-wins step}\n\n Installing the IBM Cloud Metrics Collector for SAP {: install-metrics-collector-wins}\n\nSAP requires the installation of the IBM Cloud Metrics Collector for SAP to analyze your infrastructure in the event that a support incident has been submitted. Install the collector by using the instructions in [IBM Cloud Metrics Collector for SAP](\/docs\/sap?topic=sap-ibm-metrics-collector-for-sap-windows).\n\n Downloading your SAP software {: download-sap-software-wins step}\n\nYou need an S-User ID and the Download Software authorization when you download the DVD images from the SAP Service Marketplace. To request an S-USer ID, see the [SAP Support Portal](https:\/\/support.sap.com\/en\/index.html).\n{: note}\n\nDepending on your target SAP application that you are going to install you need to gather information, which SAP images you will need to download. In this tutorial, we are choosing SAP NetWeaver ABAP on Windows using IBM Db2 for the SAP Database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-quickstudy-vs-gen2-netweaver-wins"},{"document_id":"ibmcld_05174-10419-12206","score":8.933612,"text":"\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-getting-started"},{"document_id":"ibmcld_05173-10345-12132","score":8.933612,"text":"\n* To install Watson OpenScale, set aiopenscale to true.\n* To install Cognos Dashboards, set cde to true.\n* To install Db2 Data Gate, set datagate to true.\n* To install Db2 Warehouse, set db2wh to true.\n* To install Db2 Data Management Console, set dmc to true.\n* To install RStudio Server, set rstudio to true.\n* To install Apache Spark, set spark to true.\n* To install Scheduling, set scheduler to true.\n* To install Watson Knowledge Catalog, set wkc to true.\n* To install Watson Machine Learning, set wml to true.\n* To install Watson Machine Learning Accelerator, set wmla to true.\n* To install Watson Query, set dv to true.\n* To install Watson Studio, set wsl to true.\n\n\n\nIf you don't select any services to install in this step, only the IBM Cloud Pak for Data control plane will be installed.\n\nIf you want to install a service later, you can return to the Deployment values section and set the appropriate parameter to true or you can select a service from the IBM Cloud Pak for Data Services catalog and follow the installation instructions for the service.\n\nFor more information, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html).\n\n\n\n\n\n Step 6. Install IBM Cloud Pak for Data \n\n\n\n1. Ensure that you have assigned a license for IBM Cloud Pak for Data to the deployment.\n2. Confirm that you have read and agree to the license agreements.\n3. Click Install.\n\n\n\nThe IBM Cloud Pak\u00ae for Data automated installation makes the following changes to ensure that services can be installed successfully:\n\n\n\n* Sets kernel parameters. For more information, see [Kernel parameter settings](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/prep-cluster-node-kernel.html).\n* Enables noroot squash on worker nodes for Network File System (NFS).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data"},{"document_id":"ibmcld_04504-1175-2776","score":8.695088,"text":"\nUse the ibmcloud plugin install PLUGIN_NAME command to install a specific plug-in. For example, use the following command to install the IBM Cloud Code Engine CLI plug-in:\n\nibmcloud plugin install code-engine\n\nLooking up 'code-engine' from repository 'IBM Cloud'...\nPlug-in 'code-engine 1.23.2' found in repository 'IBM Cloud'\nAttempting to download the binary file...\n54.29 MiB \/ 54.29 MiB [============================================] 100.00% 10s\n56929376 bytes downloaded\nInstalling binary...\nOK\nPlug-in 'code-engine 1.23.2' was successfully installed into \/Users\/username\/.bluemix\/plugins\/code-engine. Use 'ibmcloud plugin show code-engine' to show its details.\n\n\n\n\n\n Installing all plug-ins \n\nUse the plugin install -a command to install all the latest available plug-ins that are in the repository:\n\nibmcloud plugin install -a\n\n\n\n\n\n Installing multiple plug-ins \n\nUse the plugin install PLUGIN_NAME@VERSION command to install multiple plug-ins at the same time. For example, use the following command to install the container-service@1.0.506 and the secrets-manager@0.1.25 plug-ins:\n\nibmcloud plugin install container-service@1.0.506 secrets-manager@0.1.25\n\nFor more information, see [ibmcloud plugin install](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_settingsibmcloud_plugin_install).\n\n\n\n\n\n\n\n Confirming installed plug-ins \n\nUse the plugin list command to confirm that all required plug-ins are installed in IBM Cloud CLI. The plugin list command returns the following information for each plugin that is installed:\n\n\n\n* The plug-in name.\n* The current version of the plug-in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-plug-ins"},{"document_id":"ibmcld_03009-7-1439","score":8.500713,"text":"\nInstalling \n\nLearn how to install Watson Assistant for IBM Cloud Pak\u00ae for Data.\n\nThe IBM Cloud Pak for Data environment is a Kubernetes-based container platform that can help you quickly modernize and automate workloads that are associated with the applications and services you use. You can develop and deploy on your own infrastructure and in your data center which helps to mitigate risk and minimize vulnerabilities.\n\nThe installation process differs depending on the version you are installing. The following table shows the available versions.\n\n\n\nAvailable versions\n\n Version Cluster Installation instructions \n\n 4.7.0 IBM Cloud Pak for Data 4.7.x [Installing 4.7.0](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.7.x\/svc-assistant\/assistant-svc-install.html) \n 4.6.5 IBM Cloud Pak for Data 4.6.x [Installing 4.6.5](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-assistant\/assistant-svc-install.html) \n 4.6.3 IBM Cloud Pak for Data 4.6.x [Installing 4.6.3](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-assistant\/assistant-svc-install.html) \n 4.6.2 IBM Cloud Pak for Data 4.6.x [Installing 4.6.2](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-assistant\/assistant-svc-install.html) \n 4.6.0 IBM Cloud Pak for Data 4.6.x [Installing 4.6.0](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-assistant\/assistant-svc-install.html) \n 4.5.3 IBM Cloud Pak for Data 4.5.x [Installing 4.5.3](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.5.x\/svc-assistant\/assistant-svc-install.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-install"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11889-0-903","score":11.791073,"text":"\n\n\n\n\n\n\n  Setting up cluster groups \n\nThe cluster group specifies all clusters that you want to include in the deployment of your Kubernetes resources. The clusters can run in your Satellite location or in IBM Cloud.\n\nIf you want to use the console to create Satellite configurations, you can create cluster groups as part of the configuration creation process. If you want to use the CLI to create Satellite configurations, you must create a cluster group first. Follow these steps to create a cluster group with the CLI:\n\n\n\n1.  List the clusters that are registered with the Satellite Config component and note their ID.\n\nibmcloud sat cluster ls\n2.  Add the cluster to your cluster group.\n\nibmcloud sat group attach --cluster <cluster_ID> --group <cluster_group_name>\n3.  Verify that your cluster is successfully added to your cluster group.\n\nibmcloud sat group get --group <cluster_group_name>\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig-groups"},{"document_id":"ibmcld_11878-6858-8628","score":11.436192,"text":"\nThe cluster can run in your Satellite location or in IBM Cloud. To add a cluster that runs in IBM Cloud, you must first [register the cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-cluster-register) with the Satellite Config component.\n\nibmcloud sat group attach --cluster CLUSTER [--cluster CLUSTER] --group GROUP [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--cluster, -c CLUSTER\n: Required. The cluster that you want to add to the cluster group. To list registered clusters, run ibmcloud sat cluster ls.\n\n--group, -g GROUP\n: Required. The name or ID of the cluster group where you want to add the cluster. To list available cluster groups, run ibmcloud sat group ls.\n\n-q\n: Optional. Do not show the message of the day or update reminders.\n\n\n\n\n\n Example \n\nibmcloud sat group attach --cluster mycluster --group mygroup\n\n\n\n\n\n\n\n ibmcloud sat group create \n\nCreate a cluster group. After you created the cluster group, you can subscribe the cluster group to a Satellite configuration.\n\nibmcloud sat group create --name NAME [--cluster CLUSTER] [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--name NAME\n: Required. The name for the cluster group.\n\n--cluster, -c CLUSTER\n: Optional. The name or ID of a cluster that you want to add to the cluster group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-reference"},{"document_id":"ibmcld_11805-7-2049","score":10.675487,"text":"\nRegistering clusters with Satellite Config \n\nClusters you create in your Satellite Location are automatically registered with Satellite Config. You can also manually register other clusters in the public cloud or your existing Red Hat OpenShift on IBM Cloud clusters with Satellite Config. Follow the steps to run the registration script in your cluster to set up the Satellite Config components and make the cluster visible in Satellite.\n\nAfter you complete these steps, the cluster can be added to a cluster group in your location and [subscribed to Satellite configurations](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satcon-manage-direct-upload). However, you must still use Red Hat OpenShift on IBM Cloud to manage the worker nodes for these clusters.\n\n\n\n1. Find the cluster in the public cloud that you want to attach to Satellite Config. To list available clusters, run ibmcloud oc cluster ls or go to the [Red Hat OpenShift cluster dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift).\n\nDo not manually register clusters created in a Satellite Location. These clusters are automatically registered with Satellite Config. Registering them again manually might cause issues in your Location or cluster.\n2. From the Satellite [Clusters](https:\/\/cloud.ibm.com\/satellite\/clusters) dashboard, click Register cluster.\n3. Enter the name of your cluster and click Register cluster. Registering a cluster creates an entry in the Satellite Config ConfigMap. However, your cluster cannot be subscribed to a Satellite configuration until you install the Satellite Config agent in your cluster.\n4. Copy the command that is displayed to you.\n5. [Log in to your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster) and run the command in your cluster. The command creates the razeedeploy project, custom resource definitions and RBAC policies on your cluster that are required to make your cluster visible to Satellite Config.\n\nExample output\n\nnamespace\/razeedeploy created","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-register-openshift-clusters"},{"document_id":"ibmcld_04515-6472-8255","score":10.384565,"text":"\nibmcloud sat group attach \n\nAdd a Red Hat OpenShift on IBM Cloud cluster to your cluster group. The cluster can run in your Satellite location or in IBM Cloud. To add a cluster that runs in IBM Cloud, you must first [register the cluster](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-satellite-cli-referencecli-cluster-register) with the Satellite Config component.\n\nibmcloud sat group attach --cluster CLUSTER [--cluster CLUSTER] --group GROUP [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--cluster, -c CLUSTER\n: Required. The cluster that you want to add to the cluster group. To list registered clusters, run ibmcloud sat cluster ls.\n\n--group, -g GROUP\n: Required. The name or ID of the cluster group where you want to add the cluster. To list available cluster groups, run ibmcloud sat group ls.\n\n-q\n: Optional. Do not show the message of the day or update reminders.\n\n\n\n\n\n Example \n\nibmcloud sat group attach --cluster mycluster --group mygroup\n\n\n\n\n\n\n\n ibmcloud sat group create \n\nCreate a cluster group. After you created the cluster group, you can subscribe the cluster group to a Satellite configuration.\n\nibmcloud sat group create --name NAME [--cluster CLUSTER] [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--name NAME\n: Required. The name for the cluster group.\n\n--cluster, -c CLUSTER\n: Optional.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-satellite-cli-reference"},{"document_id":"ibmcld_11878-5342-7219","score":10.146645,"text":"\n: The name of the cluster that you want to register.\n\n--silent\n: Optional. Return only the registration command in the CLI output.\n\n-q\n: Optional. Do not show the message of the day or update reminders.\n\n\n\n\n\n Example \n\nibmcloud sat cluster register --name mycluster\n\n\n\n\n\n\n\n ibmcloud sat cluster unregister \n\nUnregister a cluster from the Satellite Config component. You can no longer subscribe the cluster to automatically deploy Kubernetes resources from a configuration, but the cluster and its existing resources still run.\n\nibmcloud sat cluster unregister --cluster CLUSTER [-f] [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Operator platform role for the Cluster resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--cluster, -c CLUSTER\n: Required. The cluster that you want to unregister from Satellite. To list registered clusters, run ibmcloud sat cluster ls.\n\n-f\n: Optional. Force the command to run with no user prompts.\n\n-q\n: Optional. Do not show the message of the day or update reminders.\n\n\n\n\n\n Example \n\nibmcloud sat cluster unregister -c mycluster\n\n\n\n\n\n\n\n\n\n Cluster group commands \n\nUse these commands to create cluster groups. Then, subscribe your cluster group to a Satellite configuration to automatically deploy Kubernetes resources to these clusters.\n\n\n\n ibmcloud sat group attach \n\nAdd a Red Hat OpenShift on IBM Cloud cluster to your cluster group. The cluster can run in your Satellite location or in IBM Cloud. To add a cluster that runs in IBM Cloud, you must first [register the cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-cluster-register) with the Satellite Config component.\n\nibmcloud sat group attach --cluster CLUSTER [--cluster CLUSTER] --group GROUP [-q]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-reference"},{"document_id":"ibmcld_05638-1360-3085","score":10.045691,"text":"\nIf the issue persists when creating additional clusters, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud ks worker ls --cluster <cluster_name_or_ID>. If worker nodes are listed, see [Unable to create or delete worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster_infra_errors). If no workers are listed, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Deleted \n\nReview the following description of the Deleted cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is deleted but not yet removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help).\n\n\n\n\n\n Deleting \n\nReview the following description of the Deleting cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is being deleted and cluster infrastructure is being dismantled. You can't access the cluster.\n\n\n\n\n\n Deploy failed \n\nReview the following description of the Deploy failed cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe deployment of the Kubernetes master can't be completed. You can't resolve this state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-states-reference"},{"document_id":"ibmcld_14619-7-2038","score":9.898785,"text":"\nDeleting clusters from vCenter Server instances \n\nYou can delete clusters from VMware vCenter Server\u00ae instances when you do not need them.\n\nDeleting clusters from vCenter Server instances with VMware vSphere\u00ae 6.5 is not supported.\n\n\n\n Before you delete clusters from vCenter Server instances \n\n\n\n* Whenever possible, delete clusters by using the IBM Cloud\u00ae for VMware Solutions console and not the VMware vSphere\u00ae Web Client. Changes that you make on the vSphere Web Client are not synchronized with the VMware Solutions console. If you want to delete clusters from vCenter Server instances by using the vSphere Web Client, do so only for on-premises clusters or clusters that you don't manage in the VMware Solutions console.\n* You can delete any cluster except for the first cluster (the one that is created during initial deployment).\n* You can delete multiple clusters at a time. You can also delete a cluster while another cluster is being created or deleted.\n* Ensure that all nodes in a cluster are powered on and operational before you delete the cluster.\n* When you delete a cluster, all VMs from the cluster are also deleted and they can't be recovered. If you want to keep the VMs, migrate them to other clusters.\n* When you delete a cluster, all storage and subnets that are associated with the cluster are deleted as well. To view the storage and subnets that are associated with a cluster, see the cluster details page.\n* You do not have to delete any services that are installed on the cluster, including services on a gateway cluster. The services are automatically deleted when you delete the cluster.\n\n\n\n\n\n\n\n Procedure to delete clusters from vCenter Server instances \n\n\n\n1. From the IBM Cloud for VMware Solutions console, click Resources > vCenter Server from the left navigation pane.\n2. In the vCenter Server table, click the instance that you want to delete clusters from.\n\nEnsure that the instance status is Available. Otherwise, you can't delete clusters from the instance.\n3. Click the Infrastructure tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_deletingclusters"},{"document_id":"ibmcld_10094-1353-3070","score":9.741261,"text":"\nIf the issue persists when creating additional clusters, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud oc worker ls --cluster <cluster_name_or_ID>. If worker nodes are listed, see [Unable to create or delete worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster_infra_errors). If no workers are listed, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Deleted \n\nReview the following description of the Deleted cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is deleted but not yet removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Deleting \n\nReview the following description of the Deleting cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster is being deleted and cluster infrastructure is being dismantled. You can't access the cluster.\n\n\n\n\n\n Deploy failed \n\nReview the following description of the Deploy failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe deployment of the Kubernetes master can't be completed. You can't resolve this state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-states-reference"},{"document_id":"ibmcld_10094-7-1844","score":9.691772,"text":"\nCluster states \n\nYou can view the current cluster state by running the ibmcloud oc cluster ls command and locating the State field.\n\n\n\n Aborted \n\nReview the following description of the Aborted cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nYou sent a delete request before the Kubernetes master deployment completed. After your cluster is deleted, it is removed from your dashboard. If your cluster is stuck in this state for a long time, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Critical \n\nReview the following description of the Critical cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master can't be reached or all worker nodes in the cluster are down. If you enabled IBM Key Protect in your cluster, the Key Protect container might fail to encrypt or decrypt your cluster secrets. If so, you can view an error with more information when you run oc get secrets.\n\n\n\n\n\n Create failed \n\nReview the following description of the Create failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe cluster cannot be created. Delete the failed cluster and try to create another one. If the issue persists when creating additional clusters, open an [IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help).\n\n\n\n\n\n Delete failed \n\nReview the following description of the Delete failed cluster state. To view the state of your cluster, run ibmcloud oc cluster get --cluster <cluster_name_or_ID>.\n\nThe Kubernetes master or at least one worker node can't be deleted. List worker nodes by running ibmcloud oc worker ls --cluster <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-states-reference"},{"document_id":"ibmcld_05567-8586-10154","score":9.602621,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13139-17831-19468","score":21.783596,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04149-3050-4970","score":21.377403,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04186-18298-19703","score":20.019478,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04132-3821-5296","score":19.764454,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_04183-0-2205","score":19.673698,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_07578-755905-757955","score":19.211302,"text":"\nYou can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01391-18343-19753","score":19.020544,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-73111-74523","score":18.66758,"text":"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-285779-286748","score":18.661732,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.-f, --force: Attempt to delete policy without prompting for confirmation.<-- <\/section \"id=\"section-delete-alert-policy-options\" \"> --><-- <section \"id=\"section-delete-alert-policy-examples\" \"> --> Examples delete an alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy delete a2633e68-1a64-2512-a321-b64a17c7db7a -f -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-delete-alert-policy\" \"> --><-- <\/section \"id=\"section-alert-policy\" \"> --><-- <section \"id=\"section-alert-webhook\" \"> --> Alert Webhook <-- <section \"id=\"section-list-alert-webhooks\" \"> --> ibmcloud cis alert-webhooks List all alert webhooks. ibmcloud cis alert-webhooks -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-list-alert-webhooks\" \"> --> Command options -i, --instance: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-31256-32402","score":18.586168,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04195-6086-8151","score":21.841892,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04149-3050-4970","score":20.675241,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04148-0-1895","score":18.471624,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04334-33215-34565","score":17.699451,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-32129-33511","score":17.688662,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-31256-32402","score":17.331856,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-34286-35758","score":17.232666,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04145-1739-3868","score":17.129137,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04171-7-2143","score":17.072668,"text":"\nKnown limitations \n\nThe following information describes some limitations when working with IBM Cloud\u00ae Internet Services (CIS), as well as some suggested courses of action to improve your experience.\n\n\n\n* It is recommended that you use Chrome.\n* The free trial plan is limited to one instance per account. After you create a resource instance and add a domain to it, you are not allowed to add new resource instances for CIS. This restriction is enforced even if you delete a trial domain and then attempt to add a domain again to the same resource instance. You'll encounter an error if you attempt to do so.\n* For this service, we support subdomain delegation only using NS records from another provider. CNAME delegation is not supported.\n* A, AAAA, and CNAME wildcard records (\"*\") cannot be proxied.\n* When you delete a dedicated certificate, it might reappear in the list for a short time before the deletion is complete.\n* To modify your custom dedicated certificate\u2019s hostnames after ordering, you must order a new certificate and then delete the old one.\n* IP rules created with two letter country codes can only be made with the Challenge action. If you want to block visitors from a country, upgrade to the Enterprise plan or place rules on your server to fully block.\n\n\n\n\n\n Global load balancer \n\n\n\n* Cloud Internet Services allows you to use the character _ in load balancer hostnames. However, Kubernetes clusters cannot use _.\n* The Standard plan permits a maximum of 5 load balancers, pools, and health checks. Each pool can have a total of 6 origins, but only 6 unique origins are permitted throughout each CIS instance.\n* Health check events for deleted pools and origins cannot be filtered, but they still appear in the table.\n* If you filter Health check events by Pool Health, Degraded pools are included because they technically are healthy, but might contain 1 or more critical origins.\n* When adding the request header name for a health check, use Host, capitalized. Using a lower-case host for a health check fails.\n\n\n\n\n\n\n\n DNS \n\n\n\n* Exporting DNS records includes Cloudflare CNAME records that should be hidden.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-known-limitations"},{"document_id":"ibmcld_07411-2937-4769","score":17.056955,"text":"\n* TTL (Default value is 15 min)\n\n\n\n\n\n\n\n SRV type record \n\nTo add this record type, valid values must exist in the Name, Service Name, and Target fields. Use the list menu to select a protocol, which defaults to the UDP protocol. Additionally, you can specify Priority, Weight, and Port. These three fields default to a value of 1. Specify a TTL value from the list menu, with a default value of 15 min.\n\nRequired fields\n\n\n\n* Name\n* Service Name\n* Target\n* TTL (Default value is 15 min)\n* Protocol (Default value is UDP)\n* Priority (Default value is 1)\n* Weight (Default value is 1)\n* Port (Default value is 1)\n\n\n\n\n\n\n\n TXT type record \n\nTo add this record type, valid values must exist in the Name and Content fields. Specify a TTL value from the list menu, with a default value of 15 min.\n\nFor security and privacy reasons, it is recommended that you not use TXT type records for sensitive and confidential data.\n\nRequired fields\n\n\n\n* Name\n* Content\n* TTL (Default value is 15 min)\n\n\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, click the Edit icon to open a panel where you can update the record.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, click the Delete icon to open a panel where you can confirm the delete process.\n\n\n\n\n\n Importing resource records \n\nTo import resource records, take the following steps:\n\n\n\n1. From your DNS Services instance, select the zone to which you want to import records\n2. Click Select record action in the zone details section and choose Import records\n3. You can drag and drop the import file into the panel that appears, or click the link to upload from your computer\n\nImport files must be plain text format, and cannot exceed 8 MB\n4. Click Import records\n\n\n\nYour import file should follow this sample format:\n\nwww.test.com. 900 IN A 127.0.0.1\nwww.test.com. 900 IN AAAA ::1\nw3.test.com.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":22.7568,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04195-6086-8151","score":21.925476,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04195-7-1947","score":21.019297,"text":"\nSetting up your Domain Name System for CIS \n\nRead some specific instructions about how to configure your IBM Cloud\u00ae Internet Services Domain Name System (DNS) records, including how to configure Secure DNS.\n\n\n\n Adding DNS records \n\nYou can use the Type list menu to select the type of record you want to create. Each DNS record type has a Name and Time-To-Live (TTL) associated with it.\n\nWhatever is entered into the Name field has the domain name appended to it unless the domain name is manually appended in the field already (for example, if www or www.example.com is typed into the field, the API handles both as www.example.com). If the exact domain name is typed into the name field, then it won't be appended on itself (for example, example.com is handled as example.com). However, the list of DNS records only shows the names without the domain name added, so www.example.com is shown as www and example.com is shown as example.com. The TTL has a default value of Automatic, but can be changed by the user. A proxied DNS record always has a TTL of Automatic, so a newly proxied record adopts this configuration during this change.\n\nFor records such as A record, CNAME, and so on, the automatic TTL is 300s.\n\n\n\n A Type record \n\nTo add this record type, valid values must exist in the Name and IPv4 Address fields. A TTL also can be specified from the list menu, with a default value of Automatic.\n\nRequired Fields: Name, IPv4 Address Optional Field: TTL (default value is Automatic)\n\n\n\n\n\n AAAA Type record \n\nTo add this record type, valid values must exist in the Name and IPv6 Address fields. A TTL also can be specified from the list menu, with the default value of Automatic.\n\nRequired Fields: Name, IPv6 Address Optional Field: TTL (default value is Automatic)\n\n\n\n\n\n CNAME Type record \n\nTo add this record type, a valid value must exist in the Name field and a fully qualified domain name must be in the Domain Name (FQDN) field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04137-7-2068","score":20.838926,"text":"\nDNS concepts \n\nThis document contains some concepts and definitions related to the internet's domain name system (DNS) and how it affects your IBM Cloud\u00ae Internet Services (CIS) deployment.\n\nThe Domain Name System (DNS) underpins the web we use every day. It works transparently in the background, converting human-readable website names into computer-readable, numerical IP addresses that follow the [internet's RFC 1918 guidelines for IPv4 and RFC 4193 for IPv6](https:\/\/en.wikipedia.org\/wiki\/Private_network). In short, DNS servers match domain names, such as ibm.com, to their associated IP addresses, which most people do not need to know.\n\nThe DNS system looks up this IP address and host name information on a network of linked DNS servers across the internet, similarly to how people might look for someplace using a phone book or a map.\n\n\n\n Name servers \n\nA name server implements services that provide responses to queries against a directory service. It translates meaningful, text-based web or host identifiers into IP addresses.\n\nName server delegation takes place when a name server for a domain receives a request for a subdomain's records and responds with the name server's reference to the delegate server. This capability allows you to decentralize the management of a large domain (such as ibm.com).\n\nA custom domain name server allows you to utilize the DNS provider's servers with the customized reference name of your own domain. For example, you can define your name server to be ns1.cloud.ibm.com instead of ns1.acme.com.\n\n\n\n\n\n Secure DNS \n\nDNSSec is a technology to digitally 'sign' DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).\n\n\n\n\n\n Root record CNAME flattening \n\nIBM CIS supports a feature called \"CNAME Flattening.\" Using this method, root records can overcome the IETF RFC restriction that if a root record is a CNAME, it cannot have any other records for that domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-concepts"},{"document_id":"ibmcld_05351-9684-10230","score":20.570652,"text":"\nDelete your DNS records from CIS. For more information, see [Deleting DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cisdeleting-dns-records).\n3. Delete each project that you created. When you delete a project, all the components contained in that project are also deleted. For more information, see [Delete a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-projectdelete-project).\n\n\n\nNote that your custom domain is not deleted, but is no longer associated with the application that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-multiple-regions"},{"document_id":"ibmcld_04148-0-1895","score":20.233828,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04145-3314-5349","score":19.762815,"text":"\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n\n\n\n\n\n Who is the registrar for my domain? \n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n\n\n\n\n\n I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS? \n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04334-34286-35758","score":19.603472,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04177-7-2309","score":19.598412,"text":"\nManaging your CIS deployment \n\nYou'll begin by using the Overview screen as your working base of operations. It shows all of the current parameters for your deployment.\n\nOnce you've set up your DNS and configured it, you are ready to go!\n\n\n\n Using the Overview screen \n\nUsing the Overview screen, you can see the status of all your selections. Each setting links to the section of the user interface where the setting is configured. To modify any selection, you can navigate by clicking the link for the setting. For example, to change the load balancer configuration or add a new load balancer, click the Load Balancer field.\n\nOn the Overview screen, you might see that your domain name configuration is in Pending status, or in Active status. Pending status indicates that your domain is not fully set up, yet. You have to update your DNS provider or registrar with the name servers that are provided as part of the setup process.\n\nEnterprise only: The Service Details section of the Overview also allows you to add additional domains to your instance of CIS, and to switch between multiple domains.\n\n\n\n\n\n Changing the Service mode \n\nIn the Service Mode section of the Overview page is a list menu to select one of two modes:\n\n\n\n* Defense Mode helps protect against existing or predicted DNS attacks. This mode prevents all traffic from reaching your origin servers through your domain.\n* Pause Service disables all security and performance benefits to your domain. DNS functions still resolve for your website, but traffic is sent directly to configured origins.\n\n\n\n\n\n Setting up Service mode \n\n\n\n1. Select the mode you want from the list menu.\n2. Click Activate mode.\n3. Confirm or cancel the selection in the confirmation pop-up.\n\n\n\nA notification appears on all pages to show that either Pause Service or Defense Mode is active. To return to normal operation, click Deactivate mode in the notification banner.\n\n\n\n\n\n\n\n Configuring and managing your DNS \n\nGo to the Reliability section, click the DNS tab and add a record. Type in the information about your DNS record and then click Add record to implement your changes.\n\nAfter creating your records, consider turning on the Proxy setting. Most of the features of CIS require that the internet traffic to your site flow through CIS infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment"},{"document_id":"ibmcld_04166-1564-3481","score":19.383879,"text":"\nA non-CIS domain cannot CNAME to a CIS domain unless the non-CIS domain is added to a CIS account.\n\nAttempting to directly access DNS records used for CIS CNAME setups also causes error 1001.\n\nDisable Always Online if using Custom Hostnames (SSL for SaaS).\n\n\n\n\n\n\n\n Error 1002: DNS points to Prohibited IP \n\nCommon causes for 1002 errors when a DNS points to a prohibited IP address are:\n\n\n\n* A DNS record in your CIS DNS points to one of CIS's IP addresses.\n* An incorrect target is specified for a CNAME record in your CIS DNS.\n* Your domain is not on CIS but has a CNAME that refers to a CIS domain.\n\n\n\n\n\n Resolution \n\nUpdate your CIS A or CNAME record to point to your origin IP address instead of a CIS IP address:\n\n\n\n1. Contact your hosting provider to confirm your origin IP address or CNAME record target.\n2. Log in to your CIS account.\n3. Select the domain that generates error 1002.\n4. Select the DNS app.\n5. Click Value for the A record to update.\n6. Update the A record.\n\n\n\nTo ensure your origin web server doesn\u2019t proxy its own requests through CIS, configure your origin webserver to resolve your CIS domain to:\n\n\n\n* The internal NAT-ed IP address, or\n* The public IP address of the origin web server.\n\n\n\n\n\n\n\n\n\n Error 1002: Restricted \n\nThe most common cause of 1002: Restricted errors is when the CIS domain resolves to a local or disallowed IP address or an IP address not associated with the domain.\n\n\n\n Resolution \n\nIf you own the website:\n\n\n\n1. Confirm your origin web server IP addresses with your hosting provider\n2. Log in to your CIS account\n3. Update the A records in the CIS DNS to the IP address confirmed by your hosting provider\n\n\n\n\n\n\n\n\n\n Error 1003 Access Denied: Direct IP Access Not Allowed \n\nThe most common cause of 1003 errors is when a client or browser directly accesses a CIS IP address.\n\n\n\n Resolution \n\nBrowse to the website domain name in your URL instead of the CIS IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-html-1xxx-errors"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15141-7808-9997","score":11.696161,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_04122-7-1660","score":10.937313,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04136-1771-3582","score":9.673625,"text":"\nAn attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model). The goal of these attacks is to exhaust the resources of the victim, by targeting the layer where web pages are generated on the server and delivered to the visitors in response to HTTP requests (that is, the application layer). Layer-7 attacks are challenging, because the traffic can be difficult to identify as malicious.\n\n\n\n\n\n Protocol attacks \n\nProtocol attacks utilize weaknesses in Layer 3 and Layer 4 of the ISO protocol stack to render the target inaccessible. These attacks, also known as a state-exhaustion attacks, cause a service disruption by consuming all the available state table capacity of web application servers, or of intermediate resources such as firewalls and load balancers.\n\n\n\n\n\n Volumetric attacks \n\nThis category of attacks attempts to create congestion by consuming all available bandwidth between the target and the wider internet. Large amounts of data are sent to a target using a form of amplification, or by other means of creating massive traffic, such as requests from a botnet.\n\n\n\n\n\n\n\n What do I do if I\u2019m under a DDoS attack? \n\nStep 1: Turn on \u201cDefense mode\" from the Overview screen.\n\nStep 2: Set your DNS records for maximum security.\n\nStep 3: Do not rate-limit or throttle requests from IBM CIS, we need the bandwidth to assist you with your situation.\n\nStep 4: Block specific countries and visitors if necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_06896-7-2172","score":8.78389,"text":"\nComparing Layer-2 and Layer-3 connections for Direct Link \n\nIBM Cloud\u00ae Direct Link accepts OSI Layer-2 and Layer-3 partner interconnections from network service providers (NSPs). Some network service providers offer services for both of these layers on different networks, however, some providers might choose not to interconnect all of their networks into IBM Cloud.\n\nWhen planning your IBM Cloud Direct Link deployment, consider the characteristics that are associated with Layer-2 and Layer-3 connections, so you can create a deployment that best suits your needs.\n\n\n\n Considerations for Layer-2 connections \n\nFor each VLAN-based virtual circuit, which you create with a Layer-2 partner interconnection, you must configure and establish a BGP session between your on-premises routers and the IBM Cloud XCR. IBM Cloud provides you with a \/31 IPv4 assignment to establish a BGP session with your router.\n\n\n\n* Layer-2 networks offer options for simple one-to-one connections between enterprises and IBM Cloud.\n* Layer-2 services rely on VLANs instead of IP addresses.\n* Layer-2 services might be lower cost and lower latency, and they might consume less overhead than Layer-3 services.\n* Layer-2 networks do not impose restrictions on the Layer-3 features that an enterprise can enable.\n\n\n\n\n\n\n\n Considerations for Layer-3 connections \n\nFor Layer-3 connections, for each virtual circuit, your service provider establishes a BGP session between IBM Cloud XCRs and the provider's edge routers. You do not need to configure BGP with IBM Cloud for your on-premises router because your service provider manages the BGP configuration to IBM Cloud. This means when you order Direct Link Connect via the IBM Portal, you need to populate the Layer 3 providers ASN for the BGP session, not your customer ASN\n\n\n\n* Layer-3 IP VPN or AVPN networks enable \"any-to-any\" connectivity.\n* Layer-3 networks require the network service provider to maintain a BGP session between the enterprise and IBM Cloud.\n* Certain network service providers might restrict certain functionalities across their network when using Layer-3 connections, such as ASN prepend, GRE tunneling, and so forth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-comparing-layer-2-layer-3"},{"document_id":"ibmcld_14311-2669-4435","score":8.716468,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-3835-5367","score":8.341179,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-7-1811","score":8.212966,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_06896-1648-3179","score":7.793345,"text":"\nThis means when you order Direct Link Connect via the IBM Portal, you need to populate the Layer 3 providers ASN for the BGP session, not your customer ASN\n\n\n\n* Layer-3 IP VPN or AVPN networks enable \"any-to-any\" connectivity.\n* Layer-3 networks require the network service provider to maintain a BGP session between the enterprise and IBM Cloud.\n* Certain network service providers might restrict certain functionalities across their network when using Layer-3 connections, such as ASN prepend, GRE tunneling, and so forth. Be sure to check with your provider about possible restrictions.\n\n\n\n\n\n\n\n Partner interconnection table \n\nThe following table summarizes the type of connections that each IBM Cloud partner provides.\n\n\n\nTable 1. Partner interconnection table\n\n Partners Interconnection type \n\n AT&T NetBond for Cloud Layer 3 \n AT&T Cloud Gateway (formerly known as RedFringe) Layer 3 \n Bell Canada Layer 3 \n British Telecom Layer 3 \n CenturyLink IP VPN Layer 3 \n CenturyLink Dynamic Connections Layer 2 \n Chief Telecomm Layer 2 \n China Unicom Layer 3 \n Colt Layer 2 \n Console Connect Layer 2 \n Epsilon Layer 2 \n EU Networks Layer 2 \n IBM BlueFringe Layer 3 \n Intercloud Layer 3 \n IXReach Layer 2 \n Megaport Layer 2 \n Neutrona Layer 2 \n nextGen GNPP Layer 3 \n NTT Layer 3 \n Orange Business Services Layer 3 \n PacketFabric Layer 2 \n Softbank Layer 3 \n SES Networks Layer 2 \n Tata IZO\u2122 Private Connect Layer 3 \n Arelion Layer 3 \n Telstra Layer 3 \n Tokai Layer 2 \n Verizon SCI Layer 3 \n Vodafone Layer 3 \n Zayo Cloud Link Layer 2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-comparing-layer-2-layer-3"},{"document_id":"ibmcld_11788-8466-10910","score":7.7532177,"text":"\nFor any other connections into your location that your applications require, you can use Satellite Link to create layer 4 communications by setting up an endpoint for each destination resource in your location. All connections through your endpoints are always under your control, including completely disabling endpoints.\n\n\n\n\n\n How do I make my data secure in transit? \n\nLink endpoints between your location and IBM Cloud are secured through two levels of encryption: high-security encryption from the location\u2019s connector to IBM Cloud that is provided by IBM , and an optional additional encryption layer between the source and destination resources.\n\nAll data that is transported over Satellite Link is encrypted using TLS 1.3 standards. This level of encryption is managed by IBM.\n\nWhen you create an endpoint, you can optionally provide another level of encryption by specifying [data encryption protocols](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloudlink-protocols) for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify TLS encryption for the connection that goes over the internet. You can provide your own signed certificates to ensure both internal security and operational auditability without exposing any data contents. IBM only transports the encrypted connection, and your resources must be configured for the data encryption protocols that you specify.\n\n\n\n\n\n\n\n Encryption protocols \n\nAll communication over Satellite Link is encrypted by IBM. When you create an endpoint, you can optionally specify an additional data encryption protocol for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify your own additional TLS encryption for the connection that goes over the internet. Note that your resources must be configured for the data encryption protocols that you specify.\n\nReview the following information about how Satellite Link handles each type of connection protocol.\n\nIf you use the Satellite console to create an endpoint, the destination protocol is inherited from the source protocol that you select. To specify a destination protocol, use the CLI to create an endpoint and include the --dest-protocol option in the ibmcloud sat endpoint create command.\n\n\n\n TCP and TLS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloud"},{"document_id":"ibmcld_04107-7548-9466","score":7.7456427,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09513-12728-14481","score":13.04694,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_13616-13587-15670","score":11.956372,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_09109-6121-7923","score":11.690017,"text":"\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_02776-3988-5695","score":11.031291,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_08515-6389-8309","score":10.798931,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keys"},{"document_id":"ibmcld_10889-1448-3175","score":10.545834,"text":"\nThe GDPR imposes strict rules on those hosting and processing personal data, anywhere in the world.\n\nIBM is committed to providing our clients and IBM Business Partners with innovative data privacy, security, and governance solutions to assist them in their journey to GDPR readiness. Data and data protection are becoming increasingly important to individuals and society. Enterprises must earn the client\u2019s trust in their ability to steward information.\n\nIBM Cloud is agile and scalable with built-in data security, and privacy services and solutions that can be consumed on premises or through public cloud. Our comprehensive data security platform helps safeguard sensitive data wherever it resides and provides a full range of data protection capabilities.\n\n\n\n\n\n Environmental information \n\nIBM Cloud, as a user and as a provider, is environmentally conscious and strives to provide power efficiency and recycling in our data centers. As such, the servers that are put in service within the IBM Cloud comply with Commission Regulation (EU) 2019\/424 of 15 March 2019 laying down ecodesign requirements for servers and data storage products (EU Lot 9).\n\nFor details, see the following data sheets on our physical hardware in the cloud:\n\n\n\n* [Rack Mount Server 618U-TR4T+](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X10DRU-i+.pdf)\n* [Rack Mount Server 6019U-TN4R4T](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11DPU.pdf)\n* [Rack Mount Server 5019C-WR-04](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11SCW.pdf)\n* [Rack Mount Server 5019S-W4TR](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11SSW-4TF.pdf)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-compliance"},{"document_id":"ibmcld_08433-6344-8271","score":10.495204,"text":"\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nA successful POST \/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-standard-keys"},{"document_id":"ibmcld_00511-7-1875","score":10.45424,"text":"\nData privacy and governance \n\nAs a pioneer in the provision of a fully managed and globally distributable Database-as-a-Service, IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae allows customers to locate data in any global IBM Cloud\u00ae or AWS region. By providing customers with such high levels of data mobility to serve the local needs of customers, IBM\u00ae, and IBM Cloudant take data privacy and governance seriously.\n\nIBM Cloud data privacy processing processes and procedures are documented within the IBM Cloud DPA. This Data Processing Addendum (DPA) and its applicable DPA Exhibits apply to the Processing of Personal Data by IBM Cloud on behalf of Client (Client Personal Data). The processing of Personal Data is subject to the General Data Protection Regulation 2016\/679 (GDPR). It is also subject to any other data protection laws that are identified at [Data Protection Laws](https:\/\/www.ibm.com\/support\/customer\/csol\/terms?id=DPA-DPL&lc=endetail-document) in order to provide services (Services) according to the Agreement between Client and IBM Cloud. The IBM Cloud DPA can be found at [Data Processing Addendum](https:\/\/www.ibm.com\/dpa).\n\nIn addition to the DPA, the cloud services contain DPA exhibits that detail the types of data that is processed by this service. Cloud services also contain the relevant processing locations (including hosting locations) where client PI is processed. The relevant DPA exhibit for IBM Cloudant can be found on the [IBM Cloud Terms site](https:\/\/www.ibm.com\/support\/customer\/csol\/contractexplorer\/cloud\/datasheets\/2052E430379B11E58B2CB2A838CE4F20\/en).\n\nIBM Cloud relies on Standard Contractual Clauses (as our primary data transfer mechanism) in our customer contracts. IBM Cloud also relies on numerous supplementary measures to help clients ensure an adequate level of protection when they transfer personal data outside of the EU\/EEA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-privacy-and-governance"},{"document_id":"ibmcld_09109-4709-6562","score":10.216173,"text":"\n<br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n IAM_token Required. Your IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the curl request. <br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br> <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n correlation_ID The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. <br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_09492-16883-18851","score":9.941793,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6173196815}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07859-4616-6150","score":9.190905,"text":"\nThe security engineering principles in SA-8 cannot be properly applied if individuals that design, code, and test information systems and system components (including information technology products) do not understand security. Therefore, organizations include qualified personnel, for example, chief information security officers, security architects, security engineers, and information system security officers in system development life cycle activities to ensure that security requirements are incorporated into organizational information systems. It is equally important that developers include individuals on the development team that possess the requisite security expertise and skills to ensure that needed security capabilities are effectively integrated into the information system. Security awareness and training programs can help ensure that individuals having key security roles and responsibilities have the appropriate experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security requirements into enterprise architecture also helps to ensure that important security considerations are addressed early in the system development life cycle and that those considerations are directly related to the organizational mission\/business processes. This process also facilitates the integration of the information security architecture into the enterprise architecture, consistent with organizational risk management and information security strategies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-3"},{"document_id":"ibmcld_16016-7-2174","score":7.4476566,"text":"\nAbout security groups \n\nIBM Cloud\u00ae Security Groups for VPC give you a convenient way to apply rules that establish filtering to a target of a virtual server instance, based on its IP address. Security group targets include virtual server instance network interfaces, endpoint gateways, and load balancers. When you create a security group, you configure it to create the network traffic patterns you want.\n\nBy default, a security group is set up with rules that deny all inbound traffic and permit all outbound traffic. As new rules are added to a security group, the new rules redefine the scope of permitted inbound or outbound traffic.\n\nRules are stateful. To have stateful rules means when you create a rule that allows traffic one way, the rule automatically permits reverse traffic. For example, if you create a rule to allow inbound TCP traffic on port 80, the rule also allows replying outbound TCP traffic on port 80 back to the originating host, without the need for another rule.\n\nSecurity groups are scoped to a single VPC. This scoping implies that a security group can be attached to any security group target within the same VPC. You can set up a security group's policy to allow traffic between all members of a security group.\n\nWhen you create a new security group, it is assigned a default security group policy. You can modify the default security group policy settings and the rules of individual security groups.\n\nWhen you create a resource that uses a security group and don't specify a security group, the resource's primary network interface is attached to the default security group of that resource's VPC.\n\nUpdating the rules fo the default security group is a separate process from updating the default security group policy. If you edit the rules of the default security group, those edited rules then apply to all current and future servers in the group. For more information, see [Updating default security group rules](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-updating-the-default-security-groupupdating-the-default-security-group).\n\n\n\n Security group targets \n\nA target is any resource you attach or detach a security group to or from.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups&interface=ui"},{"document_id":"ibmcld_16016-1760-3678","score":6.991297,"text":"\nIf you edit the rules of the default security group, those edited rules then apply to all current and future servers in the group. For more information, see [Updating default security group rules](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-updating-the-default-security-groupupdating-the-default-security-group).\n\n\n\n Security group targets \n\nA target is any resource you attach or detach a security group to or from. Security group targets include virtual server instance network interfaces, endpoint gateways, and load balancers.\n\nEach resource that can send and receive traffic can have a security group policy configured for it. This can include virtual server interfaces, bare metal servers, load balancers, any end point gateways along your data path, and more.\n\nYou can associate a security group policy with any resource along your data path.\n\n\n\n\n\n Security groups versus network ACLs \n\nSecurity groups are tied to a resource, whereas Network Access Control Lists (NACLs) are tied to the subnet.\n\nNACLs are applicable at the subnet level, so any resource in the subnet with an associated NACL will follow rules of the NACL. However, that\u2019s not the case with security groups. Security groups must be assigned explicitly to the resource. Also, unlike NACLs, a security group can be applied to multiple resources across subnets and even across zones.\n\nNACLs are stateless.\n\nBecause NACLs are not stateful, if you want to permit traffic both ways on a target you must set up two rules.\n\nZoom\n\n![Security groups across instances and zones](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/\/images\/security-groups-across-zones.svg)\n\nFigure 1: Security groups across instances and zones\n\n\n\n\n\n Defining security group rules \n\nEvery security group consists of a set of rules. The security group examines all of its rules before allowing any traffic to enter or leave the instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups&interface=ui"},{"document_id":"ibmcld_15845-46631-48404","score":6.953853,"text":"\nEvaluate your strategy and consider creating another security group with similar rules.\n\nFor further instructions to fix this problem, refer to the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpc-on-classic) or the [Using Security Groups document](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic-network?topic=vpc-on-classic-network-using-security-groups).\n\nIf this problem persists, [contact support](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-getting-help-and-support).\n\n\n\n\n\n security_group_last_security_group_is_default \n\nMessage: The default security group cannot be removed when it is the only security group attached.\n\nA network interface must be attached to at least one security group. It will be attached to the VPC's default security group if one is not specified. Attach the interface to a different security group, then try again to detach it from the default security group. For information on the default security group, refer to the [Using Security Groups document](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic-network?topic=vpc-on-classic-network-using-security-groups).\n\nIf this problem persists, [contact support](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-getting-help-and-support).\n\n\n\n\n\n security_group_limit_exceeded \n\nMessage: Exceeded security group limit.\n\nYou have attempted to create a new security group, but you are currently at your account quota. The quotas per resource are specified in [Quotas and limits for VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-quotassecurity-groups-quotas). Evaluate your strategy for assigning instances to security groups. It is often possible to reduce the overall number of security groups by assigning multiple instances to the same security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_07712-0-2413","score":6.7855835,"text":"\n\n\n\n\n\n\n  CM-4 - Security Impact Analysis \n\n\n\n  Control requirements \n\nCM-4 - 0\n:   The organization analyzes changes to the information system to determine potential security impacts prior to change implementation.\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities\n*  Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies\n*  Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely\n*  Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts\n*  Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities\n*  Check whether DevSecOps Toolchain source code contains no secrets\n*  Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code\n*  Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nOrganizational personnel with information security responsibilities (e.g., Information System Administrators, Information System Security Officers, Information System Security Managers, and Information System Security Engineers) conduct security impact analyses. Individuals conducting security impact analyses possess the necessary skills\/technical expertise to analyze the changes to information systems and the associated security ramifications. Security impact analysis may include, for example, reviewing security plans to understand security control requirements and reviewing system design documentation to understand control implementation and how specific changes might affect the controls. Security impact analyses may also include assessments of risk to better understand the impact of the changes and to determine if additional security controls are required. Security impact analyses are scaled in accordance with the security categories of the information systems.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-4"},{"document_id":"ibmcld_05215-7-2428","score":6.7513733,"text":"\nGetting started with IBM Cloud Pak for Security as a Service \n\nIBM Cloud Pak\u00ae for Security as a Service provides an open security platform that connects to your existing data sources to generate deeper insights and enable you to act faster with automation.\n\nBy using open standards and IBM innovations, Cloud Pak\u00ae for Security as a Service can securely access IBM and third-party tools to search for threat indicators across any cloud or on-premises location. Connect your workflows with a unified interface so you can make better risk-based decisions and respond faster to security incidents. Use Cloud Pak\u00ae for Security as Service to orchestrate and automate your security response so that you can better prioritize your team's time.\n\n\n\n What's inside this Cloud Pak \n\nIBM Cloud Pak\u00ae for Security as a Service includes the following offerings.\n\n\n\n* IBM\u00ae Security Threat Intelligence Insights delivers unique, actionable, and timely threat intelligence. The application provides most of the functions of IBM X-Force\u00ae Exchange.\n* IBM\u00ae Security Data Explorer enables customers to do federated search and investigation across their hybrid, multi-cloud environment in a single interface and workflow.\n* IBM\u00ae Security Case Management for IBM Cloud Pak\u00ae for Security provides organizations with the ability to track, manage, and resolve cybersecurity incidents.\n* IBM\u00ae Security Orchestration & Automation provides most of the IBM Security Orchestration, Automation, and Response Platform feature set. If you have an Orchestration & Automation license, you can choose between the stand-alone version on a virtual appliance, or the application on Cloud Pak for Security.\n* IBM\u00ae QRadar\u00ae Proxy provides communication between IBM Cloud Pak\u00ae for Security and IBM QRadar or QRadar on Cloud. This communication uses APIs to pull powerful IBM QRadar data into the QRadar Security Information and Event Management (SIEM) dashboards.\n* IBM\u00ae Security Threat Investigator automatically analyzes and investigates cases to help you make more informed decisions.\n* IBM\u00ae Security Risk Manager provides early visibility into potential security risks by correlating insights from multiple vectors to help you prioritize remedial actions based on prescriptive recommendations.\n* Detection and Response Center (Beta) provides a unified overview of your organization's security posture through use cases from different security tools and platforms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-security-saas?topic=cloud-pak-security-saas-getting-started-saas"},{"document_id":"ibmcld_11605-1954-3317","score":6.6956096,"text":"\nFor more information, see [IBM.com - IBM Security - SAP Security and GRC Strategy Services](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy)\n\n\n\n Procedure to request IBM Security Services for SAP \n\nTo begin with IBM Security Services for SAP, use either:\n\n\n\n* Live Chat with IBM Security Sales, by using [IBM.com - IBM Security](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy) and click Let's talk in the botttom-left\n* [Email with IBM Security Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-security)\n\n\n\n\n\n Procedure to request IBM Security Services for SAP, directly from IBM Cloud for VMware Solutions \n\nBecause of the close collaboration between IBM Cloud for VMware with SAP and IBM Security Services for SAP, the quickest way to use IBM Security Services in combination with SAP workloads on VMware is to:\n\n\n\n1. Open the IBM Cloud for VMware Solutions console. Scroll down to the Services section and on the Featured Workload Solutions card click IBM Security Services for SAP.\n2. On the IBM Security Services for SAP page, in the Engage IBM Security Services box, provide the requested details, and click Request a consultation.\n\nAn IBM Cloud for VMware Solutions representative will contact you by using your IBM Cloud contact information to help you with the solution that you need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-security-services"},{"document_id":"ibmcld_16016-7538-9878","score":6.6814227,"text":"\nFor example, let's say you are part of an organization and someone with access to your organization's account modifies the default security group's policy to be different than the default policy you get when you create a new security group. Your team member is a very security-conscious customer, and they change the default security group settings to deny all inbound and outbound network traffic.\n\nIn this example, if you create a new resource, it will initially be assigned to your VPC's default security group. This default security group's policy denies all inbound and outbound network traffic because of the deny rules your security-conscious team member set up. As a result, traffic to and from your new resource will have this deny behavior applied.\n\nContinuing with this example, if you are discontented with the default security group policy your team member set up, one solution is to create a new security group with customized settings and apply it to your resource. Another solution is to alter the policy on the default security group. Creating a new security group with customized settings is the easiest solution, because you can create rules that apply to the single resource you want to impact. If you alter the policy of the default security group, these changes will apply not only to the resource you want to impact, but to all other resources that have been assigned to the default security group.\n\nAny new rules you create on the default security group policy will be applied to all current and future resources that are assigned to the default security group.\n\nFor more information on updating the default security group, see [Updating default security group rules](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-updating-the-default-security-groupupdating-the-default-security-group).\n\n\n\n\n\n Use Case 2: Customizing security groups and security group policies when creating a new resource \n\nThe following diagram illustrates the potential customization options when you create a new resource. If a User creates a new resource and take no further action to specify a security group to attach it to, their new resource is assigned to the VPC's default security group. This default security group will take on the default security group policy or follow a customized policy previously configured by members of your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups&interface=ui"},{"document_id":"ibmcld_16016-5946-8052","score":6.5841346,"text":"\nFor more information on setting up security group rules using the API, see [Setting up the security group for your virtual server instance by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configuring-the-security-group&interface=apisg-using-api).\n\n\n\n\n\n Getting started \n\nTo get started using security groups, follow these steps:\n\n\n\n1. Decide if you want to create a new security group for your resource, and [Create your security group](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configuring-the-security-group&interface=ui).\n2. Review the public gateway that you've created in the [IBM Cloud console](https:\/\/cloud.ibm.com\/login).\n\n\n\n\n\n\n\n Security group use cases \n\nCreating a security group is a standard way for a user to apply rules that filter network traffic patterns to and from their resources. Your ability to perform the following actions depends on your level of authorization in your account. Contact your administrator if you have questions about your account authorizations.\n\n\n\n Use Case 1: Changing a resource's default security group \n\nEvery VPC has a default security group, which is a security group that is created for a user. That default security group also has a default policy. This default policy is the same default policy that is assigned to security groups you create before you customize the policy's setting by adding or removing rules.\n\nA default security group is different from the default policy for new security groups. You can customize both the policy on your default security group, as well as the default policy assigned to new security groups.\n\nFor example, let's say you are part of an organization and someone with access to your organization's account modifies the default security group's policy to be different than the default policy you get when you create a new security group. Your team member is a very security-conscious customer, and they change the default security group settings to deny all inbound and outbound network traffic.\n\nIn this example, if you create a new resource, it will initially be assigned to your VPC's default security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups&interface=ui"},{"document_id":"ibmcld_10689-18215-20114","score":6.555355,"text":"\nThe security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-security-group"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04109-7-2036","score":19.644527,"text":"\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country\/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_13915-3198-5235","score":19.25963,"text":"\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2\n\nIn the ruleset, ALLOW_LEGACY, there are two rules defined. The first rule drops any traffic sourced from an address group named network-group1. The second rule discards and logs any traffic destined for the telnet port (tcp\/23) from the address group named network-group2. The default-action indicates that anything else is accepted.\n\n\n\n\n\n Allowing data center access \n\nIBM\u00a9 offers several IP subnets to provide services and support to systems running within the data center. For example, DNS resolver services are running on 10.0.80.11 and 10.0.80.12. Other subnets are used during provisioning and support. You can find the IP ranges used in the data centers in [this topic](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-dedicated?topic=hardware-firewall-dedicated-ibm-cloud-ip-ranges).\n\nYou can allow data center access by placing the proper SERVICE-ALLOW rules at the beginning of the firewall rule sets with an action of accept. Where the rule set must be applied depends on the routing and firewall design being implemented.\n\nIt is recommended that you place the firewall rules in the location which causes the least duplication of work. For example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_04334-65500-67175","score":19.070473,"text":"\n[Deprecated] ibmcloud cis firewall-update FIREWALL_RULE_ID (-t, --type Type) (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n\n\n* FIREWALL_RULE_ID: The ID of firewall rule. Required.\n\n\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--json\n: The JSON file or JSON string used to describe a firewall rule. Required.\n\n\n\n* For --type access-rules: The JSON data describing a firewall access rule as follows.\n\n\n\n* Option fields are mode, notes.\n\n\n\n* mode: The type of action to perform. Valid values: block, challenge, whitelist, js_challenge.\n* notes: Some useful information about this rule to help identify the purpose of it.\n\n\n\n\n\n\n\nSample JSON data:\n\n{\n\"mode\": \"challenge\",\n\"notes\": \"This rule is added because of event X that occurred on date xyz\",\n}\n\n\n\n* For --type ua-rules: The JSON data describing a user-agent rule as follows.\n\n\n\n* Required fields are mode, configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_13915-6476-8449","score":18.491154,"text":"\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_13927-3027-3785","score":18.357311,"text":"\nThe following is an example of SERVICE-ALLOW. This is not a complete private IP rule set.\n\nset firewall name SERVICE-ALLOW rule 1 action 'accept'\nset firewall name SERVICE-ALLOW rule 1 destination address '10.0.64.0\/19'\nset firewall name SERVICE-ALLOW rule 2 action 'accept'\nset firewall name SERVICE-ALLOW rule 2 destination address '10.1.128.0\/19'\nset firewall name SERVICE-ALLOW rule 3 action 'accept'\nset firewall name SERVICE-ALLOW rule 3 destination address '10.0.86.0\/24'\n\nAfter you define the firewall rules, you can assign them as you see fit. Two examples are listed.\n\nApplying to a zone: set zone-policy zone private from dmz firewall name SERVICE-ALLOW\n\nApplying to a bond interface: set interfaces bonding bond0 firewall local name SERVICE-ALLOW","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-setting-up-nat-rules-on-vyatta-5400"},{"document_id":"ibmcld_04334-72037-73413","score":18.264692,"text":"\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet firewall rule details.\n\nibmcloud cis firewall dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-73111-74523","score":18.237799,"text":"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_13915-4792-6873","score":17.760328,"text":"\nFor example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:\n\nin - The firewall is checked against packets entering through the interface. These packets can be traversing or be destined for the VRA.\n\nout - The firewall is checked against packets leaving through the interface. These packets can be traversing or originating on the VRA.\n\nlocal - The firewall is checked against packets which are destined directly for the VRA.\n\nAn interface can have multiple rule sets applied in each direction. They are applied in the order of configuration. Note that it is not possible to firewall traffic originating from the VRA device using per-interface firewalls.\n\nAs an example, to assign the ALLOW_LEGACY rule set to the in option for the bp0s1 interface, you would use the configuration command:\n\nset interfaces dataplane dp0s1 firewall in ALLOW_LEGACY\n\n\n\n\n\n\n\n Control Plane Policing (CPP) \n\nControl plane policing (CPP) provides protection against attacks on the IBM Cloud\u00ae Virtual Router Appliance by allowing you to configure firewall policies that are assigned to desired interfaces and applying these policies to packets entering the VRA.\n\nCPP is implemented when the local keyword is used in firewall policies that are assigned to any type of VRA interface, such as data plane interfaces or loopback. Unlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_14707-5739-7927","score":17.631783,"text":"\n* Creates a management VM that runs Linux and Ansible. The management VM changes the security policy on the vSRX appliances at the required times.\n* Uses a cron job on the automation server to schedule the running of an Ansible playbook that changes the inbound firewall rule from \"Deny\" to \"Allow\". After the backup window, the customer changes the inbound firewall rule from \"Allow\" to \"Deny\".\n\n\n\nTo enable cyberbackup of the production environment, the customer:\n\n\n\n* Follows the prerequisite tasks on the bare metal server to prepare the server ready for its role as a Linux hardened repository.\n* Uses the Veeam backup server enabled the Linux hardened repository.\n* Removes the isolated recovery environment vCenter from the Veeam backup server configuration.\n* Adds the production vCenter to the Veeam backup server configuration.\n* Creates and deploys the Veeam VMware proxy servers to the production environment.\n* Creates cyber-backup jobs for the required production VMs.\n\n\n\nTo enable cyber-related tasks on the cyberbackups, such as scanning backup files for malware and recovering VMs from backups on isolated networks, the customer:\n\n\n\n* Creates a segment for their cybertoolsets, which include the malware scanners.\n* Creates a new T1 named Isolated-NW-T1 and links it to the workload T0. The Isolated-NW-T1 is configured to advertise all NAT IPs only. This action stops the advertisement of connected segments and advertises only the NAT IP addresses of the segments.\n* Creates the following two distributed firewall groups:\n\n\n\n* Name: Cyber-Tools-Segments, Category: Segments, Members: cybertools\n* Name: Cyber-Isolated-Segments, Criteria: Segment Tag Equals Isolated-Segments, Scope: Cyber\n\n\n\n* Creates a distributed firewall policy that is named Cyber-Isolated, which contains the following rules to satisfy their isolation requirements:\n\n\n\n\n\nTable 2. NSX-T distributed firewall rules\n\n Rule Name Sources Destinations Services Action \n\n Allow access to Isolated Cyber-Tools-Segments Cyber-Isolated-Segments All Allow \n Allow access between Isolated Cyber-Isolated-Segments Cyber-Isolated-Segments All Allow \n Deny access to Isolated Any Cyber-Isolated-Segments All Deny","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ire-nw"},{"document_id":"ibmcld_07578-1007575-1009533","score":17.422293,"text":"\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'\n\nThe combination of Source NAT and firewall achieves the required design goal.\n\nEnsure that the rules are appropriate for your design, and that no other rules allow traffic that should be blocked.\n* How do I protect the VRA itself with a zone-based firewall?\n\nThe VRA does not have a local zone. You can use the Control Plane Policing (CPP) functionality instead as it is applied as a local firewall on loopback.\n\nThis is a stateless firewall and you must explicitly allow the returning traffic of outbound sessions that originate on the VRA itself.\n* How do I restrict SSH and block connections that come from the internet?\n\nIt is considered a best practice to not allow SSH connections from the internet, and to use another means of accessing the private address, such as SSL VPN.\n\nBy default, the VRA accepts SSH on all interfaces. To listen only for SSH connections on the private interface, you must set the following configuration:\n\nset service ssh listen-address '10.1.2.3'\n\nKeep in mind that you must replace the IP address with the address that belongs to the VRA.\n\n\n\nPlatform Building infrastructure\n\n\n\n* What is the RMM server?\n\nRackWare Management Module (RMM) server is a software appliance that is offered by RackWare that replatforms your server from a VMware (on-premises or classic) to an IBM Cloud VPC virtual server instance.\n* Where can I find more information about the RMM server?\n\nFor RMM server overview information, see [RackWare's Cloud Migration](https:\/\/www.rackwareinc.com\/cloud-migration) documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":17.101849,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":17.06231,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":16.54102,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":15.979497,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":14.889403,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_06004-29614-31438","score":13.971069,"text":"\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_06225-7-1999","score":12.924599,"text":"\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_app"},{"document_id":"ibmcld_10645-7-1995","score":12.835217,"text":"\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_app"},{"document_id":"ibmcld_00962-3246-5702","score":12.390709,"text":"\nThe Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds. Over time, the traffic that is sent to the new version is increased until all of the traffic is sent there, at which point you can stop the old production environment. For rapid rollback while deployment is in progress, you can route all of the traffic to the original production environment. Since this strategy requires two full production environments only during deployment, the overall resource usage is lower than for the Blue-Green deployment. The Canary release deployment strategy is the slowest to move from a previous release to a current release of the software that is being deployed. Canary deployments allow organizations to test two different software versions side by side in production.\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https:\/\/cloud.ibm.com\/registration), with a Standard plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-vpc"},{"document_id":"ibmcld_13429-166159-168045","score":12.101451,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":25.983921,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":24.79351,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":23.697071,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":23.654877,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":21.566721,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":19.123835,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-14062-16080","score":18.92762,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12332-1034-2510","score":15.870344,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":15.154311,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":13.312807,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":24.444145,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":23.322874,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":21.474346,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":21.388416,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10852-43319-44485","score":17.914736,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":14.460304,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-6582-8092","score":13.110942,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":12.755876,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-2964-4516","score":12.5886135,"text":"\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https:\/\/jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_07546-13714-15229","score":12.3674965,"text":"\n@Override\npublic void onReceive(final ENSimplePushNotification message) {\nif (message.getActionName().equals(\"Accept Button\")){\nSystem.out.print(\"Clicked Accept Action\");\n} else if (message.getActionName().equals(\"Decline Button\")){\nSystem.out.print(\"Clicked Decline Action\");\n} else if (message.getActionName().equals(\"View Button\")){\nSystem.out.print(\"Clicked View Action\");\n}\n}\n};\nShow more\n\n\n\nYour Android mobile app is ready to work with your new instance of IBM Cloud\u00ae Event Notifications.\n\n\n\n\n\n\n\n Step 3: Modify an iOS mobile application \n\nModify the mobile app source code to use the new Event Notifications SDKs. You will replace the existing Push Notifications service SDK with the Event Notifications FCM SDK.\n\n\n\n Create an iOS destination \n\nCreate a destination of type Apple Push Notification (APNs) for the iOS app. Provide the P12 or P8 and their configurations.\n\nZoom\n\n![Create iOS destination](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4c9a07fe500838e5e55e71e73131ef20b44a6c66\/event-notifications\/images\/en-migration-apns.png)\n\nFigure 7. Create iOS destination\n\n\n\n\n\n Edit the iOS application \n\nFollow these steps to migrate from BMPush to ENPushDestination:\n\n\n\n1. Change the import statement\n\n\/\/ Replace this\n\nimport BMSCore\nimport BMSPush\n\n\/\/ with this\n\nimport ENPushDestination\n2. Replace SDK Initialization code\n\n\/\/ Replace this\n\nlet push = BMSClient.sharedInstance\n\npush.initialize(bluemixRegion: \"<IBM cloud region>\")\n\npush.initializeWithAppGUID(\nappGUID: \"<IBM Cloud Push Instance GUID>\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-migrate-apps"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":19.696482,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":18.884956,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":17.964684,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":17.704395,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_02772-4213-5899","score":17.121113,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":16.90811,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":11.749103,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10852-43319-44485","score":11.12509,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_16648-5538-7784","score":1.7622855,"text":"\nMetric Name ibm_watsonx_data_active_nodes_total \n Metric Type gauge \n Value Type none \n Segment By Service Instance, Resource group \n Metric Description The total number of active nodes in the Presto Co-ordinator Pod. \n\n\n\n\n\n\n\n Total number of inactive nodes \n\n\n\nTable 11: Total Number Of Inactive Nodes metric metadata\n\n Metadata Description \n\n Metric Name ibm_watsonx_data_inactive_nodes_total \n Metric Type gauge \n Value Type none \n Segment By Service Instance, Resource group \n Metric Description The total number of inactive nodes in the Presto Co-ordinator Pod. \n\n\n\n\n\n\n\n Total number of nodes \n\n\n\nTable 12: Total Number Of Nodes metric metadata\n\n Metadata Description \n\n Metric Name ibm_watsonx_data_nodes_total \n Metric Type gauge \n Value Type none \n Segment By Service Instance, Resource group \n Metric Description The total number of nodes in the Presto Co-ordinator Pod. \n\n\n\n\n\n\n\n List of roles \n\n\n\nTable 4: List Of Roles metric metadata\n\n Metadata Description \n\n Metric Name ibm_watsonx_data_roles_name \n Metric Type gauge \n Value Type none \n Segment By Service Instance, Resource group \n\n\n\n\n\n\n\n List of tables \n\n\n\nTable 5: List Of Tables metric metadata\n\n Metadata Description \n\n Metric Name ibm_watsonx_data_table_total \n Metric Type gauge \n Value Type none \n Segment By Service Instance, Resource group \n\n\n\n\n\n\n\n\n\n Attributes for segmentation \n\n\n\n Global attributes \n\nThe following attributes are available for segmenting all of the metrics that are listed above.\n\n\n\nTable 13: Global attributes\n\n Attribute Attribute Name Attribute Description \n\n Cloud Type ibm_ctype The cloud type is a value of public, dedicated, or local \n Location ibm_location The location of the monitored resource - this can be a region, data center or global \n Resource ibm_resource The resource being measured by the service - typically an indentifying name or GUID \n Resource Type ibm_resource_type The type of the resource being measured by the service \n Resource group ibm_resource_group_name The resource group where the service instance was created \n Scope ibm_scope The scope is the account, organization, or space GUID associated with this metric \n Service name ibm_service_name Name of the service generating this metric \n\n\n\n\n\n\n\n Additional attributes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-monitor_wxd"},{"document_id":"ibmcld_14647-1673-3121","score":1.4316158,"text":"\nSkylake servers are not supported for VMware vSphere\u00ae Enterprise Plus 7.0u1 instances.\n\nNSX-T instances\n\nNSX-V instances\n\n\n\nTable 1. Options for Skylake bare metal servers - NSX-T instances\n\n CPU model Cores GHz RAM \n\n Dual Intel\u00ae Xeon\u00ae Silver 4110 processor 16 2.1 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 5120 processor 28 2.2 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 6140 processor 36 2.3 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n\n\n\nVMware NSX-V is no longer supported for new deployments of vCenter Server instances V4.7 and later.\n\n\n\n\n\n Cascade Lake \n\nFor Cascade Lake servers, you can choose the following CPU models and a supported RAM size, which depends on the NSX networking solution.\n\nNSX-T instances\n\nNSX-V instances\n\n\n\nTable 2. Options for Cascade Lake bare metal servers - NSX-T instances\n\n CPU model Cores GHz RAM \n\n Dual Intel Xeon Silver 4210 processor 20 2.2 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 5218 processor 32 2.3 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 6248 processor 40 2.5 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Gold 6250 processor 16 3.9 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Dual Intel Xeon Platinum 8260 processor 48 2.4 128 GB, 192 GB, 384 GB, 768 GB, 1.5 TB \n Quad Intel Xeon Gold 6248 processor 80 2.5 384 GB, 768 GB, 1.5 TB, 3 TB \n Quad Intel Xeon Platinum 8260 processor 96 2.4 384 GB, 768 GB, 1.5 TB, 3 TB","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_orderinginstance-consold-cluster"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":28.357697,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":28.302433,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":26.331139,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":25.957233,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-15747-17355","score":24.718796,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-7-1802","score":23.470833,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":21.103533,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":20.88001,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":20.036476,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":19.882114,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.8385465275}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-7-2061","score":14.230292,"text":"\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_00324-12617-14618","score":12.5964155,"text":"\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https:\/\/cloud.ibm.com\/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_09791-7-1663","score":12.219481,"text":"\nManaging panels \n\nUse a panel to display a metric or group of metrics in a dashboard. You can copy, change the scope, duplicate, delete, export, and explore panels.\n\nYou can use any of the following panel types:\n\n\n\nTable 1. Panel types\n\n Type Description \n\n Line Use this panel to view trends over time for one or more metrics. \n Top list Use this panel to compare a metric across groups of entities. The bar chart is sorted in descending order. \n Histogram Use this panel to view the frequency distribution of a metric in buckets. \n Number Use this panel to view a single number that represents the value of an aggregated metric over time for one or more entities. \n Table Use this panel to display numerical data for your infrastructure based on metrics and segments. \n Text Use this panel to add text. Use markdown to add your text. \n\n\n\n\n\n Copy a panel into a dashboard \n\nComplete the following steps to copy a panel:\n\n\n\n1. Navigate to the Dashboards section (![dashboard section](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/dashboards.png)) in the Web UI. Select a dashboard. Then, identify the panel that displays the metric that you want to copy.\n2. Click the Actions icon ![Three dots icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/actions.png) and select Copy to Dashboard![Copy to Dashboard icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/copy.png).\n3. Select one of the dashboards that are listed, or enter a name for a new dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-panels"},{"document_id":"ibmcld_03036-4322-6185","score":12.009353,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_15214-16248-18338","score":11.484535,"text":"\nCooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.\n\nTo add scaling policies, complete the following fields on the New instance group for VPC page. If you need to add policies after your instance group is already created, see [add policies](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-instance-groupcreating-target-policies).\n\n\n\nTable 3. Scaling policies selections\n\n Field Value \n\n Metric type Select the metric type that you want to associate with a target utilization value to use for adding or removing instances from your group. You can choose one of these metrics: CPU utilization (%), RAM utilization (%), Network in (Mbps), Network out (Mbps). You can define more than one target metric policy, but only one policy for each type of metric. \n Average target utilization Specify the average utilization that you want to achieve for the metric that you select. This target value defines when the instance group manager needs to scale up instances or scale down instances in your group. At the end of each aggregation window, the instance group manager adds the current utilization of each instance and divides it by this target utilization value to determine the membership count. \n\n\n\n\n\n\n\n\n\n Setting up auto scale with the CLI \n\nYou can create an instance group in your IBM Cloud VPC to auto scale according to your requirements by using the IBM Cloud CLI.\n\n\n\n Before you begin \n\nMake sure that you set up your [IBM Cloud\u00ae CLI environment](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-set-up-environmentcli-prerequisites-setup) and your [IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=cli"},{"document_id":"ibmcld_15206-16234-18324","score":11.484535,"text":"\nCooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.\n\nTo add scaling policies, complete the following fields on the New instance group for VPC page. If you need to add policies after your instance group is already created, see [add policies](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-instance-groupcreating-target-policies).\n\n\n\nTable 3. Scaling policies selections\n\n Field Value \n\n Metric type Select the metric type that you want to associate with a target utilization value to use for adding or removing instances from your group. You can choose one of these metrics: CPU utilization (%), RAM utilization (%), Network in (Mbps), Network out (Mbps). You can define more than one target metric policy, but only one policy for each type of metric. \n Average target utilization Specify the average utilization that you want to achieve for the metric that you select. This target value defines when the instance group manager needs to scale up instances or scale down instances in your group. At the end of each aggregation window, the instance group manager adds the current utilization of each instance and divides it by this target utilization value to determine the membership count. \n\n\n\n\n\n\n\n\n\n Setting up auto scale with the CLI \n\nYou can create an instance group in your IBM Cloud VPC to auto scale according to your requirements by using the IBM Cloud CLI.\n\n\n\n Before you begin \n\nMake sure that you set up your [IBM Cloud\u00ae CLI environment](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-set-up-environmentcli-prerequisites-setup) and your [IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group"},{"document_id":"ibmcld_15215-16247-18337","score":11.484535,"text":"\nCooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.\n\nTo add scaling policies, complete the following fields on the New instance group for VPC page. If you need to add policies after your instance group is already created, see [add policies](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-instance-groupcreating-target-policies).\n\n\n\nTable 3. Scaling policies selections\n\n Field Value \n\n Metric type Select the metric type that you want to associate with a target utilization value to use for adding or removing instances from your group. You can choose one of these metrics: CPU utilization (%), RAM utilization (%), Network in (Mbps), Network out (Mbps). You can define more than one target metric policy, but only one policy for each type of metric. \n Average target utilization Specify the average utilization that you want to achieve for the metric that you select. This target value defines when the instance group manager needs to scale up instances or scale down instances in your group. At the end of each aggregation window, the instance group manager adds the current utilization of each instance and divides it by this target utilization value to determine the membership count. \n\n\n\n\n\n\n\n\n\n Setting up auto scale with the CLI \n\nYou can create an instance group in your IBM Cloud VPC to auto scale according to your requirements by using the IBM Cloud CLI.\n\n\n\n Before you begin \n\nMake sure that you set up your [IBM Cloud\u00ae CLI environment](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-set-up-environmentcli-prerequisites-setup) and your [IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=ui"},{"document_id":"ibmcld_04612-4134-6219","score":11.430445,"text":"\nA cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.\n\nTo define a schedule, complete the following steps. You can define multiple schedules.\n\n\n\n1. Open Schedules.\n2. Select the Time Zone where the schedule is defined.\n3. Indicate whether the schedule is always in effect (recurring schedules), or is only in effect for the specified date range (specific schedules).\n4. For recurring schedules, select whether the schedule is repeated weekly or monthly.\n5. For recurring schedules, select the days of the week or month when the schedule applies.\n6. Specify the start and end time of the schedule, the minimum number of instances to be run, the initial minimum instances, and the maximum instances that are run during the period.\n\n\n\nDuring the scheduled time periods, all other autoscaling rules are still in effect.\n\n\n\n\n\n\n\n\n\n Importing a JSON policy file \n\nYou can import a JSON policy file by clicking Import From JSON. See the [policy specification](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/blob\/master\/docs\/Readme.md) for the autoscaling policy JSON format.\n\n\n\n\n\n Metric statistics \n\nAfter a policy is defined with autoscaling rules, you can view the metric values and metrics history for the previous 2 hours.\n\nThe metric value is not the raw data from each app instance, but the metric values averaged over all the app instances.\n\n\n\n\n\n Scaling history \n\nUse the Scaling history tab to view the autoscaling events for the past 30 days. If autoscaling attempts failed, the tab also shows the error messages.\n\n\n\n\n\n\n\n Managing autoscaling from the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"},{"document_id":"ibmcld_04612-2600-4714","score":11.195735,"text":"\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/tree\/develop\/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"},{"document_id":"ibmcld_09999-1864-4011","score":11.0474615,"text":"\nPredicted data is only displayed when the system has been collecting historical data for at least 7 days. Until then, the graph displays a data point for each day. After 7 days, a prediction for an extra two weeks' worth of information appears.\n\n\n\n\n\n Historical and Predicted NZP \n\nThe purple and pink lines represent Historical NZP and Predicted NZP.\n\nNZP (Netezza Performance Metric) is a measure of system utilization.\nHigh level NZP indicates elevated levels of utilization. Low NZP indicates decreased resource usage.\nThe historical and predicted NZP lines are measured on the scale to the left of the chart between 0% and 100%.\n\n\n\n\n\n Historical and Suggested contour profile \n\nHistorical Contour Profile and Suggested Contour Profile are visualized by the blue bars.\n\nThe contours that are displayed to the left of the current date line are historical contours. They represent the profiles that are used on each time interval.\nThe bars that are displayed on the right side of the current date line are suggested contours for each time interval.\n\nContour profiles are suggested based on the predicted NZP during that time interval. If NZP exceeds 80%, it is suggested that contour profile is scaled up the next closest contour to increase compute and improve performance for heavy workload periods. When the algorithm predicts NZP at or below 20% for a time interval, the graph suggests to scale down to a lower profile.\n\n\n\n\n\n Confidence score \n\nConfidence score reflects the accuracy of the predictions that are provided based on your system historical workload patterns. By analyzing the confidence score, you can choose how to use your system resources.\n\n\n\n\n\n\n\n Smart scaling example \n\n\n\n1. [Log in to the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Go to Administering > Workload patterns.\n3. Review the smart scaling utilization graph.\nIn this example, as a database administrator, you want to to get a deeper understanding of your system utilization over time.\n\nIn this scenario, it turns out that every Sunday, your system utilization drops below average as compared to other days of the week.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-smartscaling"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04334-273354-274895","score":11.461053,"text":"\n<-- <\/section \"id=\"section-certificate-alert-examples\" \"> --><-- <\/section \"id=\"section-certificate-alert\" \"> --><-- <section \"id=\"section-create-glb-healthcheck-alert\" \"> --> ibmcloud cis alert-policy glb-healthcheck-alert-create Create an alert policy for changes in health status for global load balancer, pools, and origins. ibmcloud cis alert-policy glb-healthcheck-alert-create --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --pools POOLS --include-future-pools (true | false)] --health-status-trigger (healthy | unhealthy | either)] --event-source-trigger (pool | origin | either)] --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-create-glb-healthcheck-alert\" \"> --> Command options --name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.--pools: The IDs of origin pool, if set to all, the all pool IDs will be used.--include-future-pools: Whether or not include the future pools. (default \"false\")--health-status-trigger: The trigger condition to fire the notification. Valid values: \"healthy\", \"unhealthy\", \"either\". (default \"either\")--event-source-trigger: The event source of trigger to fire the notification.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_09701-9031-10960","score":11.438741,"text":"\n400 The alert configuration is not valid. \n 401 Unauthorized access. \n 404 The alert ID is not recognized. \n 409 There is a version mismatch. \n 422 The alert name is not valid. The name is already used. \n\n\n\n\n\n\n\n Body parameters \n\n\n\n id (integer) \n\nID of an alert.\n\n\n\n\n\n condition (string) \n\nDefines the threshold that is configured for the alert. This parameter is required for MANUAL alerts only.\n\nFor example, you can defines a consition as follows: avg(timeAvg(uptime)) <= 0\n\n\n\n\n\n createdOn (integer) \n\nDefines the creation time of an alert in milliseconds.\n\nThis parameter returns the Unix-timestamp when the alert was created.\n\n\n\n\n\n description (string) \n\nThis parameter describes the alert.\n\nThe description is available when you view an alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n enabled (boolean) \n\nDefines the status of an alert.\n\nBy default, this parameter is set to true and the alert is enabled when it is created.\n\n\n\n\n\n filter (string) \n\nDefines the scope of the alert by configuring segments.\n\nWhen this field is empty, all the metric sources are included. The scope is set to Everything.\n\nFor example, you can define filters like the following ones:\n\nkubernetes.namespace.name='production'\n\ncontainer.image='nginx'.\n\nkubernetes.namespace.name='production' and container.image='nginx'.\n\n\n\n\n\n name (string) \n\nName of the alert. Must be unique.\n\nThe name is used to identify the alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n modifiedOn (integer) \n\nDefines when an alert was last modified in milliseconds.\n\nThis parameter defines the Unix-timestamp when the alert was last modified.\n\n\n\n\n\n notificationChannelIds (array) \n\nLists the notification channels that are configured to notify when an alert is triggered.\n\nValid options are EMAIL, PAGER_DUTY, WEBHOOK, VICTOROPS, and SLACK.\n\n\"notificationChannelIds\": [","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_04334-266269-267601","score":11.175405,"text":"\n<-- <\/section \"id=\"section-show-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-show-alert-policy\" \"> --><-- <section \"id=\"section-create-ddos-attack-l7-alert\" \"> --> ibmcloud cis alert-policy ddos-attack-l7-alert-create Create an alert policy for DDoS attack l7. ibmcloud cis alert-policy ddos-attack-l7-alert-create --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-create-ddos-attack-l7-alert\" \"> --> Command options --name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-create-ddos-attack-l7-alert\" \"> --><-- <section \"id=\"section-create-ddos-attack-l7-alert-examples\" \"> --> Examples Create a ddos attack alert policy for instance cis-demo.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04131-7324-9010","score":10.946889,"text":"\n* --description value is the description for the alert policy.\n* --emails value is the email addresses for dispatching an alert notification. For example, --emails test1@cn.ibm.com,test2@cn.ibm.com.\n* --webhooks value is the webhook IDs for dispatching an alert notification. For example, --webhooks webhookID1,webhookID2.\n* --enabled value determines whether the alert policy is enabled.\n* --pools value is the IDs of origin pool. If set to all, all pool IDs are used.\n* --trigger-condition value is the condition of pool toggle status.\n* --include-future-pools value determines whether to include the future pools.\n* -i, --instance value is the instance name or ID.\n* --output value specifies the output format; only JSON is supported.\n\n\n\n\n\n\n\n Creating a security alert by using the CLI \n\nTo create a security alert by using the CLI, run the following command:\n\nibmcloud cis alert-policy firewall-events-alert-create --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --domains DOMAINS [--services SERVICES] [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* --name value is the name of the alert policy.\n* --description value is the description for the alert policy.\n* --emails value is the email addresses for dispatching an alert notification. For example, --emails test1@cn.ibm.com,test2@cn.ibm.com.\n* --webhooks value is the webhook IDs for dispatching an alert notification. For example, --webhooks webhookID1,webhookID2.\n* --domains value is the domain IDs for the alert policy. For example, --domains domainID1,domainID2.\n* --services value specifies which services the alert monitors (for advanced security alerts).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies"},{"document_id":"ibmcld_04334-275510-276933","score":10.791911,"text":"\n<-- <\/section \"id=\"section-create-glb-healthcheck-alert-examples\" \"> --><-- <\/section \"id=\"section-create-glb-healthcheck-alert\" \"> --><-- <section \"id=\"section-update-ddos-attack-l7-alert\" \"> --> ibmcloud cis alert-policy ddos-attack-l7-alert-update Update an alert policy for DDos attack l7. ibmcloud cis alert-policy ddos-attack-l7-alert-update POLICY_ID --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-update-ddos-attack-l7-alert\" \"> --> Command options POLICY_ID: The ID of alert policy. Required.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-update-ddos-attack-l7-alert\" \"> --><-- <section \"id=\"section-update-ddos-attack-l7-alert-examples\" \"> --> Examples Update a ddos attack alert policy a2633e68-1a64-2512-a321-b64a17c7db7a.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-288019-289188","score":10.616719,"text":"\n<-- <\/section \"id=\"section-show-alert-webhook-examples\" \"> --><-- <\/section \"id=\"section-show-alert-webhook\" \"> --><-- <section \"id=\"section-create-alert-webhook\" \"> --> ibmcloud cis alert-webhook-create Create an alert webhook for a given instance. ibmcloud cis alert-webhook-create --name NAME --url URL --secret SECRET] -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-alert-webhook-options\" \"> --> Command options --name: The name of the webhook. Required.--url: The POST endpoint to call when dispatching an alert. Required.--secret: The secret that will be passed in the webhook auth header when dispatching a webhook alert.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-alert-webhook-options\" \"> --><-- <section \"id=\"section-create-alert-webhook-examples\" \"> --> Examples Create an alert webhook for instance cis-demo. ibmcloud cis alert-webhook-create --name testwebhook --url https:\/\/hooks.slack.com\/services\/Ds3fdBFbV\/1234568 --secret 007 -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-287106-288268","score":10.587145,"text":"\n<-- <\/section \"id=\"section-list-alert-webhooks-examples\" \"> --><-- <\/section \"id=\"section-list-alert-webhooks\" \"> --><-- <section \"id=\"section-show-alert-webhook\" \"> --> ibmcloud cis alert-webhook Show the details of a given webhook. ibmcloud cis alert-webhook WEBHOOK_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-show-alert-webhook-options\" \"> --> Command options WEBHOOK_ID: The ID of alert webhook. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-show-alert-webhook-options\" \"> --><-- <section \"id=\"section-show-alert-webhook-examples\" \"> --> Examples Show the details of alert webhook b2633e68-9a64-4519-b361-a64a67c8db8e. ibmcloud cis alert-webhook b2633e68-9a64-4519-b361-a64a67c8db8e -i \"cis-demo\"\n<-- <\/section \"id=\"section-show-alert-webhook-examples\" \"> --><-- <\/section \"id=\"section-show-alert-webhook\" \"> --><-- <section \"id=\"section-create-alert-webhook\" \"> --> ibmcloud cis alert-webhook-create Create an alert webhook for a given instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04133-3844-5443","score":10.5324545,"text":"\n* --webhooks is the webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2\n* --enabled sets whether or not the alert policy is enabled.\n* --domains are the domain IDs for the alert policy. For example: --domains domainID1,domainID2\n* --services (Advanced WAF) specifies which services the alert monitors. Valid values: \"country-access-rules\", \"waf\", \"firewall-rules\", \"ratelimit\", \"securitylevel\", \"ip-access-rules\", \"browser-integrity-check\", \"ua-rules\", \"lockdowns\", \"iprange-access-rules\", \"asn-access-rules\", \"Managed-firewall\".\n* -i, --instance is the instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n* --output specifies the output format; only JSON is supported.\n\n\n\n\n\n\n\n Universal SSL alert command \n\nCreate an alert policy for certificate events.\n\nibmcloud cis alert-policy certificate-alert-create --type (universal | dedicated) --name NAME (--emails EMAILS | --webhooks WEBHOOKS) --enabled (true | false) [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* --type is the type of the certificate.\n* --name is the name of the alert policy.\n* --description is the description for the alert policy.\n* --emails is the email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com\n* --webhooks is the webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2\n* --enabled sets whether or not the alert policy is enabled.\n* -i, --instance is the instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type"},{"document_id":"ibmcld_04131-8690-10394","score":10.505032,"text":"\n* --webhooks value is the webhook IDs for dispatching an alert notification. For example, --webhooks webhookID1,webhookID2.\n* --domains value is the domain IDs for the alert policy. For example, --domains domainID1,domainID2.\n* --services value specifies which services the alert monitors (for advanced security alerts). Valid services: country-access-rules, waf, firewall-rules, ratelimit, securitylevel, ip-access-rules, browser-integrity-check, ua-rules,lockdowns, iprange-access-rules, asn-access-rules, managed-firewall, hotlink, ssl-validation. (Enterprise plan only.)\n* --enabled value determines whether the alert policy is enabled.\n* -i, --instance value is the instance name or ID.\n* --output value specifies the output format; only JSON is supported.\n\n\n\nSecurity alerts and advanced security alerts use the same command. When you create an advanced security events alert command in the CLI, specify the services for the alert. If you do not specify the services for the alert, the mean detection time changes from 5 minutes to 2 hours.\n\n\n\n\n\n Updating a DDoS Attack Alert Policy by using the CLI \n\nTo update a DDoS attack alert policy by using the CLI, run the following command:\n\nibmcloud cis alert-policy ddos-attack-l7-alert-update POLICY_ID [--name NAME] [--emails EMAILS] [--webhooks WEBHOOKS] [--enabled (true | false)] [--description DESCRIPTION] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* POLICY_ID is the ID of alert policy.\n* --name value is the name of the alert policy.\n* --description value is the description for the alert policy.\n* --emails value is the email addresses for dispatching an alert notification. For example, --emails test1@cn.ibm.com,test2@cn.ibm.com.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies"},{"document_id":"ibmcld_04334-282023-283354","score":10.485715,"text":"\nRequired.--name: The name of the alert policy.--description: The description for the alert policy.--emails: The email addresses for dispatching an alert notification. For example: --emails test1@cn.ibm.com,test2@cn.ibm.com--webhooks: The webhook ID that for dispatching an alert notification. For example: --webhook webhookID1,webhookID2--enabled: Whether or not the alert policy is enabled.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-opt-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-certificate-alert-examples\" \"> --> Examples Update a certificate alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy certificate-alert-update a2633e68-1a64-2512-a321-b64a17c7db7a --name test1 --emails test1@cn.ibm.com --webhooks b2633e68-9a64-4519-b361-a64a67c8db8e --enabled true -i \"cis-demo\"\n<-- <\/section \"id=\"section-update-certificate-alert-examples\" \"> --><-- <\/section \"id=\"section-update-certificate-alert\" \"> --><-- <section \"id=\"section-update-glb-healthcheck-alert\" \"> --> ibmcloud cis alert-policy glb-healthcheck-alert-update Update an alert policy for changes in health status for global load balancer, pools, and origins.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-2789-4951","score":13.261309,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":12.556078,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":11.215786,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":9.119313,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16417-3559-5683","score":8.758068,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":8.747321,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_13406-5036-7279","score":7.8513193,"text":"\nActual values might, for example, be 0.27, 0.52, and so on, depending on when the service receives and processes audio.\n* Values for transcription events are not related to the processing interval. The service returns event-driven results as they occur.\n\n\n\n* periodic indicates whether the metrics apply to a periodic interval or to a transcription event:\n\n\n\n* true means that the response was triggered by a processing interval. The information contains processing metrics only.\n* false means that the response was triggered by a transcription event. The information contains processing metrics plus transcription results.\n\n\n\nUse this field to identify why the service generated the response and to filter different results if necessary.\n* processed_audio includes a ProcessedAudio object that provides detailed timing information about the service's processing of the input audio.\n\n\n\nThe ProcessedAudio object includes the following fields. All of the fields refer to seconds of audio as of this response. Only the wall_clock_since_first_byte_received field refers to elapsed real-time.\n\n\n\n* received is the seconds of audio that the service has received.\n* seen_by_engine is the seconds of audio that the service has passed to its speech processing engine.\n* transcription is the seconds of audio that the service has processed for speech recognition.\n* speaker_labels is the seconds of audio that the service has processed for speaker labels. The response includes this field only if you request speaker labels.\n\n\n\nThe speech processing engine analyzes the input audio multiple times. The processed_audio object shows values for audio that the engine has processed and will not read again. Processed audio has no effect on future recognition hypotheses.\n\nThe metrics indicate the progress and complexity of the engine's processing:\n\n\n\n* seen_by_engine is audio that the service has read and passed to the engine at least once.\n* received - seen_by_engine is audio that has been buffered at the service but has not yet been seen or processed by the engine.\n* The relationship between the times is received >= seen_by_engine >= transcription >= speaker_labels.\n\n\n\nThe following relationships can also be helpful in understanding the results:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_13406-3429-5587","score":6.6881423,"text":"\nThe service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics \n\nThe service returns processing metrics for transcription events in the processing_metrics field of the SpeechRecognitionResults object. For metrics generated at periodic intervals, not with transcription events, the object contains only the processing_metrics field, as shown in the following example.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {\n\"received\": float,\n\"seen_by_engine\": float,\n\"transcription\": float,\n\"speaker_labels\": float\n},\n\"wall_clock_since_first_byte_received\": float,\n\"periodic\": boolean\n}\n}\n\nThe processing_metrics field includes a ProcessingMetrics object that has the following fields:\n\n\n\n* wall_clock_since_first_byte_received is the amount of real time in seconds that has passed since the service received the first byte of input audio. Values in this field are generally multiples of the specified metrics interval, with two differences:\n\n\n\n* Values might not reflect exact intervals such as 0.25, 0.5, and so on. Actual values might, for example, be 0.27, 0.52, and so on, depending on when the service receives and processes audio.\n* Values for transcription events are not related to the processing interval. The service returns event-driven results as they occur.\n\n\n\n* periodic indicates whether the metrics apply to a periodic interval or to a transcription event:\n\n\n\n* true means that the response was triggered by a processing interval. The information contains processing metrics only.\n* false means that the response was triggered by a transcription event.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_13129-5800-7679","score":6.389247,"text":"\nOn the left pane, click +New.\n2. Set the name to iris_model.\n3. Under Watson Machine Learning service instance, select the service previously associated.\n\n\n\n3. Click Create.\n\n\n\nOnce the model is created,\n\n\n\n1. Add training data by clicking Select data from project.\n\n\n\n1. Choose the iris_initial.csv file under Data asset.\n2. Click Select asset.\n\n\n\n2. If prompted, answer No to Create a time series forecast?.\n3. Select Species as your What do you want to predict?.\n4. Click Experiment settings.\n5. Select Data source.\n6. Under Training data split, set Holdout data split to 15% by moving the slider.\n7. On the left menu, Click on Prediction:\n\n\n\n1. Set Prediction type to Multiclass classification.\n2. Set Optimized metric as Accuracy.\n3. Click on Save settings.\n\n\n\n8. Click on Run experiment.\n9. The AutoAI experiment may take up to 5 minutes to select the right Algorithm for your model. Click on Swap view to see the Relationship map.\n\nEach model pipeline is scored for a variety of metrics and then ranked. The default ranking metric for binary classification models is the area under the ROC curve, for multi-class classification models is accuracy, and for for regression models is the root mean-squared error (RMSE). The highest-ranked pipelines are displayed in a leaderboard, so you can view more information about them. The leaderboard also provides the option to save select model pipelines after reviewing them.\n\n\n\nOnce the experiment completes running,\n\n\n\n1. Click on Pipeline comparison to view how the top pipelines compare.\n2. Sort the leaderboard by a different metric by clicking on the various column headers.\n3. Click a pipeline to view more detail about the metrics and performance.\n\nSorting by different metrics may not change the leaderboard rankings as the dataset used in this tutorial is very simple and used only for your understanding of the concepts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_05445-3925-4923","score":6.2917295,"text":"\nProgress Summary \nExperiment stage: Completed\nNumber of completed iterations: 1\n\n Winner Assessment \n> If the version being validated; i.e., the baseline version, satisfies the experiment objectives, it is the winner.\n> Otherwise, there is no winner.\nWinning version: my-app\n\n Objective Assessment \n> Identifies whether or not the experiment objectives are satisfied by the most recently observed metrics values for each version.\n+--------------------------------------+--------+\n OBJECTIVE MY-APP \n+--------------------------------------+--------+\n iter8-system\/mean-latency <= true \n 200.000 \n+--------------------------------------+--------+\n iter8-system\/error-rate <= true \n 0.010 \n+--------------------------------------+--------+\n iter8-system\/latency-95th-percentile true \n <= 500.000 \n+--------------------------------------+--------+\n\n Metrics Assessment \n> Most recently read values of experiment metrics for each version.\n+--------------------------------------+--------+\n METRIC MY-APP","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-slovalidationtut"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16250-12497-14080","score":11.332284,"text":"\nAt that point, the system can respond by updating the relevant failover metadata to route traffic to the service instance in the other region. Once a failover happens, you can decide to continue using the new region as the active instance, or if you want to resume using the initial region once it has stabilized.\n\nFor an active\/active topology, some form of a load balancing can be used, where two or more service instances in unique regions always receive a percentage of traffic. Additional logic would need to be established to determine when to pull a region out of rotation. This monitoring logic could use a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) similar to the active\/passive configuration or rely on a separate dedicated monitoring framework that determines region health. Also similar to active\/passive, determining when to insert a region back in rotation would need to be considered as well.\n\n\n\n\n\n Failover for v2 stateful API \n\nFailover for the v2 stateful API is similar to stateless, with these details to consider:\n\n\n\n* The state of a given conversation is persisted by Watson Assistant in a database that is tied to a particular region. As such, a failover for the stateful v2 \/message may more disruptive.\n* For an active\/passive topology, you should assume that all in-progress conversations are ended.\n* For an active\/active topology, given the region-locked persistence constraints of the v2 stateful \/message architecture, all turns (\/message API calls) of a given conversation (session) should occur within the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16321-12507-14690","score":10.723816,"text":"\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the conversation flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13441-10828-12897","score":10.635367,"text":"\nExtract each individual channel from the audio.\n2. Transcribe the audio from each channel separately and without using the speaker_labels parameter. Include the timestamps parameter to learn precise timing information for the words of the transcripts.\n3. Merge the results of the individual requests to re-create a single transcript of the complete exchange. You can use the timestamps of the individual requests to reconstruct the conversation.\n\n\n\nThe multichannel approach has some advantages over the use of the speaker_labels parameter:\n\n\n\n* Because it relies on basic speech recognition, the service can transcribe audio that is in any supported language. Speakers labels are restricted to a subset of the available languages.\n* Because each speaker has a dedicated channel, the service can provide more accurate results than it can for speaker labels. The service does not need to determine which speaker is talking.\n* Because each speaker has a dedicated channel, the service can accurately transcribe cross-talk, or speaker overlap. On a merged channel, cross-talk can be difficult or impossible to recognize accurately.\n\n\n\nBut the approach also has some disadvantages that you need to be aware of:\n\n\n\n* You must separate the channels prior to sending the audio and then merge the resulting transcripts to reconstruct the conversation. The use of timestamps greatly simplifies the reconstruction process.\nIBM Cloud\n\nYou are charged for all audio that you send to the service, including silence. If you send the audio from all channels in its entirety, you effectively multiply the amount of audio being recognized by the number of channels. For example, if you submit separate requests for both channels of a two-channel exchange that lasts for five minutes, your requests require ten minutes of audio processing. If your pricing plan uses per-minute pricing, this doubles the cost of speech recognition. You can consider preprocessing the audio to eliminate silence, but that approach makes it much more difficult to merge the results of the separate requests.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-speaker-labels"},{"document_id":"ibmcld_16321-14177-15957","score":10.495147,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-13886-15581","score":10.4652605,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16250-1908-4265","score":9.877758,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_02871-1651-3098","score":9.533283,"text":"\nTest the deployed assistant and make refinements.\n7. After you build an effective assistant, take a snapshot of the dialog skill and save it as a version.\n\nSaving a version when you reach a development milestone gives you something you can go back to if subsequent changes you make to the skill decrease its effectiveness. See [Creating skill versions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions).\n8. Deploy the version of the assistant into a test environment, and test it.\n9. Monitor the chat transcript logs for your test assistant to determine if you need to make improvements to your training data or dialog.\n10. When you are happy with the performance of your assistant, deploy the best version of the assistant into a production environment.\n11. Monitor the logs from conversations that users have with the deployed assistant.\n\n\n\nThe process of monitoring the conversations that your assistant has with your customers is your responsibility. Devise ways to analyze these chat transcripts so you can find out where the assistant is misunderstanding users or where its training data needs to be improved. For example, you might need to augment the training data if many customers ask for help with something that your assistant does not know anything about, or you might have two intents that are not distinct enough from one another if your assistant regularly picks the wrong dialog branches for certain topics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dev-process"},{"document_id":"ibmcld_03109-10370-12635","score":9.300281,"text":"\nWhen the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) This feature is available only to users of paid plans.\n\nPrivate network endpoints support routing services over the IBM Cloud private network instead of the public network. A private network endpoint provides a unique IP address that is accessible to you without a VPN connection.\n\nFor implementation details, see [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-public-private-endpoints).\n\n\n\n Important private network endpoint notes \n\n\n\n* The integrations that are provided with the product require endpoints that are available on the public internet. Therefore, any built-in integrations you add to your assistant will have public endpoints. If you only want to connect to a client application or messaging channel over the private network, then you must build your own custom client application or channel integration.\n* Before you can use a search integration or search skill, you must create a Discovery instance with a private network endpoint. The list of Discovery instances that are displayed for you to connect to includes only instances with private network endpoints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_02900-7-1940","score":9.176043,"text":"\nControlling the dialog flow \n\nUnderstand how your dialog is processed when a person interacts with your assistant at run time. Learn to use the conversation flow to your advantage and alter the flow if necessary.\n\n\n\n Digressions \n\nA digression occurs when a user is in the middle of a dialog flow that is designed to address one goal, and abruptly switches topics to initiate a dialog flow that is designed to address a different goal. The dialog has always supported the user's ability to change subjects. If none of the nodes in the dialog branch that is being processed match the goal of the user's latest input, the conversation goes back out to the tree to check the root node conditions for an appropriate match. The digression settings that are available per node give you the ability to tailor this behavior even more.\n\nWith digression settings, you can allow the conversation to return to the dialog flow that was interrupted when the digression occurred. For example, the user might be ordering a new phone, but switches topics to ask about tablets. Your dialog can answer the question about tablets, and then bring the user back to where they were in the process of ordering a phone. Allowing digressions to occur and return gives your users more control over the flow of the conversation at run time. They can change topics, follow a dialog flow about the unrelated topic to its end, and then return to where they were before. The result is a dialog flow that more closely simulates a human-to-human conversation.\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digression-prereqs)\n* [Customizing digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-enable-digressions)\n* [Digression usage tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digress-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_09148-7-2287","score":8.9145565,"text":"\nMonitoring operational metrics \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud Monitoring service to measure how users and applications interact with IBM\u00ae Key Protect for IBM Cloud\u00ae.\n\nIBM Cloud Monitoring records data on the operations that occur inside of IBM Cloud. This service allows you to gain operational visibility into the performance and health of your applications, services, and platforms. You can use its advanced features to monitor and troubleshoot, define alerts based on API response codes, and design custom dashboards.\n\nFor more information regarding the Monitoring service, see the [getting started tutorial for IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started-monitor).\n\n\n\n What metrics are available? \n\nYou can use Monitoring to track the type of API requests being made in your service instance as well as the latency of the requests.\n\nThe following contains examples of metrics that can be measured in your Monitoring dashboard:\n\n\n\n* Total requests being made in your Key Protect instance\n* Successful vs failed API requests categorized by API type\n* API request latency over time\n* Total API requests categorized by response code\n\n\n\n\n\n\n\n Before you begin \n\nEnabling Key Protect service metrics will add new metrics to your Monitoring instance. For information on Monitoring pricing, see [Pricing](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans).\n\nBefore you provision an instance of Monitoring, consider the following guidance:\n\n\n\n* You will need to enable a [metrics policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-monitor-metrics) in the Key Protect instance in order to retrieve operational metrics.\n* Other IBM Cloud users with administrator or editor permissions can manage the Monitoring service in the IBM Cloud. These users must also have platform permissions to create resources within the context of the resource group where they plan to provision the instance.\n\n\n\n\n\n\n\n Connecting Monitoring with Key Protect \n\nYour dashboard will show metrics for all Key Protect instances with an enabled metrics policy.\n\n\n\n Configure a Monitoring instance for metrics \n\nTo enable platform metrics in a region, complete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03107-5127-7134","score":22.011555,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16250-1908-4265","score":21.339699,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16252-3899-5971","score":20.97857,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03037-1358-3485","score":20.12339,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03112-4-2069","score":19.979847,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Accessing context data \n\nThe context is an object containing variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation; the context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_16252-7-1601","score":19.949146,"text":"\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03312-1841-4150","score":19.850088,"text":"\nWatson Assistant analytics provide overview statistics on the number of interactions with users and containment rates. Analytics doesn't cumulate statistics across regions. With an active\/passive topology, this approach to analytics should be sufficient. However, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Recommendations \n\nThe intent and user example recommendation features use production data to make the recommendations. The available recommendations may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Autolearning \n\nThe autolearning feature uses production data to train an improved intent recognizer. The autolearning results may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16324-1477-3681","score":19.775,"text":"\nIf you have an existing interactive voice response (IVR) system with a branching structure (\u201cpress 1 for billing, press 2 for payments\u201d), you might choose the [phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone) as your initial channel. You can integrate Watson Assistant with your existing system to automate the IVR experience so customers can talk with your assistant over the phone.\n\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform. For more information about ways to deploy an assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\n\n\n\n\n 2. Pick your assistant's domain of expertise \n\nDecide which general domain of expertise you want your assistant to cover (for example, billing support or scheduling appointments). To make an informed decision, review any support call logs that you have access to or ask your customer service representatives. After you choose a domain, be sure that it aligns with a channel that you can control and change. For example, don\u2019t choose to automate billing support questions if you're unable to add the web chat client to the billing web pages.\n\nAfter you select a domain, you can decide which specific questions or tasks the assistant will help customers with. Start small. Pick one or a handful of customer issues that will deliver the highest value to start. It might be valuable for your assistant to answer a simple question that is asked all the time. Or maybe there's a task, such as scheduling appointments, that you can offload to the assistant to tackle incoming customer requests.\n\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_03363-4-2165","score":19.529896,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03037-7-1971","score":19.420387,"text":"\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03028-1501-3230","score":19.53717,"text":"\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/entities_filter.png)\n\nMessages might take some time to update. Allow at least 30 minutes after a user's interaction with your assistant before attempting to filter for that content.\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.\n\nThe time that is shown for each conversation is localized to reflect the time zone of your browser. This time might differ from the timestamp shown if you review the same conversation log via an API call; API log calls are always shown in UTC.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_03354-1698-3275","score":16.35108,"text":"\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days\nTrial | Last 30 days\nLite | Last 7 days\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/entities_filter.png)\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_02991-7699-8461","score":15.602773,"text":"\n| [response.output.intents:intent::order,response.output.entities:entity::beverage] |\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 \/logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs).\n\nWith the v1 \/logs API, you can filter on the following fields:\n\n\n\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* meta.message.entities_count\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference"},{"document_id":"ibmcld_03037-7-1971","score":15.300423,"text":"\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_05891-230244-232067","score":15.045287,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-230696-232519","score":15.045287,"text":"\nAcceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log. Example: The pattern \"hello [0-9]\" would apply to \"hello 1\", \"hello 2\", and \"hello 9\".\n\n--force-update\n: Force your Fluentd pods to update to the latest version. Fluentd must be at the latest version to change your logging configurations.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExamples:\n\nThis example filters out all logs that are forwarded from containers with the name test-container in the default namespace that are at the debug level or less, and have a log message that contains \"GET request\".\n\nibmcloud ks logging filter create --cluster example-cluster --type container --namespace default --container test-container --level debug --message \"GET request\"\n\nThis example filters out all the logs that are forwarded, at an info level or less, from a specific cluster. The output is returned as JSON.\n\nibmcloud ks logging filter create --cluster example-cluster --type all --level info --output json\n\n\n\n\n\n ibmcloud ks logging filter get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView a logging filter configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05832-21399-23084","score":14.84151,"text":"\nIf not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option. \n <kubernetes_namespace> Optional: The Kubernetes namespace that you want to forward logs from. This option applies only when you are using log type container. \n <container_name> Optional: The name of the container from which you want to filter logs. \n <logging_level> Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. To display your messages in JSON, append the --output json option to the command. \n <message> Optional: Filters out logs that contain a specified message that is written as a regular expression. \n <filter_ID> Optional: The ID of the log filter. \n --show-matching-configs Optional: Show the logging configurations that each filter applies to. \n --all Optional: Delete all your log forwarding filters. \n\n\n\n\n\n1. Create a logging filter.\n\nibmcloud ks logging filter create --cluster <cluster_name_or_ID> --type <log_type> --logging-configs <configs> --namespace <kubernetes_namespace> --container <container_name> --level <logging_level> --regex-message <message>\n2. View the log filter that you created.\n\nibmcloud ks logging filter get --cluster <cluster_name_or_ID> --id <filter_ID> --show-matching-configs\n3. Update the log filter that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health"},{"document_id":"ibmcld_16310-7627-8554","score":14.841298,"text":"\nAn intent name in the response exactly matches order, and an entity name in the response exactly matches beverage. [response.output.intents:intent::order,response.output.entities:entity::beverage] \n\n\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 \/logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs).\n\nWith the v1 \/logs API, you can filter on the following fields:\n\n\n\n* language\n* meta.message.entities_count\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.context.conversation_id\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference"},{"document_id":"ibmcld_02991-4944-6614","score":14.703779,"text":"\nresponse.output.entities:value::soda\n\nSimilarly, you can filter on intents or entities sent as part of the request, as in this example:\n\nrequest.input.intents:intent::hello\n\n\n\n\n\n Filtering by other fields \n\nTo filter on another field in the log data, specify the location as a path identifying the levels of nested objects in the JSON response from the \/logs API. Use dots (.) to specify successive levels of nesting in the JSON data. For example, the location request.input.text idenfities the user input text field as shown in the following JSON fragment:\n\n\"request\": {\n\"input\": {\n\"text\": \"Good morning\"\n}\n}\n\nFiltering is not available for all fields. You can filter on the following fields:\n\n\n\n* assistant_id\n* customer_id\n* language\n* request.context.global.system.user_id\n* request.input.text\n* request_timestamp\n* response.context.global.system.user_id\n* response.output.entities\n* response.output.intents\n* response_timestamp\n* skill_id\n* snapshot\n\n\n\nFiltering on other fields is not currently supported.\n\n\n\n\n\n\n\n Examples \n\nThe following examples illustrate various types of queries using this syntax.\n\n\n\n Description Query \n\n The date of the response is in the month of July 2020. response_timestamp>=2020-07-01,response_timestamp<2020-08-01 \n The timestamp of the response is earlier than 2019-11-01T04:00:00.000Z. response_timestamp<2019-11-01T04:00:00.000Z \n The message is labeled with the customer ID my_id. customer_id::my_id \n The message was sent to a specific assistant. assistant_id::dcd5c5ad-f3a1-4345-89c5-708b0b5ff4f7 \n The user input text contains the word \"order\" or a grammatical variant (for example, orders or ordering. request.input.text:order","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference"},{"document_id":"ibmcld_04489-234834-236561","score":14.673191,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-3707-6008","score":26.267342,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_16364-101992-104197","score":23.19119,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-16079-18117","score":22.686768,"text":"\n: The dialog feature is available in the new Watson Assistant experience. If you have a dialog-based assistant that was built using the classic Watson Assistant, you can now migrate your dialog skill to the new Watson Assistant experience. For more information, see [Migrating to the new experience](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 25 March 2022 \n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.\n\nFor example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update applies to the following languages: English, French, Spanish, Italian, and the universal language model. For more information, see [Accessing intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 23 March 2022 \n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-64600-66787","score":21.27067,"text":"\n: Want a quick way to see how your dialog is doing at responding to customer queries? Enable the new coverage metric to find out. The coverage metric measures the rate at which your dialog is confident that it can address a customer's request per message. For conversations that are not covered, you can review the logs to learn more about what the customer wanted. For the metric to work, you must design your dialog to include an Anything else node that is processed when no other dialog node intents are matched. For more information, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n\nTry out the enhanced intent detection model\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time.\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-66296-68553","score":21.25721,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-36856-39124","score":20.98978,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03049-2703-4536","score":20.45928,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_16364-103662-105841","score":19.495531,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03329-1102-2607","score":19.407112,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_16364-72601-74697","score":19.082047,"text":"\nFor more information, see [Actions skill overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overview).\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests. For more information, see [Response types](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-response-types).\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nFor more information, see [Adding and referencing variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-variables).\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.6546154995}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":24.188976,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":22.81862,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":21.31814,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":21.069593,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03126-3707-6008","score":20.404339,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03353-5263-7331","score":19.996344,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03027-7-1946","score":19.822826,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03120-4813-6717","score":19.715069,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03120-4-2233","score":19.574825,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-3583-5403","score":19.45347,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03073-7-1928","score":16.717676,"text":"\nCreating skill versions \n\nVersions help you manage the workflow of a dialog skill development project.\n\nCreate a skill version to capture a snapshot of the training data (intents and entities) and dialog in the skill at key points during the development process. Being able to save an in-progress skill at a specific point in time is especially useful as you start to fine tune your assistant. You often need to make a change and see the impact of the change in real time before you can determine whether or not the change improves or lessens the effectiveness of the assistant. Based on your findings from a test environment deployment, you can make an informed decision about whether to deploy a given change to an assistant that is deployed in a production environment.\n\nTo learn more about how versions can improve the workflow you use to build an assistant, [read this blog post](https:\/\/medium.com\/ibm-watson\/watson-assistant-versions-announcement-d60869b1f5f).\n\n\n\n Creating a version \n\nYou can edit only one version of the dialog skill at a time. The in-progress version is called the development version.\n\nWhen you save a version, any skill settings that you applied to the development version are saved also.\n\nTo create a dialog skill version, follow these steps:\n\n\n\n1. From the header of the skill, click Save new version, and then describe the current state of the skill.\n\nAdding a good description will help you to distinguish multiple versions from one another later.\n2. Click Save.\n\n\n\nA snapshot is taken of the current skill and saved as a new version. You remain in the development version of the skill. Any changes you make continue to be applied to the development version, not the version you saved. To access the version you saved, go to the Versions page.\n\n\n\n\n\n Deploying a skill version \n\n\n\n1. From the skill menu, click Versions.\n\nv1.3: Click the Skills tab, and then click Versions.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions"},{"document_id":"ibmcld_03373-7076-8670","score":16.491484,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03139-2715-4132","score":16.068106,"text":"\n[Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.\n4. Select the JSON file you want to import.\n\nThe imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON file cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1createworkspace).\n5. Click Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n6. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the skill, it appears as a tile on the Skills page.\n\n\n\n\n\n Re-creating your assistant \n\nYou can now re-create your assistant. You can then link your uploaded skills to the assistant, and configure integrations for it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_03369-74273-76338","score":15.701776,"text":"\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03381-1467-3226","score":15.619455,"text":"\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill upload issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n* If you have created a dialog skill already, the Add existing skill tab is displayed, and you can click to add an existing skill.\n\n\n\n3. Specify the details for the skill:\n\n\n\n* Name: A name no more than 64 characters in length. A name is required.\n* Description: An optional description no more than 128 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n4. For Skill type, choose Dialog.\n5. Click Create skill.\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03043-7-2031","score":15.58002,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_16364-163116-165172","score":15.038901,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02839-1790-3940","score":14.935873,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03369-36856-39124","score":14.846564,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03049-1355-3132","score":14.781311,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09903-9624-10554","score":9.318088,"text":"\nHebrew [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"},{"document_id":"ibmcld_02839-1790-3940","score":8.852709,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_09913-7-1696","score":8.8173485,"text":"\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-6894-8823","score":8.236072,"text":"\nClassifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Hebrew \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Hindi \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Italian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Japanese \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09229-13577-15175","score":8.009447,"text":"\nTable 13. Dutch translation model\n\n Model ID Source Target Domain \n\n nl-en Dutch (nl) English (en) general \n\n\n\n\n\n\n\n English \n\nThe following English translation models can be customized.\n\nThe English-to-Montenegrin translation model (en-cnr) is not customizable at this time. It can be used for translation but cannot be customized.\n\n\n\nTable 14. English translation models\n\n Model ID Source Target Domain \n\n en-ar English (en) Arabic (ar) general \n en-bg English (en) Bulgarian (bg) general \n en-bn English (en) Bengali (bn) general \n en-bs English (en) Bosnian (bs) general \n en-cnr English (en) Montenegrin (cnr) general \n en-cs English (en) Czech (cs) general \n en-cy English (en) Welsh (cy) general \n en-da English (en) Danish (da) general \n en-de English (en) German (de) general \n en-el English (en) Greek (el) general \n en-es English (en) Spanish (es) general \n en-et English (en) Estonian (et) general \n en-fi English (en) Finnish (fi) general \n en-fr English (en) French (fr) general \n en-fr-CA English (en) Canadian French (fr-CA) general \n en-ga English (en) Irish (ga) general \n en-gu English (en) Gujarati (gu) general \n en-he English (en) Hebrew (he) general \n en-hi English (en) Hindi (hi) general \n en-hr English (en) Croatian (hr) general \n en-hu English (en) Hungarian (hu) general \n en-id English (en) Indonesian (id) general \n en-it English (en) Italian (it) general \n en-ja English (en) Japanese (ja) general \n en-kn English (en) Kannada (kn) general \n en-ko English (en) Korean (ko) general \n en-lt English (en) Lithuanian (lt) general \n en-lv English (en) Latvian (lv) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09229-16048-18016","score":7.989763,"text":"\nen-th English (en) Thai (th) general \n en-tr English (en) Turkish (tr) general \n en-uk English (en) Ukrainian (uk) general \n en-ur English (en) Urdu (ur) general \n en-vi English (en) Vietnamese (vi) general \n en-zh English (en) Simplified Chinese (zh) general \n en-zh-TW English (en) Traditional Chinese (zh-TW) general \n\n\n\n\n\n\n\n Estonian \n\nThe following Estonian translation model can be customized.\n\n\n\nTable 15. Estonian translation model\n\n Model ID Source Target Domain \n\n et-en Estonian (et) English (en) general \n\n\n\n\n\n\n\n Finnish \n\nThe following Finnish translation model can be customized.\n\n\n\nTable 16. Finnish translation model\n\n Model ID Source Target Domain \n\n fi-en Finnish (fi) English (en) general \n\n\n\n\n\n\n\n French \n\nThe following French translation model can be customized.\n\n\n\nTable 17. French translation model\n\n Model ID Source Target Domain \n\n fr-en French (fr) English (en) general \n\n\n\n\n\n\n\n French (Canadian) \n\nThe following French (Canadian) translation model can be customized.\n\n\n\nTable 18. Canadian French translation model\n\n Model ID Source Target Domain \n\n fr-CA-en Canadian French (fr-CA) English (en) general \n\n\n\n\n\n\n\n German \n\nThe following German translation models can be customized.\n\n\n\nTable 19. German translation models\n\n Model ID Source Target Domain \n\n de-en German (de) English (en) general \n de-fr German (de) French (fr) general \n de-it German (de) Italian (it) general \n\n\n\n\n\n\n\n Greek \n\nThe following Greek translation model can be customized.\n\n\n\nTable 20. Greek translation model\n\n Model ID Source Target Domain \n\n el-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_07060-3534-5748","score":7.907727,"text":"\nGerman (de) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1 (Installed), Optical character recognition v2 (Cloud-managed), Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Hebrew (he) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v2 (Cloud-managed), Parts of speech, Regular expressions, Smart Document Understanding, Table Understanding \n Hindi (hi) Classifier (Document and Text), Custom entities, Dictionary, Parts of speech, Regular expressions, Stemmer \n Italian (it) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Japanese (ja) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1, Parts of speech, Phrase sentiment, Regular expressions, Smart Document Understanding, Table Understanding \n Korean (ko) Advanced rules models, Built-in entities, Classifier (Document and Text), Custom entities, Dictionary, Document sentiment, Keywords, Machine Learning, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Table Understanding \n Norwegian (Bokma\u030al) (nb) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Norwegian (Nynorsk) (nn) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Stemmer, Table Understanding \n Polish (pl) Classifier (Document and Text), Custom entities, Dictionary, Optical character recognition v1, Parts of speech, Regular expressions, Smart Document Understanding, Table Understanding","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support"},{"document_id":"ibmcld_09226-18248-20249","score":7.752969,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_02747-19701-21292","score":7.7088804,"text":"\nlg-UG Ganda Uganda \n ka-GE Georgian Georgia \n de-AT German Austria \n de-DE German Germany \n de-LU German Luxembourg \n de-CH German Switzerland \n el-GR Greek Greece \n gu-IN Gujarati India \n ha-NG Hausa Nigeria \n he-IL Hebrew Israel \n hi-IN Hindi India \n hu-HU Hungarian Hungary \n is-IS Icelandic Iceland \n ig-NG Igbo Nigeria \n id-ID Indonesian Indonesia \n it-IT Italian Italy \n it-CH Italian Switzerland \n ja-JP Japanese Japan \n kn-IN Kannada India \n kk-KZ Kazakh Kazakhstan \n km-KH Khmer Cambodia \n rw-RW Kinyarwanda Rwanda \n kok-IN Konkani India \n ko-KR Korean South Korea \n lo-LA Lithuanian Lithuania \n lv-LV Latvian Latvia \n lt-LT Khmer Cambodia \n mk-MK Macedonian Macedonia \n ms-Latn-MY Malay-Latin Malaysia \n ml-IN Malayalam India \n mt-MT Maltese Malta \n mr-IN Marathi India \n mn-Cyrl-MN Mongolian-Cyrillic Mongolia \n ne-IN Nepali India \n ne-NP Nepali Nepal \n nb-NO Norwegian Bokm\u00e5l Norway \n nn-NO Norwegian Nynorsk Norway \n or-IN Oriya (Odia) India \n om-ET Oromo Ethiopia \n pl-PL Polish Poland \n pt-AO Portuguese Angola \n pt-BR Portuguese Brazil \n pt-MO Portuguese Macao S.A.R. of the PRC \n pt-MZ Portuguese Mozambique \n pt-PT Portuguese Portugal \n pa-IN Punjabi India \n ro-RO Romanian Romania \n ru-RU Russian Russia \n sr-Cyrl-RS Serbian-Cyrillic Serbia \n sr-Latn-ME Serbian-Latin Montenegro \n sr-Latn-RS Serbian-Latin Serbia \n si-LK Sinhala Sri Lanka \n sk-SK Slovak Slovakia \n sl-SI Slovenian Slovenia \n es-AR Spanish Argentina \n es-BO Spanish Bolivia \n es-CL Spanish Chile \n es-CO Spanish Colombia \n es-CR Spanish Costa Rica \n es-DO Spanish Dominican Republic \n es-EC Spanish Ecuador","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-types"},{"document_id":"ibmcld_09913-1307-2928","score":7.704279,"text":"\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)\n* [Hindi](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthindi)\n* [Italian](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportitalian)\n* [Japanese](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportjapanese)\n* [Korean](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportkorean)\n* [Norwegian](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian)\n* [Norwegian (Bokmal)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian-bokmal)\n* [Norwegian (Nyorsk)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportnorwegian-nyorsk)\n* [Polish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportpolish)\n* [Portuguese](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportportuguese)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2139862647,"ndcg_cut_10":0.2139862647}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-15701-17094","score":16.477581,"text":"\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.\n\nClient libraries use POST method instead of GET because they have a similar behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails?descending=true\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nconst { CloudantV1 } = require('@ibm-cloud\/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.postView({\ndb: 'users',\nddoc: 'allusers',\nview: 'getVerifiedEmails',\ndescending: true\n}).then(response => {\nconsole.log(response.result);\n});\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00539-2548-4016","score":15.632468,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_16471-106006-108222","score":14.348302,"text":"\nAll other spans are left untouched.\n* LeftToRight\n\nThis policy processes the spans in order from left to right. When overlap occurs, it retains the leftmost, longest, non-overlapping span. This policy emulates the overlap-handling policy of most regular expression engines.\n\n\n\n* <priority_column>\n\nSpecifies a column of type Text, String, Integer, or Float. Can be specified only with the LeftToRight consolidation policy.\n* <priority_order>\n\nSpecifies either ascending or descending order. Can be specified only with the LeftToRight consolidation policy. The ascending order ensures that if a tuple T1 has priority 1 and a tuple T2 has priority 2, T1 has a higher priority than T2. By contrast, if the priority order is descending, T2 has a higher priority. The default value of the priority order is ascending.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* When the priority clause is present, the semantics of consolidation follow this order:\n\n\n\n* Process spans from left to right, and when spans overlap, retain the leftmost spans.\n* If you have multiple overlapping spans that start at the same offset, retain the ones with the highest priority according to the priority order.\n* Break remaining ties by retaining the longest spans among those spans with the same priority.\n\n\n\n* Consolidate treats nulls as identical. All inputs with a null <consolidate target> result in a single output tuple, which is chosen randomly among those inputs. This behavior is similar to how tuples are consolidated with an identical span in the target column. The exception to resulting in a single output tuple is if the policy is ContainsButNotEqual. In that case, the null <consolidate target> outputs all inputs with null consolidate target.\n\n\n\n\n\n\n\n Examples \n\nExample 1: Consolidate on single column\n\nThis example directs the system to examine the field Person.name of all output tuples and to use the ContainedWithin consolidation policy to resolve overlap.\n\nconsolidate on Person.name\nusing 'ContainedWithin'\n\nExample 2: Consolidate on expression, involving multiple columns\n\nThis example directs the system to examine the result of applying the CombineSpans scalar function to fields Person.firstname and Person.lastname in each output tuple.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_00644-14024-16089","score":14.070644,"text":"\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https:\/\/en.wikipedia.org\/wiki\/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_03184-7285-9367","score":13.994992,"text":"\nIf multiple actions in a single JSON action array add the result of their programmatic call to the same context variable, then the order in which the context is updated matters. Per action type, the order in which the actions are defined in the array determines the order in which the context variable's value is set. The context variable value returned by the last action in the array overwrites the values calculated by any other actions.\n\nThe result_variable property is required. If the client action does not return any result, specify null as the value.\n\n\n\n\n\n\n\n\n\n Client action example \n\nThe following example shows what a request for a call to an external weather service might look like. It is added to the JSON editor that is associated with the node response. By the time the node-level response is triggered, slots have collected and stored the date and location information from the user. This example assumes that the client action is named weather_forecast, that it takes a location parameter, and that the results are to be stored in the weather_forecast context variable.\n\n{\n\"actions\": [\n{\n\"name\": \"get_weather\",\n\"type\": \"client\",\n\"parameters\": {\n\"location\": \"$location\"\n},\n\"result_variable\": \"weather_forecast\"\n}\n]\n}\n\nThe client application must check for the presence of any client actions in the responses to messages it sends to the assistant. When it recognizes a request for the get_weather action, it executes the action (calling the external weather service), and it stores the result in the specified context variable (weather_forecast). It then sends a message to the service, including the updated context.\n\nTo handle this message in your dialog, create a child node following the node that requested the action. You can condition this child node on the special condition true to ensure that it is always triggered by the message that the client sends after completing the requested action. In this child node, add the response to show the user, reading the stored action result from the $my_forecast context variable:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_03285-34490-35530","score":13.903621,"text":"\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the output.generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Goodbye.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"end_session\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_00644-20617-22169","score":13.391641,"text":"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nFor example, if you have a database that returns one result when you use a start_key of alpha and an end_key of beta, you would get a 400 (Bad request) error with a reversed order. The reason is that the entries in the view are reversed before the key filter is applied.\n\nSee the example that uses HTTP to illustrate why reversing the order of start_key and end_key might return a query parse error:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true&start_key=\"alpha\"&end_key=\"beta\" HTTP\/1.1\n\nSee the example illustrating why reversing the order of start_key and end_key might cause a 400 error.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails?descending=true&start_key=\"alpha\"&end_key=\"beta\"\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.startKey(\"alpha\")\n.endKey(\"beta\")\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_07085-4625-5922","score":13.317036,"text":"\n\"key\": \"TAMPA\",\n\"matching_results\": 29\n}\n]\n}\n]\n}\n]\n}\n],\n\"results\": []\nShow more\n\nThe order in which you specify the aggregations matters. For example, if you reverse the order of the term aggregations from the previous example, you get different results.\n\n{\n\"query\":\"brake\",\n\"aggregation\": \"term(field:CITY,count:3).term(field:STATE,count:1)\"\n}\n\nThe new order produces results that surface Chicago, a city that wasn't included in the previous set of results. When the request starts by grouping by state, Illinois, which has only one city with a high number of traffic incident reports, is not included in the results. New York and Florida, which both have more than one city with many incident reports, produce a higher number of statewide matches and therefore, were returned. When you group by city first, the results change.\n\n{\n\"matching_results\": 9064,\n\"retrieval_details\": {\n\"document_retrieval_strategy\": \"untrained\"\n},\n\"aggregations\": [\n{\n\"type\": \"term\",\n\"field\": \"CITY\",\n\"count\": 4,\n\"results\":\n{\n\"key\": \"LOS ANGELES\",\n\"matching_results\": 77,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"STATE\",\n\"count\": 1,\n\"results\":\n{\n\"key\": \"CA\",\n\"matching_results\": 77\n}\n]\n}\n]\n},\n{\n\"key\": \"SAN DIEGO\",\n\"matching_results\": 66,\n\"aggregations\":\n{\n\"type\": \"term\",\n\"field\": \"STATE\",\n\"count\": 1,\n\"results\":\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-aggregations"},{"document_id":"ibmcld_13429-14164-15905","score":13.171465,"text":"\n* [Improved language model customization for next-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-customizationcustomLanguage-intro-ng)\n* [Upgrading custom models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade)\n* [Using customization weight](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUseweight)\n* [Character insertion bias](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsinginsertion-bias)\n\n\n\nDefect fix: Grammar files now handle strings of digits correctly\n: Defect fix: When grammars are used, the service now handles longer strings of digits correctly. Previously, it was failing to complete recognition or returning incorrect results.\n\n\n\n\n\n 15 February 2023 \n\nImportant: All previous-generation models are deprecated and will reach end of service on 31 July 2023\n: Important: All previous-generation models are deprecated and will reach end of service effective 31 July 2023. On that date, all previous-generation models will be removed from the service and the documentation. The previous deprecation date was 3 March 2023. The new date allows users more time to migrate to the appropriate next-generation models. But users must migrate to the equivalent next-generation model by 31 July 2023.\n\nMost previous-generation models were deprecated on 15 March 2022. Previously, the Arabic and Japanese models were not deprecated. Deprecation now applies to all previous-generation models.\n\n\n\n* For more information about the next-generation models to which you can migrate from each of the deprecated models, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_16481-11758-13691","score":13.131114,"text":"\n* Annotator_1 places a mention on a span of text; Annotator_2 does not.\n* Annotator_1's index begins or ends before or after Annotator_2's (there is a partial overlap or subrange of text).\n* Annotator_1 assigns an entity type that is different from the entity type that Annotator_2 assigned.\n\n\n\n* Relations\n\n\n\n* Annotator_1 creates a relation between two mentions; Annotator_2 does not.\n* Annotator_1 and Annotator_2 create a relation between the same mentions, but with a different relation type.\n* Annotator_1 and Annotator_2 create a relation between the same mentions, but in the reverse order (rare, because the relation between the first mention and second mention is constrained by the type system).\n\n\n\n* Coreference chains\n\n\n\n* Annotator_1's version of a coreference chain includes (or excludes) mentions that Annotator_2's coreference chain excludes (or includes). The alignment of entities between Annotator_1 and Annotator_2 becomes a matter of scoring.\n\n\n\n\n\n\n\n\n\n Resolving annotation conflicts \n\nAdjudication is a step that allows you to review annotation conflicts in overlapping documents before you promote the annotations to ground truth. You can compare the annotations added by a pair of human annotators, or compare human annotations to the current ground truth.\n\n\n\n Before you begin \n\n[Watch](https:\/\/www.youtube.com\/watch?v=EbexfsuXxoQ&feature=youtu.be) a 3-minute video that illustrates how to adjudicate documents.\n\n\n\n\n\n About this task \n\nAfter human annotators complete their annotation tasks, they must submit their completed annotation sets for review. When you evaluate the inter-annotator agreement scores, you can see how different pairs of annotators annotated the same document. If the inter-annotator agreement score is acceptable, you approve the annotation set. If a document does not overlap across annotation sets in the task, the annotations in the approved document are promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16437-8176-9767","score":7.6042547,"text":"\nAs the test documents get used iteratively to improve the model, they can start to influence the model training indirectly. That's why the \"blind\" set of documents is so important.\n\n\n\n\n\n How do I control which documents are allocated to a set? \n\nWhen you create a machine learning model, you must specify the ratio of documents from the set to allocate to the train, test, or blind sets. Knowledge Studio automatically applies a ratio of 70\/23\/7 to the document sets that you use to build a machine learning model. You can change these values.\n\n\n\n* To add a set that was annotated by humans to the training set, specify a 100\/0\/0 breakdown ratio.\n* After training with a set, you can use it for testing. To use a document set for testing only, specify a 0\/100\/0 breakdown ration.\n* Only add a document set that has never been used for training or testing to the blind set. To do so, specify a 0\/0\/100 breakdown ratio for the document set.\n\n\n\nPlan to stop using a blind set after a few iterations. The more you use a blind set, the less \"blind\" it becomes. The same goes for your test data. Rather than discard the sets, you can migrate them to serve a new purpose. Follow this migration flow:\n\nblind --> test --> train\n\nAs the sets migrate, you can add new, unseen document sets as blind data, and as test data. But, be sure to retain a method for evaluating accuracy across model versions. One way to establish a baseline is to run an earlier version of the model on the new document sets. The results of this run give you a basis of comparison with runs of newer models on those same sets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_16495-8166-9757","score":7.6042547,"text":"\nAs the test documents get used iteratively to improve the model, they can start to influence the model training indirectly. That's why the \"blind\" set of documents is so important.\n\n\n\n\n\n How do I control which documents are allocated to a set? \n\nWhen you create a machine learning model, you must specify the ratio of documents from the set to allocate to the train, test, or blind sets. Knowledge Studio automatically applies a ratio of 70\/23\/7 to the document sets that you use to build a machine learning model. You can change these values.\n\n\n\n* To add a set that was annotated by humans to the training set, specify a 100\/0\/0 breakdown ratio.\n* After training with a set, you can use it for testing. To use a document set for testing only, specify a 0\/100\/0 breakdown ration.\n* Only add a document set that has never been used for training or testing to the blind set. To do so, specify a 0\/0\/100 breakdown ratio for the document set.\n\n\n\nPlan to stop using a blind set after a few iterations. The more you use a blind set, the less \"blind\" it becomes. The same goes for your test data. Rather than discard the sets, you can migrate them to serve a new purpose. Follow this migration flow:\n\nblind --> test --> train\n\nAs the sets migrate, you can add new, unseen document sets as blind data, and as test data. But, be sure to retain a method for evaluating accuracy across model versions. One way to establish a baseline is to run an earlier version of the model on the new document sets. The results of this run give you a basis of comparison with runs of newer models on those same sets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_13942-13473-14921","score":7.097993,"text":"\nset system conntrack modules 'gre'\nset system conntrack modules h323 'disable'\nset system conntrack modules nfs 'disable'\nset system conntrack modules pptp 'disable'\nset system conntrack modules sip 'disable'\nset system conntrack modules sqlnet 'disable'\nset system conntrack modules tftp 'disable'\nset system conntrack table-size '3000000'\n\n\n\n\n\n\n\n Set system conntrack timeout \n\n\n\n Set system conntrack timeout issues \n\nset system conntrack timeout icmp '30'\nset system conntrack timeout other '600'\nset system conntrack timeout tcp close '10'\nset system conntrack timeout tcp close-wait '60'\nset system conntrack timeout tcp established '432000'\nset system conntrack timeout tcp fin-wait '120'\nset system conntrack timeout tcp last-ack '30'\nset system conntrack timeout tcp syn-recv '60'\nset system conntrack timeout tcp syn-sent '120'\nset system conntrack timeout tcp time-wait '60'\n\n\n\n\n\n\n\n Time based firewall \n\n\n\n Time based firewall issues \n\nset firewall name PRIV_SERVICE_IN rule 58 action 'accept'\nset firewall name PRIV_SERVICE_IN rule 58 description '586427 Acesso a base de dados ate 22-2-18'\nset firewall name PRIV_SERVICE_IN rule 58 destination address '10.150.156.57'\nset firewall name PRIV_SERVICE_IN rule 58 destination port '3306'\nset firewall name PRIV_SERVICE_IN rule 58 protocol 'tcp'\nset firewall name PRIV_SERVICE_IN rule 58 source address '10.150.156.104'\nset firewall name PRIV_SERVICE_IN rule 58 time startdate '2017-08-22'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-vyatta-5400-common-migration-issues"},{"document_id":"ibmcld_14690-4276-6282","score":6.823373,"text":"\nset security address-book global address-set SERVICE address SL19\nset security address-book global address-set SERVICE address SL20\nset security screen ids-option untrust-screen icmp ping-death\nset security screen ids-option untrust-screen ip source-route-option\nset security screen ids-option untrust-screen ip tear-drop\nset security screen ids-option untrust-screen tcp syn-flood alarm-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood attack-threshold 200\nset security screen ids-option untrust-screen tcp syn-flood source-threshold 1024\nset security screen ids-option untrust-screen tcp syn-flood destination-threshold 2048\nset security screen ids-option untrust-screen tcp syn-flood queue-size 2000\nset security screen ids-option untrust-screen tcp syn-flood timeout 20\nset security screen ids-option untrust-screen tcp land\nset security policies from-zone trust to-zone trust policy default-permit match source-address any\nset security policies from-zone trust to-zone trust policy default-permit match destination-address any\nset security policies from-zone trust to-zone trust policy default-permit match application any\nset security policies from-zone trust to-zone trust policy default-permit then permit\nset security policies from-zone trust to-zone untrust policy default-permit match source-address any\nset security policies from-zone trust to-zone untrust policy default-permit match destination-address any\nset security policies from-zone trust to-zone untrust policy default-permit match application any\nset security policies from-zone trust to-zone untrust policy default-permit then permit\nset security zones security-zone trust tcp-rst\nset security zones security-zone trust interfaces reth0.0 host-inbound-traffic system-services all\nset security zones security-zone untrust screen untrust-screen\nset security zones security-zone untrust interfaces reth1.0 host-inbound-traffic system-services all\nset interfaces ge-0\/0\/1 gigether-options redundant-parent reth0","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-iaas-def-config"},{"document_id":"ibmcld_16468-8522-10510","score":6.754796,"text":"\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_13891-7711-9318","score":6.6615777,"text":"\nset system acm operational-ruleset rule 9980 command '\/show\/tech-support\/save-uncompressed\/'\nset system acm operational-ruleset rule 9980 group 'vyattaop'\nset system acm operational-ruleset rule 9981 action 'allow'\nset system acm operational-ruleset rule 9981 command '\/show\/tech-support\/brief\/save'\nset system acm operational-ruleset rule 9981 group 'vyattaop'\nset system acm operational-ruleset rule 9982 action 'deny'\nset system acm operational-ruleset rule 9982 command '\/show\/tech-support\/brief\/save\/'\nset system acm operational-ruleset rule 9982 group 'vyattaop'\nset system acm operational-ruleset rule 9983 action 'allow'\nset system acm operational-ruleset rule 9983 command '\/show\/tech-support\/brief\/save-uncompressed'\nset system acm operational-ruleset rule 9983 group 'vyattaop'\nset system acm operational-ruleset rule 9984 action 'deny'\nset system acm operational-ruleset rule 9984 command '\/show\/tech-support\/brief\/save-uncompressed\/'\nset system acm operational-ruleset rule 9984 group 'vyattaop'\nset system acm operational-ruleset rule 9985 action 'allow'\nset system acm operational-ruleset rule 9985 command '\/show\/tech-support\/brief\/'\nset system acm operational-ruleset rule 9985 group 'vyattaop'\nset system acm operational-ruleset rule 9986 action 'deny'\nset system acm operational-ruleset rule 9986 command '\/show\/tech-support\/brief'\nset system acm operational-ruleset rule 9986 group 'vyattaop'\nset system acm operational-ruleset rule 9987 action 'deny'\nset system acm operational-ruleset rule 9987 command '\/show\/tech-support'\nset system acm operational-ruleset rule 9987 group 'vyattaop'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-accessing-and-configuring-the-ibm-virtual-router-appliance"},{"document_id":"ibmcld_14287-11299-13149","score":6.562735,"text":"\n(Primary Private Subnet 1102\/Storage)\nset firewall group network-group 1102STORAGEA network ... (Portable Private Subnet 1102\/Storage Path A)\nset firewall group network-group 1102STORAGEB network ... (Portable Private Subnet 1102\/Storage Path B)\nset firewall group network-group 1103VMACCESS network ... (Portable Private Subnet 1103\/Virtual Machines)\ncommit\nsave\nShow more\n\n\n\n\n\n Configuring firewall name rules \n\nDefine the firewall rules for each direction of traffic.\n\nUse the following commands in configure mode:\n\nset firewall name INSIDE2OUTSIDE\nset firewall name INSIDE2OUTSIDE default-action drop\nset firewall name INSIDE2OUTSIDE rule 10 action accept\nset firewall name INSIDE2OUTSIDE rule 10 protocol all\nset firewall name INSIDE2OUTSIDE rule 10 source group network-group 1101MGMT\nset firewall name INSIDE2OUTSIDE rule 20 action accept\nset firewall name INSIDE2OUTSIDE rule 20 protocol all\nset firewall name INSIDE2OUTSIDE rule 20 source group network-group 1103VMACCESS\nset firewall name OUTSIDE2INSIDE\nset firewall name OUTSIDE2INSIDE default-action drop\nset firewall name OUTSIDE2INSIDE rule 10 action accept\nset firewall name OUTSIDE2INSIDE rule 10 protocol udp\nset firewall name OUTSIDE2INSIDE rule 20 action accept\nset firewall name OUTSIDE2INSIDE rule 20 protocol udp\nset firewall name OUTSIDE2INSIDE rule 20 destination port 4500\nset firewall name OUTSIDE2INSIDE rule 30 action accept\nset firewall name OUTSIDE2INSIDE rule 30 protocol udp\nset firewall name OUTSIDE2INSIDE rule 30 destination port 500\nset firewall name OUTSIDE2INSIDE rule 40 action accept\nset firewall name OUTSIDE2INSIDE rule 40 ipsec match-ipsec\nset firewall name OUTSIDE2INSIDE rule 50 action accept\nset firewall name OUTSIDE2INSIDE rule 50 protocol gre\nset firewall name OUTSIDE2INSIDE rule 60 action accept\nset firewall name OUTSIDE2INSIDE rule 60 protocol tcp","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-set-up-brocade"},{"document_id":"ibmcld_13891-8982-10626","score":6.4696894,"text":"\nset system acm operational-ruleset rule 9986 command '\/show\/tech-support\/brief'\nset system acm operational-ruleset rule 9986 group 'vyattaop'\nset system acm operational-ruleset rule 9987 action 'deny'\nset system acm operational-ruleset rule 9987 command '\/show\/tech-support'\nset system acm operational-ruleset rule 9987 group 'vyattaop'\nset system acm operational-ruleset rule 9988 action 'deny'\nset system acm operational-ruleset rule 9988 command '\/show\/configuration'\nset system acm operational-ruleset rule 9988 group 'vyattaop'\nset system acm operational-ruleset rule 9989 action 'allow'\nset system acm operational-ruleset rule 9989 command '\/clear\/'\nset system acm operational-ruleset rule 9989 group 'vyattaop'\nset system acm operational-ruleset rule 9990 action 'allow'\nset system acm operational-ruleset rule 9990 command '\/show\/'\nset system acm operational-ruleset rule 9990 group 'vyattaop'\nset system acm operational-ruleset rule 9991 action 'allow'\nset system acm operational-ruleset rule 9991 command '\/monitor\/'\nset system acm operational-ruleset rule 9991 group 'vyattaop'\nset system acm operational-ruleset rule 9992 action 'allow'\nset system acm operational-ruleset rule 9992 command '\/ping\/'\nset system acm operational-ruleset rule 9992 group 'vyattaop'\nset system acm operational-ruleset rule 9993 action 'allow'\nset system acm operational-ruleset rule 9993 command '\/reset\/'\nset system acm operational-ruleset rule 9993 group 'vyattaop'\nset system acm operational-ruleset rule 9994 action 'allow'\nset system acm operational-ruleset rule 9994 command '\/release\/'\nset system acm operational-ruleset rule 9994 group 'vyattaop'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-accessing-and-configuring-the-ibm-virtual-router-appliance"},{"document_id":"ibmcld_14688-1674-3523","score":6.387162,"text":"\nShow more\n\n\n\n Set commands \n\nset system login user pokeyjo uid 2000\n\nset system login user pokeyjo class super-user\n\nset system login user pokeyjo authentication encrypted-password\n\"removed for security\"\n\nset system root-authentication encrypted-password\n\"removed for security\"\n\nset system services ssh\n\nset system services web-management http interface fxp0.0\n\nset system services web-management http interface ge-0\/0\/0.0\n\nset system syslog user * any emergency\n\nset system syslog file messages any any\n\nset system syslog file messages authorization info\n\nset system syslog file interactive-commands interactive-commands any\n\nset security screen ids-option untrust-screen icmp ping-death\n\nset security screen ids-option untrust-screen ip source-route-option\n\nset security screen ids-option untrust-screen ip tear-drop\n\nset security screen ids-option untrust-screen tcp syn-flood\nalarm-threshold 1024\n\nset security screen ids-option untrust-screen tcp syn-flood\nattack-threshold 200\n\nset security screen ids-option untrust-screen tcp syn-flood\nsource-threshold 1024\n\nset security screen ids-option untrust-screen tcp syn-flood\ndestination-threshold 2048\n\nset security screen ids-option untrust-screen tcp syn-flood queue-size\n2000\n\nset security screen ids-option untrust-screen tcp syn-flood timeout 20\n\nset security screen ids-option untrust-screen tcp land\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match source-address any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match destination-address any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit match application any\n\nset security policies from-zone trust to-zone trust policy\ndefault-permit then permit\n\nset security policies from-zone trust to-zone untrust policy\ndefault-permit match source-address any","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcsvsrx-default-config"},{"document_id":"ibmcld_16410-8324-10312","score":6.3797116,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15111-10169-12034","score":21.212671,"text":"\nBy using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n\n\n\n\n\n\n\n Performance questions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_15007-13930-15825","score":20.816347,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-13969-15864","score":20.816347,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_14984-4-2041","score":20.240896,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_07578-891912-893651","score":20.236782,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":20.236782,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14996-4-1904","score":20.141222,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore&interface=ui"},{"document_id":"ibmcld_14984-1616-3476","score":20.121649,"text":"\nFor more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restorebaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore"},{"document_id":"ibmcld_15034-3931-5816","score":20.070377,"text":"\nWhen you restore a volume from a snapshot, and the tags that are applied to the new volume match the tags in a backup policy, the new volume is backed up. But you can't directly back up a snapshot that has tags in a backup policy.\n\n\n\n\n\n How long are backups retained? \n\nYou can specify that backups be kept 1 - 30 days (default). The retention period can't be shorter than the backup frequency or it returns an error.\n\nYou can also specify the number of backups to retain, up to 750 per volume, after which the oldest backups are deleted.\n\n\n\n\n\n Are there limitations on how many backups I can take? \n\nYes. You can create 10 backup policies per account and up to 750 backups of a volume. For other limitations of this release, see [Limitations in this release](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-limitations).\n\n\n\n\n\n How do I create a new volume from a backup? \n\nRestoring from a backup snapshot creates a volume with data from the snapshot. You can restore data from a backup by using the UI, the CLI, or the API. You can restore boot and data volumes during instance creation, when you modify an existing instance, or when you provision a stand-alone volume. When you restore data from a backup snapshot, the data is pulled from an Object Storage bucket. For best performance, you can enable backup snapshots for fast restore. By using the fast restore feature, you can restore a volume that is fully provisioned when the volume is created. When you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"},{"document_id":"ibmcld_15051-1531-3437","score":20.036037,"text":"\nBilling Think about the number of backup snapshots that you want to take and other [billing considerations](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=apisnapshots_vpc_considerations) as the number of backup snapshots grows. \n Volume restore Evaluate when you might want to restore a volume from a backup. Keep in mind that restoring from a backup is a manual operation and not immediate such as a disaster recovery solution. \n Fast-restore You can create and cache a copy of the backup snapshot in one or more zones of the region where your volume resides. Fast-restore can be used in disaster recovery scenarios when you need to restore volumes in a different zone of the same region. The fast restore feature can achieve a<br><br>recovery time objective<br><br>(RTO) quicker than restoring from a regular snapshot. Evaluate when to enable snapshots for [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restoresnapshots-vpc-use-fast-restore). \n Cross-regional copy <br><br>New You can create and store a copy of the backup snapshot in another region, and use it to create volumes in the target region. This feature can be used in disaster recovery scenarios when you need to start your virtual server instance and data volumes in a different region. Think about whether you need to restore data in other regions. \n Naming Make sure you have a unique name for your backup policy. For example, if you have a method for naming volumes, you might name a backup policy by using a similar convention. Naming conventions for backups that are created by the plan are the same as snapshots. For more information, see [Naming snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-naming). \n Creating backups: \n Prerequisites Verify that the volume is attached to a virtual server instance and that the instance is in a running state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-planning"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.7536976113,"ndcg_cut_10":0.7536976113}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09081-7-2309","score":16.848923,"text":"\nProtecting data with envelope encryption \n\nKey Protect uses envelope encryption to assist in protecting your Key Protect data. Envelope encryption involves encrypting your data with a Data Encryption Key, then encrypting the Data Encryption Key with a root key. This topic describes the process of envelope encryption and how to use Key Protect to encrypt and decrypt your data.\n\nWhen working with sensitive data, it is important to use advanced encryption techniques to prevent a data breach. If you have large amounts of confidential data, it is often helpful to use a Key Management System to assist in keeping your data secure. Key Protect uses the envelope encryption technique to keep your data resilient. Envelope encryption is the process of using encrypted keys, Data Encryption Keys and Root Keys, to protect your sensitive data.\n\nImagine that you plan to send a letter to a colleague. You want to discuss information that is highly sensitive, so you generate a secret code (Data Encryption Key) that is used to write (encrypt) the message in the letter. The letter is delivered to a mailbox (wrapped Data Encryption Key) that can only be opened by those with a copy of the mailbox key (Root key), including the colleague. Anyone who does not have an exact copy of the key will be unable to open the mailbox and see it's contents. When your colleague uses the key to unlock (unencrypt) the mailbox, they will need to know the secret code that the letter is written in to be able to understand the message. Everyone who is not aware of the secret code will conclude that the letter is a random mix of characters and will not be able to understand the letter's contents.\n\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_13108-7-2001","score":16.453842,"text":"\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/key-protect?topic=key-protect-about"},{"document_id":"ibmcld_12678-7-2410","score":15.322416,"text":"\nKnown issues (Limitations) \n\nUse this topic to find the details of the limitations that are applicable to the Data Security Broker software.\n\n\n\n Application-level Encryption: \n\nData Security Broker encryption gives database applications a no-code way to implement application-level encryption. Application-level encryption can be implemented by including a database proxy that intercepts and encrypts sensitive data in accordance with the pre-established data protection policy.\n\nData Security Broker encryption has some restrictions, like any other approaches to the application-level encryption implementation. The various aspects of the application level encryption limitations are explained below:\n\nPerformance hit Data encryption consumes more time and resources than data decryption. This overhead is normally negligible. If the proxy (Shield) has an appropriately sized CPU and Memory, there should not be any noticeable performance penalties. Most users experience a 10--20% reduction in the overall application performance. This can be mitigated by horizontal scaling. In the event of failure, Shield can be horizontally scaled by adding more of them behind a load balancer.\n\nKey management You must have a place to store your secret key or key file. You can use IBM Key Protect. IBM Key Protect provides full encryption visibility and control, allowing you to see and manage data encryption and the entire key lifecycle from a single location. Alternatively, you can secure the information with a password, but this reduces security, depending on the level of your password's strength.\n\nAccessibility If your key file is lost, your data is also lost. So, make a backup of your data and your key.\n\nDatabase operations carried out on encrypted versions of the data The information is kept in encrypted form in the database and the database engine and, consequently, the database administrator is never permitted to see the information in form of the plaintext.\n\nMany of today's server and network technologies allow for easier configuration and implementation to minimize the impact on utilization. Implementing encryption of data in transit from endpoint to endpoint both remotely and internally is mandatory in today's cyber risk environment.\n\nThe following are considered equality check operators and are supported:\n\n\n\n* =\n* <>\n* IS NULL\n* IS NOT NULL\n* IN\n* NOT\n* JOIN (all types)\n* GROUP BY","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_limitations"},{"document_id":"ibmcld_08739-8238-10173","score":14.368312,"text":"\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-database.svg)\n\nFigure 5. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications. Typically, database users do not need to be aware of default encryption and database client applications do not need to be adapted specifically.\n\nDb2 default encryption uses a two-tiered key hierarchy: Data is encrypted with a data encryption key (DEK). The DEK is encrypted with a master key and is stored in encrypted form with the database or the backup image. A unique DEK is generated by Db2 for each encrypted database and for each encrypted backup. A master key is used to encrypt a DEK. Each encrypted database is associated with one master key at one time.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_08766-5724-7551","score":13.705791,"text":"\n[Application encryption by using PKCS #11](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/application-encryption-pkcs11.svg)\n\nFigure 3. Application encryption by using PKCS #11\n\n\n\n\n\n Databases encryption by using the PKCS 11 API \n\nWith Hyper Protect Crypto Services, you can encrypt Oracle\u00ae Database by using Transparent Data Encryption (TDE) and encrypt IBM Db2\u00ae Database by using Db2 default encryption.\n\n\n\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-database.svg)\n\nFigure 4. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_12667-7-2097","score":13.59308,"text":"\nData Encryption using IBM Cloud Databases for PostgreSQL \n\n\n\n Overview \n\nData Security Broker functions as an application-level encryption (ALE) equivalent in this mode encrypting data on a field-level basis. This is performed using Data Security Broker Manager to enumerate the data schema and enable an encryption key mapping.\n\n\n\n\n\n Procedure \n\nComplete the following steps to encrypt the data with Data Security Broker Manager on an IBM Cloud PostgreSQL Database:\n\n\n\n1. Login to Data Security Broker Manager.\n2. Click on an application and select the drop down which is present in the Migration Details field in the right side and click Encrypt.\n3. Select the Database and the table where you have the data created and select the Column which needs to be encrypted. Choose the Data Protection policy, Encryption mode, and masking mode for the encryption process and click Review.\n\nZoom\n\n![Encryption](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/57ab3ec034294d8a6de510b97bec3035d4654761\/security-broker\/images\/encryption_schema.svg)\n\nStandard Encryption\n4. Choose Deploy Policy & Migrate Data under the Deployment Plan option. There are three options that you can choose to implement your data encryption policy. For more information on Deployment plans, see Deployment Plans in IBM Cloud Data Security Broker. Select the Security Broker Shield service IP address in the Migration Shield field and click Save to start the encryption process.\n5. The status of the application shows Migrating when the encryption process starts.\n6. Once the encryption is complete, the status is changed to Protected. You can view more information by clicking Migration Details in the Applications sidebar.\n\n\n\nIf there is new data which gets inserted in the database, by default, the data is encrypted by using the default data encryption policy that is being selected by the user.\n\n\n\n\n\n Reference \n\n\n\n\n\n Format Preserving Encryption (FPE) Supported Data Types \n\nThe following tables lists the FPE supported data types for the data encryption in Data Security Broker Manager:\n\n\n\n\n\n PostgreSQL \n\n\n\nTable 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_encrypt_data"},{"document_id":"ibmcld_00045-7-1433","score":13.151514,"text":"\nKey management by application \n\nThis topic describes how to manage column encryption keys by application. It explains how to provide master keys and how to write and read encrypted data using these master keys.\n\n\n\n Providing master keys \n\nTo provide master keys:\n\n\n\n1. Set the class implementing EncryptionPropertiesFactory:\n\nparameter name: \"parquet.crypto.factory.class\"\nparameter value: \"com.ibm.parquet.key.management.IBMKeyToolsFactory\"\n2. Pass the explicit master keys, in the following format:\n\nparameter name: \"parquet.encryption.key.list\"\nparameter value: \"<master key ID>:<master key (base64)> , <master key ID>:<master key (base64)>..\"\n\nFor example:\n\nsc.hadoopConfiguration.set(\"parquet.crypto.factory.class\",\"com.ibm.parquet.key.management.IBMKeyToolsFactory\")\nsc.hadoopConfiguration.set(\"parquet.encryption.key.list\" , \"k1:iKwfmI5rDf7HwVBcqeNE6w== , k2:LjxH\/aXxMduX6IQcwQgOlw== , k3:rnZHCxhUHr79Y6zvQnxSEQ==\")\n\nThe length of master keys before base64 encoding can be 16, 24 or 32 bytes (128, 192 or 256 bits).\n\n\n\n\n\n\n\n Writing encrypted data \n\nTo write encrypted data:\n\n\n\n1. Specify which columns to encrypted, and which master keys to use:\n\nparameter name: \"parquet.encryption.column.keys\"\nparameter value: \"<master key ID>:<column>,<column>;<master key ID>:<column>,...\"\n2. Specify the footer key:\n\nparameter name: \"parquet.encryption.footer.key\"\nparameter value: \"<master key ID>\"\n\nFor example:\n\ndataFrame.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-application-serverless"},{"document_id":"ibmcld_12439-7-1984","score":12.44873,"text":"\nComparison between Secrets Manager and related IBM Cloud services \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secrets. If you need to integrate general-purpose secrets to authenticate your apps, you can use Secrets Manager to create\n\ndynamic secretsand manage their lifecycle. But for other application secrets, such as encryption keys, your business might require a higher level of control that relies on highly secure, customer-controlled cryptographic hardware.\n\nFor example, consider the following scenarios and how they map to secrets management offerings and data protection offerings in IBM Cloud.\n\nZoom\n\n![The image describes three use cases for secrets management and how they map to available services in IBM Cloud. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/secrets-mgmt-options.svg)\n\nFigure 1. Secrets management use cases\n\n\n\n Which data protection service is best for me? \n\nThe following table lists the different offerings that you can use with IBM Cloud to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n As a DevOps team contributor, you need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. With [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager), you can manage secrets of various types in a dedicated instance. \n You need to generate, renew, and manage SSL\/TLS certificates for your deployments. You can also manage your SSL\/TLS certificates and private keys in dedicated instance of [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager). \n You need to create and manage encryption keys that are backed by FIPS 140-2 Level 3 validated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud"},{"document_id":"ibmcld_00046-7-1614","score":11.843099,"text":"\nKey management by Key Protect \n\nThis topic describes managing column encryption keys by using IBM\u00ae Key Protect for IBM Cloud\u00ae (Key Protect). It explains how to create a Key Protect instance and to provide master keys and how to write and read encrypted data using these master keys.\n\n\n\n Creating a Key Protect instance and master keys \n\nTo create a Key protect instance and master keys:\n\n\n\n1. Create a Key Protect service instance. See [Provisioning the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-provision).\n2. Create customer root keys in this instance. The customer root keys serve as master keys for column encryption. See [Creating root keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys).\n\nIf you want to use existing root keys, you can import those. See [Importing root keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys).\n3. Configure user access rights to the master keys by using the IBM IAM service. See [Granting access to master keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keysgrant-access-key-level).\n\n\n\n\n\n\n\n Writing encrypted data \n\nTo write encrypted data:\n\n\n\n1. Pass the following parameters to IBM Analytics Engine Serverless:\n\n\n\n* \"parquet.crypto.factory.class\": the class implementing EncryptionPropertiesFactory. Set to \"com.ibm.parquet.key.management.IBMKeyToolsFactory\".\n\nsc.hadoopConfiguration.set(\"parquet.crypto.factory.class\",\"com.ibm.parquet.key.management.IBMKeyToolsFactory\")\n* \"parquet.encryption.kms.instance.id\": The ID of your KeyProtect instance, for example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-key-protect-serverless"},{"document_id":"ibmcld_05581-18776-20654","score":11.608756,"text":"\n100-499 Gi 100-6000 IOPS \n 500-999 Gi 100-10000 IOPS \n 1000-1999 Gi 100-20000 IOPS \n 2000-2999 Gi 200-40000 IOPS \n 3000-3999 Gi 200-48000 IOPS \n 4000-7999 Gi 300-48000 IOPS \n 8000-9999 Gi 500-48000 IOPS \n 10000-12000 Gi 1000-48000 IOPS \n\n\n\n\n\n5. Choose if you want to keep your data after the cluster or the persistent volume claim (PVC) is deleted.\n\n\n\n* If you want to keep your data, then choose a retain storage class. When you delete the PVC, only the PVC is deleted. The PV, the physical storage device in your IBM Cloud infrastructure account, and your data still exist. To reclaim the storage and use it in your cluster again, you must remove the PV and follow the steps for [using existing block storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-block_storageexisting_block).\n* If you want the PV, the data, and your physical block storage device to be deleted when you delete the PVC, choose a storage class without retain.\n\n\n\n6. Choose if you want to be billed hourly or monthly. The default setting is hourly billing.\n\n\n\n\n\n\n\n Setting up encryption for Block Storage for Classic \n\nYou can set up encryption for Block Storage for Classic by using IBM Key Protect.\n\nThe following example explains how to create a service ID with the required access roles for Key Protect and your cluster. The credentials of this service ID are used to enable encryption for your Block Storage for Classic volumes.\n\nYou can enable encryption by creating a Kubernetes secret that uses your personal API key as long as you have the Reader service access role for your Key Protect instance as well as the Viewer platform access role and the Writer service access role for your cluster.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-block_storage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08669-6042-7847","score":19.253992,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_08511-7-2392","score":18.592354,"text":"\nHigh availability and disaster recovery \n\nIBM Cloud\u00ae Hyper Protect Crypto Services is a highly available, regional service with automatic features that help keep your applications secure and operational.\n\nLearn more about availability and disaster recovery strategies of Hyper Protect Crypto Services.\n\n\n\n Locations, tenancy, and availability \n\nYou can create Hyper Protect Crypto Services resources in one of the supported [IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions), which represent the geographic area where your Hyper Protect Crypto Services requests are handled and processed. Each IBM Cloud region contains [multiple availability zones](https:\/\/www.ibm.com\/cloud\/data-centers\/) to meet local access, low latency, and security requirements for the region.\n\nAs you plan your encryption at rest strategy with IBM Cloud, keep in mind that provisioning Hyper Protect Crypto Services in a region that is nearest to you is more likely to result in faster, more reliable connections when you interact with the Hyper Protect Crypto Services APIs. Choose a specific region if the users, apps, or services that depend on a Hyper Protect Crypto Services resource are geographically concentrated. Users and services who are far away from the region might experience higher latency.\n\nYour encryption keys are confined to the region that you created them in. Hyper Protect Crypto Services does not copy or export encryption keys to other regions.\n\n\n\n\n\n In-region data redundancy and failover \n\nMultiple\n\ncrypto unitsin a service instance are automatically synchronized and load balanced across multiple availability zones. If one available zone that contains your provisioned service instance cannot be accessed, Hyper Protect Crypto Services has automatic in-region data failover in place. The service follows IBM Cloud requirements for planning and recovering from disaster events. For more information, see [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr"},{"document_id":"ibmcld_09515-7-2313","score":18.560268,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate AWS data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite SaaS offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same AWS data center to a new infrastructure\n3. Recover to a secondary AWS data center\n\n\n\nIn the event a disaster is declared, the base parameters are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-backups-and-disaster-recovery"},{"document_id":"ibmcld_09494-7-2307","score":18.392616,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate IBM Cloud data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally for non-production systems, expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite Dedicated Service offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same IBM Cloud data center to a new infrastructure\n3. Recover to a secondary IBM Cloud data center","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-backups-and-disaster-recovery"},{"document_id":"ibmcld_08511-1920-3732","score":18.22595,"text":"\nFor more information, see [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:\n\n\n\n* If you create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, the failover crypto units back up the operational crypto units and keystores in another region. When a regional disaster occurs, your data is restored automatically with the failover crypto units to reduce the downtime and data loss. For more information about how to use failover crypto units to restore data, see [Restoring your data by using failover crypto units](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n* If you don't enable failover crypto units, you can use the default daily backup to restore your data. In this case, you need to open a support ticket so that IBM can create a new service instance in another supported region to restore your data from the backup. Then, you need to manually load your master key to the new instance again to make it work. In this process, you're the only person who owns the master key. IBM administrators or any third-party users can't access your data or keys in the backup or the restored service instance. For more information about the recovery process, see [Restoring your data by opening an IBM support ticket](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-datarestore-data-open-support-ticket).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr"},{"document_id":"ibmcld_14774-27023-28718","score":18.209103,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14533-1761-4064","score":17.730688,"text":"\nThe encryption key is not stored and is unavailable to IBM. After the VMware Cloud Director Data Center is deleted, all backups are deleted, and cannot be recovered.\n\n\n\n\n\n High availability and disaster recovery \n\nThe VMware Shared management service is initially only offered in the IBM Cloud NA South and Europe regions. Recovering from potential disasters that affect an entire location requires planning and preparation.\n\n\n\n* You are responsible for understanding your configuration, customization, and usage of the service.\n* You are responsible for enabling your VMs or virtual applications (vApps) to participate in the provided backup service.\n* You are responsible for being ready to restore all instances of your VMs or vApps used in the service in the restored location or new location.\n\n\n\n\n\n High availability \n\nVMware Shared supports high availability of the VMware Cloud Director service itself. The service achieves high availability automatically and transparently by using the Multizone region (MZR) feature that is provided by IBM Cloud.\n\nHowever, you cannot configure workloads that are running VMs and vApps in a high availability manner across multiple IBM Cloud data center sites. VMware Shared currently allows workloads to operate in only one IBM Cloud data center site.\n\nUse VMware Shared with vCenter Server to achieve high availability. You can deploy vCenter Server in multiple IBM Cloud data center regions.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because MZRs are not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location, including a vCenter Server instance.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_data"},{"document_id":"ibmcld_09434-5744-7613","score":17.659094,"text":"\n[IBM Cloud\u00ae Object Storage provides several options to encrypt your data.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Meet security and compliance objectives Maintain controls that are commensurate to various industry compliance standards such as SOC2, PCI, HIPAA and Privacy Shield. Set up and maintain security and regulation compliance for your apps and data. This includes: <br>[Defining the account management strategy](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_account) <br>[Configuring the accounts settings for compliance](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_acc_settings) <br>Define IAM Strategy <br>[Define the notification strategy](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_alerts) \n\n\n\n\n\n\n\n Disaster recovery \n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Restore the service[] Automatically recover and restart service components after any disaster event. N\/A \n Backup the IBM Log Analysis key resources that are provided by the service Daily backup of the IBM Log Analysis infrastructure and components. N\/A \n Backup logging agents N\/A Backup each logging agent YAML file that is deployed in your organization. \n Recovery of logging agents N\/A [Reinstall](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-logdna_agentlogdna_agent_configure) the logging agent in the event of any disaster event that impacts the agent runtime. \n Backup the metadata of a logging instance Backup metadata that is used by the service. [Backup the metadata such as views, dashboards, screens, parsing templates, and alerts for each logging instance.](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-reuse_resource_definitionsexport_config_res)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-shared-responsibilities"},{"document_id":"ibmcld_14774-18795-21198","score":17.62199,"text":"\nWhile this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.\n* SFTP\/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the protected region for extra protection.\n\n\n\nReview the following Veeam design decisions:\n\n\n\n* For optimal performance and availability, placing the Veeam components on separate virtual and physical servers is considered best practice. However, this practice increases complexity in smaller environments. Therefore, the all-in-one deployment scenario for use case 1 is selected.\n* As the total number of protected VMs is low, the embedded database option for the database for use case 1 is selected.\n* The bare metal servers with direct attached storage option are used as it provides a backup infrastructure that is separated from the virtualized infrastructure compute and storage.\n* In a two-site environment, it is best practice to install the Veeam Backup server component in the DR site. In a disaster situation, Veeam Backup server is available to start the recovery.\n* Deploy Enterprise Manager to use password loss protection. Enterprise Manager administrators can unlock backup files by using a challenge-response mechanism.\n* It is recommended that the proxy is as close as possible to the source data with a high-bandwidth connection. The traffic from the source to the proxy is not yet optimized, meaning that 100% of the backup data is transferred over this link. A good connection is required between proxy and repository as optimized data (normally 50% of the source data size) is transferred across this link. Therefore, place proxies in both the protected and recovery regions.\n* Proxies can be hosted on Windows Server or Linux OS with almost no performance differences. For the all-in-one deployment scenario, a Windows OS is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14738-7598-10031","score":17.47881,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15129-4-2136","score":12.349437,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to VPC Infrastructure Services can be controlled with context-based restrictions and identity and access management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the VPC Infrastructure Services to create, update, or delete rules that target VPC Infrastructure Services. A user must have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule only.\n\nThe context-based restriction service generates audit logs every time a context-based policy is enforced. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_15130-4-2136","score":12.349437,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to VPC Infrastructure Services can be controlled with context-based restrictions and identity and access management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the VPC Infrastructure Services to create, update, or delete rules that target VPC Infrastructure Services. A user must have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule only.\n\nThe context-based restriction service generates audit logs every time a context-based policy is enforced. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"},{"document_id":"ibmcld_15129-1577-3432","score":11.854391,"text":"\nFor more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services. Context-based restrictions can be created for IBM Cloud VPC or any of its child services; for example, [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-subnets-vpc), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practice), and [block storage volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storage&interface=cli).\n\nSee the [rule creation section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbrcbr-rules) for details on how you can create rules with the required attributes for each service.\n\n\n\n\n\n Creating network zones \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services\n\n\n\n\n\n Service references \n\nA service reference, defined as part of a network zone, allows the given service to talk to the restricted resources or APIs that are targeted by a particular context-based restriction policy. The following table includes service references that need to be included when using context-based restrictions in the context of VPC Infrastructure Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_15130-1577-3446","score":11.358552,"text":"\nFor more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services. Context-based restrictions can be created for IBM Cloud VPC or any of its child services; for example, [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-subnets-vpc), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practice), and [block storage volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storage&interface=cli).\n\nSee the [rule creation section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=clicbr-rules) for details on how you can create rules with the required attributes for each service.\n\n\n\n\n\n Creating network zones \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services\n\n\n\n\n\n Service references \n\nA service reference, defined as part of a network zone, allows the given service to talk to the restricted resources or APIs that are targeted by a particular context-based restriction policy. The following table includes service references that need to be included when using context-based restrictions in the context of VPC Infrastructure Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"},{"document_id":"ibmcld_15394-1560-3269","score":11.248562,"text":"\nData on a file share is encrypted at rest with IBM-managed encryption by default. For added security, you can use your own root keys to protect your file shares with customer-managed keys. When you specify the security group access mode and attach a [virtual network interface](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vni-about) to the file share mount target, you can enable encryption of data in transit. For more information, see [File share encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-aboutFS-encryption).\n\nYou can apply user tags and access management tags to your file shares. Add tags when you create a share or update an existing share with the UI, CLI, API, or Terraform. For more information, see [Tags for file shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-aboutfs-about-fs-tags).\n\nYou can enable context-based restrictions (CBR) for all file share operations. These restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure, such as creating a file share. For more information, see [Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr).\n\nFile Storage for VPC is integrated with the Security and Compliance Center to help you manage security and compliance for your organization. For more information, see [Managing security and compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-managingfs-vpc-manage-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about"},{"document_id":"ibmcld_15413-1573-3308","score":11.233152,"text":"\nData on a file share is encrypted at rest with IBM-managed encryption by default. For added security, you can use your own root keys to protect your file shares with customer-managed keys. When you specify the security group access mode and attach a [virtual network interface](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vni-about) to the file share mount target, you can enable encryption of data in transit. For more information, see [File share encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=uiFS-encryption).\n\nYou can apply user tags and access management tags to your file shares. Add tags when you create a share or update an existing share with the UI, CLI, API, or Terraform. For more information, see [Tags for file shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=uifs-about-fs-tags).\n\nYou can enable context-based restrictions (CBR) for all file share operations. These restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure, such as creating a file share. For more information, see [Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr).\n\nFile Storage for VPC is integrated with the Security and Compliance Center to help you manage security and compliance for your organization. For more information, see [Managing security and compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-managingfs-vpc-manage-security).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=ui"},{"document_id":"ibmcld_07368-8632-9722","score":10.857919,"text":"\nDNS Services requires you have appropriate access to VPC resources in one of the following operations:\n\n\n\n* Add a VPC to permitted networks of a DNS zone.\n* Create custom resolver on a particular VPC.\n* Create GLB origin pool with healthcheck on VPC subnets.\n\n\n\nYou must work with an account administrator to ensure appropriate VPC operator permission for IAM access policy, and to ensure that no CBR rules blocking you operate on the VPC. For the latter two operations, you must also have subnet reader permission and ensure no CBR rules blocking you get details of the subnets.\n\n\n\n\n\n Monitoring context-based restrictions in DNS Services \n\nThe context-based restriction service generates audit logs every time a context-based rule is enforced. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nActivity tracker events that are generated by the context-based restriction service contain a CorrelationId field. You can search the value of this field to find the audit events that are generated by DNS Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-cbr"},{"document_id":"ibmcld_01790-5035-7392","score":10.713737,"text":"\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.\n\n Service Service type \n\n All Account Management services Account Management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis"},{"document_id":"ibmcld_15129-16897-18665","score":10.608532,"text":"\nRequests for provisioning resources do not contain a resource ID.\n\nIf you do not find a context-based restriction event in Activity Tracker, it's possible access was denied due to IAM access policies. For more information, see [VPC IAM getting started guide](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-getting-started).\n\n\n\n\n\n Client-to-site VPN data plane impact with context-based restrictions \n\nIf a user enables a User ID and passcode when configuring [client authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planningclient-authentication) for a client-to-site VPN, and creates context-based rules on VPC resources, the client connection to the VPN is impacted by context-based restrictions. If the VPN client remote IP is not in the Network Zone, the connection to the VPN server returns an Auth Failed error.\n\nAfter the VPN client connects to the VPN server, the requests to the VPE endpoint or Cloud Service Endpoint (CSE) are controlled with context-based restrictions. Also, the requests' source IP is the VPC [Cloud service endpoint source addresses](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtaincse-source-addresses). Make sure that the VPC CSE source addresses are in the CBR Network Zone; otherwise, the request is denied.\n\n\n\n\n\n\n\n Limitations \n\n\n\n* Context-based restrictions protect only the actions associated with the [VPC Infrastructure Services APIs](https:\/\/cloud.ibm.com\/apidocs\/vpc) or the is plugin, through the IBM CLI. The SDK and Terraform options are also supported. Actions associated with the following platform APIs are not protected by context-based restrictions:\n\n\n\n* [Resource Instance List APIs](https:\/\/cloud.ibm.com\/apidocs\/resource-controller\/resource-controllerlist-resource-instances)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_15130-16925-18693","score":10.608532,"text":"\nRequests for provisioning resources do not contain a resource ID.\n\nIf you do not find a context-based restriction event in Activity Tracker, it's possible access was denied due to IAM access policies. For more information, see [VPC IAM getting started guide](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-getting-started).\n\n\n\n\n\n Client-to-site VPN data plane impact with context-based restrictions \n\nIf a user enables a User ID and passcode when configuring [client authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planningclient-authentication) for a client-to-site VPN, and creates context-based rules on VPC resources, the client connection to the VPN is impacted by context-based restrictions. If the VPN client remote IP is not in the Network Zone, the connection to the VPN server returns an Auth Failed error.\n\nAfter the VPN client connects to the VPN server, the requests to the VPE endpoint or Cloud Service Endpoint (CSE) are controlled with context-based restrictions. Also, the requests' source IP is the VPC [Cloud service endpoint source addresses](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtaincse-source-addresses). Make sure that the VPC CSE source addresses are in the CBR Network Zone; otherwise, the request is denied.\n\n\n\n\n\n\n\n Limitations \n\n\n\n* Context-based restrictions protect only the actions associated with the [VPC Infrastructure Services APIs](https:\/\/cloud.ibm.com\/apidocs\/vpc) or the is plugin, through the IBM CLI. The SDK and Terraform options are also supported. Actions associated with the following platform APIs are not protected by context-based restrictions:\n\n\n\n* [Resource Instance List APIs](https:\/\/cloud.ibm.com\/apidocs\/resource-controller\/resource-controllerlist-resource-instances)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11855-1664-3547","score":14.861203,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c8335d66af691d19e837116fd633481c477061eb\/satellite\/images\/topology-1.svg)\n\nFigure 1. Compute hosts from third-party infrastructure provider\n\n\n\n\n\n 2. Compute hosts are located in IBM Cloud and edge or data centers \n\nIn this example, the compute resources are located in both IBM Cloud and any one of the supported infrastructure providers or edge. The hosts that make up the control plane are from IBM Cloud, but the hosts that make up the services are located in separate, customer-owned edge or infrastructure providers. Note that while you can use other IBM Cloud virtual servers, such as Virtual Servers for VPC for test environments, the only supported IBM Cloud infrastructure to use in IBM Cloud Satellite\u00ae for production environments is IBM Cloud\u00ae Bare Metal Servers for Classic that is running Red Hat CoreOS.\n\nZoom\n\n![Compute hosts located in IBM Cloud and an edge or data center.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c8335d66af691d19e837116fd633481c477061eb\/satellite\/images\/topology-2.svg)\n\nFigure 2. Compute hosts from IBM Cloud and other edge or infrastructure provider\n\n\n\n\n\n 3. Compute hosts are located in IBM Cloud and multiple data centers or edge \n\nIn this example, the compute resources are located in both IBM Cloud and in multiple data center or edge. The hosts that make up the control plane are from IBM Cloud, but the hosts that make up the services are located multiple other customer-owned edge or infrastructure providers. Note that while you can use other IBM Cloud virtual servers, such as Virtual Servers for VPC for test environments, the only supported IBM Cloud infrastructure to use in IBM Cloud Satellite\u00ae for production environments is IBM Cloud\u00ae Bare Metal Servers for Classic that is running Red Hat CoreOS.\n\nZoom\n\n![Compute resources in both IBM Cloud and multiple edge or data centers.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-multi-infra"},{"document_id":"ibmcld_11746-7355-9523","score":13.404292,"text":"\nSo, those are kind of the core ideas in Satellite: locations and link allow us to extend our cloud catalog services to any location, giving you the power of cloud, and the power of IBM Cloud, anywhere in the world that you need it. All you need is some Linux infrastructure and IBM does the rest. Thanks a lot.\n\n\n\n\n\n What are Satellite locations, hosts, and so on? \n\nBefore you get started, become familiar with some key terms for Satellite. Afterward, you can test your knowledge and [!take a quiz](https:\/\/ibm.biz\/BdPUqR)\n\n\n\nTable 1. Satellite terminology\n\n Term Description \n\n Satellite location A Satellite location is a representation of an environment in your infrastructure provider, such as an on-prem data center or cloud. Locations can be made up of communications endpoints such as a Docker container, or of compute resources called hosts, which are used to form separate availability zones out of a given x86 infrastructure. \n Satellite Connector A Satellite Connector is a deployment model that enables only the secure communications from IBM Cloud to on-prem resources with a light weight container, deployed on the client's container platform hosts, such as Docker hosts. This option brings all the security and auditability of Satellite communication, but with much less resources required. \n Satellite hosts A Satellite host is a compute source that resides in your infrastructure provider or even locally. After you attach your hosts to a Satellite location, assign the hosts to the location control plane or to a Satellite-enabled IBM Cloud services to provide the computing power to run your service workloads. See [Attaching hosts to your location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts). \n Satellite-enabled service An IBM Cloud service that you can set up in a Satellite location, such as a Red Hat OpenShift cluster. The service is managed from the IBM Cloud region that your location is managed from, but you provide the infrastructure hosts to run the service's resources in your location. See [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-getting-started"},{"document_id":"ibmcld_06056-3468-5769","score":12.896575,"text":"\nIf the production environment needs more than one more worker node, you might resize down some worker pools in development, create a worker pool that uses on demand worker nodes, or add more contracts to the reservation. If you are concerned about a development environment using up your production environment resources, consider creating separate reservations for the different environments.\n\n\n\n Reservation usage and lifecycle \n\nHow can I use my reservation?\n: You can use your reservation to create worker pools in new or existing clusters. Your reservation is account-wide, so you can use the reserved worker nodes in different clusters, worker pools, and even resource groups. However, because prices vary by zone, you can't use reserved worker nodes across different metros or multizone regions. You also can't used reserved instances from other IBM Cloud infrastructure services, such as virtual server instances, for your worker nodes, but must use the IBM Cloud Kubernetes Service reservations.\n\nDoes a reservation guarantee computing capacity in a zone?\n: Reserving worker nodes does not guarantee compute capacity whenever you want to create a worker pool. Instead, you reserve a certain number of worker nodes for a term so that you lock in the discounted price that is associated with the reservation.\n\nHow do I know how many reserved worker nodes I need?\n: See [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing).\n\nWhat kind of workloads are best suited for reservations?\n: The following workloads are good candidates to run on reserved worker nodes:\n\n\n\n* Production workloads\n* Mission-critical workloads that must run 24\/7\n* Predictable workloads that have continuous usage and steady states\n* Workloads that you want to increase high availability for by creating replicas in different zones and regions\n\n\n\nCan I convert existing worker nodes to reserved worker nodes to save money?\n: No. Instead, you can create reservations and contracts for the worker nodes in your clusters. Then, create worker pools in your existing clusters that use the reserved worker nodes. Consider using labels to reschedule your existing workloads to the new reserved worker pools. Then, delete your old, on demand worker pools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservations"},{"document_id":"ibmcld_10487-3471-5772","score":12.643859,"text":"\nIf the production environment needs more than one more worker node, you might resize down some worker pools in development, create a worker pool that uses on demand worker nodes, or add more contracts to the reservation. If you are concerned about a development environment using up your production environment resources, consider creating separate reservations for the different environments.\n\n\n\n Reservation usage and lifecycle \n\nHow can I use my reservation?\n: You can use your reservation to create worker pools in new or existing clusters. Your reservation is account-wide, so you can use the reserved worker nodes in different clusters, worker pools, and even resource groups. However, because prices vary by zone, you can't use reserved worker nodes across different metros or multizone regions. You also can't used reserved instances from other IBM Cloud infrastructure services, such as virtual server instances, for your worker nodes, but must use the Red Hat OpenShift on IBM Cloud reservations.\n\nDoes a reservation guarantee computing capacity in a zone?\n: Reserving worker nodes does not guarantee compute capacity whenever you want to create a worker pool. Instead, you reserve a certain number of worker nodes for a term so that you lock in the discounted price that is associated with the reservation.\n\nHow do I know how many reserved worker nodes I need?\n: See [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing).\n\nWhat kind of workloads are best suited for reservations?\n: The following workloads are good candidates to run on reserved worker nodes:\n\n\n\n* Production workloads\n* Mission-critical workloads that must run 24\/7\n* Predictable workloads that have continuous usage and steady states\n* Workloads that you want to increase high availability for by creating replicas in different zones and regions\n\n\n\nCan I convert existing worker nodes to reserved worker nodes to save money?\n: No. Instead, you can create reservations and contracts for the worker nodes in your clusters. Then, create worker pools in your existing clusters that use the reserved worker nodes. Consider using labels to reschedule your existing workloads to the new reserved worker pools. Then, delete your old, on demand worker pools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-reservations"},{"document_id":"ibmcld_10835-22529-24347","score":12.430191,"text":"\nTo minimize these dependencies on your local environment, use the [Packaging Python code with a Docker virtual environment in a compressed file](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-prepprep_python_virtenv) approach. This approach creates the compressed action file, but also leverages the Python environment inside the Cloud Functions Python runtime image itself so that both the generated action compressed file and the later execution environment fully match.\n\nBefore you begin\n\n\n\n* The following steps assume that you are running the commands on a Linux-based distribution on a processor with AMD64-based architecture.\n* [Review the packages that are included with the Python runtime](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimesopenwhisk_ref_python_environments) to see whether a dependency of your app is already included with the runtime. If your dependency is not included, you must package it with your app.\n* Make sure that the locally installed Python version to create the compressed action file (for example, Python 3.11.x) matches the Cloud Functions kind that is chosen to later create the action (--kind python:3.11).\n* Install the virtualenv Python package.\n\npip install virtualenv\n\n\n\nTo package your app:\n\n\n\n1. Create a directory that you can use to create your virtual environment. In this example, a jokes directory is created on the desktop. After you create the jokes directory, cd to it.\n\ncd desktop; mkdir jokes; cd jokes\n2. From the jokes directory, create a virtual environment named virtualenv.\n\nThe virtual environment must be named virtualenv.\n\nvirtualenv virtualenv\n\nExample output\n\ncreated virtual environment CPython3.9.10.final.0-64 in 398ms\ncreator CPython3Posix(dest=\/action\/Projects\/python\/virtualenv, clear=False, no_vcs_ignore=False, global=False)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-prep"},{"document_id":"ibmcld_05435-5923-7833","score":11.86506,"text":"\nSelect a Satellite location to use for your compute environment.\n4. Select the zones and worker nodes per zone for your compute environment. For more information about zones, see [Plan for a multizone location](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-infrastructure-planinfra-plan-multizone).\n5. Select a region. For Beta, you must select eu-de.\n6. Name your compute environment.\n7. Click Create.\n\n\n\nAfter your compute environment is set up, you can create a project and start deploying apps and running jobs.\n\nEven though CLI commands are available for projects, apps and jobs, you must use the UI for these tasks when you select a project from a Satellite compute environment.\n\n\n\n\n\n Creating a project in a compute environment \n\nWhen you create a project, it is automatically selected as the current context. Note that you must create your project from the UI as you cannot select your compute environment from the CLI. To create a project in a compute environment, follow these steps.\n\n\n\n1. From the [Projects page on the Code Engine console](https:\/\/cloud.ibm.com\/codeengine\/projects), click Create.\n2. Select Satellite as your platform.\n3. Choose a location to deploy the project.\n4. Enter a name for the project. The name must be unique for all your projects within the specified location.\n5. Choose the resource group where you want to create the project.\n6. Click Create.\n\n\n\nAfter your project is created, you can start deploying apps and running jobs in your Satellite location.\n\n\n\n\n\n Why doesn't my compute environment create? \n\n\n\n1. Verify that you set up service-to-service access. [Follow the steps](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-satellite-cesatellite-ce-authority) to set it up. Because Code Engine continuously polls Satellite for the assigned location, as soon as you set up service-to-service access, the compute environment creation process continues.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-satellite-ce"},{"document_id":"ibmcld_11510-7-2157","score":11.72483,"text":"\nFAQs for IBM Cloud Qiskit Runtime \n\nTo find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is Qiskit Runtime service? \n\nQiskit Runtime service is a runtime environment through the IBM Cloud that provides access to the IBM Quantum processors and simulators. They allow users to run quantum programs, which require specialized quantum hardware that is coupled closely with traditional \u201cclassical\u201d, computer hardware.\n\n\n\n\n\n Why is IBM launching Qiskit Runtime service? \n\nIBM made quantum computers available through the cloud in 2016. In 2022, IBM integrates with IBM Cloud\u00ae accounts to offer Qiskit Runtime API access. This access creates a smoother customer experience and the ability to combine Qiskit Runtime with other kinds of cloud compute resources for their particular workflow or application.\n\n\n\n\n\n What can Qiskit Runtime service not do? \n\nQiskit Runtime service provides access to IBM Quantum systems. Today\u2019s quantum systems are somewhat constrained in the size of problems that they can address due to available scale and quantum volume. Nonetheless, these systems can already be used to solve small problems and to explore this new and exciting field.\n\n\n\n\n\n What skills are required to use the Qiskit Runtime service? \n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.\n\n\n\n\n\n What are the benefits of using Qiskit Runtime? \n\nQiskit Runtime provides access to industry-leading quantum hardware, closely coupled with IBM Cloud resources to enable optimized computing. Qiskit Runtime enables clients to experiment, learn, and prepare for a quantum-accelerated future.\n\n\n\n\n\n What are Qiskit Runtime primitives? \n\nThe Qiskit Runtime primitives define abstract interfaces for common tasks that are found in quantum applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-qiskit-runtime-faqs"},{"document_id":"ibmcld_07578-258172-260367","score":11.447186,"text":"\nThe improved process now offers:\n\n\n\n1. Faster copy of stock image to your private project.\n2. The stock image cannot be exported. One can do VM capture and export on a deployed VM that uses the stock image.\n3. Storage pool and tier of a stock image shows \"Empty\" (API) or \"Any\" (UI) as VM can be deployed to any tier\/pool by using the stock image.\n\n\n\n* Can I select a specific resource group when I create a cloud connection?\n\nNO. When you create a cloud connection by using Power Systems Virtual Server, the cloud connection is always created in the default resource group even if you choose a specific resource group.\n\n\n\nQiskit Runtime\n\n\n\n* What is Qiskit Runtime service?\n\nQiskit Runtime service is a runtime environment through the IBM Cloud that provides access to the IBM Quantum processors and simulators. They allow users to run quantum programs, which require specialized quantum hardware that is coupled closely with traditional \u201cclassical\u201d, computer hardware.\n* Why is IBM launching Qiskit Runtime service?\n\nIBM made quantum computers available through the cloud in 2016. In 2022, IBM integrates with IBM Cloud\u00ae accounts to offer Qiskit Runtime API access. This access creates a smoother customer experience and the ability to combine Qiskit Runtime with other kinds of cloud compute resources for their particular workflow or application.\n* What can Qiskit Runtime service not do?\n\nQiskit Runtime service provides access to IBM Quantum systems. Today\u2019s quantum systems are somewhat constrained in the size of problems that they can address due to available scale and quantum volume. Nonetheless, these systems can already be used to solve small problems and to explore this new and exciting field.\n* What skills are required to use the Qiskit Runtime service?\n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-258146-260341","score":11.447186,"text":"\nThe improved process now offers:\n\n\n\n1. Faster copy of stock image to your private project.\n2. The stock image cannot be exported. One can do VM capture and export on a deployed VM that uses the stock image.\n3. Storage pool and tier of a stock image shows \"Empty\" (API) or \"Any\" (UI) as VM can be deployed to any tier\/pool by using the stock image.\n\n\n\n* Can I select a specific resource group when I create a cloud connection?\n\nNO. When you create a cloud connection by using Power Systems Virtual Server, the cloud connection is always created in the default resource group even if you choose a specific resource group.\n\n\n\nQiskit Runtime\n\n\n\n* What is Qiskit Runtime service?\n\nQiskit Runtime service is a runtime environment through the IBM Cloud that provides access to the IBM Quantum processors and simulators. They allow users to run quantum programs, which require specialized quantum hardware that is coupled closely with traditional \u201cclassical\u201d, computer hardware.\n* Why is IBM launching Qiskit Runtime service?\n\nIBM made quantum computers available through the cloud in 2016. In 2022, IBM integrates with IBM Cloud\u00ae accounts to offer Qiskit Runtime API access. This access creates a smoother customer experience and the ability to combine Qiskit Runtime with other kinds of cloud compute resources for their particular workflow or application.\n* What can Qiskit Runtime service not do?\n\nQiskit Runtime service provides access to IBM Quantum systems. Today\u2019s quantum systems are somewhat constrained in the size of problems that they can address due to available scale and quantum volume. Nonetheless, these systems can already be used to solve small problems and to explore this new and exciting field.\n* What skills are required to use the Qiskit Runtime service?\n\nThe Qiskit Runtime service is meant to be accessible to anyone comfortable with Python. Use of Qiskit Runtime primitives requires expressing a problem as quantum circuits. The Qiskit application modules can facilitate this task for various application domains such as optimization, chemistry, finance, and machine learning. Creation of novel Qiskit Runtime programs requires more knowledge of the Qiskit backend interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-748057-750349","score":11.089345,"text":"\nMigration will not automatically de-provision your existing environment. If you do not want to maintain both accounts, you can de-provision it from IBM Cloud.\n* Can I access my current IBM Cloud classic environment if I migrate to VPC?\n\nYes, you can establish a link to your existing IBM Cloud classic infrastructure when you migrate to VPC. The migration will not disrupt anything from your existing environment.\n* Why is my migration process taking so long?\n\nMigration can take a significant amount of time depending on the number of instances you are migrating, the size of your images, network performance, and the source location (data center) and the destination region (MZR). Wait until the process is complete and keep the VPC+ Cloud Migration tab open. When the migration process is complete, you will see a success message.\n\n\n\nNetworking Bandwidth Metering for Classic\n\n\n\n* How is bandwidth metering priced?\n\n\n\n* Public bandwidth egress (or bandwidth allocation) pricing depends on regions. To learn more, visit [Bandwidth packages from IBM Cloud](https:\/\/www.ibm.com\/cloud\/bandwidth) and contact a specialist.\n* Public bandwidth usage over GB allocation is charged per GB.\n\n\n\n* What IMS permissions do I need to view and change bandwidth allocations (or add and remove devices to and from bandwidth pools)?\n\nThe BANDWIDTH_MANAGE IMS infrastructure classic permission is the only required permission for bandwidth metering. After you allow this permission, you can complete the following actions:\n\n\n\n* Create a bandwidth pool\n* Move a device into or out of a pool\n* Void a device\u2019s move into a pool\n* Cancel a pool\n\n\n\nCertain actions pertaining to bandwidth pools, including visibility, might be constrained based on device-level permission. Reconcile your device-level permissions on specific devices to manage their bandwidth and membership in pools.\n* Why don't I see the same number of devices as displayed on the devices count?\n\nThis issue might be due to permission restrictions because some users do not have permission to view specific devices. This issue might also be the result of devices that were reclaimed in the middle of the billing cycle, but are still contributing to the cost of the pool.\n* What kind of devices generate bandwidth?\n\nCompute devices use bandwidth.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-754408-756389","score":21.44864,"text":"\nYes, NetScaler VPX appliances support High Availability (HA) configurations.\n\nNetScaler VPX servers are not redundant, unless configured in HA mode with a partner. As part of your back up and recovery strategy, it is highly recommended to deploy an HA environment when using NetScaler VPX.\n\nIt is also important to provide redundancy for other hardware and software components. For example, power supplies and local disk drives may not have redundancy. A failure in these components may result in data loss.\n* Does the IBM Cloud NetScaler offering include SSL VPN functionality?\n\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-754871-756890","score":18.976091,"text":"\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04489-25567-27336","score":18.483921,"text":"\nibmcloud ks cluster config --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster create classic \n\nClassic infrastructure\n\nCreate a cluster with worker nodes on classic infrastructure. For free clusters, you specify the cluster name; everything else is set to a default value. A free cluster is automatically deleted after 30 days. You can have one free cluster at a time. To take advantage of the full capabilities of Kubernetes, create a standard cluster.\n\nibmcloud ks cluster create classic [--hardware HARDWARE] --zone ZONE --flavor FLAVOR --name NAME [--operating-system UBUNTU_20_64|UBUNTU_18_64] [--version MAJOR.MINOR.PATCH] [--no-subnet] [--sm-group GROUP] [--sm-instance INSTANCE] [--private-vlan PRIVATE_VLAN] [--public-vlan PUBLIC_VLAN] [--private-only] [--gateway-enabled] [--private-service-endpoint] [--public-service-endpoint] [--workers WORKER] [--disable-disk-encrypt] [--pod-subnet SUBNET] [--service-subnet SUBNET] [--skip-advance-permissions-check] [-q]\n\nTo create a VPC cluster, use the [ibmcloud ks cluster create vpc-gen2 command](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clicli_cluster-create-vpc-gen2) instead.\n\nMinimum required permissions\n: Administrator platform access role for IBM Cloud Kubernetes Service at the account level\n: Administrator platform access role for IBM Cloud Container Registry at the account level\n: Super User role for IBM Cloud infrastructure\n\nCommand options:\n\n--hardware HARDWARE\n: The level of hardware isolation for your worker node. Use dedicated so that available physical resources are dedicated to you only, or shared to allow physical resources to be shared with other IBM customers. The default is shared. This value is optional for VM standard clusters and is not available for free clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05374-4649-6424","score":12.960331,"text":"\nAnd now what I'll do is ibmcloud ce project create \u2014name amazing product production app. So this create our nice, little\u2026 Target first. I\u2019ll get my default resource group and then I'll go ahead and create the project. There we go. Should only take a moment - perfect. Now you can change your name to whatever you like. This is just a catch-all for your project, which is useful. Then I will take the next command, which is ibmcloud ce app create \u2014name pythonbackend \u2014 build-source . \u2014strategy build packs\n\nNow because I already have a requirements.txt, this will be, this application is smart enough to figure out, \u201chey it's a python application! So let's go ahead and build it!\", which is nice. So as you can see, it's taking step one here. It's running the build, which is good. It creates a nice, private image for us too, which is useful. It takes a couple moments. There we go and now we see that if we wanted to do this with no wait, which is the -nw, we can actually put this into the background and wait for it to come up and then we can check it via this build run get the actual name. Being that we're going to be looking at this live, we'll go ahead and do this here.\n\nPerfect! So now I go ahead and open up the this URL here and it came over here and as you can see\n\n\u201chello moving from Heroku to Code Engine\u201d\n\nAnd that's it. I took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-heroku-migrate"},{"document_id":"ibmcld_12486-6850-8413","score":12.242012,"text":"\nIn this tutorial, you interact with the Dallas region. If you're logged in to a different region, be sure to set Dallas as your target region by running the following command.\n\nibmcloud target -r us-south -g default\n2. Create a Kubernetes cluster.\n\nibmcloud ks cluster create classic --zone dal10 --flavor free --name my-test-cluster\n3. Create a Secrets Manager instance.\n\nibmcloud resource service-instance-create my-secrets-manager secrets-manager trial us-south\n\nProvisioning for both Secrets Manager and your Kubernetes cluster takes 5 - 15 minutes to complete.\n4. Before you continue to the next step, verify that your cluster and Secrets Manager instance are provisioned successfully.\n\n\n\n1. Verify that the deployment of your worker node is complete.\n\nibmcloud ks worker ls --cluster my-test-cluster\n\nWhen your worker node is finished provisioning, the status changes to Ready.\n\nID Public IP Private IP Flavor State Status Zone Version\nkube-c39pf4ld0m87o3fv1utg-mytestclust-default-000000dd 169.xx.xx.xxx 10.xxx.xx.xxx free normal Ready mex01 1.20.7_1543\n2. Next, verify that your Secrets Manager instance provisioned successfully.\n\nibmcloud resource service-instance my-secrets-manager\n\nWhen the instance is finished provisioning, the state changes to Active.\n\nName: my-secrets-manager\nID: crn:v1:bluemix:public:secrets-manager:us-south:a\/f047b55a3362ac06afad8a3f2f5586ea:fe06948b-0c6b-4183-8d4b-e6c1d38ff65f::\nGUID: fe06948b-0c6b-4183-8d4b-e6c1d38ff65f\nLocation: us-south\nService Name: secrets-manager\nService Plan Name: trial\nResource Group Name: default","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets"},{"document_id":"ibmcld_07549-2080-3567","score":12.039373,"text":"\n(Author Vic Sh\u00f3stak) (https:\/\/proxy.golang.org\/github.com\/gofiber\/fiber\/v2\/@v\/v2.10.0.zip)<-- <\/section \"id=\"section-CC-BY-SA-4.0\" \"> --><-- <section \"id=\"section-GPL-V3\" \"> --> GNU GENERAL PUBLIC LICENSE, VERSION 3 The Program includes some or all of the following licensed to you as Separately Licensed Code under the GNU General Public License. For copies of the source code for this software, send an email to deepika.kothamasu@in.ibm.com]deepika_.kothamasu_in_.ibm_.com] identifying the IBM product and the GPL-licensed program for which you are requesting the source code.ACLOCAL Thrift], AX_LUA (GPL V3 WITH AUTOCONF EXCEPTION) Thrift] ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! Copyright \u00a9 2007 Free Software Foundation, Inc. <https:\/\/fsf.org\/>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.PreambleThe GNU General Public License is a free, copyleft license for software and other kinds of works.The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_15476-5751-7575","score":11.554945,"text":"\nSLES 12 SP4 (SAP HANA and SAP applications) 30 June 2023 Pay-as-you-Go \n\n\n\n\n\n\n\n Ubuntu LTS \n\nThe following table describes the end of support date and license model for Ubuntu operating systems. This guest OS is a free operating system. For more information, see [Ubuntu](https:\/\/ubuntu.com\/).\n\n\n\nTable 7. Lifecycle for Ubuntu operating systems\n\n Operating sytem End of support License model \n\n Ubuntu 22.04 minimal 30 April 2027 Free \n Ubuntu 20.04 minimal 30 April 2025 Free \n Ubuntu 18.04 minimal <br><br>[1] 31 May 2023 Free \n Ubuntu 16.04 minimal 01 April 2021 Free \n\n\n\n\n\n\n\n Windows Server \n\nThe following table describes the end of support date and license model for Windows Server operating systems. This guest OS is a paid operating system. For more information, see [Microsoft Windows Server](https:\/\/www.microsoft.com\/en-us\/windows-server).\n\n\n\nTable 8. Lifecycle for Windows Server operating systems\n\n Operating sytem End of support License model \n\n Windows Server 2022 full standard 14 October 2031 Pay-as-you-Go \/ BYOL \n Windows Server 2019 core 09 January 2029 Pay-as-you-Go \/ BYOL \n Windows Server 2019 full standard 09 January 2029 Pay-as-you-Go \/ BYOL \n Windows Server 2016 core 11 January 2027 Pay-as-you-Go \/ BYOL \n Windows Server 2016 full standard 11 January 2027 Pay-as-you-Go \/ BYOL \n Windows Server 2012 full standard 10 October 2023 Pay-as-you-Go \/ BYOL \n Windows Server 2012 r2 full standard 10 October 2023 Pay-as-you-Go \/ BYOL \n Windows Server 2019 Standard Edition with SQL Server 2019 Web Edition 08 January 2030 Pay-as-you-Go \n\n\n\nBYOL: For Windows operating systems, you can bring your own license (BYOL) to IBM Cloud VPC when you import a custom image. These images are registered and licensed by you. You maintain control over your license and incur no additional costs by using your license.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-guest-os-lifecycle"},{"document_id":"ibmcld_11650-6280-7614","score":9.757327,"text":"\n* Allow inbound DNS traffic (UDP port 53)\n* Allow inbound SSH traffic (TCP port 22)\n\n\n\nAfter the successful deployment of the infrastructure, the Terraform script calls the Ansible Playbook, which automatically installs the SAP application. Access creating single-tier VPC for SAP by using Terraform to get the detailed steps about using Terraform only for the creation of a VPC for SAP.\n\n\n\n\n\n Ansible for SAP installation \n\nAnsible is an automation tool for the deployment several IT tasks. This solution performs the automated deployment of SAP HANA 2.0 DB on Red Hat Enterprise Linux 7.6 for SAP HANA on stand-alone SAP HANA box VSI. For more information about Ansible, check out the documentation available on the Ansible page.\n\nThe deployment is done by the Ansible core, which provides CLI tools for automation. More information about Ansible core can be found on [the Ansible core page](https:\/\/docs.ansible.com\/ansible-core\/devel\/index.html).\n\nThe Ansible playbook is called directly by the Terraform script. The Terraform script is run in one run. During the run, the first steps are Terraform specific for creating the VPC, and it continues automatically with the second, Ansible, steps for the installation of the SAP system.\n\nThis automation is offered free of charge however, the provisioned infrastructure comes at cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-hana-vpc-background"},{"document_id":"ibmcld_01121-723-2379","score":9.553033,"text":"\nThere are two possible causes for high storage usage:\n\n\n\n* The storage attached to your system is reaching maximum capacity.\n* There is empty space on the disks that must be reclaimed.\n\n\n\n\n\n\n\n Diagnosing and resolving \n\nIf the output from the previous SQL query indicates that storage usage on your instance is high, the following steps will help to diagnose and resolve this scenario:\n\n\n\n1. Check if the instance has reclaimable space by running the following SQL query as an admin user:\n\ndb2 \"SELECT SUBSTR(TBSP_NAME, 1,30) AS TBSP_NAME, SUM(TBSP_USED_PAGES * TBSP_PAGE_SIZE)\/ 1073741824 AS TBSP_USED_SIZE_GB, SUM((TBSP_PENDING_FREE_PAGES+ tbsp_free_pages) TBSP_PAGE_SIZE)\/ 1073741824 AS FREE_OR_PENDING_GB FROM TABLE(MON_GET_TABLESPACE('',-2)) where TBSP_NAME not like '%SYS%' and TBSP_NAME not like '%TEMP%' and RECLAIMABLE_SPACE_ENABLED = 1 and (TBSP_PENDING_FREE_PAGES+ tbsp_free_pages) >= 1 GROUP BY TBSP_NAME ORDER BY 3 DESC\"\n. If the data is very skewed across Db2 partitions, meaning that one or more Db2 partitions is almost full while other Db2 partitions still have significant capacity remaining, then see [Choosing a hash distribution key for a table in an MPP database](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.doc\/learn_how\/choosing_dist_key_mpp.html){: external}.\n2. If one or more table spaces have reclaimable space, complete the following steps to reclaim that space:\n\nDo not reclaim space during an online backup. The reclaim operation can also impact the performance of ongoing workloads, so it is best to run the following steps during off-peak hours.\n\na. Verify that an online backup is not running:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-stor_intro"},{"document_id":"ibmcld_12572-1567-3411","score":8.930009,"text":"\n-f, --force\n: Force update without confirmation\n\n\n\n\n\n Examples \n\nRename resource group example-group to trial-group:\n\nibmcloud resource group-update example-group -n trial-group\n\n\n\n\n\n\n\n ibmcloud resource group-delete \n\nDelete an existing resource group\n\nibmcloud resource group-delete NAME [-f, --force]\n\n\n\n Command options \n\nNAME (required)\n: Name of the target resource group\n\n-f, --force\n: Force deletion without confirmation\n\n\n\n\n\n Examples \n\nDelete resource group example-group:\n\nibmcloud resource group-delete example-group -f\n\n\n\n\n\n\n\n ibmcloud resource quotas \n\nList all quota definitions.\n\nibmcloud resource quotas\n\n\n\n Examples \n\nList all quota definitions:\n\nibmcloud resource quotas\n\n\n\n\n\n\n\n ibmcloud resource quota \n\nShow details of a quota definition.\n\nibmcloud resource quota NAME\n\n\n\n Command options \n\nNAME (required)\n: Name of the quota\n\n\n\n\n\n Examples \n\nShow details of quota free:\n\nibmcloud resource quota free\n\n\n\n\n\n\n\n ibmcloud resource service-instances \n\nList service instances.\n\nibmcloud resource service-instances [--service-name SERVICE_NAME] [--location LOCATION] [--type INSTANCE_TYPE] [-g RESOURCE_GROUP | --all-resource-groups] [--long]\n\n\n\n Command options \n\n--service-name SERVICE_NAME\n: Name of belonging service\n\n--location LOCATION\n: Filter by location\n\n--type INSTANCE_TYPE\n: Type of instances. service_instance type is used if not specified, use all to list all types of instances.\n\n-g RESOURCE_GROUP\n: Resource group name\n\n--all-resource-groups\n: Query all resource groups\n\n--long\n: Show more fields in output.\n\n\n\n\n\n Examples \n\nList service instances of service test-service:\n\nibmcloud resource service-instances --service-name test-service\n\n\n\n\n\n\n\n ibmcloud resource service-instance \n\nShow details of a service instance.\n\nibmcloud resource service-instance (NAME|ID) [--location LOCATION] [--id]\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_resource"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03310-1389-3175","score":6.2168922,"text":"\nThe following table shows examples of the shorthand syntax that you can use to write context variables in condition expressions.\n\n\n\n Shorthand syntax Full syntax in SpEL \n\n $card_type context['card_type'] \n $(card-type) context['card-type'] \n $card_type:VISA context['card_type'] == 'VISA' \n $card_type:(MASTER CARD) context['card_type'] == 'MASTER CARD' \n\n\n\nYou can include special characters, such as hyphens or periods, in context variable names. However, doing so can lead to problems when the SpEL expression is evaluated. The hyphen could be interpreted as a minus sign, for example. To avoid such problems, reference the variable by using either the full expression syntax or the shorthand syntax $(variable-name) and do not use the following special characters in the name:\n\n\n\n* Parentheses ()\n* More than one apostrophe ''\n* Quotation marks \"\n\n\n\nWhen you refer to a context variable in a text response or a dialog node condition, you can use the short syntax.\n\nFor example, Hello, $name. If the $name context variable contains Sam, then the response is shown as Hello, Sam.\n\nIf you want to reference a context variable by using the full syntax in a text response, be sure to surround the context variable in <? ?>. For example, Hello, <? context['name'] ?>.\n\nIf you want to reference a context variable that has multiple fields, such as $context.integrations.chat.browser_info.page_url. To use the full sytnax, specify <? context['integrations']['browser_info'] ?>.\n\n\n\n\n\n Shorthand syntax for entities \n\nThe following table shows examples of the shorthand syntax that you can use when referring to entities.\n\n\n\n Shorthand syntax Full syntax in SpEL \n\n @year entities['year']?.value \n @year == 2016 entities['year']?.value == 2016 \n @year != 2016 entities['year']?.value != 2016","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-language"},{"document_id":"ibmcld_02914-7-1833","score":5.763214,"text":"\nPersonalizing the dialog with context \n\nTo personalize the conversation, your assistant can collect information from the customer and then refer back to it later in the conversation.\n\n\n\n Anatomy of a dialog call \n\nEach user input is passed to the dialog as a \/message API call. Replies that users make in response to prompts from the dialog that ask them for more information are included. A single \/message API call is equivalent to a single dialog turn, which consists of an input from the customer and a corresponding response from the dialog.\n\nThe body of the \/message API call request and response includes the following objects:\n\n\n\n* context: Contains variables that are meant to be persisted. For the dialog to subsequently reference information that is submitted by the user, you must store the information in the context object. For example, the dialog can collect the user's name and then refer to the user by name in subsequent nodes. The following example shows how the context object is represented in the dialog JSON editor:\n\n{\n\"context\" : {\n\"user_name\" : \"<? @name.literal ?>\"\n}\n\nSee [Retaining information across dialog turns](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context) for more information.\n* input: The string of text that was submitted by the user. The text string can contain up to 2,048 characters. The following example shows how the input object is represented in the dialog JSON editor:\n\n{\n\"input\" : {\n\"text\" : \"Where's your nearest store?\"\n}\n* output: The dialog response to return to the user. The following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"},{"document_id":"ibmcld_01790-5035-7392","score":5.7350364,"text":"\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.\n\n Service Service type \n\n All Account Management services Account Management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis"},{"document_id":"ibmcld_02988-1440-3193","score":5.652539,"text":"\n$(card-type) context['card-type'] \n $card_type:VISA context['card_type'] == 'VISA' \n $card_type:(MASTER CARD) context['card_type'] == 'MASTER CARD' \n\n\n\nYou can include special characters, such as hyphens or periods, in context variable names. However, doing so can lead to problems when the SpEL expression is evaluated. The hyphen could be interpreted as a minus sign, for example. To avoid such problems, reference the variable by using either the full expression syntax or the shorthand syntax $(variable-name) and do not use the following special characters in the name:\n\n\n\n* Parentheses ()\n* More than one apostrophe ''\n* Quotation marks \"\n\n\n\n\n\n\n\n Shorthand syntax for entities \n\nThe following table shows examples of the shorthand syntax that you can use when referring to entities.\n\n\n\n Shorthand syntax Full syntax in SpEL \n\n @year entities['year']?.value \n @year == 2016 entities['year']?.value == 2016 \n @year != 2016 entities['year']?.value != 2016 \n @city == 'Boston' entities['city']?.value == 'Boston' \n @city:Boston entities['city']?.contains('Boston') \n @city:(New York) entities['city']?.contains('New York') \n\n\n\nIn SpEL, the question mark (?) prevents a null pointer exception from being triggered when an entity object is null.\n\nIf the entity value that you want to check for contains a ) character, you cannot use the : operator for comparison. For example, if you want to check whether the city entity is Dublin (Ohio), you must use @city == 'Dublin (Ohio)' instead of @city:(Dublin (Ohio)).\n\n\n\n\n\n Shorthand syntax for intents \n\nThe following table shows examples of the shorthand syntax that you can use when referring to intents.\n\n\n\nIntents shorthand syntax\n\n Shorthand syntax Full syntax in SpEL \n\n `#help` `intent == 'help'` \n `!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-language"},{"document_id":"ibmcld_03421-6867-8448","score":5.572494,"text":"\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\nonLoad: function(instance) {\n\/\/ Subscribe to the \"pre:send\" event.\ninstance.on({ type: \"pre:send\", handler: preSendhandler });\ninstance.render();\n}\n};\n\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_12537-4970-7359","score":5.372424,"text":"\nReview each service's documentation to learn more about how they integrate with context-based restrictions.\n\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-context-restrictions-whatis"},{"document_id":"ibmcld_03233-1603-3253","score":4.92204,"text":"\nYou can condition against context variable values by referencing a context variable from a dialog node condition to determine whether to execute a node. You can also reference a context variable from dialog node response conditions to show different reponses depending on a value provided by an external service or by the user.\n\nLearn more:\n\n\n\n* [Passing context from the application](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-from-app)\n* [Passing context from node to node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-node-to-node)\n* [Defining a context variable](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-var-define)\n* [Common context variable tasks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-common-tasks)\n* [Deleting a context variable](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-delete)\n* [Updating a context variable](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-update)\n* [How context variables are processed](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-processing)\n* [Order of operation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-order-of-ops)\n* [Adding context variables to a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-var-slots)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context"},{"document_id":"ibmcld_03191-48077-49402","score":4.7724366,"text":"\n\"context\": {\n\"input_lower_case\": \"<? input.text.toLowerCase() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"input_lower_case\": \"this is a dog!\"\n}\n}\n\n\n\n\n\n String.toUpperCase() \n\nThis method returns the original String converted to uppercase letters.\n\nFor this input:\n\n\"hi there\".\n\nThis syntax:\n\n{\n\"context\": {\n\"input_upper_case\": \"<? input.text.toUpperCase() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"input_upper_case\": \"HI THERE\"\n}\n}\n\n\n\n\n\n String.trim() \n\nThis method trims any spaces at the beginning and the end of the string and returns the modified string.\n\nFor this Dialog runtime context:\n\n{\n\"context\": {\n\"my_text\": \" something is here \"\n}\n}\n\nThis syntax:\n\n{\n\"context\": {\n\"my_text\": \"<? $my_text.trim() ?>\"\n}\n}\n\nResults in this output:\n\n{\n\"context\": {\n\"my_text\": \"something is here\"\n}\n}\n\n\n\n\n\n java.lang.String support \n\nIn addition to the built-in methods, you can use standard methods of the java.lang.String class.\n\n\n\n java.lang.String.format() \n\nYou can apply the standard Java String format() method to text. See [java.util.formatter reference](https:\/\/docs.oracle.com\/javase\/7\/docs\/api\/java\/util\/Formatter.htmlsyntax) for information about the syntax to use to specify the format details.\n\nFor example, the following expression takes three decimal integers (1, 1, and 2) and adds them to a sentence.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_02914-22357-24003","score":4.715357,"text":"\nIn this example, a variable named new_variable is added to a context block that already contains a variable.\n\n{\n\"context\":{\n\"existing_variable\": \"value\",\n\"new_variable\":\"value\"\n}\n}\n\nTo subsequently reference the context variable, use the syntax $name where name is the name of the context variable that you defined. For example, $new_variable.\n\n\n\nLearn more:\n\n\n\n* [Deleting a context variable in JSON](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-delete-json)\n* [Updating a context variable value in JSON](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-update-json)\n* [Setting one context variable equal to another](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-var-equals-var)\n\n\n\n\n\n Deleting a context variable in JSON \n\nTo delete a context variable, set the variable to null.\n\n{\n\"context\": {\n\"order_form\": null\n}\n}\n\nIf you want to remove all trace of the context variable, you can use the JSONObject.remove(string) method to delete it from the context object. However, you must use a variable to perform the removal. Define the new variable in the message output so it will not be saved beyond the current call.\n\n{\n\"output\": {\n\"text\" : {},\n\"deleted_variable\" : \"<? context.remove('order_form') ?>\"\n}\n}\n\nAlternatively you can delete the context variable in your application logic.\n\n\n\n\n\n Updating a context variable value in JSON \n\nIn general, if a node sets the value of a context variable that is already set, then the previous value is overwritten by the new value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"},{"document_id":"ibmcld_16262-7-2107","score":4.585286,"text":"\nAccessing context data in dialog \n\nThe context is an object that contains variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation. The context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each user who interacts with the assistant. For user-based plans, this ID is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills that are used by an assistant, including internal system variables that are used to manage conversation flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14884-7-2123","score":25.747946,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"},{"document_id":"ibmcld_06926-1815-3739","score":25.672392,"text":"\nUsing VRF, IBM Cloud tenants are allowed to use remote IP addresses that normally would not be allowed to overlap in the Global table. IBM still reserves the following RFC 1918, link-local addresses, and multicast addresses, which are not routable from this VRF service:\n\n\n\n* 10.0.0.0\/14\n* 10.200.0.0\/14\n* 10.198.0.0\/15\n* 169.254.0.0\/16\n* 224.0.0.0\/4\n* 166.9.0.0\/16 (used by the private endpoint service)\n* Any IP ranges assigned to your VLANs on the IBM platform.\n\n\n\nIBM is moving forward with a next-generation Cloud deployment to enable Virtual Private Cloud (VPC) in our availability zones (AZs). This new VPC capability enables Bring-Your-Own-IP (BYoIP) in the VPC-enabled AZs, which are located in Dallas, Washington DC, London, Frankfurt, Tokyo, and Sydney.\n\nFor example, each tenant on the backbone who uses VRF can have only one customer VRF per Direct Link, which provides connectivity among all the tenant\u2019s servers, regardless of location. However, an IBM Cloud tenant might have more than one Direct Link account that feeds into a single cross-connect router.\n\n\n\n* A tenant\u2019s servers in any VLAN, in any pod, in any data center worldwide can reach all of that tenant\u2019s other servers globally.\n* Every tenant\u2019s customer VRF is connected to the common shared services network to provide private reachability for those servers to use DNS, shared storage, monitoring, patching, and more.\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_14870-7-1912","score":25.599566,"text":"\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-overview"},{"document_id":"ibmcld_11554-1776-3838","score":23.090603,"text":"\nVPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n\n\n SAP products architecture on IBM Cloud VPC \n\nA [Virtual Private Cloud (VPC)](https:\/\/www.ibm.com\/cloud\/learn\/vpc?mhsrc=ibmsearch_a&mhq=VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. What\u2019s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new concept handles all the networking for every virtual instance running within VPC across regions and zones.\n\n\n\n\n\n 1. Highly available system for SAP NetWeaver on IBM Cloud VPC \n\nIn a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in the following placement groups section.\n\nZoom\n\n![Figure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"},{"document_id":"ibmcld_14886-1801-3922","score":22.949598,"text":"\nBenefits \n\n\n\n BYOL \n\nRenting licenses can get expensive. Bringing your own license is an option for IBM Cloud Bare Metal Servers for VPC.\n\n\n\n\n\n Rapid scaling \n\nScale your dedicated, bare metal server environment for your needs quickly. Often, in 10 minutes or less when resources are available.\n\n\n\n\n\n Network orchestration \n\nA network orchestration layer handles the networking for all bare metal servers that are within an IBM Cloud VPC across regions and zones. Create multiple, virtual private clouds in multizone regions. Network orchestration also helps improve security, reduce latency, and increase high availability.\n\nYou are responsible for security on your bare metal server. That means upgrading or patching the operating system as needed to make sure that vulnerabilities are addressed in a timely manner. Bare metal servers with associated floating IP addresses are internet-facing and you need to take appropriate precautions. For more information, see [Understanding your responsibilities](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n\n\n\n\n\n\n\n Pricing options \n\nPay-as-you-go bandwidth is per gigabyte. Your billing charges accrue from provision to cancellation, and are billed in arrears. Total pricing includes bare metal server instance profiles and software, internet data transfers, and optional VPC services. Each additional component is priced separately and included as part of your total IBM Cloud VPC charge. Service tiers are bound to your account, not to any specific VPC.\n\nFor more information about pricing, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricingtab_2651670).\n\n\n\n\n\n Bare Metal Servers for VPC versus bare metal server on classic infrastructure \n\nWith Bare Metal Servers for VPC, you can enjoy the security and performance of the private cloud with the flexibility and scalability of the public cloud. Compared to the classic bare metal infrastructures, Bare Metal Servers for VPC provides better connectivity and networking throughput by using VPC concepts.\n\nBare Metal Servers for VPC has local NVMe, which you can use to create VMWare vSAN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers"},{"document_id":"ibmcld_14910-3069-4898","score":22.676392,"text":"\nAs multiple personas and legal entities collaborate, it\u2019s essential to separate duty and access. Hyper Protect Virtual Servers for VPC is based on a newly introduced [encrypted contract](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_se) concept. It enables each persona to provide its contribution and be ensured through encryption that none of the other personas can access this data or intellectual property. The deployment can be validated by an auditor persona through an [attestation record](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-attestation), which is signed and encrypted to ensure only the auditor has this level of insight.\n* Malware protections\n\nHyper Protect Virtual Servers for VPC leverages Secure Build to set up a verification process to ensure that only authorized code is running in an application. It deploys only container versions that are validated at deployment through explicit [digest or are signed](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_images) and may be pulled from a [private container registry with authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_auths) only.\n* Bring your own OCI image and leverage managed Container Runtime service\n\nUse any [open-container initiative (OCI)](https:\/\/opencontainers.org\/) image and gain the benefits of a confidential computing solution for extra levels of protection. Ensure through a [signed contract](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_sign), that only a given combination of your workload and environment is deployed.\n* Built on the Virtual Private Cloud (VPC) infrastructure for extra network security\n\nChoose from various profile sizes and grow as needed to protect containerized applications and pay-as-you-go on an hourly basis.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-se"},{"document_id":"ibmcld_13243-7-1952","score":22.146801,"text":"\nUse a VPC\/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https:\/\/www.strongswan.org\/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution46-vpc-vpn\/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3. The strongSwan open source IPsec gateway software is used on-premises to establish the VPN connection with the cloud environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-site2site-vpn"},{"document_id":"ibmcld_16095-7-1863","score":21.758322,"text":"\nUse a VPC\/VPN gateway for secure and private on-premises access to cloud resources \n\nThis tutorial will incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIBM offers a number of ways to securely extend an on-premises computer network with resources in the IBM Cloud. This allows you to benefit from the elasticity of provisioning cloud resources when you need them and removing them when no longer required. Moreover, you can easily and securely connect your on-premises capabilities to the IBM Cloud services.\n\nThis tutorial provides the automation to create resources that demonstrate Virtual Private Network (VPN) connectivity between on-premises servers and cloud resources like IBM Cloud\u00ae Virtual Private Cloud Virtual Service Instances (VSIs) and IBM Cloud data services. DNS resolution to cloud resources is also configured. The popular [strongSwan](https:\/\/www.strongswan.org\/) VPN Gateway is used to represent the on-premises VPN gateway.\n\n\n\n Objectives \n\n\n\n* Access a virtual private cloud (VPC) environment from an on-premises data center\n* Securely reach cloud services using private endpoint gateways\n* Use DNS on-premises to access cloud resources over VPN\n\n\n\nThe following diagram shows the resources created by this tutorial\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution46-vpc-vpn\/vpc-site2site-vpn-tutorial.png)\n\nFigure 1. Architecture diagram of the tutorial\n\nA terraform configuration will create the following resources:\n\n\n\n1. The infrastructure (VPC, Subnets, Security Groups with rules, Network ACL and VSIs).\n2. The Object Storage and Databases for PostgreSQL private endpoint gateways to data services.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-site2site-vpn"},{"document_id":"ibmcld_07505-1672-3873","score":21.626816,"text":"\nSome network infrastructure and certain key resources are costly and require lengthly lead times and manual labor to set up. These resources benefit from enterprise-level centralization to avoid the costs and delays that would be incurred if deployed at an account level. These needs must be balanced against the desire for separation of concerns and blast radius reduction.\n\n\n\n\n\n Hyper Protect Crypto Services \n\nHyper Protect Crypto Services (HPCS) instances are centrally located so they can be shared across the enterprise to reduce costs. Two instances are required to reach the scale requirements of this recommendation. Smaller organizations can start with a single instance and grow as needed. When services are provisioned in workload accounts, service to service policies (in the network and services hub account) enable those services to access HPCS.\n\n\n\n\n\n Centralized network services \n\nA Transit Gateway in the network and services hub account connects all VPCs in the environment to each other with private networking. This unified private network is then linked to the corporate network through Direct Link. Network isolation is achieved within this flat network through VPC security groups and network ACLs. For more detailed recommendations on securely configuring VPC networking, see [Financial Services Cloud Networking](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-overview).\n\nMake sure that VPC network addresses do not overlap across the enterprise.\n\nA firewall might be deployed in this account or within the corporate network to ensure that traffic from the production environment cannot reach the development environment.\n\nVirtual Private Endpoints (VPE) for shared IBM Cloud services are configured within a VPC in the network and services hub account as VPEs might be attached at only one point in the flat address space. This VPC also includes a custom DNS resolver to ensure the centralized VPEs are properly DNS resolved from all VPCs in the environment.\n\nSome details on how VPEs should be centralized are still being worked out. This document will be updated when that information is available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-hub-account"},{"document_id":"ibmcld_14759-2917-4957","score":21.565594,"text":"\nFor day two of operation, it is your responsibility to monitor and manage the vCenter and NSX-T, including backups, patching, configuration, and monitoring of the VMware software and the underlying vSphere hypervisor.\n\n\n\n\n\n Key benefits \n\nThe architecture provides fundamental building blocks, which include VMware vSphere, vCenter Server, VMware NSX-T, and shared storage options, such as VMware vSAN or IBM Cloud VPC file share. These building blocks are needed to flexibly design a VMware software-defined data center solution that best fits your workloads.\n\nVMware Solutions in IBM Cloud VPC have the following key benefits over IBM Cloud classic deployments:\n\n\n\n* IBM Cloud VPC gives you the ability to easily and rapidly define and control a virtual network, which is logically isolated from all other tenants. The logical isolation is implemented by using virtual network functions and security that is built into the platform.\n* Provisioning the IBM Cloud bare metal server on IBM Cloud VPC takes minutes instead of hours when compared to the IBM Cloud bare metal server on IBM Cloud classic.\n* VMware workloads by running in IBM Cloud VPC can take advantage of all original functions for VPC networking capabilities and other IBM Cloud interconnectivity services.\n\n\n\nWith this single-tenant IBM Cloud bare metal server infrastructure that is provided in IBM Cloud VPC, you can quickly deploy network, compute, and storage capacity for your VMware environment to the IBM Cloud in minutes.\n\nUnlike the managed service offerings, this architecture gives you flexibility to design a solution for your needs, and provides you full and complete access to all components.\n\n\n\n\n\n Related links \n\n\n\n* [IBM Cloud VPC getting started](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started)\n* [IBM Cloud VPC Bare Metal Servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers)\n* [IBM Cloud VPC RYO VMware reference architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-arch-overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.3633175613,"ndcg_cut_10":0.3633175613}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03185-6701-8694","score":17.568422,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_02952-3289-5462","score":17.264378,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02882-18936-21214","score":17.186682,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-1632-3754","score":17.024647,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03113-4-2033","score":16.656754,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02900-4643-6783","score":16.650013,"text":"\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_03113-7328-8943","score":16.607588,"text":"\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST \/dialog_nodes\/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-7-2075","score":16.518707,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03270-1613-3746","score":16.04764,"text":"\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03188-1732-3801","score":15.968445,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.4574945262}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03010-7-2157","score":15.693579,"text":"\nDefining intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03334-5529-7605","score":13.805571,"text":"\n* Both training and test data (for evaluation purposes) should reflect the distribution of intents in real usage. Generally, more frequent intents have relatively more examples, and better response coverage.\n* You can include punctuation in the example text, as long as it appears naturally. If you believe that some users express their intents with examples that include punctuation, and some users will not, include both versions. Generally, the more coverage for various patterns, the better the response.\n\n\n\n\n\n\n\n How entity references are treated \n\nWhen you include an entity mention in a user example, the machine learning model uses the information in different ways in these scenarios:\n\n\n\n* [Referencing entity values and synonyms in intent examples](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intentsintents-related-entities)\n* [Annotated mentions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intentsintents-annotated-mentions)\n* [Directly referencing an entity name in an intent example](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intentsintents-entity-as-example)\n\n\n\n\n\n Referencing entity values and synonyms in intent examples \n\nIf you have defined, or plan to define, entities that are related to this intent, mention the entity values or synonyms in some of the examples. Doing so helps to establish a relationship between the intent and entities. It is a weak relationship, but it does inform the model.\n\n\n\n\n\n Annotated mentions \n\nAs you define entities, you can annotate mentions of the entity directly from your existing intent user examples. A relationship that you identify in this way between the intent and the entity is not used by the intent classification model. However, when you add the mention to the entity, it is also added to that entity as new value. And when you add the mention to an existing entity value, it is also added to that entity value as new synonym. Intent classification does use these types of dictionary references in intent user examples to establish a weak reference between an intent and an entity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03373-2953-4766","score":13.621715,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03334-15077-16547","score":13.527685,"text":"\n* To download all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Download all intents icon. ![Download all intents icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/download-all.png)\n* To download the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents on the current page. Click the Download icon. ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/download.png)\n* To download one or more specific intents, select the intents that you want to download, and then click the Download icon. ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/download.png).\n\n\n\n2. Specify the name and location in which to store the CSV file that is generated, and then click Save.\n\n\n\n\n\n\n\n Uploading intents and examples \n\nIf you have a large number of intents and examples, you might find it easier to upload them from a comma-separated value (CSV) file than to define them one by one. Be sure to remove any personal data from the user examples that you include in the file.\n\nAlternatively, you can upload a file with raw user utterances (from call center logs, for example) and let Watson find candidates for user examples from the data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03334-1458-3293","score":13.289823,"text":"\nThe user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) If you already have chat transcripts from a call center or customer inquiries that you collected from an online application, put that data to work for you. Share the real customer utterances with Watson and let Watson recommend the best intents and intent user examples for your needs. See [Get help defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-recommendations) for more details.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nKeep the name as short as possible. It's easier to read in the \"Try it out\" pane and conversation logs if you keep the intent name short and concise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_16360-1493-3354","score":13.110534,"text":"\nAll phrases corresponding to an intent are created as example phrases for the new action. This can provide a helpful starting point when you are ready to start building actions in the new experience.\n\n\n\n1. Download the intents that you want to migrate to actions from the classic Watson Assistant experience. For more information, see [Downloading intents](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-intents-entitiesmigrate-intents-download). The format for each line in the file is as follows:\n\n<phrase>,<intent>\n\nwhere <phrase> is the text of a user example phrase, and <intent> is the name of the intent. For example:\n\nTell me the current weather conditions.,weather_conditions\nIs it raining?,weather_conditions\nWhat's the temperature?,weather_conditions\nWhere is your nearest location?,find_location\nDo you have a store in Raleigh?,find_location\n2. From the main actions page, click the Upload icon ![Upload icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/upload.svg).\n3. Select the intents file that you downloaded.\n\nThe file is validated and uploaded, and the system trains itself on the new data.\n\nThe intents in column 2 are created as new actions, and the phrases in column 1 are created as example phrases for the corresponding action. For example, if you upload the example from step 1, two new actions are created for the weather_conditions and find_location intents. The underscores (_) in the intent names are replaced with spaces, for example, the weather_conditions intent becomes the weather conditions action.\n\nIn this example, the weather_conditions action will have three example phrases: Tell me the current weather conditions., Is it raining?, and What's the temperature?. The find_location action will have two example phrases: Where is your nearest location? and Do you have a store in Raleigh?.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-upload-download-actions"},{"document_id":"ibmcld_03403-1720-3144","score":12.650601,"text":"\nStep 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03145-1287-2166","score":12.60461,"text":"\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_02877-2458-4452","score":12.507244,"text":"\nThis method returns true if the input JSONArray contains the input value.\n\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.contains('ham')\n\nResult: True because the array contains the element ham.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or higher than the minimum confidence score, or the intent is lower in the array than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top two intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"},{"document_id":"ibmcld_03334-19597-21305","score":12.494607,"text":"\nIt provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16640-7-2035","score":6.374648,"text":"\nKnown issues (Limitations) \n\nThe following limitations and known issues, apply to IBM\u00ae watsonx.data.\n\n\n\n Issue: Unable to view created schema \n\nWhen a user with the User role and the Create access (the user only has the Create access) is added to an external database, they cannot see the schemas that they created. Though the user can create schemas, they cannot view them. Following is the system response:\n\npresto:default> show schemas;\nSchema\n--------\n(0 rows)\n\nWorkaround: Provide select privilege for the schema the user created.\n\n\n\n\n\n Issue: Access denied message occurs when querying an external database \n\nWhen a user with the User role and Create access (the user only has Create access), is added to an external database, they cannot run the select query from the table they have created. Though the user can connect to the Presto engine and create tables and schemas, they cannot query from the table. The system displays an Access Denied message.\n\nQuery 20230608_132213_00042_wpmk2 failed: Access Denied: Cannot select from columns [id] in table or view tab_appiduser_01\n\nWorkaround: Provide select privilege for the table the user created.\n\n\n\n\n\n Issue: Schema created under different catalog \n\nSchemas are available across Iceberg and Hive catalogs. When a schema is created under Iceberg catalog, it is listed under Hive catalog and vice versa.\n\n\n\n\n\n Issue: Presto does not support deletion of Iceberg tables \n\n\n\n\n\n Issue: DROP SCHEMA in Db2 \n\nIn Db2, the schema can be dropped only if it is empty. Initiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-known_issues"},{"document_id":"ibmcld_16471-134960-136979","score":6.2481785,"text":"\ncreate external table create table \n\n <br><br> * Defines a placeholder for a table whose content is supplied at initialization time.<br><br><br> <br><br> * Requires that the content of the table is available at compile time.<br> * Serialized in the compiled representation (.tam) of a module.<br><br><br> \n\n\n\n\n\n\n\n Examples \n\nExample 1: Creating an external table that is populated at load time\n\nThe external table, PersonNegativeClues, expects to be populated at load-time because of the flag, allow_empty false.\n\nmodule PersonModuleFrench;\n\ncreate external table PersonNegativeClues (name Text)\nallow_empty false;\n\nexport table PersonNegativeClues;\n\nExample 2: Creating a dictionary with an external table\n\nDictionaries can also be created from external tables, similar to being created from inline tables that are declared with the create table statement.\n\ncreate external table Product (nickName Text, formalName Text)\nallow_empty false;\n\n\/\n* Dictionary of product nicknames, from the nickName field\n* of the customizable external table Product.\n\/\ncreate dictionary ProductDict\nfrom table Product\nwith entries from nickName;\n\n\n\n\n\n Documenting the create external table statement with AQL Doc \n\nThe AQL Doc comment for a create external table statement contains the following information:\n\n\n\n* General description about the table.\n* @field for every column name in the schema of this table.\n\n\n\n\/ Create a table that maps company names to locations of corporate headquarters.\n* @field name name of the company\n* @field location location of corporate headquarters\n\/\ncreate external table Company2Location\n(name Text, location Text)\nallow_empty false;\n\n\n\n\n\n\n\n The create external view statement \n\nThe create external view statement in AQL allows specification of more metadata about a document as a new view, in addition to the predefined Document view that holds the textual and label content.\n\n\n\n Syntax \n\ncreate external view <view_name> (\n<colname> <type> [, <colname> <type>]\n)\nexternal_name '<view_external_name>';","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_11667-4046-5741","score":5.9214973,"text":"\nIf you're manually creating the initial subnet, versus creating it when you created your VPC, the region (location) that you select is used as the region of the VPC. All additional resources that you in this VPC are created in the selected region.\n\nIf you created a subnet when you created your VPC, more subnets must be created in the same region. You can create multiple subnets within VPC zones.\n5. Click Create subnet.\n\n\n\n\n\n\n\n\n\n Provisioning your Intel virtual server \n\nBefore you can create a virtual server, you must create the VPC and you must create an SSH key that you add to the server instance during its creation - see more details on [SSH keys with virtual servers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys).\n\nUse the following steps to order your virtual server and necessary components. For more information about creating a virtual server, see [Creating virtual server instances by using the IBM Cloud console](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-virtual-servers).\n\n\n\n1. Log in to the [IBM Cloud console](https:\/\/cloud.ibm.com) with your unique credentials.\n2. Click Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg) > VPC Infrastructure > Virtual server instances.\n3. Click Create.\n4. Enter a unique Name for the virtual server, which becomes the hostname. SAP hostnames must consist of a maximum of 13 alpha-numeric characters. For more information about SAP hostnames, see [SAP Notes 611361](https:\/\/launchpad.support.sap.com\/\/notes\/611361) and [129997](https:\/\/launchpad.support.sap.com\/\/notes\/129997).\n5. Choose a Resource group.\n\nThe resource group can't be changed after the virtual server is created.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-vs-set-up-infrastructure"},{"document_id":"ibmcld_12011-1600-3752","score":5.5598497,"text":"\nBlueprint create fails with an invalid blueprint template: unable to find file error \n\n What\u2019s happening \n\nWhen you create the configuration, the create fails before the config is created with an error that the template, or input files cannot be found.\n\n Why it\u2019s happening \n\nWhen you create the configuration, Schematics attempts to download the input files, and template from the Git repositories that are specified on the create and validate the YAML schema. The repository was located, but the template or input files cannot be found.\n\nSample error\n\nFAILED\nCould not create the blueprint. Please verify that your request is correct. If the problem persists, contact IBM Cloud support.\n\nInvalid blueprint templates. Error - Unable to find basic-blueprint1.yaml in the target repo\n\n How to fix it \n\nCheck that the template file and input files that are identified in the error message exist in the target repository and are correctly specified on the config create.\n\nRerun the create operation with the correct file name.\n\n\n\n\n\n Blueprint create fails with the requested resource group as invalid \n\n What\u2019s happening \n\nWhen you create the configuration, the create fails before the config is created with an error that the requested resource group ID is invalid or needed permissions.\n\n Why it\u2019s happening \n\nOn creation, blueprints are assigned to the Schematics management resource group passed on the create. If the group is invalid or the user does not have the correct Schematics IAM permissions for the group the create operation will fail.\n\nSample error\n\nFAILED\nCould not create the blueprint. Please verify that your request is correct. If the problem persists, contact IBM Cloud support.\n\nThe requested resource group id is invalid or required permissions for performing the action are not present on resource group. Please check the resource group ID and permissions.\n\n How to fix it \n\nCheck that the resource group that is specified on the --resource_group option is valid and that the user has the correct Schematics [IAM permissions](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-accessblueprint-permissions) to create blueprints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-fails"},{"document_id":"ibmcld_15500-1707-3590","score":5.0338535,"text":"\n* The volume must be in the region where you want to create the custom image.\n* The volume must be a primary boot volume with 100 GB capacity. Data volumes are not supported.\n* The volume must be attached to an instance. Unattached boot volumes are not supported.\n* The instance must be in an available state.\n* The available, running instance must be stopped before you create the custom image. Creating an image from a running instance is not allowed.\n\n\n\n\n\n\n\n\n\n Options for creating an image from a volume \n\nYou can create a custom image from a boot volume in several ways.\n\n\n\n* In the [UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifvimage-from-volume-vpc-ui), you can create a custom image from any of the following places.\n\n\n\n* The Custom images for VPC page,\n* The list of instances on the Virtual server instances for VPC page,\n* The Instance details page,\n* The list of volumes on Block storage volumes for VPC page.\n* The Volume details page.\n\n\n\n* In the [API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifvimage-from-volume-vpc-api), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. With the regional API, you create an image by making a POST \/images call and passing the boot volume ID.\n* From the [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifvimage-from-volume-vpc-cli), you can create a custom image at the same time as you create a new instance, or you can create an image from an existing instance. Issue the ibmcloud is image-create command and specify the boot volume's ID.\n\n\n\n\n\n\n\n Image from volume encryption \n\nWhen you create an image from a volume, you have the following encryption choices.\n\n\n\n* If you want to create an instance and boot volume with default IBM-managed encryption, then the image from that boot volume inherits the IBM-managed encryption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc"},{"document_id":"ibmcld_03106-3091-5136","score":4.9918666,"text":"\ncatalog_integration.create creates a custom extension \n catalog_integration.delete deletes a custom extension \n catalog_integration.update updates a custom extension \n counterexample.create marks test user input in the \"Try it out\" pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant \n counterexample.delete deletes a counterexample \n counterexample.update edits a counterexample \n data.delete deletes multiple training data items, such as multiple entities or intents \n data.update does a bulk action, such as importing a CSV file of intents or entities to the skill \n data_type.create creates a saved response \n data_type.delete deletes a saved response \n data_type.update updates a saved response \n entity.create creates an entity \n entity.delete deletes an entity \n entity.update edits an entity \n environment.create adds an environment \n environment.delete deletes an environment \n environment.updates updates an environment \n example.create adds a user input example to an intent \n example.delete deletes a user example from an intent \n example.update edits a user example that is associated with an intent \n integration_defintion.create creates an integration \n integration_defintion.delete deletes an integration \n integration_defintion.update updates an integration \n intent.create creates an intent \n intent.delete deletes an intent \n intent.update edits an intent \n log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page \n node.create creates a dialog node \n node.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"},{"document_id":"ibmcld_16248-2956-5001","score":4.9918666,"text":"\ncatalog_integration.create creates a custom extension \n catalog_integration.delete deletes a custom extension \n catalog_integration.update updates a custom extension \n counterexample.create marks test user input in the \"Try it out\" pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant \n counterexample.delete deletes a counterexample \n counterexample.update edits a counterexample \n data.delete deletes multiple training data items, such as multiple entities or intents \n data.update does a bulk action, such as importing a CSV file of intents or entities to the skill \n data_type.create creates a saved response \n data_type.delete deletes a saved response \n data_type.update updates a saved response \n entity.create creates an entity \n entity.delete deletes an entity \n entity.update edits an entity \n environment.create adds an environment \n environment.delete deletes an environment \n environment.updates updates an environment \n example.create adds a user input example to an intent \n example.delete deletes a user example from an intent \n example.update edits a user example that is associated with an intent \n integration_defintion.create creates an integration \n integration_defintion.delete deletes an integration \n integration_defintion.update updates an integration \n intent.create creates an intent \n intent.delete deletes an intent \n intent.update edits an intent \n log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page \n node.create creates a dialog node \n node.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-auditing"},{"document_id":"ibmcld_09841-1360-2978","score":4.9908156,"text":"\nmqcloud.trust-store-cert.create An event is created when you import a certificate into a trust store \n mqcloud.trust-store-cert.delete An event is created when you delete a certificate from a trust store \n mqcloud.trust-store-cert.update An event is created when you update a certificate in a trust store \n mqcloud.admin-credentials.create An event is created when you create administrator credentials \n mqcloud.admin-credentials.delete An event is created when you delete administrator credentials \n mqcloud.admin-credentials.update An event is created when you update administrator credentials \n mqcloud.admin-apikey.create An event is created when you create an API key for an administrator \n mqcloud.admin-apikey.update An event is created when you update an API key for an administrator \n mqcloud.app-credentials.create An event is created when you create application credentials \n mqcloud.app-credentials.delete An event is created when you delete application credentials \n mqcloud.app-credentials.update An event is created when you update application credentials \n mqcloud.app-apikey.update An event is created when you update an API key for an application \n mqcloud.cluster.create An event is created when you create a cluster \n\n\n\n\n\n\n\n Where to view the events \n\nThe following table shows the location (region) in IBM Cloud where you can monitor MQ on Cloud events:\n\n\n\n MQ on Cloud service instance location Activity Tracker service instance location \n\n Dallas (us-south) Dallas (us-south) \n Frankfurt (eu-de) Frankfurt (eu-de) \n London (eu-gb) London (eu-gb) \n Washington DC (us-east) Washington DC (us-east)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-at_events"},{"document_id":"ibmcld_10727-7-1794","score":4.9381175,"text":"\nCreating actions \n\nCreate an IBM Cloud\u00ae Functions action, which is a top-level function that returns a JSON object. You can combine actions into a package to simplify the management of your actions.\n\nBefore you begin\n\nTo create an action, your source code must meet certain requirements. For example, if you want to create an action from code that is contained in multiple files, package your code as a single .zip file before you create the action.\n\nSee [Preparing apps for actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-prep) for details about the requirements for packaging code for each runtime.\n\n\n\n Creating actions from the CLI \n\n\n\n1. Create an action by running the [ibmcloud fn action create](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_action_create) command.\n\nibmcloud fn action create <action_name> <file> --kind <runtime>\n\nExample\n\nibmcloud fn action create hello hello.js --kind nodejs:10\n\nExample output\n\nok: created action hello\n2. Verify that the action is in your actions list.\n\nibmcloud fn action list\n\nExample output\n\nactions\nhello private\n\n\n\nTips:\n\n\n\n* To save on cost, you can set limits.\n\n\n\n* To set a limit for memory usage, include --memory <value> with your create command, where the value is in megabytes.\n* To set a timeout, include --timeout <value> with your create command, where the value is in milliseconds.\n\n\n\n* If you packaged your code as a Docker image, include --docker <docker_hub_username>\/<docker_hub_image>:<tag> with your create command instead of the local path to your app and the --kind flag. Manage your images well by not using the latest tag whenever possible. When the latest tag is used, the image with that tag is used, which might not always be the most recently created image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions"},{"document_id":"ibmcld_03106-4717-6754","score":4.835933,"text":"\nnode.delete deletes a dialog node \n node.update edits a dialog node \n notifier.create creates a notifier \n notifier.delete deletes a notifier \n notifier.update updates a notifier \n processor.create creates a processor \n processor.delete deletes a processor \n processor.update updates a processor \n recommendationfile.create uploads a CSV file of utterances to a skill from which Watson can derive intent recommendations \n recommendationfile.delete deletes a CSV file of utterances that is used to derive intent recommendations from a skill. \n recommendationsources.update updates a CSV file or assistant log that is being used as the source for intent recommendations \n release.create create a version from content in the draft environment \n release.delete delete a version \n release.deploy publish a version to an environment \n skill.create creates a skill \n skill.delete deletes a skill \n skill.update updates a skill \n skill_reference.create adds a specific skill to an assistant \n skill_reference.delete removes a specific skill from an assistant \n skill_reference.update updates a specific skill that is associated with an assistant \n skill_variable.create create a skill variable \n skill_variable.delete delete a skill variable \n skill_variable.update update a skill variable \n skills.export export a skill \n skills.import import a skill \n snapshot.create creates a version of a dialog skill \n snapshot.delete deletes a version of a dialog skill \n snapshot.update updates a version of a dialog skill \n step.create adds a step to an action \n step.delete deletes a step from an action \n step.update updates a step in an action \n step_handler.create create a step handler \n step_handler.delete delete a step handler \n step_handler.update update a step handler \n synonym.create creates a synonym for an entity value \n synonym.delete deletes a synonym that is associated with an entity value \n synonym.update edits a synonym that is associated with an entity value \n userdata.delete deletes data that was created by a specified customer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-auditing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":15.02634,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03369-36856-39124","score":13.308093,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03373-4-1923","score":12.88006,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_16364-163116-165172","score":12.63012,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-7-1790","score":12.38318,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03085-4-2046","score":12.12834,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_16364-74209-76251","score":11.291971,"text":"\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021 \n\nActions skill improvement\n: Actions now include a new choice, Go to a subaction, for what to do next in a step. This feature lets you can call one action from another action, to switch the conversation flow to another action to perform a certain task. If you have a portion of an action that can be applied across multiple use cases you can build it once and call to it from each action. This new option is available in the And then section of each step. For more information, see [Go to a subaction](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-what-nextgo-to-another-action).\n\n\n\n\n\n 21 April 2021 \n\nPreview button for testing your assistant\n: For testing your assistant, the new Preview button replaces the previous Preview tile in Integrations.\n\nNew checklist with steps to go live\n: Each assistant includes a checklist that you can use to ensure you're ready to go live.\n\nActions skill improvement\n: Actions now include currency and percentage response types.\n\nLearn what's new\n: The What's new choice on the help menu opens a list of highlighting recent features.\n\n\n\n\n\n 14 April 2021 \n\nActions skill improvement","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03329-1102-2607","score":11.205162,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03049-2703-4536","score":11.171718,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03369-74273-76338","score":11.034704,"text":"\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03405-3051-4760","score":16.870113,"text":"\nClick the System entities tab, and then turn on these entities:\n\n\n\n* @sys-time\n* @sys-date\n* @sys-number\n\n\n\n\n\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"},{"document_id":"ibmcld_03071-3000-4820","score":16.514608,"text":"\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_03196-53970-56256","score":15.480294,"text":"\n* Jump to another dialog node: Use this option when you want the conversation to go directly to an entirely different dialog node. You can use a Jump to action to route the flow to a common dialog node from multiple locations in the tree, for example.\n\nThe target node that you want to jump to must exist before you can configure the jump to action to use it.\n\n\n\n\n\n Configuring the Jump to action \n\nIf you choose to jump to another node, specify when the target node is processed by choosing one of the following options:\n\n\n\n* Condition: If the statement targets the condition section of the selected dialog node, your assistant checks first whether the condition of the targeted node evaluates to true.\n\n\n\n* If the condition evaluates to true, the system processes the target node immediately.\n* If the condition does not evaluate to true, the system moves to the next sibling node of the target node to evaluate its condition, and repeats this process until it finds a dialog node with a condition that evaluates to true.\n* If the system processes all the siblings and none of the conditions evaluate to true, the basic fallback strategy is used, and the dialog evaluates the nodes at the base level of the dialog tree.\n\n\n\nTargeting the condition is useful for chaining the conditions of dialog nodes. For example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated above the current node in the dialog tree. Otherwise, you can create an infinite loop. If your assistant jumps to the earlier node and checks its condition, it is likely to return false because the same user input is being evaluated that triggered the current node last time through the dialog. Your assistant will go to the next sibling or back to root to check the conditions on those nodes, and will likely end up triggering this node again, which means the process will repeat itself.\n* Response: If the statement targets the response section of the selected dialog node, it is run immediately.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_02882-32106-34249","score":15.049624,"text":"\nFor example, the response might ask the user a yes or no question. The dialog will not progress until the user provides more input.\n* Skip user input: Use this option when you want to bypass waiting for user input and go directly to the first child node of the current node instead.\n\nThe current node must have at least one child node for this option to be available.\n* Jump to another dialog node: Use this option when you want the conversation to go directly to an entirely different dialog node. You can use a Jump to action to route the flow to a common dialog node from multiple locations in the tree, for example.\n\nThe target node that you want to jump to must exist before you can configure the jump to action to use it.\n\n\n\n\n\n Configuring the Jump to action \n\nIf you choose to jump to another node, specify when the target node is processed by choosing one of the following options:\n\n\n\n* Condition: If the statement targets the condition section of the selected dialog node, your assistant checks first whether the condition of the targeted node evaluates to true.\n\n\n\n* If the condition evaluates to true, the system processes the target node immediately.\n* If the condition does not evaluate to true, the system moves to the next sibling node of the target node to evaluate its condition, and repeats this process until it finds a dialog node with a condition that evaluates to true.\n* If the system processes all the siblings and none of the conditions evaluate to true, the basic fallback strategy is used, and the dialog evaluates the nodes at the base level of the dialog tree.\n\n\n\nTargeting the condition is useful for chaining the conditions of dialog nodes. For example, you might want to first check whether the input contains an intent, such as turn_on, and if it does, you might want to check whether the input contains entities, such as @lights, @radio, or @wipers. Chaining conditions helps to structure larger dialog trees.\n\nAvoid choosing this option when configuring a jump-to from a conditional response that goes to a node situated before the current node in the dialog tree. Otherwise, you can create an infinite loop.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03196-4-2102","score":14.919692,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Creating a dialog \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. From the Skills menu, click Dialog.\n\nThe following nodes are created for you automatically:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs used in integrations with channels such as Facebook or Slack skip nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\nFor more information about these built-in nodes, see [Starting and ending the dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-start).\n2. To add more nodes to the dialog tree, click Add node.\n\nYour new node is added after the Welcome node and before the Anything else node.\n3. Add a name to the node.\n\nUse a short, customer-friendly description of what the node does as its name. For example, Open an account, Get policy information, or Get a weather forecast.\n\nThe name can be up to 512 characters in length.\n\nThis node name is shown to customers or service desk personnel to express the purpose of this branch of the dialog, so take some time to add a name that is concise and descriptive.\n4. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03218-24900-26959","score":14.81869,"text":"\nFor each node, you configure whether:<-- <ul> --> * a digression can start from and leave the node * a digression that starts elsewhere can target and enter the node * a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed<-- <\/ul> -->To change the digression behavior for an individual node, complete the following steps:<-- <ol> -->1. Click the node to open its edit view.2. Click Customize, and then click the Digressions tab.\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\nDigressions away from this node\n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n<-- <ul> -->\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response switch to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it left off. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_03188-1732-3801","score":14.764198,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_02998-4422-6015","score":14.437228,"text":"\nWe'll create a simple dialog that handles greeting and ending intents, each with a single node.\n\n\n\n Adding a start node \n\n\n\n1. From the Skills menu, click Dialog.\n2. Two nodes were added to the dialog for you:\n\n\n\n* Welcome: Contains a greeting that is displayed to your users when they first engage with the assistant.\n* Anything else: Contains phrases that are used to reply to users when their input is not addressed by any of the existing dialog nodes.\n\n\n\n![A new dialog with two built-in nodes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-new-dialog.png)\n3. Click the Welcome node to open it in the edit view.\n4. Replace the default response with the text, Welcome to the Watson Assistant tutorial!.\n\n![Editing the welcome node response](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-edit-welcome-node.png)\n5. Click ![Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/close.png) to close the edit view.\n\n\n\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03270-3352-5135","score":14.336136,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03113-9858-11006","score":14.32268,"text":"\n![Example dialog 6](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_6.png)\n\nNote that node_1, node_4, node_5, and node_7 were all deleted. When you delete a node, all descendants of that node are deleted as well. Therefore, if you delete a root node, you are actually deleting an entire branch of the dialog tree. Any other references to the deleted node (such as next_step references) are changed to null.\n\nIn addition, node_2 is updated to point to node_8 as its new previous sibling.\n\n\n\n\n\n Renaming a node \n\nFinally, let's rename node_2 using the POST \/dialog_nodes\/node_2 method with the following body:\n\n{\n\"dialog_node\": \"node_X\"\n}\n\n![Example dialog 7](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_7.png)\n\nThe structure of the dialog has not changed, but once again multiple nodes were modified to reflect the changed name:\n\n\n\n* The parent properties of node_9 and node_6\n* The previous_sibling property of node_3\n\n\n\nAny other references to the deleted node (such as next_step references) are also changed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16454-9876-11996","score":15.273756,"text":"\nFor example, a PERSON entity can be an employee of an ORGANIZATION entity or a geo-political entity (GPE), such as MaryemployedByIBM, but organizations and geo-political entities cannot be employed by a person. When a human annotator clicks an entity in the ground truth editor , the list of available relation types is controlled by what is defined in the type system.\n\nDo not define relation attributes. They are not used by the machine learning model. The model uses only the relation type and order, and ignores the relation attributes.\n5. Use the Edit and Delete icons to modify entity types and their associated relation types, or to delete an entity type or relation type from the type system.\n\nIf you delete an entity that is used in a relation type definition, the relation type definition is also deleted.\n\n\n\n\n\n\n\nRelated tasks:\n\n[Modifying a type system without losing human annotations](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n Type system creation guidelines \n\nThe purpose of any type system in Knowledge Studio is to define how spans of text can be annotated. If you choose to create a type system from scratch, follow these guidelines.\n\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"},{"document_id":"ibmcld_16454-11402-13678","score":14.562446,"text":"\nFor example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.\n\nPlan to spend a good amount of time defining the type system before your team begins any human annotation tasks. When the team does start to annotate documents, begin with a small set, perhaps no more than 50.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"},{"document_id":"ibmcld_16527-11091-13443","score":13.913991,"text":"\nFocus on creating an inventory of entity types and relation types that cover the information that is needed by the application in which the type system will be used. Do not cover things that are not needed. Do not split types or make distinctions that are not needed by the application. For example, if the source document contains the sentence Murder on the Orient Express made headlines, then how you define entity types to capture the key information in the sentence differs depending on the type of application that will use the model that you build with the type system.\n\n\n\n* For a literary application, you might create types that capture this information:\n\n[NOVEL] [CRITICAL_RECEPTION]\n\n[Murder on the Orient Express] [made headlines]\n* For a public safety application, you might create these types:\n\n[EVENT_CRIME] [LOCATION]\n\n[Murder] on the [Orient Express] made headlines\n\n\n\nThe structure is often driven by characteristics of the documents from which information will be extracted, but should always be tempered by what information the application will actually use from those documents. For example, you might be creating an application that gains insights from medical records. To build the type system, you start looking at patient records to see what kinds of information must be captured. The patient records might all contain a field that describes what the patient ate for lunch. However, if the application will not use that information, do not add it to the type system. And in making the decision to make this omission, recognize that this means that sections of your patient record documents will be left unannotated. That is alright and even expected.\n\nMentions annotate a span of text; they do not replace the text. A type system is not an ontology for a domain. Expect to have general entity types such as MEDICATION_NAME instead of having an entity type for each medicine type. The document text will continue to contain the specific medicine name. It will just be enhanced with an annotation that identifies its type, which makes the information easier to find and extract programmatically.\n\nAs you get started, define 10 to 40 entity types and relation types. Stay to the lower end of the range if the human annotators who will be working on the workspace are not highly specialized in the field. Do not define more than 50.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"},{"document_id":"ibmcld_07069-9761-11096","score":12.373724,"text":"\n\"SIRE_ENTITY_LEVEL\" : \"NONE\",\n\"SIRE_ENTITY_SUBTYPE\" : \"NONE\",\n\"SIRE_MENTION_ROLE\" : \"FURNITURE_PATIO\",\n\"SIRE_MENTION_TYPE\" : \"NONE\"\n},\n\"type\" : \"FURNITURE_PATIO\",\n\"begin\" : 3221,\n\"end\" : 3234,\n\"inCoref\" : false\n},\nShow more\n\nDon't forget to rename the parent mention labels.\n\nFor example, find mentions that specify \"SIRE_ENTITY_SUBTYPE\" : \"OTHER\", and then change the value from OTHER to NONE.\n\nChange the value of the SIRE_MENTION_ROLE and type for the mention to the new parent entity type label.\n\nFor example, change the SIRE_MENTION_ROLE and type values for these mentions from FURNITURE to FURNITURE_NONE, and the SIRE_ENTITY_SUBTYPE to NONE.\n\n{\n\"id\" : \"Sports_herald.com_be99aca94a7cff5abb74476b844a11b6.en-M75\",\n\"source\" : \"IMPORT\",\n\"properties\" : {\n\"SIRE_MENTION_CLASS\" : \"SPC\",\n\"SIRE_ENTITY_LEVEL\" : \"NONE\",\n\"SIRE_ENTITY_SUBTYPE\" : \"NONE\",\n\"SIRE_ENTITY_CLASS\" : \"SPC\",\n\"SIRE_MENTION_TYPE\" : \"NONE\",\n\"SIRE_MENTION_ROLE\" : \"FURNITURE_NONE\"\n},\n\"type\" : \"FURNITURE_NONE\",\n\"begin\" : 2063,\n\"end\" : 2071,\n\"inCoref\" : false\n},\nShow more\n7. Add annotations for relationships that are missing based on the new flattened entity types.\n8. Create a Knowledge Studio workspace, and then upload the converted type system.\n\nFollow the appropriate steps for uploading a type system based on your Knowledge Studio deployment type:\n\n\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-wks"},{"document_id":"ibmcld_07411-14782-16101","score":11.780969,"text":"\nName _sip._tcp.video.example.com\nType SRV\nCreated On 2020-04-10 09:15:56.940189115 +0000 UTC\nModified On 2020-04-10 09:15:56.940189115 +0000 UTC\nTTL 900\nData\nport 953\npriority 10\ntarget media.example.com\nweight 10\n\n\n\n\n\n Creating type 'TXT' resource record \n\nUse the ibmcloud dns resource-record-create command with --type TXT option to create a type TXT resource record. --name and --text are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type TXT --name text --text \"This is a text record.\"\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID TXT:92648285-c7e5-49ef-bf8b-a5be91d5c5d3\nName text.example.com\nType TXT\nCreated On 2020-04-10 09:16:50.169135062 +0000 UTC\nModified On 2020-04-10 09:16:50.169135062 +0000 UTC\nTTL 900\nData\ntext This is a text record.\n\n\n\n\n\n Creating type 'MX' resource record \n\nUse ibmcloud dns resource-record-create command with --type MX option to create a type MX resource record. --name and --exchange are the mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type MX --name mail --preference 10 --exchange exchange.example.com\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_16454-4998-7161","score":11.768749,"text":"\nFor a relation mention to exist, text must explicitly define the relation and bind mentions of the two entities together, and must do so within a single sentence. For example, the sentence Mary works for IBM is textual evidence of the employedBy relation type.\n\nFor some relation types, the order of entity mentions matters. For example, the employedBy relation type allows the entity type PERSON or PEOPLE as the first mention in the relationship, and ORGANIZATION or GPE as the second mention, but not the other way around. MaryemployedByIBM is a valid relationship. IBMemployedByMary is not. For some relation types, such as spouseOf, colleague, or sibling, order does not matter. When you define a relation type where order is not important, a best practice is to add information to the annotation guidelines to regularize how the relation type is used. A convention for noting such symmetrical relations is to say that the entity mention that occurs first in the text should be the first one in the relation.\n\nRelated concepts:\n\n[Uploading resources from another workspace](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-exportimport)\n\n\n\n\n\n\n\n Adding a type system to the workspace \n\nYou must create or upload a type system before you begin any annotation tasks.\n\n\n\n About this task \n\nThe following naming rules apply to type system entries:\n\n\n\n* Names cannot contain spaces.\n* Use only the following alphanumeric ASCII characters and the underscore character in values that you add to the type system: A through Z, a through z, 0 through 9.\n* The first character in an entity or relation type name must be alphabetical.\n* Entity type names cannot be longer than 64 characters.\n* Relation type names cannot be longer than 128 characters.\n\n\n\nBy convention, entity type names are specified in uppercase characters (ORGANIZATION) and relation type names are specified in camel case (employedBy). But, this convention is optional.\n\n\n\n\n\n Procedure \n\n\n\n1. Log in as a Knowledge Studio administrator or project manager and open the Assets> Entity Types page.\n2. Choose one of the following methods to create a type system:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"},{"document_id":"ibmcld_07411-17619-18802","score":11.634284,"text":"\ncname www.example.com\n\n\n\n\n\n Creating type 'AAAA' resource record \n\nUse ibmcloud dns resource-record-create command with --type AAAA option to create a type AAAA resource record. --name and --ipv6 are mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type AAAA --name www --ipv6 2019::2020\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID AAAA:37e1e701-e549-4ca1-8c22-86574bf4aaed\nName www.example.com\nType AAAA\nCreated On 2020-04-10 09:37:15.063814601 +0000 UTC\nModified On 2020-04-10 09:37:15.063814601 +0000 UTC\nTTL 900\nData\nip 2019::2020\n\n\n\n\n\n Getting a resource record \n\nUse ibmcloud dns resource-record command followed by the zone ID and resource record ID to get details of a resource record.\n\n$ ibmcloud dns resource-record $DNS_ZONE_ID A:f20cfe91-b936-4bad-a8d1-f7afa4ac32a6\nGetting resource record 'A:f20cfe91-b936-4bad-a8d1-f7afa4ac32a6' in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID A:f20cfe91-b936-4bad-a8d1-f7afa4ac32a6\nName www.example.com\nType A\nCreated On 2020-04-10 09:12:07.858707275 +0000 UTC","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_07033-9327-11385","score":10.807855,"text":"\nLabeling tips \n\nReview these tips before you begin:\n\n\n\n* The document collection that you label must contain a representative set of documents. The documents must have many and varied examples of the entity types that you want the entity extractor to recognize. If the collection you selected when you started to create the entity extractor does not meet the requirement, stop now and start over with a different document collection.\n* Define entity types that are clearly distinct from one another.\n* Aim to label at least 40 examples of each entity type.\n* Label every valid example of an entity type. Do not skip any occurrences. To speed up the process, use the bulk label feature.\n\n\n\n\n\n\n\n Labeling entity examples \n\nLabel terms in the document that represent examples of the entity types you defined. When you are done with one document, switch the document status from In progress to Complete, and then move on to the next document.\n\nOnly the first 40,000 characters from each document are available for labeling. 40,000 characters is approximately 20 pages.\n\nTo label entity examples, complete the following steps:\n\n\n\n1. Review the text of the document. Look for entity examples to label.\n\nThe following table shows some examples.\n\n\n\nEntity types and examples\n\n Entity type Examples to label in the document \n\n color white, green, purple \n car convertible, SUV, sedan \n auto_model Explorer, Civic, Sorrento \n auto_manufacturer Ford, Honda, Kia \n clothing shirt, blouse, skort \n instruments bonds, stocks, ETFs, munis \n\n\n\nIf an entity type that you want to identify is not created yet, add the entity type. From the Entity types panel, click Create new. For more information about adding entity types, see [Defining entity types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractorentity-extractor-add-entities).\n2. First, click the entity type from the Entity types panel.\n3. In the document body, select the word or phrase that represents the entity example.\n\nThe term is selected and a color label is applied to the term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractor"},{"document_id":"ibmcld_07411-13875-15037","score":10.167792,"text":"\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID A:f20cfe91-b936-4bad-a8d1-f7afa4ac32a6\nName www.example.com\nType A\nCreated On 2020-04-10 09:12:07.858707275 +0000 UTC\nModified On 2020-04-10 09:12:07.858707275 +0000 UTC\nTTL 900\nData\nip 192.168.1.100\n\n\n\n\n\n Creating type 'SRV' resource record \n\nUse the ibmcloud dns resource-record-create command with --type SRV option to create a type SRV resource record. --name, --service, --protocol, and --target are the mandatory options.\n\n$ ibmcloud dns resource-record-create $DNS_ZONE_ID --type SRV --name video --service _sip --protocol tcp --priority 10 --weight 10 --port 953 --target media.example.com\nCreating resource record in zone 'example.com:f7f40364-a5e6-48f7-9fc9-387434c579ae' for service instance 'DNS Services-km' ...\nOK\n\nID SRV:c7c8938b-87c7-4aee-95fa-63f28452c8d4\nName _sip._tcp.video.example.com\nType SRV\nCreated On 2020-04-10 09:15:56.940189115 +0000 UTC\nModified On 2020-04-10 09:15:56.940189115 +0000 UTC\nTTL 900\nData\nport 953\npriority 10\ntarget media.example.com\nweight 10\n\n\n\n\n\n Creating type 'TXT' resource record","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_11722-7825-8801","score":10.154799,"text":"\nThe PARAMETER1 value PARAMETER2 must contain only alphabets, numbers, underscore, and hyphen.\n\nError type: Bad request\n\nResponse code: 400\n\n\n\n\n\n ST0048 error message \n\nFailed to update wanted storage configuration. Assignment creation failed.\n\nError type: Services\n\nResponse code: 500\n\n\n\n\n\n ST0049 error message \n\nConfiguration is created in CONFIG-LOCATIOIN location but the cluster is in CLUSTER-LOCATION location. Re-create the configuration in CLUSTER-LOCATION location and retry.\n\nError type: Bad request\n\nResponse code: 400\n\n\n\n\n\n ST0050 error message \n\nThe controller ID is not specified in the request.\n\nError type: Bad request\n\nResponse code: 400\n\n\n\n\n\n ST0051 error message \n\nFailed to retrieve OBJECT-TYPE. BackendError: BACKEND-ERROR\n\nError type: Services\n\nResponse code: 500\n\n\n\n\n\n ST0052 error message \n\nUnable to create or update storage configuration. Multiple storage classes defined with the name STORAGE-CLASS-NAME.\n\nError type: Bad request\n\nResponse code: 400","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-debug-storage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03126-3707-6008","score":21.941946,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03043-7-2031","score":21.704922,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03126-5596-6966","score":21.411964,"text":"\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03373-4-1923","score":21.367498,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_16364-98714-100707","score":20.996235,"text":"\nFor more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n\nAutolearning has been moved and improved\n: Go to the Analytics>Autolearning page to enable the feature and see visualizations that illustrate how autolearning impacts your assistant's performance over time. For more information, see [Empower your skill to learn automatically](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nSearch from actions skill\n: The actions skill now supports triggering a search that uses your associated search skill from within an action step. For more information, see [Deciding what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-what-next).\n\nSystem entities language support change\n: The new system entities are now used by all skills except Korean-language dialog skills. If you have a Korean skill that uses the older version of the system entities, update it. The legacy version will stop being supported for Korean skills in March 2021. For more information, see [Legacy system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-legacy-system-entities).\n\nDisambiguation selection enhancement\n: When a customer chooses an option from a disambiguation list, the corresponding intent is submitted. With this latest release, a confidence score of 1.0 is assigned to the intent. Previously, the original confidence score of the option was used.\n\nSkill import improvements\n: Importing of large skills from JSON data is now processed in the background. When you import a JSON file to create a skill, the new skill tile appears immediately. However, depending on the size of the skill, it might not be available for several minutes while the import is being processed. During this time, the skill cannot be opened for editing or added to an assistant, and the skill tile shows the text Processing.\n\n\n\n\n\n 23 November 2020 \n\nDeploy your assistant to WhatsApp!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-163116-165172","score":20.97183,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-3966-5647","score":20.367178,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03381-4347-6258","score":20.233377,"text":"\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add an actions or dialog skill.\n3. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions page instead.\n\n\n\n\n\n\n\n Sharing a dialog skill with team members \n\nAfter you create the service instance, you can give other people access to it. Together, you can define the training data and build the dialog.\n\nOnly one person can edit an intent, entity, or a dialog node at a time. If multiple people work on the same item at the same time, then the changes made by the person who saves their changes last are the only changes applied. Changes that are made during the same time frame by someone else and are saved first are not retained. Coordinate the updates that you plan to make with your team members to prevent anyone from losing their work.\n\nTo share a dialog skill with other people, you must give them access to the service instance that hosts the skill. Note that the person you invite will be able to access any skill or assistant in this service instance.\n\n\n\n1. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03054-18427-20301","score":19.99261,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_13042-15810-17906","score":19.4437,"text":"\nFor details about how to add a search skill response type, see [Adding a Search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n* My response text is surrounded by brackets: If you notice that your response text is surrounded by brackets and quotation marks ([\"My response text\"]) when you test it from the Preview, for example, you might need to change the source field that you're using in the configuration. The unexpected formatting indicates that the value is stored in the source document as an array. Any field that you extract text from must contain a value with a String data type, not an Array data type. When the chat integration shows a response that is extracted from a field that stores the data as an array, it does a straight conversion of the array value into a string, which produces a response that includes the array syntax.\n\nFor example, maybe the field in the source document contains an array with a single text value as its only array element:\n\n\"title\": [\"a single array element\"]\n\nThe array value is converted by the Watson Assistant into this string value:\n\n\"title\": \"[\"a single array element\"]\"\n\nAs a result, the string is returned in this format in the chat; the surrounding brackets and quotation marks are displayed:\n\n[\"a single array element\"]\n\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03054-22692-24767","score":18.873663,"text":"\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.\n* Search skill only: If only a search skill is linked to an assistant, and no dialog skill is linked to the assistant, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Try it out pane of the search skill.\n\nYou cannot test the full end-to-end user experience from the dialog skill's Try it out pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its Try it out pane.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, you must test it by using the API.\n\n\n\n1. From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2. Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03054-7-2020","score":18.666761,"text":"\nCreating a search skill \n\nAn assistant uses a search skill to route complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from a configured data source and returns it to the assistant.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the preview link integration](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-preview-link.png)\n\nYou must have Discovery for IBM Cloud Pak for Data installed and an instance provisioned before you can complete this procedure to create a search skill. The search skill can connect only to an existing Discovery for IBM Cloud Pak for Data instance.\n\nYour search skill can connect to a single Discovery project. The project can contain multiple collections.\n\nTo learn more about how search skill can benefit your business, [read this blog post](https:\/\/medium.com\/ibm-watson\/adding-search-to-watson-assistant-99e4e81839e5).\n\n\n\n How it works \n\nThe search skill searches for information from one or more data collections that you create by using Discovery for IBM Cloud Pak for Data.\n\nDiscovery for IBM Cloud Pak for Data crawls, converts, and normalizes your unstructured data. The product applies data analysis and cognitive intuition to enrich your data such that you can more easily find and retrieve meaningful information from it later. To read more about Discovery, see the [product documentation](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about).\n\nTypically, the type of data collection you add to Discovery and access from your assistant contains information that is owned by your company.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03196-46002-48092","score":17.950119,"text":"\nYou can trigger a search of the existing material in real time to get the latest and most up-to-date answer for your customers.\n\nTo use the search skill response type, you must create a search skill and add it to the same assistant that uses this dialog skill. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\nTo add a Search skill response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Search skill.\n\nIndicates that you want to search an external data source for a relevant response.\n2. To edit the search query to pass to the Discovery service, click Customize, and then fill in the following fields:\n\n\n\n* Query: Optional. You can specify a specific query in natural language to pass to Discovery. If you do not add a query, then the customer's exact input text is passed as the query.\n\nFor example, you can specify What cities do you fly to?. This query value is passed to Discovery as a search query. Discovery uses natural language understanding to understand the query and to find an answer or relevant information about the subject in the data collection that is configured for the search skill.\n\nYou can include specific information provided by the user by referencing entities that were detected in the user's input as part of the query. For example, Tell me about @product. Or you can reference a context variable, such as Do you have flights to $destination?. Just be sure to design your dialog such that the search is not triggered unless any entities or context variables that you reference in the query have been set to valid values.\n\nThis field is equivalent to the Discovery natural_language_query parameter. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n* Filter: Optional. Specify a text string that defines information that must be present in any of the search results that are returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03383-17365-19519","score":17.927382,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":17.927382,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-19820-21851","score":17.25526,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-20671-22804","score":17.181427,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":17.181427,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03043-7-2031","score":17.110392,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03383-19002-21103","score":16.91242,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3044671975}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":17.101849,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":17.06231,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":16.54102,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":15.979497,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":14.889403,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_06004-29614-31438","score":13.971069,"text":"\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_06225-7-1999","score":12.924599,"text":"\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_app"},{"document_id":"ibmcld_10645-7-1995","score":12.835217,"text":"\nManaging the app lifecycle \n\nUse Kubernetes-native and third-party tools to perform rolling updates and rollbacks of apps without downtime for your users.\n\n\n\n Update strategies \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are backwards-compatible so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version. You can create the new version: green deployment, wait until it is ready, and then delete the version: blue deployment. Or you can perform a [rolling update](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_appapp_rolling), but set the maxUnavailable parameter to 0% and the maxSurge parameter to 100%.\n\nCanary or A\/B deployment\n: A more complex update strategy, a canary deployment is when you pick a percentage of users such as 5% and send them to the new app version. You collect metrics in your logging and monitoring tools on how the new app version performs, do A\/B testing, and then roll out the update to more users. As with all deployments, labeling the app (such as version: stable and version: canary) is critical.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_app"},{"document_id":"ibmcld_00962-3246-5702","score":12.390709,"text":"\nThe Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds. Over time, the traffic that is sent to the new version is increased until all of the traffic is sent there, at which point you can stop the old production environment. For rapid rollback while deployment is in progress, you can route all of the traffic to the original production environment. Since this strategy requires two full production environments only during deployment, the overall resource usage is lower than for the Blue-Green deployment. The Canary release deployment strategy is the slowest to move from a previous release to a current release of the software that is being deployed. Canary deployments allow organizations to test two different software versions side by side in production.\n\n\n\n Before you begin \n\nBefore you start this tutorial, make sure that you have the following resources in place:\n\n\n\n* An [IBM Cloud account](https:\/\/cloud.ibm.com\/registration), with a Standard plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-vpc"},{"document_id":"ibmcld_13429-166159-168045","score":12.101451,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":12.56995,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-15747-17355","score":11.885875,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-1342-3184","score":11.579045,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":11.277381,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":9.692465,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":9.485115,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-7-1743","score":9.151035,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":7.3725224,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":5.3946576,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02229-1540-3221","score":1.2065415,"text":"\nFor more information, see the tutorial for [Getting started with Terraform on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-getting-started). The plug-in abstracts the IBM Cloud APIs that are used to complete this task.\n* Create a Terraform configuration file that is named main.tf. In this file, you define resources by using HashiCorp Configuration Language. For more information, see the [Terraform documentation](https:\/\/www.terraform.io\/docs\/language\/index.html).\n\n\n\n\n\n\n\n Viewing details about your software instance by using Terraform \n\nYou can't view details about your software instance by using Terraform. To view your software instance details, switch to the UI steps.\n\n\n\n\n\n Viewing logs for your software instance by using Terraform \n\nYou can't view logs for your software instance by using Terraform. To view the logs, switch to the UI steps.\n\n\n\n\n\n Renaming your software instance by using Terraform \n\nYou can rename your software instance by using Terraform.\n\n\n\n1. Create an argument in your main.tf file. The following example shows the software instance details by using the ibm_cm_offering_instance resource, where label is a display name to identify the instance. To rename your software instance, update label.\n\nresource \"ibm_cm_offering_instance\" \"cm_offering_instance\" {\ncatalog_id = \"catalog_id\"\nlabel = \"label\"\nkind_format = \"operator\"\nversion = \"version\"\ncluster_id = \"cluster_id\"\ncluster_region = \"cluster_region\"\ncluster_namespaces = [ \"cluster_namespaces\", \"cluster_namespaces\" ]\ncluster_all_namespaces = false\n}\n\nYou can specify an update timeout for the ibm_cm_offering_instance resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-sw-instance-details"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.5323325779}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":19.546469,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":18.005184,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-15747-17355","score":16.696918,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-1426-3052","score":16.401257,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":14.935527,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_04518-7-1743","score":14.179741,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":13.306639,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":13.056106,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":11.544727,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_05410-2860-4697","score":10.531742,"text":"\nIf workloads in different projects want to communicate with each other, then the communication must either use the internet or an internal IBM private network. For more information, see [Options for visibility for a Code Engine application](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-application-workloadsoptionsvisibility).\n\nCreate a project in Code Engine called sample.\n\nibmcloud ce project create --name sample\n\nExample output\n\nCreating project 'sample'...\nID for project 'sample' is 'abcdabcd-abcd-abcd-abcd-abcd12e3456f7'.\nWaiting for project 'sample' to be active...\nNow selecting project 'sample'.\nOK\n\nNotice that your project is also selected for context, so all subsequent application-related commands are within the scope of this new sample project.\n\n\n\n\n\n Step 3: Creating a directory and source code \n\n\n\n1. Create a directory on your local workstation that is named myapp and navigate into it. In this directory, save all the files that are required to build the image and to run your app.\n\nmkdir myapp && cd myapp\n2. Create a file called server.js and copy the following source code into it.\n\nconst http = require('http');\n\nhttp.createServer(function (request, response) {\nresponse.writeHead(200, {'Content-Type': 'text\/plain'});\nresponse.end( \"Hello worldn\" );\n}).listen(8080);\n\nThis example uses Node.js. You can substitute code from any [supported runtime](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-plan-buildbuild-buildpack-strat).\n\n\n\n\n\n\n\n Step 4: Deploying your application \n\nPush your code to Code Engine by using the application create command. You must provide a name for your application and the location of the source code. The following example creates an application called myapp that uses the buildpack strategy and provides the location for the source code in the current directory (.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-migrate-cf-ce-local"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":20.767672,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":19.095493,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07532-7-2311","score":17.847227,"text":"\nPush notifications \n\nEvent Notifications provides a push notification service for sending transactional and informational event notifications to mobile devices.\n\n\n\n Adding a push service destination \n\nAdd an IBM Cloud push notification destination to your instance of Event Notifications by clicking Add in the Destinations view of the Event Notifications dashboard. After a new push destination is created, you see an entry IBM Cloud push service in the Destination list. You must configure your push destination by adding credentials for Apple Push Notification Service (APNS) or Firebase Cloud Messaging (FCM).\n\nEach application and platform requires a separate push destination.\n\nYou can use Pre-production destination, as low-cost push destination, for your development and test environments. You can change the Pre-production destination to Production destination post completion of your development and testing. This feature is only available for Standard pricing plan.\n\n\n\n\n\n Using a push service destination \n\nTo use a push service destination, add it to a subscription. The subscription also needs a topic to filter events of interest from your sources. When an event lands in the topic, Event Notifications immediately routes the event notification to your registered devices.\n\nThe push service works along with an app on your users' mobile devices. You must instrument the app with the Event Notifications push SDK. The app must ensure that users consent to notifications, and then the SDK helps to register their mobile devices. For more information, see [Create an Event Notifications destination](https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-create-en-destination).\n\n\n\n\n\n Push troubleshooting and telemetry \n\nTroubleshooting and telemetry information for push notifications is available in the IBM\u00ae Log Analysis service. You can see the dispatch status as well as delivered and opened information for individual devices. For more information, see [Logging for Event Notifications](https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-logs).\n\n\n\n\n\n Push charges \n\nThe IBM Cloud push service has two components to pricing: a destination instance fee and a consumption price.\n\nThe destination instance fee is a fixed amount charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-destinations-push"},{"document_id":"ibmcld_02772-1628-3402","score":17.030396,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-6582-8092","score":16.802992,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-4371-5701","score":16.264648,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02665-1570-3896","score":16.119366,"text":"\nStandard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n\n\n\n\n What are the charges to use App Configuration? \n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID. This task is most easily accomplished by programming your app or microservice to send the Entity ID by using the App Configuration SDK.\n\nAPI Call - An API call is the invocation of the App Configuration through a programmable interface.\n\nExactly what constitutes an API call varies depending on the entity type (for example, a microservice or a mobile app). For server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_10864-5549-7975","score":16.03156,"text":"\nAdditionally, Cloud Functions actions can be connected to an API Management tool of choice. Similar to other use cases, all considerations for scalability, and other Qualities of Services apply.\n\nSee the following example that includes a discussion of [using Serverless as an API backend](https:\/\/martinfowler.com\/articles\/serverless.htmlACoupleOfExamples).\n\n\n\n\n\n Mobile back end \n\nMany mobile applications require server-side logic. However, mobile developers usually don\u2019t have experience in managing server-side logic, and would rather focus on the app that is running on the device. This development goal is easily obtained by using Cloud Functions as the server-side back end, and is a good solution. In addition, the built-in support for server-side Swift allows developers to reuse their existing iOS programming skills. Since mobile applications often have unpredictable load patterns, you want to use a Cloud Functions solution like IBM Cloud\u00ae. This solution can scale to meet practically any demand in workload without the need to provision resources ahead of time.\n\n\n\n\n\n Data processing \n\nWith the amount of data now available, application development requires the ability to process new data, and potentially react to it. This requirement includes processing both structured database records as well as unstructured documents, images, or videos. Cloud Functions can be configured by system-provided or custom feeds to react to changes in data, and automatically execute actions on the incoming feeds of data. Actions can be programmed to process changes, transform data formats, send and receive messages, invoke other actions, and update various data stores. Supported data stores include SQL based relational databases, in-memory data grids, NoSQL database, files, messaging brokers, and various other systems. Cloud Functions rules and sequences provide flexibility to change the processing pipeline without programming, and is performed through simple configuration updates. The data store options and low administrative maintenance make a Cloud Functions based system highly agile, and easily adaptable to changing requirements.\n\n\n\n\n\n Cognitive \n\nCognitive technologies can be effectively combined with Cloud Functions to create powerful applications. For example, Watson Visual Recognition can be used with Cloud Functions to automatically extract useful information from videos without having to watch them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"},{"document_id":"ibmcld_02772-7-2195","score":15.747428,"text":"\nMobile apps \n\nWith IBM Cloud\u00ae App ID, you can quickly construct an authentication layer for your native or hybrid mobile app.\n\n\n\n Understanding the flow \n\nA mobile flow is useful when you are developing an app that is to be installed on a user's device (a native application). By using this flow, you can securely authenticate users on your app to provide personalized user experiences across devices.\n\n\n\n What is the flow's technical basis? \n\nSince native applications are installed directly on a user's device, private user information and application credentials can be extracted by third-parties with relative ease. By default, these types of applications are known as untrusted clients as they cannot store global credentials or user refresh tokens. As a result, untrusted clients require users to input their credentials every time their access tokens expire.\n\nTo convert your application into a trusted client, App ID uses [Dynamic Client Registration](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749). Before an application instance begins authenticating users, it first registers as an OAuth2 client with App ID. Because of client registration, your application receives an installation-specific client ID that can be digitally signed and used to authorize requests with App ID. Since App ID stores your application's corresponding public key, it can validate your request signature that allows your application to be viewed as a confidential client. This process minimizes your application's risk of exposing credentials indefinitely and greatly improves the user experience by allowing automatic token refresh.\n\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10805-1522-3235","score":15.578749,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10863-7246-8495","score":14.559974,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10817-6582-8092","score":14.453955,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02679-8312-9928","score":14.060541,"text":"\nThe SDK uses the attribute values to determine whether the specified entity satisfies the targeting rules, and returns the appropriate feature flag value.\n\n\n\n\n\n\n\n Get single property \n\nconst property = appConfigClient.getProperty('property_id'); \/\/ property can be null incase of an invalid property id\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Get all properties \n\nconst properties = appConfigClient.getProperties();\nconst property = properties['property_id'];\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Evaluate a property \n\nYou can use the property.getCurrentValue(entityId, entityAttributes) method to evaluate the value of the property. This method returns a JSON object containing evaluated value and evaluation details.\n\nconst entityId = '<entityId>';\nconst entityAttributes = {\ncity: 'Bangalore',\ncountry: 'India',\n};\n\nconst result = property.getCurrentValue(entityId, entityAttributes);\nconsole.log(result.value); \/\/ Evaluated value of the property. The type of evaluated value will match the type of property (Boolean, String, Numeric).\nconsole.log(result.details); \/\/ a JSON object containing detailed information of the evaluation. See below\n\n\/\/ the result.details will have the following\nconsole.log(result.details.valueType); \/\/ a string value. Example: DEFAULT_VALUE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks"},{"document_id":"ibmcld_13455-24911-26512","score":13.41137,"text":"\n\"content-type\": \"audio\/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_12335-0-917","score":13.280976,"text":"\n\n\n\n\n\n\n  Errors \n\n\n\n  Error delivery \n\nSDK methods MUST surface errors to the caller in the manner that is idiomatic for the particular language. For example, a Go SDK should return an error value from the method, but a Java SDK should raise an Exception.\n\n\n\n\n\n  Error content \n\nWhen an SDK method encounters an error, it MUST capture all relevant information about the error and return it in the error structure that is returned to the caller. Relevant information includes the entire contents of the error response and all response headers. The SDK documentation MUST clearly describe how this information is returned and how it can be accessed by the calling program.\n\nErrors that are generated within the SDK MUST give a clear and specific description of the problem. For example, if a method parameter failed a validation, the message should state which parameter is invalid and the reason it is invalid.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-errors"},{"document_id":"ibmcld_10863-6347-7636","score":12.473758,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_13429-166159-168045","score":12.338677,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_02679-9543-11489","score":12.175998,"text":"\nconsole.log(result.value); \/\/ Evaluated value of the property. The type of evaluated value will match the type of property (Boolean, String, Numeric).\nconsole.log(result.details); \/\/ a JSON object containing detailed information of the evaluation. See below\n\n\/\/ the result.details will have the following\nconsole.log(result.details.valueType); \/\/ a string value. Example: DEFAULT_VALUE\nconsole.log(result.details.reason); \/\/ a string value. Example: Default value of the property.\nconsole.log(result.details.segmentName); \/\/ (only if applicable, else it is undefined) a string value containing the segment name for which the property was evaluated.\nconsole.log(result.details.errorType); \/\/ (only if applicable, else it is undefined) contains the error.message if any error was occured during the evaluation.\nShow more\n\n\n\n* entityId: Id of the entity. This is a string identifier related to the entity against which the property is evaluated. For example, an entity might be an instance of an app that runs on a mobile device, a microservice that runs on the cloud, or a component of infrastructure that runs that microservice. For any entity to interact with App Configuration, it must provide a unique entity ID.\n* entityAttributes: A JSON object consisting of the attribute name and their values that define the specified entity. This is an optional parameter if the property is not configured with any targeting definition. If the targeting is configured, then entityAttributes should be provided for the rule evaluation. An attribute is a parameter that is used to define a segment. The SDK uses the attribute values to determine whether the specified entity satisfies the targeting rules, and returns the appropriate property value.\n\n\n\n\n\n\n\n Get secret property \n\nExplicit method for getting the secret references stored in App Configuration.\n\nconst secretPropertyObject = appConfigClient.getSecret(propertyId, secretsManagerObject);\n\nWhere,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks"},{"document_id":"ibmcld_10863-4041-5570","score":12.083396,"text":"\nresolve({ cloudant_result: 'SUCCESS' });\n}, 5000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cloudant_result\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:53:36.739565Z stdout: fake db access done. Resolving Promise...\"\n]\n\n\n\n\n\nYour db-access action is ready!\n\n\n\n\n\n Step 3: Create the ow-sdk-action actionow-sdk-action action \n\nThe ow-sdk-action action is a Node.js program that calls the other two actions: cos-access and db-access. When invoked, the ow-sdk-action action code acts as a custom sequence, first calling cos-access, then db-access, and finally cos-access again. The results of each action are stored in a variable that is called chained_action_results, which is then returned at the end. When the action is invoked, follow the code comments to see what is happening.\n\n\n\n1. From the Actions page, create a third action called ow-sdk-action.\n\n\n\n1. Name your action ow-sdk-action.\n2. Select the action-tutorial package.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n\/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_02667-8417-10541","score":12.047331,"text":"\nPercentage rollout capability is available for Lite and Enterprise plans.\n\nFollowing are some of the percentage rollout scenarios:\n\n\n\n* If the feature flag is disabled, then SDK returns the default Disabled value.\n* If the feature flag is enabled without any segment rules and no percentage rollout is set, then the SDK returns default Enabled value.\n* If the feature flag is enabled without any segment rule and percentage rollout is set to 0%, then the SDK returns Disabled value for all users.\n* If the feature flag is enabled without any segment rule and percentage rollout is set to a percent, say 50%, then the SDK checks if the user belongs to the configured percentage rollout size, if the user belongs to the rollout criteria, then the SDK returns the Enabled value. If the user doesn't belong to the rollout criteria, then the SDK returns the Disabled value.\n* If the feature flag is enabled with segment rules, then SDK first evaluates the user against the configured rules. If user is part of the configured rule, then the SDK evaluates if the user is eligible for percentage rollout.\n\n\n\n* If multiple rules are configured and the user is checked for rule match until the first match. If no match found, then the SDK evaluates against the default rollout.\n* If the user is evaluated to be part of the segment and the segment percentage rollout is 0%, then even if the user is part of the segment, user will not receive the segment value. The SDK returns the default Disabled value.\n* If the user is evaluated to be part of the segment and the segment percentage rollout is set to a percentage, say 50%, then the SDK checks if the user belongs to configured rollout size, if the user belongs to the rollout criteria, then the SDK returns the segment overriding value. If the user doesn't belongs to the rollout criteria, then the SDK returns Disabled value.\n\n\n\n\n\n\n\n View as table \n\n\n\nTable 1. Percentage rollout scenarios\n\n Feature Flag Is targeting configured? Percentage <br>rollout Is user <br>part of <br>configured segment Is user <br>part of <br>percentage rollout <br>criteria Value <br>returned <br>by SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-feature-flags"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":23.823868,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-6582-8092","score":23.052431,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":21.739855,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02731-4670-6607","score":19.243326,"text":"\n: Server SDK: You can protect your back-end resources that are hosted on IBM Cloud and your web apps by using the server SDK. It extracts the access token from a request and validates it with App ID. Client SDK: You can protect your mobile apps with the Android or iOS client SDK. The client SDK communicates with your cloud resources to start the authentication process when it detects an authorization challenge.\n\nIBM Cloud\n: App ID: After successful authentication, App ID returns access and identity tokens to your app. Cloud Directory: Users can sign up for your service with their email and a password. You can then manage your users in a list view through the UI. With Cloud Directory, App ID functions as your identity provider.\n\nExternal (third party)\n: Social and enterprise identity providers: App ID supports Facebook, Google+, and SAML 2.0 Federation as identity provider options. The service arranges a redirect to the identity provider and verifies the returned authentication tokens. If the tokens are valid, the service grants access to your app.\n\n\n\n\n\n Integrations \n\nYou can use App ID with other IBM Cloud offerings.\n\nKubernetes Service\n: By configuring Ingress in a standard cluster you can secure your apps at the cluster level. Check out the [App ID authentication Ingress annotation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsapp-id-authentication) or the [Announcing App ID integration to IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/announcing-app-id-integration-ibm-cloud-kubernetes-service) blog post to get started.\n\nCloud Functions and API Connect\n: When you create your APIs with [Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) and [API Connect](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-getting-started), you can secure your applications at the gateway rather than in your app code.\n\nActivity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-about"},{"document_id":"ibmcld_10852-45155-46272","score":18.47093,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":18.067535,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-44214-45420","score":18.01512,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-1628-3402","score":17.968801,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_02772-4213-5899","score":17.941568,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-4371-5701","score":17.449337,"text":"\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.\n\n\n\n\n\n Invoke a mobile SDK action \n\nTo invoke a remote action, you can call invokeAction with the action name. Use a dictionary to pass parameters to the action as needed.\n\nExample\n\n\/\/ In this example, we are invoking an action to print a message to the IBM Cloud Functions Console\nvar params = Dictionary<String, String>()\nparams[\"payload\"] = \"Hi from mobile\"\ndo {\ntry whisk.invokeAction(name: \"helloConsole\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: false, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nprint(\"Action invoked!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\nShow more\n\n\n\n\n\n Fire a mobile SDK trigger \n\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16233-7-2298","score":16.888098,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_03330-4-2191","score":16.38169,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_13160-7-1812","score":15.429949,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_13160-1449-3062","score":15.395846,"text":"\n[Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2. The chatbot utilizes a custom extension with REST API deployed as Python app on [Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started)\n3. The custom extension app retrieves data from and inserts data into a [Db2 on Cloud](https:\/\/cloud.ibm.com\/docs\/Db2onCloud) database\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* Code Engine plugin,\n\n\n\n* git to clone source code repository,\n* jq to query JSON data.\n\n\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\n\n\n\n\n Step 1: Set up services and deploy backend \n\nIn this section, you are going to set up the needed services and deploy the backend app. All of this can be accomplished from the command line interface (CLI) in a terminal.\n\n\n\n1. Clone the [GitHub repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson) and navigate into the cloned directory:\n\ngit clone https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_07080-6045-7467","score":15.153406,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Conversational Search project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"},{"document_id":"ibmcld_13160-6371-8160","score":15.004598,"text":"\nReplace projectid, region, and MY_SECRET accordingly.\n\ncurl -X 'POST' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/database\/recreate' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\nThe above request should return an error message that the confirmation is missing. Now try again with a query parameter:\n\ncurl -X 'POST' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/database\/recreate?confirmation=True' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\nThe request should succeed and indicate that the database was recreated. Time for another test:\n\ncurl -X 'GET' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/events' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\n\n\n\n\n\n\n Step 2: Create an assistant \n\nIn this part of the tutorial you are going to work with the Watson Assistant service. First, you create a new assistant. Then, you create the custom extension and add it to the assistant. Thereafter, you will create actions and test them using the web preview. Finally, you integrate the chatbot with Slack and perform more tests.\n\n\n\n1. In the [IBM Cloud Resource List](https:\/\/cloud.ibm.com\/resources) open the overview of your services. Locate the instance of the Watson Assistant service under the AI \/ Machine Learning section. Click on its entry to open the service details.\n2. Click on Launch Watson Assistant to get to the Watson Assistant Tool.\n3. In the welcome dialog, create a new assistant by using slackbot as Assistant name, then click Next to start personalizing.\n4. For the first question on deployment pick Web.\n5. For the other questions answer for your role or with Other \/ Not sure at this time.\n6. Click Next for the opportunity to customize the chat UI if desired.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_03330-3253-5192","score":14.837681,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_09228-1610-2667","score":14.8298235,"text":"\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https:\/\/developer.ibm.com\/components\/watson-apis\/patterns\/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https:\/\/github.com\/ibm\/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https:\/\/github.com\/IBM\/tensorflow-hangul-recognition)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_16729-6810-8822","score":14.8175955,"text":"\n[Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nCode Engine Watson Assistant\n\n+1\n\nDb2 on Cloud\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek)Use NeuralSeek to return polished answers from existing help content\n\nIn this tutorial, you will use the Watson Discovery, Watson Assistant, and NeuralSeek services that are available from the IBM Cloud catalog to create a virtual assistant that can answer questions about Watson Discovery. The assistant will generate answers by using the existing Watson Discovery product documentation as its knowledge base.\n\nWatson Assistant\n\n\n\n* 4 hours\n* 2023-05-05\n\n\n\nAnalytics[Explore creating serverless instances and submitting applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli)Explore creating serverless instances and submitting applications using the CLI\n\nLearn how to use the IBM Analytics Engine CLI to create the services that you need to create and manage a serverless instance, and submit and monitor your Spark applications.\n\nAnalytics Engine\n\n\n\n* 15 minutes\n* 2022-08-26\n\n\n\n[Process big data logs with SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics)Process big data logs with SQL\n\nIn this tutorial, you will build a log analysis pipeline designed to collect, store and analyze log records to support regulatory requirements or aid information discovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16293-7-1797","score":14.779524,"text":"\nIntegrating with Slack \n\nIBM Cloud\n\nSlack is a cloud-based messaging application that helps people collaborate with one another.\n\nAfter you create an action, you can integrate your assistant with Slack.\n\nWhen integrated, depending on the events that you configure the assistant to support, your assistant can respond to questions that are asked in direct messages or in channels where the assistant is directly mentioned.\n\nAn example and instructions on how to create a Slackbot using Watson Assistant, Slack, and Db2 are given in the solution tutorial, [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson).\n\n\n\n Adding the Slack integration \n\n\n\n1. Go to the Integrations page by clicking the integrations icon (![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)) in the left menu.\n2. Click Add on the Slack tile.\n3. Click Confirm.\n4. You need to have a Slack app to connect to.\n\nIf you don\u2019t have a Slack app, create one now. See [Starting with Slack apps](https:\/\/api.slack.com\/start).\n5. Go to the [Your Apps](https:\/\/api.slack.com\/apps) page on the Slack website, and then click the app you want to use.\n\nOpen the Slack app in a new browser tab, so you can easily switch back and forth between the Slack app settings page and Watson Assistant Slack integration configuration page.\n6. From the settings page for your Slack app, open the App Home page.\n7. Add access scopes for your Slack app.\n\nThe button label might be Review Scopes to Add or Update scopes depending on whether you are creating a new app or editing an app that you created before February 2020.\n\nThe method for Slack access changed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09920-5038-6185","score":23.274328,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_09118-10321-12086","score":18.702744,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_07223-4208-5090","score":18.434591,"text":"\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=uigisF50F8s&feature=youtu.be)\n\n\n\n[Cognitive Banking Chatbot](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/?cm_sp=Developer-_-code-_-banking_chatbot) Create a web UI chatbot using the IBM Watson Node.js SDK to include conversation interaction, anger detection, natural language understanding, and answer discovery. Answers are discovered from a collection of FAQ documents. Built as a fictional financial institution, this app calls out to simple banking services code as an example of how to include external business data in a conversation response.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sample-apps"},{"document_id":"ibmcld_09920-3951-5345","score":18.25846,"text":"\n[External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/snap-and-translate)\n\n\n\n\n\n\n\n Analyze product reviews and generate a shopping guide \n\nCreate a Node.js app to make cognitive decisions using product reviews evaluated by Watson Natural Language Understanding.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/analyze-product-reviews-and-generate-a-shopping-guide\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-second-opinion?cm_sp=Developer-_-slug-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=wwNAEvbxd54)\n\n\n\n\n\n\n\n Create a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_16233-7-2298","score":17.895142,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_09118-9294-10691","score":17.42801,"text":"\n[Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Tone Analyzer](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Watson OpenScale](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_03330-4-2191","score":16.472881,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_09921-1508-2973","score":16.44745,"text":"\nsatisfied An affective response to perceived service quality \n sympathetic An affective mode of understanding that involves emotional resonance \n\n\n\n\n\n* Example response:\n\n{\n\"usage\": {\n\"text_units\": 1,\n\"text_characters\": 60,\n\"features\": 1\n},\n\"language\": \"en\",\n\"classifications\": [\n{\n\"confidence\": 0.564849,\n\"class_name\": \"excited\"\n},\n{\n\"confidence\": 0.355816,\n\"class_name\": \"satisfied\"\n},\n{\n\"confidence\": 0.126127,\n\"class_name\": \"polite\"\n},\n{\n\"confidence\": 0.026995,\n\"class_name\": \"sympathetic\"\n},\n{\n\"confidence\": 0.012211,\n\"class_name\": \"frustrated\"\n},\n{\n\"confidence\": 0.011065,\n\"class_name\": \"sad\"\n},\n{\n\"confidence\": 0.000872,\n\"class_name\": \"impolite\"\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n Migrating from Watson Tone Analyzer Customer Engagement endpoint to Natural Language Understanding \n\nYou can migrate your [Watson Tone Analyzer customer-engagement](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-utco) analysis requests to Natural Language Understanding. This can help you better understand your interactions with customers and improve your communications generally, or for specific customers.\n\n\n\n Reformatting your input data \n\nIn Watson Tone Analyzer, you pass the \/v3\/tone_chat method a JSON ToneChatInput object consisting of utterances, text, and an optional user string fields. For Natural Language Understanding, you pass a JSON object that contains text to be analyzed, and a language-specific model classification ID, to the \/v1\/analyze method.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics"},{"document_id":"ibmcld_16364-199341-201521","score":16.183407,"text":"\nAnd the links between nodes are represented in a way that makes it easier to understand the relationships between the nodes.\n\n\n\n\n\n 21 June 2017 \n\nArabic support\n: Language support for Arabic is now generally available. For details, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\nLanguage updates\n: The Watson Assistant service algorithms have been updated to improve overall language support. See the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_09919-9389-11561","score":15.801385,"text":"\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics\n: [Tone analytics](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) is now available, for English and French languages only. The tone analytics feature detects excited, frustrated, impolite, polite, sad, satisfied, and sympathetic tones from text.\n\n\n\n\n\n 12 October 2021 \n\nKeyword and syntax support for additional languages\n: Support for keywords and syntax is now available, for all public and premium service instances, for the following languages: Hindi, Romanian, and Turkish. In addition, syntax is available for all supported languages. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\n\n\n\n\n 15 August 2021 \n\nCustom classification feature\n: The [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) feature is now generally available (GA).\n\nCategories stock model updated\n: The [categories stock model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy) has been updated to use the [IAB Tech Lab 2.0 taxonomy](https:\/\/iabtechlab.com\/standards\/content-taxonomy\/).\n\n\n\n\n\n 5 May 2021 \n\nAdvanced Rules beta feature deprecated\n: The advanced rules beta feature is deprecated. As of June 10, 2021, you will not be able to deploy advanced rules models to Natural Language Understanding; existing models will keep running. After June 24, 2021, no advanced rules models will run in Natural Language Understanding.\n\n\n\n\n\n 25 March 2021 \n\nCustom classifications beta feature","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08197-0-402","score":15.700273,"text":"\n\n\n\n\n\n\n  Supported browsers \n\nFor a list of supported browsers, see [Required Browsers for IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor Safari, clear the options Prevent cross-site tracking and Block all cookies under Safari > Preferences > Privacy.\n\nIf you encounter problems when you use these browsers, disable your browser plug-ins.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-help-support-browsers"},{"document_id":"ibmcld_13167-13903-15855","score":15.170994,"text":"\nLeave the field for Service account as is to go with the default.\n* Finish by clicking Continue.\n\n\n\n5. Next, click on Access policy. In the list of services, select All Identity and Access enabled services and click Next. Go with All resources, click Next again, then select Viewer, and again click on Next. In the section Roles and actions, select Reader for Service access and Viewer for Platform access. When done, click Next and finally Add.\n6. Review the Summary on the right side, then Create the trusted profile with the shown trust relationship and the listed access privileges. Leave the browser tab open for later.\n\n\n\n[Utilizing an access group to assign access is best practices](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setuplimit-policies). For the sake of simplicity, we opted for assigning read-only access through a direct access policy. The recommendation is to create an access group with assigned privileges, then make the trusted profile a member of it.\n\n\n\n\n\n Step 4: Deploy the app \n\nWith the Kubernetes cluster and the trusted profile in place, it is time to deploy a simple test app. The source code for the app and the configuration is in the [GitHub repository trusted-profile-enterprise-security](https:\/\/github.com\/IBM-Cloud\/trusted-profile-enterprise-security) You don't need it for the deployment, but might be interested in how it works nonetheless.\n\n\n\n1. In the browser tab cluster overview, check that the cluster has been fully deployed. You might want to refresh the browser and check that all checkmarks are green. If this is the case, click on Kubernetes dashboard and a new browser tab opens (Kubernetes dashboard).\n2. In the top left, find the namespace selector and switch to All namespaces.\n3. On the upper right, click on + to create a new resource. Paste the following content into the text form Create from input.\n\napiVersion: v1\nkind: Namespace\nmetadata:\nname: tptest\nlabels:\nname: tptest\n---","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-trusted-profile-for-enterprise-security"},{"document_id":"ibmcld_16306-2449-4025","score":14.27021,"text":"\nFor more information, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid). \n Slack The Slack member ID (for example, U2147483697). \n Facebook The Facebook sender ID (for example, 4310101122439797). \n Whatsapp The customer's phone number. \n Phone The customer's phone number. \n SMS with Twilio The customer's phone number. \n\n\n\n\n\n\n\n\n\n chat \n\nIncluded only if the web chat integration is in use.\n\n\n\n Properties \n\n\n\nProperties of the chat object\n\n Name Type Description \n\n browser_info.browser_name String The browser name, such as chrome, edge, or firefox. \n browser_info.browser_version String The browser version, such as 109.0.0. \n browser_info.browser_OS String The operating system of the customer's computer, such as Mac OS. \n browser_info.language String The default locale code of the browser, such as en-US. \n browser_info.page_url String The URL of the web page where the web chat is embedded, not including any query parameters or hashes. \n browser_info.screen_resolution String The height and width of the browser window, such as width: 1440, height: 900. \n browser_info.user_agent String The content of the HTTP User-Agent request header. \n browser_info.client_ip_address String The IP address of the customer's computer. \n browser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_07578-7341-9464","score":14.221876,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-7341-9464","score":14.221876,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09581-6148-7096","score":13.884376,"text":"\nIf you want to run your application or access the end point from a browser that is not on the private network, you must take these additional steps:\n\n\n\n* Ensure your Cloud IaaS or SL account is [enabled for private endpoints](https:\/\/cloud.ibm.com\/docs\/account?topic=account-service-endpoints-overview).\n* Create a virtual machine (VSI) that runs Linux\n* Configure a user account with SSH access\n* From your workstation, run ssh -D 2345 user@vsi-host This starts an SSH session and open a SOCKS proxy on port 2345 that forwards all traffic through the VSI\n* Configure your browser or application to use a SOCKS5 proxy on localhost:2345\n* Run your application or open the preferred private-endpoint in your browser (for example, a management UI).\n\n\n\n\n\n\n\n Using Virtual Private Endpoints \n\nReview the IBM Cloud\u00ae Databases [documentation on Virtual Private Endpoints (VPEs) here](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-vpes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-service-endpoints"},{"document_id":"ibmcld_04229-7-2195","score":13.467221,"text":"\nWorking with Edge functions \n\nIBM Cloud\u00ae Internet Services Edge functions allow you to create or modify existing applications, without having to configure or maintain infrastructure, by using a serverless execution environment. Edge functions can be defined and uploaded to the Cloud edge to process requests before they reach the origin. CIS Edge functions can be used to modify HTTP requests and responses, make parallel requests, or generate responses from the Cloud edge.\n\n\n\n How Edge functions work \n\nEdge functions associates actions with URIs based on a defined domain. This association is called a trigger. Incoming requests to your site are intercepted at the Cloud edge and matched against the triggers in your account or domain. If the request URL matches the trigger's URI, the action associated with the trigger is run.\n\nEdge functions are modeled on the [Service Worker API](https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/API\/Service_Worker_API) available in modern web browsers, and use the same API whenever possible.\n\nThe Service Worker API allows you to intercept any request that is made to your site. After your JavaScript is handling the request, you can elect to make any number of subrequests to your site or others, and finally return a response to your visitor.\n\nUnlike standard service workers, Edge functions run on CIS edge servers, not in the user\u2019s browser. That means you can trust that your code runs in a trusted environment where it cannot be bypassed by malicious clients. It also means that the user does not need to be using a modern browser that supports service workers \u2013 you can even intercept requests from API clients that aren't browsers.\n\nInternally, Edge functions use the same V8 JavaScript engine, which is used in the Chrome browser to run workers on our infrastructure. V8 dynamically compiles your JavaScript code into ultra-fast machine code, enhancing performance. This makes it possible for your code to run in microseconds, and for our edge server to run many thousands of scripts per second.\n\nWhile Edge functions does use V8, it does not use Node.js. The JavaScript APIs available to you inside workers are implemented by us directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-working-with-edge-functions"},{"document_id":"ibmcld_16306-3764-4754","score":12.854702,"text":"\nbrowser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",\n\"page_url\": \"https:\/\/us-south.assistant.watson.cloud.ibm.com\/crn%3Av1%3Abluemix%3Apublic%3Aconversation%3Aus-south%3Aa%2Fc41400d63d91741a749091dc63574c2c%3Ab696c1e5-7316-4fb0-a61c-664438397e91%3A%3A\/assistants\/e344fcfe-506c-449f-a182-ebdefe4356ad\/actions\/actions\/custom\/edit\/action_28584\",\n\"screen_resolution\": \"width: 1920, height: 1080\",\n\"user_agent\": \"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/109.0.0.0 Safari\/537.36\",\n\"client_ip_address\": \"65.191.135.254\",\n\"ip_address_list\": [\n\"65.191.135.254\",\n\" 104.99.56.143\",\n\"10.185.27.136\",\n\"172.30.226.64\"\n]\n}\n},\n\"channel\": {\n\"name\": \"Web chat\",\n\"private\": {\n\"user\": {\n\"id\": \"anonymous_IBMuid-727c0302-6fd7-4abb-b7ee-f06b4bf30e99\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_03418-4-2127","score":12.433531,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_16270-0-505","score":12.273066,"text":"\n\n\n\n\n\n\n  Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overviewweb-chat-architecture-browsers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-browser-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":15.217186,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":11.667901,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13761-1826-3662","score":10.246308,"text":"\nIn such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice. The second sample speaks the same text with the same voice but with the indicated style. A request that uses the <express-as> element fails if the style is not one of the supported values or is omitted from the element.\n\n\n\nTable 1. Speaking styles\n\n Style Example input text Audio sample \n\n cheerful \"Oh, that's good news. I am very happy for you!\" Your browser does not support the audio tag. \n \"<express-as style='cheerful'>Oh, that's good news. I am very happy for you!<\/express-as>\" Your browser does not support the audio tag. \n empathetic \"Oh, I'm sorry to hear that. I know how difficult that can be.\" Your browser does not support the audio tag. \n \"<express-as style='empathetic'>Oh, I'm sorry to hear that. I know how difficult that can be.<\/express-as>\" Your browser does not support the audio tag. \n neutral \"A five-alarm fire early this morning claimed the lives of more than a dozen residents.\" Your browser does not support the audio tag. \n \"<express-as style='neutral'>A five-alarm fire early this morning claimed the lives of more than a dozen residents.<\/express-as>\" Your browser does not support the audio tag. \n uncertain \"That's strange. Hmm, I don't know if I've seen this before.\" Your browser does not support the audio tag. \n \"<express-as style='uncertain'>That's strange.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_13443-7-2262","score":10.13662,"text":"\nKeyword spotting and word alternatives \n\nThe IBM Watson\u00ae Speech to Text service can identify user-specified keywords in its transcription results. It can also suggest alternative words that are acoustically similar to the words of a transcript. In both cases, the keywords and word alternatives must meet a user-specified level of confidence.\n\n\n\n Keyword spotting \n\nThe keywords and keywords_threshold parameters are supported only with previous-generation models, not with next-generation models.\n\nThe keyword spotting feature detects specified strings in a transcript. The service can spot the same keyword multiple times and report each occurrence. The service spots keywords only in the final results, not in interim results. By default, the service does no keyword spotting.\n\nTo use keyword spotting, you must specify both of the following parameters:\n\n\n\n* Use the keywords parameter to specify an array of strings to be spotted. The service spots no keywords if you omit the parameter or specify an empty array. A keyword string can include more than one token. For example, the keyword Speech to Text has three tokens. Keyword matching is case-insensitive, so Speech to Text is effectively equivalent to speech to text.\n\nFor US English, the service normalizes each keyword to match spoken versus written strings. For example, it normalizes numbers to match how they are spoken as opposed to written. For other languages, keywords must be specified as they are spoken.\n* Use the keywords_threshold parameter to specify a probability between 0.0 and 1.0 for a keyword match. The threshold indicates the lower bound for the level of confidence the service must have for a word to match the keyword. A keyword is spotted in the transcript only if its confidence is greater than or equal to the specified threshold.\n\nSpecifying a small threshold can potentially produce many matches. If you specify a threshold, you must also specify one or more keywords. Omit the parameter to return no matches.\n\n\n\nThe following limits apply to keyword spotting:\n\n\n\n* You can spot a maximum of 1000 keywords with a single request.\n* A single keyword can have a maximum length of 1024 characters. The maximum effective length for double-byte languages might be shorter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spotting"},{"document_id":"ibmcld_03353-8238-10149","score":9.740394,"text":"\n[Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03027-8135-10108","score":9.429412,"text":"\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_16364-192793-195089","score":8.995184,"text":"\nThe name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-21733-23882","score":8.779176,"text":"\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases).\n\nChanges to unrecognized requests algorithm\n: In Analyze, the Recognition page lets you view groups of similar unrecognized requests. You can use the requests as example phrases in new or existing actions to address questions and issues that aren't being answered by your assistant. With this release, the criteria for grouping the requests is relaxed for customers with lesser amounts of data. Also, the group names have been improved with better grammar and to be more representative of the requests. For more information, see [Use unrecognized requests to get action recommendations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 1 February 2023 \n\nActions templates updated with new design and new choices\n: The actions template catalog has a new design that lets you select multiple templates at the same time. It also has new and updated templates, including starter kits you can use with external services such as Google and HubSpot. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\n\n\n\n\n 26 January 2023 \n\nDisplay formats for variables\n: In Global settings for actions, Display formats lets you specify the display formats for variables that use date, time, numbers, currency, or percentages. You can also choose a default locale to use if one isn't provided by the client application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_13741-6046-8162","score":8.665439,"text":"\nYou can use the parameter to direct the service to spell out individual characters more slowly, in groups of one, two, or three characters. Use the parameter with the SSML <say-as> element to control how the characters of a string are synthesized. For more information, see [Specifying how strings are spelled out](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-paramsparams-spell-out-mode).\n\nThe spell_out_mode parameter is beta functionality that is supported only for German voices.\n\n\n\n\n\n Word timings \n\nWith the WebSocket interface, you can obtain timing information about the location of words in the audio that the service returns. Timing information is useful for synchronizing the input text and the audio.\n\nYou can use the SSML <mark> element to identify specific locations, such as word boundaries, in the audio. For languages other than Japanese, you can also request word timing information for all words of the input text. For more information, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n\n\n\n\n\n\n\n Using speech synthesis features with expressive neural voice \n\nWith expressive neural voices, the service supports additional features that modify how the text that you pass is synthesized into audio.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. You can embellish the voices' natural tendencies by indicating that all or some of the text is to emphasize a specific style: cheerful, empathetic, neutral, or uncertain. You use SSML to indicate the style and the text to which it is to be applied. For more information, see [Using speaking styles](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressivesyntheses-expressive-styles).\n\n\n\n\n\n Emphasizing interjections \n\nWhen you use expressive neural voices, the service automatically detects a collection of common interjections based on context.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-service-features"},{"document_id":"ibmcld_16251-8219-10227","score":8.643331,"text":"\nFor example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\n\n\n\n\n Using multilingual downloads for translation \n\nYou can enable the download of language data files, in CSV format, so you can translate training examples and assistant responses into other languages and use in other assistants.\n\nEach CSV file includes translatable_string data that you can use with a machine or human translation service.\n\nEach CSV file also includes id, resource_type, and locator data that Watson Assistant can use in another assistant to re-create your source assistant. You don't need to edit this information.\n\nThe overview of the multilingual process is:\n\n\n\n* [Enable multilingual download](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-enable): In your source assistant, enable multilingual download\n* [Translate content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-translate): Use the CSV files with a translation service\n* [Upload to language-specific assistants](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-multilingual-upload): In a destination assistant for another language, use the CSV files to upload translated training and responses\n\n\n\n\n\n Enabling multilingual download \n\nTo enable multilingual download:\n\n\n\n1. Open Assistant settings.\n2. In the Download\/Upload section, click Enable multilingual download.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03707-0-719","score":6.3099804,"text":"\n\n\n\n\n\n\n  Why can\u2019t I access details about my commitments? \n\nYou are unable to view your account's commitments and subscriptions in the IBM Cloud\u00ae console.\n\n  What\u2019s happening \n\nYou try to view the Commitments and Subscriptions page, but a message is displayed that says Looks like you don't have access to view this page.\n\n  Why it\u2019s happening \n\nYou don't have the correct access to view this information. To access this information, you need an access policy with the Viewer role or higher on the Billing account management service.\n\n  How to fix it \n\nContact your administrator for access. For more information, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) for more information.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-access-commit-page"},{"document_id":"ibmcld_13041-1336-3131","score":5.240571,"text":"\nCheck to be sure that you have the [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platform).\n2. In the IBM Cloud catalog, select App ID. The service configuration screen opens.\n3. Give your service instance a name, or use the preset name.\n4. Select your pricing plan and click Create.\n\n\n\nThat's it! You're ready to start configuring your application settings.\n\n\n\n\n\n Step 2: Configure a sample app \n\nYou can use one of the preconfigured sample apps to get familiar with working with the service.\n\nOut of the box, the sample apps are configured with two identity providers and the ability to review authentication. Sample apps are offered in iOS Swift, Android, Node.js, Java and Single-page application. If you don't see a language in which you feel comfortable working, don't worry! You can integrate App ID into your own application by using the provided APIs.\n\nTo build a sample app:\n\n\n\n1. Click Download Sample.\n2. Click on the language of your choice to download the sample. Don't see the language you're looking for? Don't worry! You can take advantage of App ID through the APIs.\n3. Be sure that you have the prerequisites installed or completed.\n4. Follow the Build & Run steps to set up your sample with App ID.\n5. Click Review Activity to see any authentication events that occurred. Any type of sign in creates an event that is visible on this page.\n6. Customize the sign in widget.\n\n\n\n1. Add an image such as a brand logo by clicking Select and browsing your local system for an image to upload.\n2. Choose a color scheme by either selecting one of the color options or specifying in a hex value.\n3. Change between web and mobile to see how the color scheme looks on each type of device.\n4. When you're happy with your choices, click Save Changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/appid?topic=appid-getting-started"},{"document_id":"ibmcld_01602-3776-5022","score":5.1865926,"text":"\n[View more](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew)03 April 2023 | Customize your private catalog and private products\n\nYou can enhance the appearance of your private catalog to match your brand by adding a custom banner image to your private catalogs. You can also make it easier for users to search for your products added to a private catalog by specifying a custom provider name. Adding a custom provider name for your private products can help users find them quickly by using the Provider filter in the catalog.\n\n29 March 2023 | Generate a report on the MFA status of account users\n\nUsers that don't meet MFA requirements leave your account vulnerable. You can now identify the users in your account that don't satisfy your MFA requirements.\n\n29 March 2023 | An extra layer of security for users that don't use MFA\n\nIBM recommends enabling multifactor authentication (MFA) for all users in your account, but some automation scenarios might require you to exclude specific users from your MFA requirement. For users that are excluded from MFA, you can make access more secure by disabling CLI logins with only a username and password. This way, you require an API key to log in to the CLI or users can log in with --sso.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account\/eu_hipaa_supported.html"},{"document_id":"ibmcld_12754-0-705","score":4.948921,"text":"\n\n\n\n\n\n\n  Why don't I see any results? \n\nYou've created a profile or a rule but don't see any results.\n\n  What\u2019s happening \n\nYou can't find the results for your new profile or rule in your account.\n\n  Why it\u2019s happening \n\nYou might not be able to view results for the following reasons:\n\n\n\n*  Your rule isn't associated with a specification or profile.\n*  Your attachment hasn't been evaluated yet.\n*  An error occurred during the scan.\n\n\n\n  How to fix it \n\nDepending on the reason, you might try one or more of the following options to resolve the issue.\n\n\n\n*  Verify that the attachment is created.\n*  Wait for the scan to run.\n*  Wait 24 hours for the next scan to run, or open a support ticket.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-ts-results"},{"document_id":"ibmcld_07578-569630-571594","score":4.892118,"text":"\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails. A password reset email is triggered, which remains active for 24 hours.\n* If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username with _srs at the end (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n* Will all my brand settings be carried over from the ResellOne reseller account?\n\n Will all my brand settings be carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-569584-571548","score":4.892118,"text":"\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails. A password reset email is triggered, which remains active for 24 hours.\n* If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username with _srs at the end (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n* Will all my brand settings be carried over from the ResellOne reseller account?\n\n Will all my brand settings be carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12601-0-1026","score":4.6100993,"text":"\n\n\n\n\n\n\n  Why can't I see the enterprise subscriptions? \n\n  What\u2019s happening \n\nWhen you go to view the Subscriptions page in the IBM Cloud\u00ae console from a child account, the following message is displayed:\n\n> Looks like you don't have permission to view subscription data for this account. Contact your account owner or administrator to request access.\n\nThe following message is displayed in the Billing section on your enterprise dashboard:\n\n> Looks like you don't have permission to view this information. Learn more about IAM access.\n\n  Why it\u2019s happening \n\nAccess to billing and payment information for future billing periods is restricted to users in the enterprise account. Users in a child account can't access billing and payment information, such as subscriptions, even if they previously had access in the account.\n\n  How to fix it \n\nTo view or manage billing, you need to be invited to the enterprise account and given access to the Billing service in that account. Contact the account owner to request access.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-viewsub-enterprise"},{"document_id":"ibmcld_16727-566812-568563","score":4.359257,"text":"\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact? \n\nIf you have questions, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns).\n* What if I don't want all domains transferred to a single account?\n\n What if I don't want all domains transferred to a single account? \n\nIf you want to have all your domains transferred to multiple accounts, ensure that all domains in your IBM account have the same registrant\/owner email address. If you do not perform this step, domains are moved into independent retail accounts.\n* What if I don't want to move to Hover?\n\n What if I don't want to move to Hover? \n\nIf you don\u2019t think Hover is a suitable option, and you\u2019d rather be set up with a reseller account, Tucows can migrate you to their OpenSRS reseller platform instead. To migrate your account to OpenSRS, reach out to [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns) by 1 October 2021. If you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-566858-568609","score":4.359257,"text":"\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact? \n\nIf you have questions, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns).\n* What if I don't want all domains transferred to a single account?\n\n What if I don't want all domains transferred to a single account? \n\nIf you want to have all your domains transferred to multiple accounts, ensure that all domains in your IBM account have the same registrant\/owner email address. If you do not perform this step, domains are moved into independent retail accounts.\n* What if I don't want to move to Hover?\n\n What if I don't want to move to Hover? \n\nIf you don\u2019t think Hover is a suitable option, and you\u2019d rather be set up with a reseller account, Tucows can migrate you to their OpenSRS reseller platform instead. To migrate your account to OpenSRS, reach out to [IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-gettinghelp-with-dns) by 1 October 2021. If you don\u2019t take action, your domains are automatically moved to Hover retail accounts.\n* By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account?\n\n By what date do I need to notify IBM to be switched to a Tucows\u2019 OpenSRS Reseller account? \n\nYou must notify IBM by 1 October 2021 to switch to a Tucows\u2019 OpenSRS Reseller account.\n* What happens if I don\u2019t respond to the email from Hover?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_02259-0-1260","score":4.3282137,"text":"\n\n\n\n\n\n\n  Why can't I manage a service ID that I created and previously had access to? \n\nIn the case that you aren't able to manage a service ID that you created in another user's account, you might need to check your assigned access.\n\n  What\u2019s happening \n\nYou don't have access to manage a service ID that you created in an account that you're not the owner of. You received an error message about not having the required access, but you used to be able to manage it.\n\n  Why it\u2019s happening \n\nIf you create a service ID in an account that you don't own, an administrator policy for that specific service ID is automatically generated for you only if you don't already have access to manage service IDs in the account. For example, if you are already assigned the Administrator role on the IAM Identity service, then a new policy is not automatically generated because you already have access. However, if the account administrator later revokes your access as an administrator on the IAM Identity service, then you can no longer manage the service IDs that you created in the account.\n\n  How to fix it \n\nRequest the correct level of access from the account administrator to manage all service IDs in the account or just the specific ones that you created.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-troubleshoot-serviceid-access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02998-8791-9815","score":21.927397,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_05171-4-2124","score":17.12512,"text":"\n{:step: data-tutorial-type=\"step\"} {:hide-dashboard: .hide-dashboard} {:apikey: data-credential-placeholder=\"apikey\"}\n\n\n\n Developing a web application \n\nThis tutorial shows you how to build a simple image gallery using IBM Cloud\u00ae Object Storage, bringing together many different concepts and practices key to web development.\n\nFrom beginning to end, building a web application covers a lot of different concepts and is a great way to introduce yourself to the features of IBM Cloud Object Storage. Your application uses IBM Cloud Object Storage for storage in a Node.js application that allows a user to upload and view JPEG image files.\n\n\n\n The Scenario \n\nThe scenario for this tutorial involves many moving parts:\n\n\n\n* A web server to host the web application\n* Use of the command line\n* A storage instance for the images in the gallery\n* A version control system integrated into continuous delivery\n* Client-side application bindings in both scripts and markup\n* Images to upload and display\n\n\n\nAnd if you are looking for all that in one package, this tutorial will provide a complete, start-to-finish, example for you. However, this instruction can only temporarily set aside principles of security and secure code. Web applications actually put into production require proper security, or they won't be suitable for possible visitors.\n\n\n\n\n\n Before you begin \n\nEnsure that you have what you need to start:\n\n\n\n* An account for the IBM Cloud Platform\n* Docker, as part of the IBM Cloud Developer Tools\n* Node.js\n* Git (both desktop and command line)\n\n\n\n\n\n Using the Command Line \n\nLet's start by opening a tool familiar to experienced developers, and a new best friend to those just getting started: the command line. For many, the graphic user interface (GUI) relegated your computer's command-line interface to second-class status. But now, it's time to bring it back (although the GUI isn't going away anytime soon, especially when we need to browse the web to download instructions for the command-line toolset).\n\nOpen a shell and create a directory. Change your own reference directory to the new one you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_03916-7-1838","score":16.949823,"text":"\nDeveloping applications \n\nAfter you install smart contracts (chaincode) and deploy your peer and ordering nodes, you are ready to develop client applications to transact with other members of your IBM Blockchain Platform network. Applications invoke the business logic contained in smart contracts to create, transfer, and update assets on the blockchain ledger. Use this page to learn how to use client applications to interact with networks from the IBM\u00ae Blockchain Platform console.\n\nTarget audience: This topic is designed for application developers who are interested in developing client apps for an IBM Blockchain Platform network, in Node.js, Go, or Java.\n\n\n\n Using the v2.4 Fabric Gateway peer service \n\nIBM Blockchain Platform v2.5.4 adds support for the v2.4 Hyperledger Fabric Gateway peer service, which introduces an updated model for developing applications. The v2.4 gateway peer model relocates node connection and transaction processing requirements from the client application to the v2.4 peer nodes. The [v2.4 Fabric Gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.4\/gateway.html) method therefore enables developers to focus on business solutions, without having to code gateway connection or transaction processing logic in client applications, as is required for earlier releases.\n\n\n\n Supported app development methods in Fabric v2.4 \n\nTo develop new applications for IBM Blockchain Platform v2.5.4, using the latest v2.4 Hyperledger Fabric Gateway peer service and API are recommended, as documented in [Running a Fabric Application](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.4\/write_first_app.html). However, for existing applications developed for IBM Blockchain Platform v2.5.2 and earlier, no migration is required\u2014 your existing applications will continue to run on v2.5.4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_03916-39203-41294","score":16.321554,"text":"\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('..\/identity\/user\/isabella\/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_05413-4562-6193","score":16.27435,"text":"\nNotice that your project is also selected for context, so all subsequent application-related commands are within the scope of this new sample project.\n\n\n\n\n\n Step 3: Creating a directory and source code \n\n\n\n1. Create a directory on your local workstation that is named myapp and navigate into it. In this directory, save all the files that are required to build the image and to run your app.\n\nmkdir myapp && cd myapp\n2. Create a file called server.js and copy the following source code into it.\n\nconst http = require('http');\n\nhttp.createServer(function (request, response) {\nresponse.writeHead(200, {'Content-Type': 'text\/plain'});\nresponse.end( \"Hello worldn\" );\n}).listen(8080);\n\nThis example uses Node.js. You can substitute code from any [supported runtime](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-plan-buildbuild-buildpack-strat).\n\n\n\n\n\n\n\n Step 4: Deploying your application \n\nPush your code to Code Engine by using the application create command. You must provide a name for your application and the location of the source code. The following example creates an application called myapp that uses the buildpack strategy and provides the location for the source code in the current directory (.).\n\nibmcloud ce app create --name myapp --build-source . --strategy buildpacks\n\nExample output\n\nCreating application 'myapp'...\nPackaging files to upload from source path '.'...\nSubmitting build run 'myapp-run-220999-210706331'...\nCreating image 'private.us.icr.io\/ce--6ef04-khxrbwa0lci\/app-myapp:220418-0207-askql'...\nWaiting for build run to complete...\nBuild run status: 'Running'\nBuild run completed successfully.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-migrate-cf-ce-tutorial"},{"document_id":"ibmcld_03916-8219-9928","score":16.039307,"text":"\nThis tutorial focuses on using the High-level Fabric Gateway SDKs.\n\nIBM recommends the High-level Fabric Gateway SDKs which allow client applications to interact with IBM Blockchain Platform networks. These SDKs, available for Node, Java, and Go, allow a client application to invoke smart contracts for the purpose of submitting transactions and evaluating queries. It is recommended that administrative tasks, such as creating channels, deploying smart contracts, are done by using the console, APIs, or Ansible scripts.\n\nThe SDKs use the concept of a \"Gateway\" object to represent the connection of a single identity (user) to a blockchain network. For performance reasons, applications need to keep a gateway object instance in scope for as long as it is required, and can use it to submit multiple transactions across different smart contracts and network channels. If an application needs to handle multiple user identities, then a separate gateway object instance should be maintained for each identity.\n\nRefer to the SDK documentation for each language for details:\n\n\n\n* [Java](https:\/\/hyperledger.github.io\/fabric-gateway-java\/release-2.2\/)\n* [Node](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/)\n* [Go](https:\/\/pkg.go.dev\/github.com\/hyperledger\/fabric-sdk-go\/pkg\/gateway)\n\n\n\nFor best practices and examples of how to use the SDKs see the Fabric [Asset Transfer Sample](https:\/\/github.com\/hyperledger\/fabric-samples\/tree\/master\/asset-transfer-basic)\n\nFor information about migrating your applications created using the v1.4 SDK to the 2.x SDK, check out [Migrating client applications from v1.4 to v2.0](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/tutorial-migration.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_02953-3805-5544","score":15.929801,"text":"\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03916-46686-48366","score":15.850499,"text":"\nConnecting to your network by using low-level Fabric SDK APIs \n\nIf you are interested in preserving your existing application code, or by using Fabric SDKs for languages other than Node.js, you can still connect to your network by using lower-level Fabric SDK APIs. Use the console to [download your connection profile](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-profile). You can then import the endpoints of the peers and ordering nodes of your channel directly from the connection profile, or use the node endpoint information to manually add peer and orderer objects. You will also need to use your CA to [create an application identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-identities), and then use the CA endpoint information enroll on the client side, or generate certificates using your console.\n\nThe [Fabric Node SDK](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html) documentation provides a tutorial on how to [connect to your network using a connection profile](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/tutorial-commonconnectionprofile.html). The tutorial uses the CA endpoint information in your connection profile to generate keys using the SDK. You can also use your console to generate a signing certificate and private key and convert the keys into PEM format. You can then set a user context by passing your keys directly to the SDKs' [Fabric Client class](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/Client.html) using the following code:\n\nfabric_client.createUser({\nusername: 'admin',\nmspid: 'org1',\ncryptoContent: {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_16281-0-376","score":15.217346,"text":"\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-custom-app"},{"document_id":"ibmcld_02850-0-1147","score":14.922587,"text":"\n\n\n\n\n\n\n  Integrating with a custom application \n\nBuild your own client application as the interface between the assistant and your customers.\n\nTo use the API, you need to construct the URL to use in your requests.\n\n\n\n1.  From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2.  Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n\nYou might want to copy the bearer token also. You will need to pass the token when you make an API call.\n3.  From the launched application instance, go to the Assistants page. Click the More options menu for the assistant you want to use, and click Settings.\n4.  Click API details, and then copy the assistant ID. You will specify this value as the {assistant_id}.\n5.  Build a URL by using the IDs you copied. For example, the following request creates a session:\n\ncurl -H \"Authorization: Bearer eyJhb<snip>yA9g\" -X POST \"{url}\/v2\/assistants\/{assistant_id}\/sessions?version=2020-04-01 -k\"\n\n\n\n\n\n*  For API reference documentation, see [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v2).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10203-2544-4340","score":14.263598,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_05970-9976-11472","score":14.21632,"text":"\nIn this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Note that if you [create a DNS subdomain](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer_hostname) for your NLB, users can access your app through the NLB's subdomain instead. A DNS system service resolves the subdomain to the portable public IP address of the NLB.\n2. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address. The IPIP encapsulating packet uses the worker node 10.73.14.25 IP as its source IP address.\n3. The NLB routes the IPIP packet to a worker that an app pod is on and that has the private IP address 10.73.13.26. If multiple app instances are deployed in the cluster, the NLB routes the requests between the workers where app pods are deployed.\n4. Worker 10.73.14.26 unpacks the IPIP encapsulating packet, and then unpacks the client request packet. The client request packet is forwarded to the app pod on that worker node.\n5. Worker 10.73.14.26 then uses the source IP address from the original request packet, the client IP, to return the app pod's response packet directly to the client.\n\n\n\n\n\n\n\n Traffic flow in a multizone cluster \n\nThe following diagram shows how version 2.0 NLBs in each zone direct traffic from the internet to an app in a multizone cluster.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer-about"},{"document_id":"ibmcld_05970-11047-12722","score":13.981885,"text":"\nThe client request packet is forwarded to the app pod on that worker node.\n5. Worker 10.73.14.26 then uses the source IP address from the original request packet, the client IP, to return the app pod's response packet directly to the client.\n\n\n\n\n\n\n\n Traffic flow in a multizone cluster \n\nThe following diagram shows how version 2.0 NLBs in each zone direct traffic from the internet to an app in a multizone cluster.\n\nZoom\n\n![Expose an app in IBM Cloud Kubernetes Service by using an NLB 2.0](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_loadbalancer_ipvs_multizone.png)\n\nFigure 5. Expose an app in IBM Cloud Kubernetes Service by using an NLB 2.0\n\n\n\n1. A request to your app uses the [DNS subdomain](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer_hostname) for your NLBs. You can also access the NLB in each zone by using its public IP address and port on the worker node. Note that by default, each NLB 2.0 is set up in one zone only. To achieve high availability, you must deploy an NLB 2.0 in every zone where you have app instances.\n2. A DNS system service resolves the subdomain to the portable public IP address of one of the NLBs and its assigned port on the worker node. In this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Requests are handled by the NLBs in various zones in a round-robin cycle.\n3. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer-about"},{"document_id":"ibmcld_05970-12311-13510","score":13.907242,"text":"\nIn this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Requests are handled by the NLBs in various zones in a round-robin cycle.\n3. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address. The IPIP encapsulating packet uses the worker 10.73.14.25 IP as its source IP address.\n4. The NLB routes the IPIP packet to a worker that an app pod is on and that has the private IP address 10.73.13.26. Note that each NLB routes requests to the app instances in its own zone and to app instances in other zones. Additionally, if multiple app instances are deployed in one zone, the NLB routes the requests between the app pods in the zone.\n5. Worker 10.73.14.26 unpacks the IPIP encapsulating packet, and then unpacks the client request packet. The client request packet is forwarded to the app pod on that worker node.\n6. Worker 10.73.14.26 then uses the source IP address from the original request packet, the client IP, to return the app pod's response packet directly to the client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer-about"},{"document_id":"ibmcld_08357-12759-14528","score":13.569611,"text":"\nvpc_worker_dns_domain IBM Cloud DNS Services domain name to be used for the compute cluster, for example, \"test.example.corp\". No dnsworker.com \n vpn_enabled Set the value as true to deploy a VPN gateway for VPC in the cluster. No false \n vpn_peer_address The peer public IP address to which the VPN is connected. No _NOT_SET_ \n vpn_peer_cidrs Comma-separated list of peer CIDRs (for example, 192.168.0.0\/24) to which the VPN is connected. No _NOT_SET_ \n vpn_preshared_key The pre-shared key for the VPN No _NOT_SET_ \n windows_image_name Name of the custom image that you want to use to create Windows\u00ae virtual server instances in your IBM Cloud account to deploy the IBM Spectrum Symphony cluster. By default, the solution uses a base image with additional software packages, which are mentioned [here](https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphonycreate-custom-image). If you want to include your application-specific binary files, follow the instructions in [Planning for custom images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-images) to create your own custom image and use that to build the IBM Spectrum Symphony cluster through this offering. No hpcc-sym731-win2016-10oct22-v1 \n windows_worker_node Set to true to deploy Windows\u00ae worker nodes in the cluster. By default, the cluster deploys Linux\u00ae worker nodes. If the variable is set to true, the values of both worker_node_min_count and worker_node_max_count should be equal because the current implementation doesn't support dynamic creation of worker nodes through Host Factory. No false \n worker_node_instance_type Specify the virtual server instance or bare metal server profile type name to be used to create the worker nodes for the Spectrum Symphony cluster based on worker_node_type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-deployment-values"},{"document_id":"ibmcld_13149-4008-5969","score":13.460538,"text":"\n* For Kubernetes on Classic infrastructure see reference documentation [Creating classic cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui).\n* Choose a resource group.\n* Uncheck all zones except one.\n* Scale down to 1 Worker nodes per zone.\n* Choose the smallest Worker Pool flavor.\n* Enter a Cluster name.\n* Click Create.\n\n\n\n\n\n\n\n Step 2: Clone a sample application \n\nIn this section, you will clone a GitHub repo with a simple Helm-based [NodeJS](https:\/\/nodejs.dev) sample application with a landing page and two endpoints to get started. You can always extend the sample application based on your requirement.\n\n\n\n1. On a terminal, run the below command to clone the [GitHub repository](https:\/\/github.com\/IBM-Cloud\/kubernetes-node-app\/) to your machine:\n\ngit clone https:\/\/github.com\/IBM-Cloud\/kubernetes-node-app\n2. Change to the application directory:\n\ncd kubernetes-node-app\n\n\n\nThis sample application code contains all the necessary configuration files for local development and deployment to Kubernetes.\n\n\n\n\n\n Step 3: Deploy application to cluster using helm chart \n\n\n\n Deploy the application with Helm 3 \n\nThe container image for the application as already been built and pushed to a public Container Registry. In this section you will deploy the sample application using [Helm](https:\/\/helm.sh\/). Helm helps you manage Kubernetes applications through Helm Charts, which helps define, install, and upgrade even the most complex Kubernetes application.\n\nNote: If you want to build and push the application to your own container registry you can use the Docker CLI to do so. The Dockerfile is provided in the repository and images can be pushed to the Container Registry or any other container registry.\n\n\n\n1. Define an environment variable named MYAPP and set the name of the application by replacing the placeholder with your initials:\n\nexport MYAPP=<your-initials>kubenodeapp\n2. Identify your cluster:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-kubernetes"},{"document_id":"ibmcld_05838-25355-26994","score":13.421612,"text":"\nThe Autorecovery system uses various checks to query worker node health status. If Autorecovery detects an unhealthy worker node based on the configured checks, Autorecovery triggers a corrective action like rebooting a VPC worker node or reloading the operating system in a classic worker node. Only one worker node undergoes a corrective action at a time. The worker node must complete the corrective action before any other worker node undergoes a corrective action. For more information, see this [Autorecovery blog post](https:\/\/www.ibm.com\/cloud\/blog\/autorecovery-utilizes-consistent-hashing-high-availability).\n\nAutorecovery requires at least one healthy worker node to function properly. Configure Autorecovery with active checks only in clusters with two or more worker nodes.\n\nBefore you begin:\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms):\n\n\n\n* Administrator platform access role for the cluster\n* Writer or Manager service access role for the kube-system namespace\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo configure Autorecovery:\n\n\n\n1. [Follow the instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-helminstall_v3) to install the Helm version 3 client on your local machine.\n2. Create a configuration map file that defines your checks in JSON format. For example, the following YAML file defines three checks: an HTTP check and two Kubernetes API server checks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_10361-11892-13498","score":13.381318,"text":"\nYou can also access the NLB in each zone by using its public IP address and port on the worker node. Note that by default, each NLB 2.0 is set up in one zone only. To achieve high availability, you must deploy an NLB 2.0 in every zone where you have app instances.\n2. A DNS system service resolves the subdomain to the portable public IP address of one of the NLBs and its assigned port on the worker node. In this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Requests are handled by the NLBs in various zones in a round-robin cycle.\n3. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address. The IPIP encapsulating packet uses the worker 10.73.14.25 IP as its source IP address.\n4. The NLB routes the IPIP packet to a worker that an app pod is on and that has the private IP address 10.73.13.26. Note that each NLB routes requests to the app instances in its own zone and to app instances in other zones. Additionally, if multiple app instances are deployed in one zone, the NLB routes the requests between the app pods in the zone.\n5. Worker 10.73.14.26 unpacks the IPIP encapsulating packet, and then unpacks the client request packet. The client request packet is forwarded to the app pod on that worker node.\n6. Worker 10.73.14.26 then uses the source IP address from the original request packet, the client IP, to return the app pod's response packet directly to the client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer-about"},{"document_id":"ibmcld_05967-15142-16962","score":13.329367,"text":"\nIf no app pod exists on the same worker node as the load balancer service pod, the NLB forwards the request to a different worker node. The source IP address of the package is changed to the public IP address of the worker node where the load balancer service pod runs.\n\nTo preserve the original source IP address of the client request, you can [enable source IP](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/preserving-the-client-source-ip) for load balancer services. The TCP connection continues all the way to the app pods so that the app can see the actual source IP address of the initiator. Preserving the client\u2019s IP is useful, for example, when app servers have to apply security and access-control policies.\n\nAfter you enable the source IP, load balancer service pods must forward requests to app pods that are deployed to the same worker node only. Typically, load balancer service pods are also deployed to the worker nodes that the app pods are deployed to. However, some situations exist where the load balancer pods and app pods might not be scheduled onto the same worker node:\n\n\n\n* You have edge nodes that are tainted so that only load balancer service pods can deploy to them. App pods are not permitted to deploy to those nodes.\n* Your cluster is connected to multiple public or private VLANs, and your app pods might deploy to worker nodes that are connected only to one VLAN. Load balancer service pods might not deploy to those worker nodes because the NLB IP address is connected to a different VLAN than the worker nodes.\n\n\n\nTo force your app to deploy to specific worker nodes where load balancer service pods can also deploy to, you must add affinity rules and tolerations to your app deployment.\n\n\n\n Adding edge node affinity rules and tolerations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer"},{"document_id":"ibmcld_10361-9547-11111","score":13.256984,"text":"\n[Expose an app in Red Hat OpenShift on IBM Cloud by using a version 2.0 NLB](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/cs_loadbalancer_ipvs_planning.png)\n\nFigure 4. Expose an app in Red Hat OpenShift on IBM Cloud by using a version 2.0 NLB\n\n\n\n1. A client request to your app uses the public IP address of your NLB and the assigned port on the worker node. In this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Note that if you [create a DNS subdomain](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer_hostname) for your NLB, users can access your app through the NLB's subdomain instead. A DNS system service resolves the subdomain to the portable public IP address of the NLB.\n2. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address. The IPIP encapsulating packet uses the worker node 10.73.14.25 IP as its source IP address.\n3. The NLB routes the IPIP packet to a worker that an app pod is on and that has the private IP address 10.73.13.26. If multiple app instances are deployed in the cluster, the NLB routes the requests between the workers where app pods are deployed.\n4. Worker 10.73.14.26 unpacks the IPIP encapsulating packet, and then unpacks the client request packet. The client request packet is forwarded to the app pod on that worker node.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13206-2553-4129","score":14.860417,"text":"\nIBM Cloud VPC concepts and the networking constructs are explained in the [VPC pages of the IBM Cloud\u2122 Docs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). More information about planning and deploying bare metal servers on VPC can be found in the [Bare metal server section of IBM Cloud VPC pages](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n\n\n\n Objectives \n\n\n\n* Understand the Virtual Private Cloud infrastructure used for VMware vSphere deployment.\n* Create a IBM Cloud VPC, subnets and bare metal server instances for a vSphere deployment.\n* Manually deploy vCenter and create a compute cluster.\n* Create shared storage for your compute cluster either by using vSAN or VPC file share (NFS).\n* Use IBM Cloud VPC networking for your VMware Virtual Machines.\n\n\n\nThe following diagram presents an overview of the base deployment in IBM Cloud VPC. The deployment is based on IBM Cloud\u00ae Bare Metal Servers for Virtual Private Cloud and uses [subnets](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpc) to host the servers' network interfaces and [access control lists and security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc) to secure the network access. VMware vSAN with local ESXi host embedded SSDs or IBM Cloud VPC file share are the storage options for datastores to be used for VMware Virtual Machines. IBM Cloud VPC subnets can also be used to host network interfaces of VMware Virtual machines. Alternatively NSX-T can be used for Virtual Machines, but this is not mandatory.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware"},{"document_id":"ibmcld_13206-1130-3047","score":12.064351,"text":"\n[IBM Cloud Bare Metal Servers for Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers) environment provide a new option to deploy VMware on IBM Cloud. Currently the IBM Cloud VPC environment provides only the automated vSphere Hypervisor (ESXi) Operating System image deployment to Intel Bare Metals on VPC. Therefore, you need to manually install and configure the required VMware components, such as ESXi hosts, vCenter, vSAN or NSX-T components.\n\nThis tutorial walks you through creating your own IBM Cloud VPC with multiple subnets as required to support vSphere networking and the provisioning of IBM Cloud Bare Metal Servers for Virtual Private Cloud (BMS) for a basic VMware vSphere deployment. After the IBM Cloud VPC and Bare Metal Servers for VPC have been provisioned, the tutorial covers a manual deployment of the vCenter, creating VMware compute cluster with vSAN or NFS shared storage options. The tutorial also covers optional features, such as using IBM Cloud VPC network for VMware Virtual Machine networking.\n\nThis tutorial assumes a working knowledge of VMware vSphere Hypervisor and vCenter Server 7.0 as well as IBM Cloud zones, regions, prefixes, subnets and security groups that build the base IBM Cloud VPC networking and are used to support the vSphere deployment. More information about VMware products can be found in [VMware Docs](https:\/\/docs.vmware.com). IBM Cloud VPC concepts and the networking constructs are explained in the [VPC pages of the IBM Cloud\u2122 Docs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). More information about planning and deploying bare metal servers on VPC can be found in the [Bare metal server section of IBM Cloud VPC pages](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-for-bare-metal-servers).\n\n\n\n Objectives \n\n\n\n* Understand the Virtual Private Cloud infrastructure used for VMware vSphere deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware"},{"document_id":"ibmcld_11554-13102-14857","score":10.049315,"text":"\nDNS records](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/sap-terraform-ha-dns.png)\n\nFigure 6. DNS records\n\n\n\n\n\n\n\n 2. Highly available system for SAP HANA database \n\nZoom\n\n![Figure 7. SAP HA for HANA DB instances cluster nodes Primary (Active) and Secondary (Passive)](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f89cc64b006ca59b35404693959c83d5747fee3e\/sap\/images\/sap-ha-hana-vpc-single-zone.svg)\n\nFigure 2. SAP HA for HANA DB instances cluster nodes Primary (Active) and Secondary (Passive)\n\nAt the most basic level, a standard HA HANA cluster in an active-passive configuration has two nodes: one is the primary node and the other is the standby node. This simply means that the primary node is actively serving the active SAP instances (PAS and AAS), while the standby node is waiting to jump in if there is a failure.\n\nThe cluster is set with a virtual hostname IP (hostname is mapped to the FQDN of the HANA ALB through DNS, which is the same as explained previously for SAP ASCS and ERS instances). App instances (PAS and AAS), these are the details to be used on the SAP profiles to call that particular component. The cluster assigns that virtual IP to the active node and uses a heartbeat monitor to confirm the availability of the components. If the primary node stops responding, it triggers the automatic failover mechanism that calls the standby node to step up to become the primary node. The ALB detects the change, redirects the traffic to the new active node, and assigns the virtual IP to it, restoring the component availability. After the failed node is fixed, it comes online as a standby node.\n\n\n\n Synchronous on disk (sync) HANA database replication mechanism supported by SAP","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"},{"document_id":"ibmcld_05653-261467-263039","score":9.7567425,"text":"\n: Removed all [virtual machine worker node flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) that are 48 or more cores. You can still provision [bare metal worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) with 48 or more cores.\n\n\n\n\n\n 8 May 2019 \n\nAPI\n: Added a link to the [global API swagger docs](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/).\n\nCloud Object Storage\n: [Added a troubleshooting guide for Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cos_pvc_pending) in your IBM Cloud Kubernetes Service clusters.\n\nKubernetes strategy\n: Added a topic about [What knowledge and technical skills are good to have before I move my apps to IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyknowledge).\n\nKubernetes version 1.14\n: Added that the [Kubernetes 1.14 release](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive) is certified.\n\nReference topics\n: Updated information for various service binding, logging, and nlb operations in the [user access](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) and [CLI reference](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli) pages.\n\n\n\n\n\n 7 May 2019 \n\nCluster DNS provider\n: [Explained the benefits of CoreDNS](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster_dns) now that clusters that run Kubernetes 1.14 and later support only CoreDNS.\n\nEdge nodes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_13200-11725-13301","score":9.110193,"text":"\nIn the next sections, you will use the script [test_provision.bash](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/test_provision.bash) to confirm that the servers have been provisioned successfully, are able (or not) to access the Internet and that the uploaded.sh script was correctly executed.\n\n\n\n\n\n\n\n Step 2: Using the IBM Cloud CLI and shell scripts \n\nThe IBM Cloud CLI provides commands to interact with all the resources you can create in the IBM Cloud. This section explains how to use these commands, but you are not going to create any resources. It is recommended to use Terraform to deploy full solutions.\n\n\n\n Before you begin \n\nInstall the command line (CLI) tools by [following these steps](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli)\n\n\n\n\n\n Provision virtual server instances and install software \n\nThe CLI has a [plugin for all VPC-related functionality](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference), including compute and network resources.\n\n\n\n1. Before working with VPC resources, set the current resource group and region:\n\nibmcloud target -g $TF_VAR_resource_group_name -r $TF_VAR_region\n2. To provision a virtual server instance, run the ibmcloud is create-instance CLI command. In [shared\/install.sh](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/shared\/install.sh) is the cloud-init file used to initialize the frontend and the backend servers. You can pass the script with the --user-data parameter like this:\n\nibmcloud is instance-create ... --user-data @shared\/install.sh\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-app-deploy"},{"document_id":"ibmcld_16029-10951-12763","score":9.065887,"text":"\nIn such cases, you can use the SSH connection to the server to upload files with scp and then execute scripts on the server with ssh. The scripts could also retrieve software installers from the Internet, or from your on-premise systems assuming you have established a connection [such as a VPN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-site2site-vpn) between your on-premise systems and the cloud.\n\nThe tutorial code contains a script named [uploaded.sh](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/shared\/uploaded.sh) which will be uploaded from your workstation to the virtual server instances (manually or through automation like Terraform and Ansible).\n\nIn the next sections, you will use the script [test_provision.bash](https:\/\/github.com\/IBM-Cloud\/vpc-tutorials\/blob\/master\/vpc-app-deploy\/test_provision.bash) to confirm that the servers have been provisioned successfully, are able (or not) to access the Internet and that the uploaded.sh script was correctly executed.\n\n\n\n\n\n\n\n Step 2: Using the IBM Cloud CLI and shell scripts \n\nThe IBM Cloud CLI provides commands to interact with all the resources you can create in the IBM Cloud. This section explains how to use these commands, but you are not going to create any resources. It is recommended to use Terraform to deploy full solutions.\n\n\n\n Before you begin \n\nInstall the command line (CLI) tools by [following these steps](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli)\n\n\n\n\n\n Provision virtual server instances and install software \n\nThe CLI has a [plugin for all VPC-related functionality](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference), including compute and network resources.\n\n\n\n1. Before working with VPC resources, set the current resource group and region:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-app-deploy"},{"document_id":"ibmcld_16127-2961-4817","score":8.988623,"text":"\nFor information about images for x86 processor architecture, see [x86 virtual server images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-images).\n\nWith a cloud-init enabled image, you can provide user data. In the User Data field on the order form, you can enter optional cloud-init user data for the server. For more information about user data and automation, see [User data](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-user-data).\n\nWhen using the IBM Hyper Protect Container Runtime image, container details are provided at instance creation through the contract, specified in the User Data field on the order form. Once the containers start, you can interact with the workload that is brought up on the containers. For more information, see [Contract](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_se).\n\nYou can access details about each operating system, such as the url for the operating system, by using the API call, [List all operating systems](https:\/\/cloud.ibm.com\/apidocs\/vpclist-operating-systems).\n\n\n\n\n\n Stock image naming conventions \n\nAll IBM-provided stock, public images are named by using the following convention:\n\nibm-<family>-<version>-<type>-<architecture>-<build>\n\nThe following example shows the image naming convention.\n\nibm-hyper-protect-container-runtime-1-0-s390x-11\n\nThe following list explains the variables that make up the components of the image name:\n\n\n\n* The leading prefix of ibm- is used for IBM-provided images. Custom images cannot be named with this prefix.\n* The family component provides the operating system family, such as redhat, debian or in this example hyper-protect.\n* The version component provides the operating system version, such as 18-04 for Ubuntu 18.04, or 1.0 for hyper-protect.\n* The type component provides the minimization level of the operating system image, such as minimal or full.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsabout-images"},{"document_id":"ibmcld_10392-234546-235908","score":8.619768,"text":"\n* [Security information for Red Hat OpenShift clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security).\n* [Accessing clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* [App networking options](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_network_planning) with comparisons of routes, NodePort, load balancers, and Ingress.\n* [Common app modification scenarios](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) for moving apps from community Kubernetes to Red Hat OpenShift.\n* Updated [pricing FAQ](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges) to explain the monthly license in more detail.\n* [Resizing and externally exposing the internal registry](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry).\n* Tutorial overview with links to tutorials.\n* [Using the internal registry in Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry).\n\n\n\nEntitled software\n: If you have licensed products from your [MyIBM.com](https:\/\/myibm.ibm.com) container software library, you can [set up your cluster to pull images from the entitled registry](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrysecret_entitled_software).\n\nscript update command","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_14903-1532-3376","score":8.603819,"text":"\nWindows Server 2019 Standard Edition with SQL Server 2019 Web Edition x86-64 \n\n\n\nFor information about images for IBM Z (s390x processor architecture), see [s390x virtual server images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsabout-images).\n\nWhen you order an instance, the images are cloud-init enabled to optimize creation times. With a cloud-init enabled image, you can provide user data. In the User Data field on the order form, you can enter optional cloud-init user data for the server. For more information about user data and automation, see [User data](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-user-data).\n\nYou can access details about each operating system, such as the url for the operating system, by using the API call, [List all operating systems](https:\/\/cloud.ibm.com\/apidocs\/vpclist-operating-systems).\n\n\n\n\n\n Stock image naming conventions \n\nAll IBM-provided stock, public images are named by using the following convention:\n\nibm-<family>-<version>-<type>-<architecture>-<build>\n\nFor example,\n\nibm-centos-7-6-minimal-amd64-2\n\nThe following list explains the variables that make up the components of the image name:\n\n\n\n* The leading prefix of ibm- is used for IBM-provided images. Custom images cannot be named with this prefix.\n* The family component provides the operating system family, such as redhat, debian or windows-server.\n* The version component provides the operating system version, such as 18-04 for Ubuntu 18.04, or 2012-r2 for Windows 2012 R2.\n* The type component provides the minimization level of the operating system image, such as minimal or full.\n* The architecture component provides the vCPU architecture that is supported by the operating system image, such as amd64.\n* The build component is a small, non-negative integer that is incremented each time a new build of the operating system is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-images&interface=ui"},{"document_id":"ibmcld_10056-9379-11260","score":8.486202,"text":"\nWhen you delete the PVC, only the PVC is deleted. The PV, the physical storage device in your IBM Cloud infrastructure account, and your data still exist. To reclaim the storage and use it in your cluster again, you must remove the PV and follow the steps for [using existing block storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storageexisting_block).\n* If you want the PV, the data, and your physical block storage device to be deleted when you delete the PVC, choose a storage class without retain.\n\n\n\n6. Choose if you want to be billed hourly or monthly. The default setting is hourly billing.\n\n\n\n\n\n\n\n Setting up encryption for Block Storage for Classic \n\nYou can set up encryption for Block Storage for Classic by using IBM Key Protect.\n\nThe following example explains how to create a service ID with the required access roles for Key Protect and your cluster. The credentials of this service ID are used to enable encryption for your Block Storage for Classic volumes.\n\nYou can enable encryption by creating a Kubernetes secret that uses your personal API key as long as you have the Reader service access role for your Key Protect instance as well as the Viewer platform access role and the Writer service access role for your cluster.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Make sure that you are assigned the Editor platform access role and the Writer service access role for Key Protect so that you can create your own root key that you use to encrypt your Block Storage for Classic instance. You can review your IAM access roles in the [IAM console](https:\/\/cloud.ibm.com\/iam). For more information about IAM roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05628-4-2149","score":16.731096,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Kubernetes cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Kubernetes clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Kubernetes master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location. For the best performance, select the metro location that is physically closest to you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui"},{"document_id":"ibmcld_10085-4-2104","score":16.545073,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Red Hat OpenShift cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Red Hat OpenShift master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classic"},{"document_id":"ibmcld_11889-0-903","score":15.851111,"text":"\n\n\n\n\n\n\n  Setting up cluster groups \n\nThe cluster group specifies all clusters that you want to include in the deployment of your Kubernetes resources. The clusters can run in your Satellite location or in IBM Cloud.\n\nIf you want to use the console to create Satellite configurations, you can create cluster groups as part of the configuration creation process. If you want to use the CLI to create Satellite configurations, you must create a cluster group first. Follow these steps to create a cluster group with the CLI:\n\n\n\n1.  List the clusters that are registered with the Satellite Config component and note their ID.\n\nibmcloud sat cluster ls\n2.  Add the cluster to your cluster group.\n\nibmcloud sat group attach --cluster <cluster_ID> --group <cluster_group_name>\n3.  Verify that your cluster is successfully added to your cluster group.\n\nibmcloud sat group get --group <cluster_group_name>\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig-groups"},{"document_id":"ibmcld_11805-7-2049","score":14.87509,"text":"\nRegistering clusters with Satellite Config \n\nClusters you create in your Satellite Location are automatically registered with Satellite Config. You can also manually register other clusters in the public cloud or your existing Red Hat OpenShift on IBM Cloud clusters with Satellite Config. Follow the steps to run the registration script in your cluster to set up the Satellite Config components and make the cluster visible in Satellite.\n\nAfter you complete these steps, the cluster can be added to a cluster group in your location and [subscribed to Satellite configurations](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satcon-manage-direct-upload). However, you must still use Red Hat OpenShift on IBM Cloud to manage the worker nodes for these clusters.\n\n\n\n1. Find the cluster in the public cloud that you want to attach to Satellite Config. To list available clusters, run ibmcloud oc cluster ls or go to the [Red Hat OpenShift cluster dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift).\n\nDo not manually register clusters created in a Satellite Location. These clusters are automatically registered with Satellite Config. Registering them again manually might cause issues in your Location or cluster.\n2. From the Satellite [Clusters](https:\/\/cloud.ibm.com\/satellite\/clusters) dashboard, click Register cluster.\n3. Enter the name of your cluster and click Register cluster. Registering a cluster creates an entry in the Satellite Config ConfigMap. However, your cluster cannot be subscribed to a Satellite configuration until you install the Satellite Config agent in your cluster.\n4. Copy the command that is displayed to you.\n5. [Log in to your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster) and run the command in your cluster. The command creates the razeedeploy project, custom resource definitions and RBAC policies on your cluster that are required to make your cluster visible to Satellite Config.\n\nExample output\n\nnamespace\/razeedeploy created","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-register-openshift-clusters"},{"document_id":"ibmcld_11878-6858-8628","score":14.684234,"text":"\nThe cluster can run in your Satellite location or in IBM Cloud. To add a cluster that runs in IBM Cloud, you must first [register the cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-cluster-register) with the Satellite Config component.\n\nibmcloud sat group attach --cluster CLUSTER [--cluster CLUSTER] --group GROUP [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--cluster, -c CLUSTER\n: Required. The cluster that you want to add to the cluster group. To list registered clusters, run ibmcloud sat cluster ls.\n\n--group, -g GROUP\n: Required. The name or ID of the cluster group where you want to add the cluster. To list available cluster groups, run ibmcloud sat group ls.\n\n-q\n: Optional. Do not show the message of the day or update reminders.\n\n\n\n\n\n Example \n\nibmcloud sat group attach --cluster mycluster --group mygroup\n\n\n\n\n\n\n\n ibmcloud sat group create \n\nCreate a cluster group. After you created the cluster group, you can subscribe the cluster group to a Satellite configuration.\n\nibmcloud sat group create --name NAME [--cluster CLUSTER] [-q]\n\n\n\n Minimum required permissions \n\nIBM Cloud IAM Editor platform role for the Cluster group resource in Satellite. For more information, see [Checking user permissions](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-iam-assign-accesschecking-perms).\n\n\n\n\n\n Command options \n\n--name NAME\n: Required. The name for the cluster group.\n\n--cluster, -c CLUSTER\n: Optional. The name or ID of a cluster that you want to add to the cluster group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-reference"},{"document_id":"ibmcld_05567-8586-10154","score":14.392088,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-8604-10172","score":14.392088,"text":"\nPATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.create \n POST\/v1\/clusters\/{idOrName}\/kms Create a key management service (KMS) provider configuration for a cluster. containers-kubernetes.cluster.create containers-kubernetes.account.update \n POST\/v1\/clusters\/{idOrName}\/services Bind an IBM Cloud service to a cluster. containers-kubernetes.cluster.update containers-kubernetes.service.create \n POST\/v1\/clusters\/{idOrName}\/usersubnets Add an existing user-managed subnet to a cluster. containers-kubernetes.cluster.operate containers-kubernetes.subnet.create \n POST\/v1\/clusters\/{idOrName}\/vlans\/{vlanId} Create an IBM Cloud infrastructure subnet and add it to an existing cluster. containers-kubernetes.cluster.create containers-kubernetes.vlan.create \n POST\/v1\/clusters\/{idOrName}\/webhooks Add a webhook to a cluster. containers-kubernetes.cluster.update containers-kubernetes.cluster.create \n POST\/v2\/applyRBACAndGetKubeconfig Apply IAM roles to the cluster, then retrieve the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n POST\/v2\/autoUpdateMaster Set the autoupdate status of the cluster master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_11913-27689-29304","score":14.181982,"text":"\nTo make sure that your cluster is registered with Satellite Config or to create groups, see [Setting up clusters to use with Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig).\n\nExample command to list cluster groups.\n\nibmcloud sat group ls\n\nExample command to list clusters.\n\nibmcloud oc cluster ls --provider satellite\n\nExample command to list Satellite services.\n\nibmcloud sat service ls --location <location>\n3. Assign your storage configuration to the cluster, group, or service that you retrieved earlier. For more information, see the ibmcloud sat storage assignment create[command](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-storage-assign-create).\n\nExample command to assign a configuration to a cluster group.\n\nibmcloud sat storage assignment create --group GROUP --config CONFIG --name NAME\n\nExample command to assign a configuration to a cluster.\n\nibmcloud sat storage assignment create --cluster CLUSTER --config CONFIG --name NAME\n\nExample command to assign a configuration to a service cluster.\n\nibmcloud sat storage assignment create --service-cluster-id CLUSTER --config CONFIG --name NAME\n4. Verify that your assignment is created.\n\nibmcloud sat storage assignment ls (--cluster CLUSTER | --config CONFIG | --location LOCATION | --service-cluster-id CLUSTER)\n\n\n\n\n\n\n\n Creating a storage assignment in the API \n\n\n\n1. Copy one of the following example requests.\n\nExample request to assign a [configuration to a cluster](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/satellite\/createAssignmentByCluster).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-odf-local"},{"document_id":"ibmcld_11907-15097-16712","score":14.181982,"text":"\nTo make sure that your cluster is registered with Satellite Config or to create groups, see [Setting up clusters to use with Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig).\n\nExample command to list cluster groups.\n\nibmcloud sat group ls\n\nExample command to list clusters.\n\nibmcloud oc cluster ls --provider satellite\n\nExample command to list Satellite services.\n\nibmcloud sat service ls --location <location>\n3. Assign your storage configuration to the cluster, group, or service that you retrieved earlier. For more information, see the ibmcloud sat storage assignment create[command](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-storage-assign-create).\n\nExample command to assign a configuration to a cluster group.\n\nibmcloud sat storage assignment create --group GROUP --config CONFIG --name NAME\n\nExample command to assign a configuration to a cluster.\n\nibmcloud sat storage assignment create --cluster CLUSTER --config CONFIG --name NAME\n\nExample command to assign a configuration to a service cluster.\n\nibmcloud sat storage assignment create --service-cluster-id CLUSTER --config CONFIG --name NAME\n4. Verify that your assignment is created.\n\nibmcloud sat storage assignment ls (--cluster CLUSTER | --config CONFIG | --location LOCATION | --service-cluster-id CLUSTER)\n\n\n\n\n\n\n\n Creating a storage assignment in the API \n\n\n\n1. Copy one of the following example requests.\n\nExample request to assign a [configuration to a cluster](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/satellite\/createAssignmentByCluster).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-local-volume-file"},{"document_id":"ibmcld_11912-7200-8815","score":14.181982,"text":"\nTo make sure that your cluster is registered with Satellite Config or to create groups, see [Setting up clusters to use with Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig).\n\nExample command to list cluster groups.\n\nibmcloud sat group ls\n\nExample command to list clusters.\n\nibmcloud oc cluster ls --provider satellite\n\nExample command to list Satellite services.\n\nibmcloud sat service ls --location <location>\n3. Assign your storage configuration to the cluster, group, or service that you retrieved earlier. For more information, see the ibmcloud sat storage assignment create[command](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-satellite-cli-referencecli-storage-assign-create).\n\nExample command to assign a configuration to a cluster group.\n\nibmcloud sat storage assignment create --group GROUP --config CONFIG --name NAME\n\nExample command to assign a configuration to a cluster.\n\nibmcloud sat storage assignment create --cluster CLUSTER --config CONFIG --name NAME\n\nExample command to assign a configuration to a service cluster.\n\nibmcloud sat storage assignment create --service-cluster-id CLUSTER --config CONFIG --name NAME\n4. Verify that your assignment is created.\n\nibmcloud sat storage assignment ls (--cluster CLUSTER | --config CONFIG | --location LOCATION | --service-cluster-id CLUSTER)\n\n\n\n\n\n\n\n Creating a storage assignment in the API \n\n\n\n1. Copy one of the following example requests.\n\nExample request to assign a [configuration to a cluster](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/satellite\/createAssignmentByCluster).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-netapp-trident"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12581-17606-19704","score":20.378082,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_16727-623510-625767","score":17.284412,"text":"\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-623552-625809","score":17.284412,"text":"\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12095-7-2147","score":16.96295,"text":"\nGeneral \n\nAnswers to common questions about the IBM Cloud Schematics are classified into following section.\n\n\n\n What is IBM Cloud Schematics and how does it work? \n\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n\n\n\n\n\n What is Infrastructure as Code? \n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n\n\n\n\n\n What am I charged for when I use Schematics? \n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faq"},{"document_id":"ibmcld_11997-5537-6386","score":16.808062,"text":"\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12095-1659-3450","score":16.783428,"text":"\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated. Use schematics or sch in your command.\n\n\n\n\n\n Does IBM Cloud Schematics support multiple Terraform provider versions? \n\nYes, IBM Cloud Schematics supports multiple Terraform provider versions. You need to add Terraform provider block with the right provider version. By default the provider run current version 1.21.0, and previous four versions such as 1.20.1, 1.20.0, 1.19.0, 1.18.0 are supported.\n\nExample for a multiple provider configuration:\n\nterraform{\nrequired_providers{\nibm = \">= 1.21.0\" \/\/ Error !! version unavailable.\nibm = \">= 1.20.0\" \/\/ Execute against latest version.\nibm = \"== 1.20.1\" \/\/ Executes version v1.20.1.\n}\n}\n\nCurrently, version 1.21.0 is released. For more information, see [provider version](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-setup_cliinstall_provider).\n\n\n\n\n\n How do I generate IAM access token, if client ID bx is used? \n\nTo create IAM access token, use export IBMCLOUD_API_KEY=<ibmcloud_api_key> and run the command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faq"},{"document_id":"ibmcld_12098-7-1814","score":15.850085,"text":"\nSoftware deployment in IBM Cloud Schematics \n\nTry out one of the IBM\u00ae provided software templates to quickly spin up a classic Virtual Server Instance (VSI), and automatically configure the instance to connect to an IBM Cloud\u00ae Databases for PostgreSQL instance.\n\nWith IBM Cloud Schematics, you can choose from a wide variety of [software and infrastructure templates](https:\/\/cloud.ibm.com\/catalogsoftware) that you can use to set up IBM Cloud services, and to install IBM and Third party software. The templates are applied by using the built-in Terraform, Ansible, Helm, CloudPak, and Operator capabilities in Schematics.\n\nAs part of this getting started tutorial, you create a Schematics Workspaces that points to the [VSI database](https:\/\/cloud.ibm.com\/catalogabout) template. Then, you run this template and watch Schematics provision your VSI and your IBM Cloud Databases for PostgreSQL instance. IBM Cloud Databases for PostgreSQL is a fully managed database offering in IBM Cloud that supports storing of non-relational and relational data types. For more information about this offering, see [What is PostgreSQL?](https:\/\/www.ibm.com\/cloud\/databases-for-postgresql).\n\nThis getting started tutorial incurs costs. You must have an [IBM Cloud Pay-As-You-Go or Subscription](https:\/\/cloud.ibm.com\/registration) account to proceed. Make sure that you review pricing information for [classic VSIs](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/provision\/vs) and [PostgreSQL](https:\/\/cloud.ibm.com\/databases\/databases-for-postgresql\/create).\n\n\n\n Before you begin \n\nBefore you can use this template, you must complete the following tasks.\n\n\n\n* Make sure that you have the permissions to [create classic virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-device-access).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-get-started-software"},{"document_id":"ibmcld_11997-4388-5975","score":15.460728,"text":"\n[Schematics Blueprints feature overview](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ba89e173287b28d1453d2a327d8a1f74ae2f1662\/schematics\/\/images\/new\/bp-features.svg)\n\nSchematics Blueprints feature overview\n\nSchematics Blueprints complements Terraform with IaC based environment management capabilities:\n\n\n\n* [Modular composition](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-terraform): Build infrastructure architectures from an eco-system of reusable IBM Cloud automation modules written in Terraform\n* [Scalability](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-scaling): Scale environments by linking discrete modular environments as the layers and components of large and complex application architectures using dependencies.\n* [Reusability](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-reuse): Share and reuse templates and modules across environments, pipelines and teams\n* [Lifecycle](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints): Manage environments cradle-to-grave, from initial creation, through maintenance and ops to final decommissioning.\n\n\n\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro"},{"document_id":"ibmcld_12321-7-1946","score":15.421537,"text":"\nSetting up continuous deployment with Schematics and DevOps toolchain \n\n\n\n Description \n\nIn this tutorial, you can learn to use your credentials and an API key to use a Terraform template of IBM Cloud\u00ae Object Storage in the Schematics Workspace. Then, you also learn to automate the continuous deployment by using DevOps delivery pipeline. As part of the tutorial, you use ibm_cos_bucket Terraform template example.\n\nThe ibm_cos_bucket example creates an instance of IBM Cloud Object Storage, IBM Cloud\u00ae Activity Tracker, and IBM Cloud\u00ae Monitoring.\n\nCosts are incurred based on your resource usage. For more information about the pricing, see [Pricing](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges). About the support and help, see [Schematics help](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-help).\n\n\n\n\n\n Objectives \n\nIn this tutorial, you can:\n\n\n\n* Explore an IBM provided Terraform template to create an IBM Cloud Object Storage instance that binds with the IBM resource instance, and IBM resource group.\n* Learn how to create an IBM Cloud Schematics Workspace.\n* Learn to automate continuous deployment of a resource by using IBM Cloud Schematics and DevOps toolchain.\n* Review the IBM Cloud resources that you create.\n\n\n\n\n\n\n\n Time needed \n\n1 hour\n\n\n\n\n\n Audience \n\nThis tutorial is intended for the developer and system administrators who want to learn how to use Terraform templates to create. And automate the continuous deployment of resource by using IBM Cloud Schematics and DevOps toolchain.\n\n\n\n\n\n Prerequisites \n\nAbout IBM Cloud Schematics\n\n[IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) is an IBM Cloud automation tool. It provides simplified provisioning, orchestrating Infrastructure as Code (IaC), templates, and managing IBM Cloud resources in your IBM Cloud environment by using various resources tools such as Terraform, Helm.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deployment"},{"document_id":"ibmcld_12610-7198-9624","score":15.306313,"text":"\nFor example, when a usage report is generated the project tags will be included, allowing the accounting team to allocate costs to projects without any additional effort. Other types of configuration management tasks such as determining an inventory of particular types of applications or resources can also be accomplished by project tagging and resource views.\n\n\n\n\n\n Essential concepts \n\nReview the following concepts and processes to help you learn about working with projects in your account.\n\n\n\n Configurations \n\nA single project typically manages configurations for one or more IaC templates called deployable architectures in IBM Cloud. The set of input values and the architecture that you are configuring together become a configuration. In addition to providing review and approval work flows, projects monitor each configuration for cost, compliance, and version updates from the catalog.\n\nTypically, a project holds several configurations of each architecture. An architecture might have separate configurations for the development, test, and production environments, or for three separate regions, all of which are in the production environment.\n\n\n\n\n\n Deployable architectures \n\nProjects provide governance and management for deployable architectures, which are infrastructure as code templates. [Custom deployable architectures can be developed](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-customize-from-catalog) by using the tooling of your choice and can be [added to a private catalog](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom) in the IBM Cloud console. You must select Deployable Architecture as the type of product that you are onboarding for it to be used with projects.\n\n\n\n\n\n Project tooling \n\nProjects have internal versioned configuration storage and validation pipelines to support project governance. Projects also leverage Schematics workspaces to store the Terraform state for each configuration and to run the automation. These workspaces are in the region and resource group that you specify when you create the project. The Schematics workspace is also tagged with the project name, making it easier to identify that workspace among other ones.\n\nDon't delete or directly modify these workspaces. This can cause projects to lose track of the configuration state that can lead to creation of duplicate resources and other issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-understanding-projects"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.687147516}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-1609-3779","score":22.292051,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_11408-13151-14243","score":19.298866,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_10116-16035-17814","score":18.822586,"text":"\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-8826-10757","score":18.23596,"text":"\nReview each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-3176-5101","score":18.177547,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-10237-12114","score":17.67616,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for Red Hat OpenShift on IBM Cloud clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11408-11687-13539","score":17.66908,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_05666-4707-6582","score":17.454422,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for IBM Cloud Kubernetes Service clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_14886-1801-3922","score":16.28505,"text":"\nBenefits \n\n\n\n BYOL \n\nRenting licenses can get expensive. Bringing your own license is an option for IBM Cloud Bare Metal Servers for VPC.\n\n\n\n\n\n Rapid scaling \n\nScale your dedicated, bare metal server environment for your needs quickly. Often, in 10 minutes or less when resources are available.\n\n\n\n\n\n Network orchestration \n\nA network orchestration layer handles the networking for all bare metal servers that are within an IBM Cloud VPC across regions and zones. Create multiple, virtual private clouds in multizone regions. Network orchestration also helps improve security, reduce latency, and increase high availability.\n\nYou are responsible for security on your bare metal server. That means upgrading or patching the operating system as needed to make sure that vulnerabilities are addressed in a timely manner. Bare metal servers with associated floating IP addresses are internet-facing and you need to take appropriate precautions. For more information, see [Understanding your responsibilities](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n\n\n\n\n\n\n\n Pricing options \n\nPay-as-you-go bandwidth is per gigabyte. Your billing charges accrue from provision to cancellation, and are billed in arrears. Total pricing includes bare metal server instance profiles and software, internet data transfers, and optional VPC services. Each additional component is priced separately and included as part of your total IBM Cloud VPC charge. Service tiers are bound to your account, not to any specific VPC.\n\nFor more information about pricing, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricingtab_2651670).\n\n\n\n\n\n Bare Metal Servers for VPC versus bare metal server on classic infrastructure \n\nWith Bare Metal Servers for VPC, you can enjoy the security and performance of the private cloud with the flexibility and scalability of the public cloud. Compared to the classic bare metal infrastructures, Bare Metal Servers for VPC provides better connectivity and networking throughput by using VPC concepts.\n\nBare Metal Servers for VPC has local NVMe, which you can use to create VMWare vSAN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers"},{"document_id":"ibmcld_07532-5547-6568","score":15.782439,"text":"\nSee the Event Notifications catalog page for current pricing.\n\n\n\n* As of 31 July, you create a pre-production destination and does not register any devices or send messages, the charges for July will be $15.\n* As of 1 August, you register 500 devices and 5001 messages sent. The charges for August will be $30 (This is due to the message threshold exceeds the permitted limit.)\n* As of 5 August, you change from pre-production destination to production destination. Then, the charges for August will be $30 plus pro-rata charges of consumption price, which will be equal to\n\nAmount charged = $30 + $ (50\/31) x (remaining number of days in the month) = $30 + [(50\/31) x 26] = $71.86.\n* If you create a pre-production destination on 1 August and do not register any devices and do not sent any message, but on 5th August change from pre-production destination to a production destination, then the charges will be:\n\nAmount charged = $15 + $ (50\/31) x (remaining number of days in the month) = $15 + [(50\/31) x 26] = $56.86.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-destinations-push"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-1609-3779","score":19.188263,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-7-2093","score":19.108875,"text":"\nPricing for IBM Blockchain Platform for IBM Cloud \n\nATTENTION!! IBM Blockchain Platform SaaS Edition is being replaced by IBM Support for Hyperledger Fabric!! IBM Blockchain Platform SaaS Edition will no longer be supported after July 31, 2023. Customers have been directed to migrate their networks by July 31, 2023. After this date, IBM Blockchain Platform SaaS networks that are not migrated to IBM Support for Hyperledger Fabric will be at risk for potential security vulnerabilities. A migration tool is provided from your console, and the disruption to your network is minimal. See [Migrating to IBM Support for Hyperledger Fabric](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-migrating-to-hlf-support) for details.\n\nThis guide helps you understand the pricing model for IBM\u00ae Blockchain Platform for IBM Cloud, and how much you will pay when you develop and grow your blockchain network of peers, ordering nodes, and Certificate Authorities components, which are based on Hyperledger Fabric v2.2.10.\n\n\n\n Pricing model \n\nIBM Blockchain Platform introduces a new hourly pricing model that is based on virtual processor core (VPC) allocation. This simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes are allocated on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour.\n\nA VPC is a unit of measurement that is used to determine the licensing cost of IBM products. It is based on the number of virtual cores (vCPUs) that are available to the product. A vCPU is a virtual core that is assigned to a virtual machine or a physical processor core. For IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_10116-13064-14929","score":18.963425,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Default storage for images \n\nTo store images in the internal registry, Red Hat OpenShift on IBM Cloud creates a storage instance that varies by infrastructure provider.\n\n\n\n* Classic clusters: A classic IBM Cloud File Storage for Classic volume is automatically created for you. Your file storage volume is provisioned with an ibmc-file-gold storage class of 100 GB capacity at 10 IOPS\/GB, and billed at an hourly rate. If you need more image storage capacity, you can [update the volume size](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry), which modifies the cost.\n* VPC clusters: A bucket in an existing IBM Cloud Object Storage instance is created for you. For more information, see [Billing and pricing in the Object Storage documentation](https:\/\/www.ibm.com\/cloud\/object-storage).\n\n\n\n\n\n\n\n Storage for apps \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-7536-9272","score":18.368309,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)\n* [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage)\n* [Portworx Enterprise pricing](https:\/\/cloud.ibm.com\/catalog\/services\/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_15111-1536-3423","score":18.176826,"text":"\nThe volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n\n\n\n\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_15034-5426-7253","score":17.93882,"text":"\nWhen you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"},{"document_id":"ibmcld_16727-871736-873537","score":17.886505,"text":"\nFor more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-871859-873660","score":17.886505,"text":"\nFor more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04031-10086-11557","score":17.641897,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_10544-0-2569","score":17.601402,"text":"\n\n\n\n\n\n\n  Storage class reference \n\nThe available storage classes correspond to the predefined File Storage for VPC profiles. For more information about the profiles and IOPs tiers, see [File Storage for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles).\n\nBy default, all File Storage for VPC devices are provisioned with an hourly billing type and endurance storage. If you choose a monthly billing type, when you remove the persistent storage, you still pay the monthly charge for it, even if you used it only for a short amount of time. If you want to keep your data, then choose a retain storage class. When you delete the PVC, only the PVC is deleted. The PV, the physical storage device in your IBM Cloud infrastructure account, and your data still exist. To reclaim the storage and use it in your cluster again, you must remove the PV and follow the steps for [using existing File Storage for VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-file-vpc-apps). If you want the PV, the data, and your physical File Storage for VPC device to be deleted when you delete the PVC, choose a storage class without retain\n\nStorage classes that have retain in the title have a reclaim policy of Retain. Example: ibmc-file-retain-bronze. Storage classes that don't have retain in the title have a reclaim policy of Delete. Example: ibmc-file-bronze.\n\n3 IOPS\n\n5 IOPS\n\n10 IOPS\n\n\n\n3 IOPS\n\n Characteristics          Setting                                                                           \n\n Name                     ibmc-vpc-file-3iops-tier  <br>ibmc-vpc-file-retain-3iops-tier                     \n Type                     Endurance storage                                                                 \n File system              NFS                                                                               \n IOPS per gigabyte        3                                                                                 \n Size range in gigabytes  20-12000 Gi                                                                       \n Hard disk                SSD                                                                               \n Reclaim policy           ibmc-vpc-file-3iops-tier: Delete  <br>ibmc-vpc-file-retain-3iops-tier: Retain     \n Billing                  Hourly                                                                            \n Pricing                  [Pricing information](https:\/\/cloud.ibm.com\/cloud-storage\/file\/order)                                                           \n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-file-vpc-sc-ref"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":28.449621,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":26.57926,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_16727-1079289-1081125","score":26.039698,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":26.039698,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01660-7085-8964","score":24.042477,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_12824-7-1978","score":23.910494,"text":"\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-migrated-products"},{"document_id":"ibmcld_11142-7-1829","score":23.329092,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_02660-1509-3609","score":23.162031,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_01705-11723-13541","score":22.787266,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_11142-1400-2265","score":22.770084,"text":"\nGo to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials \n\nCheck out our [tutorials for Lite plans](https:\/\/cloud.ibm.com\/docs?tab=tutorials&filters=lite-account) for detailed steps about using IBM Cloud services that provide free Lite plans for you to implement common patterns based on best practices and proven technologies at no cost.\n\n\n\n\n\n Next steps \n\nBuild your apps! For more information, see the [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-13208-15001","score":25.170448,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01705-14609-15453","score":24.30491,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-8584-10307","score":23.340298,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":23.295204,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":23.295204,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01660-7085-8964","score":22.71025,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-11723-13541","score":22.200481,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07578-1075256-1077185","score":21.636162,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":21.636162,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-4245-6093","score":20.897182,"text":"\nIn the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account. However, if you want to use the capabilities that are not available in a service's Lite plan, you must [upgrade the plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing) for the specific service. After you change a service plan, it might be necessary to restage your application.\n\n\n\n\n\n Can I convert my account? \n\nYes, the following options are available depending on your account type:\n\n\n\n* If you have a feature code from an online course or educational event, you can use it to convert your Lite account to a trial account. Go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code to your account.\n* To convert your Pay-As-You-Go account to a Subscription account, contact [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule).\n\n\n\n\n\n\n\n Can I convert my Pay-As-You-Go account to a trial account? \n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account.\n\n\n\n\n\n Can I add an educational feature code to an account after I have added a credit card? \n\nWhen you add a credit card to your trial account, your account is upgraded to a Pay-As-You-Go account. Educational feature codes can't be used in a Pay-As-You-Go account. In addition, a Pay-As-You-Go account can't be converted back to a trial account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.5012658353,"ndcg_cut_10":0.5012658353}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-7-1620","score":27.210909,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-8584-10307","score":26.797817,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":25.600668,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":25.600668,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01660-7085-8964","score":25.06172,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-11723-13541","score":22.907774,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07578-1075256-1077185","score":22.609133,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":22.609133,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11142-7-1829","score":22.153091,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_12824-7-1978","score":21.211332,"text":"\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-migrated-products"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04377-7-1819","score":14.432568,"text":"\nManaging accounts and users (ibmcloud account) \n\nUse the following commands from the IBM Cloud\u00ae Command Line Interface to manage accounts and users in an account.\n\n\n\n ibmcloud account orgs \n\nList all organizations:\n\nibmcloud account orgs [-r REGION_NAME] [--guid] [-c ACCOUNT_ID] [-u ACCOUNT_OWNER]\n\n\n\n Command options \n\n-r REGION_NAME\n: Region name. List the organizations in the region specified. Default to current region if not specified. If set to 'all', list the organizations in all regions.\n\n--guid\n: Display the guid of the organizations. This option is exclusive with --output.\n\n-c ACCOUNT_ID\n: Account ID. List the organizations under the account. Default to current account if not specified. If set to all, list organizations under all accounts. This option is exclusive with -u.\n\n-u ACCOUNT_OWNER\n: Account owner name. List the organizations under the accounts that are owned by the user. Default to current account if not specified. If set to 'all', list organizations under all accounts. This option is exclusive with -c.\n\n\n\n\n\n Examples \n\nList all the organizations in region us-south with the GUID displayed:\n\nibmcloud account orgs -r us-south --guid\n\nList all the organizations in JSON format:\n\nibmcloud account orgs --output JSON\n\n\n\n\n\n\n\n ibmcloud account org \n\nShow the information of the specified organization:\n\nibmcloud account org ORG_NAME [-r REGION] [--guid]\n\n\n\n Command options \n\nORG_NAME (required)\n: The name of the organization.\n\n-r REGION\n: Region name. If not specified, the default is current region. If set to all, orgs with the given name in all regions are listed.\n\n--guid\n: Retrieve and display the org's guid. All other output for the org is suppressed. This option is exclusive with --output.\n\n\n\n\n\n Examples \n\nShow the information of organization IBM with the GUID displayed:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_account"},{"document_id":"ibmcld_04488-133306-134586","score":13.861469,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_12571-27906-29494","score":13.486971,"text":"\nCreate service policy from JSON file for service ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976:\n\nibmcloud iam service-policy-create ServiceId-cb258cb9-8de3-4ac0-9aec-b2b2d27ac976 --file @policy.json\n\nGrant service test the Administrator role for all account management services:\n\nibmcloud iam service-policy-create test --roles Administrator --account-management\n\nGrant service test the Viewer role for all resources in account:\n\nibmcloud iam service-policy-create test --roles Viewer\n\nGrant service test the Viewer role and a custom role Responder for all sample service instances in account:\n\nibmcloud iam service-policy-create test --roles Viewer,Responder --service-name sample\n\nGive service test the Viewer role for service is resources with attribute instanceId equal to :\n\nibmcloud iam service-policy-create sample-service --roles Viewer --service-name is --attributes \"instanceId=\"\n\n\n\n\n\n\n\n ibmcloud iam service-policy-update \n\nUpdate an access policy for a service ID:\n\nibmcloud iam service-policy-update SERVICE_ID POLICY_ID {--file JSON_FILE | [-r, --roles ROLE_NAME1,ROLE_NAME2...] [--service-name SERVICE_NAME] [--service-instance SERVICE_INSTANCE_GUID] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID] [--account-management] [--attributes name=value,name=value...]} [--output FORMAT] [-q, --quiet] [-f, --force] [--api-version v1 | v2]\n\n\n\n Command options \n\nSERVICE_ID (required)\n: Name or UUID of service ID.\n\nPOLICY_ID (required)\n: ID of the service policy.\n\n--file","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"},{"document_id":"ibmcld_07476-8220-9755","score":13.42194,"text":"\nYou can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n\n\n\n\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n\n\n\n\n\n\n\n Specific FAQs (for 500 domains or more) \n\n\n\n Will all my brand settings be carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n\n\n\n\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.\n\n\n\n\n\n When can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username followed by _srs (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n\n\n\n\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-migration"},{"document_id":"ibmcld_04377-11298-12907","score":13.222221,"text":"\nibmcloud account org-account ORG_NAME [-r, --region REGION] [--guid]\n\n\n\n Command options \n\n-r (optional)\n: Region name. Default to current region if not specified.\n\n--guid (optional)\n: Display account ID only\n\n\n\n\n\n\n\n ibmcloud account show \n\nShow account details:\n\nibmcloud account show\n\n\n\n Examples \n\nShow details of currently targeted account:\n\nibmcloud account show\n\n\n\n\n\n\n\n ibmcloud account update \n\nUpdate a specific account:\n\nibmcloud account update (--service-endpoint-enable true | false)\n\n\n\n Command options \n\n--service-endpoint-enable true | false\n: Enable or disable service endpoints connectivity for a SoftLayer account.\n\n\n\n\n\n Examples \n\nEnable service endpoint connectivity for current account:\n\nibmcloud account update --service-endpoint-enable true\n\n\n\n\n\n\n\n Classic infrastructure account audit-logs \n\nList SoftLayer account audit logs:\n\naccount audit-logs [-u, --user-name USER_NAME] [-t, --object-type OBJECT_TYPE] [-o, --object OBJECT] [-a, --action ACTION] [-s, --start-date START_DATE] [-e, --end-date END_DATE]\n\n\n\n Command options \n\n-a, --action ACTION\n: Action. List audit logs with the action.\n\n-e, --end-date END_DATE\n: End date. List audit logs before the end date. Supported formats are yyyy-MM-ddTHH:mm:ss.\n\no, --object OBJECT\n: Object. List audit logs with the object.\n\nt, --object-type OBJECT_TYPE\n: Object type. List audit logs with the object type.\n\ns, --start-date START_DATE\n: Start date. List audit logs after the start date. Supported formats are yyyy-MM-ddTHH:mm:ss.\n\nu, --user-name USER_NAME\n: User name. List audit logs with the user name.\n\n\n\n\n\n Examples \n\nList audit logs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_account"},{"document_id":"ibmcld_09762-8926-10146","score":13.167743,"text":"\n[--service-name SERVICE_NAME] [--service-instance SERVICE_INSTANCE] [--region REGION] [--resource-type RESOURCE_TYPE] [--resource RESOURCE] [--resource-group-name RESOURCE_GROUP_NAME] [--resource-group-id RESOURCE_GROUP_ID]}\n\nWhere valid roles are Reader, Writer, and Manager.\n\nYou must use a JSON file to create the team policy.\n\nFor example, you can run the following command:\n\nibmcloud iam access-group-policy-create accessGroupName accessGroupGUID --file policy.json\n\nWhere\n\n\n\n* accessGroupName is the access group name.\n* accessGroupGUID is the GUID of the access group.\n\n\n\nYou can run the command ibmcloud iam access-groups to get the list of names and corresponding GUIDs in the account.\n\nAnd use the following JSON file.\n\n{\n\"type\": \"access\",\n\"subjects\": [\n{\n\"attributes\":\n{\n\"name\": \"access_group_id\",\n\"value\": \"AccessGroupGuid\"\n}\n]\n}\n],\n\"roles\" : [\n{\n\"role_id\" : \"crn:v1:bluemix:public:iam::::serviceRole:Reader\"\n}\n],\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"accountGuid\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"sysdig-monitor\"\n},\n{\n\"name\": \"serviceInstance\",\n\"value\": \"instanceGuid\"\n},\n{\n\"name\": \"sysdigTeam\",\n\"value\": \"sysdigTeamID\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n Add permissions through the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-iam_grant_team"},{"document_id":"ibmcld_12818-11014-11891","score":13.118477,"text":"\nAuthorization: basic dXNlcjpwYXNzd29yZA==\nX-Broker-Api-Version: 2.12\nX-Broker-API-Originating-Identity: ibmcloud aWJtaWQtNDU2MzQ1WA==\n{\n\"service_id\": \"0bc9d744-6f8c-4821-9648-2278bf6925bb\", \/\/ your service's GUID from onboarding\n\"plan_id\": \"ecc19311-aba2-49f7-8198-1e450c8460d4\", \/\/your plan's GUID from onboarding\n\"context\": {\n\"platform\": \"ibmcloud\",\n\"account_id\": \"003e9bc3993aec710d30a5a719e57a80\",\n\"crn\": \"crn:v1:bluemix:public:compose-redis:us-south:a\/003e9bc3993aec710d30a5a719e57a80:416d769b-682d-4833-8bd7-5ef8778e5b52\",\n\"resource_group_crn\": \"crn:v1:bluemix:public:resource-controller::a\/003e9bc3993aec710d30a5a719e57a80::resource-group:b4570a825f7f4d57aa54e8e1d9507926\",\n\"target_crn\": \"crn:v1:bluemix:public:resource-catalog::a\/e97a8c01ac694e308ef3ad7795c7cdb3::deployment:e62e2c19-0c3b-41e3-b8b3-c71762ecd489:us-south38399\"\n},\n\"parameters\": {\n\"location\": \"us-south\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-how-it-works"},{"document_id":"ibmcld_07578-569630-571594","score":13.016113,"text":"\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails. A password reset email is triggered, which remains active for 24 hours.\n* If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username with _srs at the end (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n* Will all my brand settings be carried over from the ResellOne reseller account?\n\n Will all my brand settings be carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-569584-571548","score":13.016113,"text":"\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, as all your customizations are copied over. Allow us to do the heavy lifting for you.\n* What happens if I don\u2019t respond to any of the emails?\n\n What happens if I don\u2019t respond to any of the emails? \n\nYour reseller account automatically moves to the Tucows\u2019 OpenSRS reseller platform if you don't respond to the emails. A password reset email is triggered, which remains active for 24 hours.\n* If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account?\n\n If I choose to migrate to OpenSRS, when can I access my account in the new Tucows\u2019 OpenSRS Reseller account? \n\nAccounts are provisioned in October 2021 at OpenSRS. You will be able to access your accounts using your IBM username with _srs at the end (for example, username_srs). You can use the Forgot Password link if you need to reset your password.\n\nIf you reset your password, the same email address is used from your previous account.\n* How do I connect to OpenSRS\u2019 API?\n\n How do I connect to OpenSRS\u2019 API? \n\nYou can find information about OpenSRS\u2019 API in the [OpenSRS API guide](https:\/\/domains.opensrs.guide\/docs\/overview), located in the Connection Information section.\n* Will all my brand settings be carried over from the ResellOne reseller account?\n\n Will all my brand settings be carried over from the ResellOne reseller account? \n\nYes, all your branding settings, along with any customized messaging content, are carried over to your new account at OpenSRS.\n* Can I migrate to OpenSRS before the End of Service date?\n\n Can I migrate to OpenSRS before the End of Service date? \n\nYes, you can migrate to OpenSRS before the End of Service date. However, we recommend waiting for your account to be automatically migrated, when all your customizations are copied over. Allow us to do the heavy lifting for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09153-7148-8536","score":13.004914,"text":"\ncreate a private service instance\n$ ibmcloud resource service-instance-create <service-name> kms tiered-pricing us-south -p '{\"allowed_network\": \"private-only\"}'\nCreating service instance <service-name> in resource group Default of account <account name> as <email address>...\nOK\nService instance <service-name> was created.\n\nName: <service-name>\nID: crn:v1:bluemix:public:kms:us-south:a\/ea988d3289c24739a0977651b46fb145:a152eee4-262e-4a39-ae13-a71b9882dcb6::\nGUID: a152eee4-262e-4a39-ae13-a71b9882dcb6\nLocation: us-south\nState: active\nType: service_instance\nSub Type: kms\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-05-31T15:10:23Z\nUpdated at: 2020-05-31T15:10:23Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n list the service instances\n$ ibmcloud resource service-instances\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nName Location State Type\n<service-name> us-south active service_instance\n\n list the private service instance\n$ ibmcloud resource service-instance <service-name>\nRetrieving service instance <service-name> in resource group Default under account <account name> as <email address>...\nOK\n\nName: <service-name>\nID: crn:v1:bluemix:public:kms:us-south:a\/ea988d3289c24739a0977651b46fb145:a152eee4-262e-4a39-ae13-a71b9882dcb6::","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-provision"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-3519-5413","score":29.060701,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_01660-8584-10307","score":26.37889,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":26.089,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":26.089,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03729-1672-3956","score":25.836262,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_00558-1499-3456","score":22.210026,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01447-9266-11226","score":22.0401,"text":"\nIf you're on the standard plan, you're charged by GB of usage per month. The first 5 GB each month is free. If you're on the free plan, you can pull images from your namespace until you reach the quota limit for the free plan.\n\nPull traffic across public connections counts toward usage and quota. Pull traffic across private connections doesn't count.\n\nThe following example is for the standard plan:\n: In the month, you pulled images that contain layers with a total size of 14 GB. Your monthly usage is calculated as shown in the following example:\n\nIn the standard plan, the first 5 GB per month is free, so you get charged for 9 GB (14 GB - 5 GB).\n\n\n\n\n\n\n\n Quota limits for storage and pull traffic \n\nDepending on the service plan that you choose, you can push and pull images to and from your namespace until you reach your plan-specific or custom quota limits for each region.\n\n\n\n Storage quota limits \n\nWhen you reach or exceed the quota limits for your plan, you can't push any images to the namespaces in your IBM Cloud account until you complete one of the following tasks.\n\n\n\n* [Free up space by removing images](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quotaregistry_quota_freeup) from your namespaces.\n* [Upgrade to the standard plan](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n* If you set quota limits for storage in your free or standard plan, you can also [increase this quota limit](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quotaregistry_quota_set) to enable the pushing of new images again.\n\n\n\nThe following example is for the standard plan:\n: Your current quota limit for storage is set to 1 GB. All private images that are stored in the namespaces of your IBM Cloud account already use 900 MB of this storage. You have 100 MB storage available until you reach your quota limit. One user wants to push an image with a size of 2 GB on the local computer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_07578-512956-514877","score":21.789803,"text":"\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-512910-514831","score":21.789803,"text":"\nYou might use the same instance of App Configuration for both scenarios for a total cost of just over $1600 per month.\n\n\n\n* What are the capabilities, quotas, and limits for various aspects of the App Configuration plans?\n\n\n\nTable 2. Capabilities, quotas, and limits for various pricing plans\n\n Lite Standard Enterprise \n\n Number of collaborators (team members) No restriction No restriction No restriction \n Max number of instances 1 No restriction No restriction \n Instance life 30 days of inactivity No restriction No restriction \n Base price for instance (monthly) Free Charge (see catalog page) Charge (see catalog page) \n Monthly active entity IDs included with instance 10 1000 10,000 \n Monthly active entity ID overage Overage not allowed overage allowed overage allowed \n Max monthly active entity IDs per instance 10 Unlimited Unlimited \n API calls included with instance 5,000 100,000 1,000,000 \n API call overage price Overage not allowed Overage allowed Overage allowed \n Max monthly API calls per instance 5,000 Unlimited Unlimited \n Environments 1 15 15 \n Collections 1 20 Unlimited \n Properties 10 (properties + flags) 1000 Unlimited \n Property types All All All \n Max property size 10 kB 10 kB 10 kB \n Max storage size (all properties) 0.1 MB 10 MB 10 MB \n Flags 10 (properties + flags) 100 Unlimited \n Attributes Glean from response and custom attributes Glean from response and custom attributes Glean from response and custom attributes \n Segments 3 <br><br> * <br><br><br> Unlimited \n Segment definition rules per segment 3 <br><br> * <br><br><br> 25 \n Max targeting definition rules per instance 3 <br><br> * <br><br><br> 100 \n Targeting definition rules per feature <br><br> * <br><br><br> <br><br> * <br><br><br> 50 \n Delivery mode Websocket (server)pull or get (client) Websocket (server) pull or get(client) Websocket(server)pull or get (client) \n Role-based access Env-level Env-level Env-level","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12904-1535-3460","score":21.189165,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":25.350574,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07103-29564-31587","score":24.386166,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_01705-7-1620","score":23.832115,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_16727-1079289-1081125","score":23.31371,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":23.31371,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07152-7168-8788","score":22.538395,"text":"\nPremium \n\nPremium plans offer developers and organizations a single tenant instance of one or more Watson services for better isolation and security. These plans offer compute-level isolation on the existing shared platform, as well as end-to-end encrypted data while in transit and at rest.\n\nFor more information, or to purchase a Premium plan, contact [Sales](https:\/\/ibm.biz\/contact-wdc-premium).\n\n\n\n\n\n Additional information \n\nFor information about calculating costs, see the [IBM Cloud Pricing Calculator](https:\/\/cloud.ibm.com\/estimator\/review).\n\nFor additional pricing information, see the [Discovery catalog](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Notes for Customers with Existing Plans \n\n\n\n* Beginning 1 August 2018, your billing and usage is based on this pricing plan.\n* The Lite plan is now reduced from 2,000 documents\/400 Discovery News queries per month to 1,000 documents\/200 Discovery News queries per month. If you already exceeded the new Lite plan limits, you cannot add any more documents. However, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Standard plan is retired and is no longer available to new users. If you are currently on an existing Standard plan, you can continue using it or upgrade to an Advanced or Premium plan.\n* The Advanced and Premium plans are now based on document tiers. They are no longer based on document hours. Your monthly bill will not fluctuate, based on the number of documents, unless you switch between tiers.\n* Premium customers, contact [Sales](https:\/\/ibm.biz\/contact-wdc-premium) for details on billing changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans"},{"document_id":"ibmcld_12904-7-1919","score":22.385427,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07103-32746-34817","score":22.180637,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_00558-7-1874","score":21.954033,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07152-7-1723","score":21.893255,"text":"\nDiscovery pricing plans \n\nIBM Watson\u2122 Discovery offers three plans -- Lite, Advanced, and Premium -- that provide different levels of resources and capabilities to suit your needs.\n\nFor more information about Premium plans that were created after 16 July 2020 or about Plus plans (including Plus Trial), see [these docs](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-pricing-plans).\n\nPrivate data use cases have the following features, limits, and prices:\n\n\n\n Lite \n\n\n\n Size Number of Docs* Price \n\n N\/A 1,000 docs total Free \n\n\n\nThe Lite plan is a starter plan, so do not use it in your production environment. When you upgrade to a paid plan, you can keep all ingested documents. Lite plan instances are deleted after 30 days of inactivity.\n\nAttributes:\n\n\n\n* 1 environment\n* Up to 2 collections\n* Free NLU enrichments**\n\n\n\nAdditional options:\n[Custom Models](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks):\nOne IBM Watson\u2122 Knowledge Studio model included. Additional models: Not available\n[Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification)***: 500 pages included per month. Additional pages: Not available\n[News Queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news): 200 News queries included per month. Additional queries: Not available\n[Query Expansions](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion): 500 query expansions with 1,000 total terms. Additional expansions: Not available\n[Document splitting](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicedoc-segmentation): 250 segments per plan. Additional segments: Not available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02660-1509-3609","score":26.52545,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_01705-11723-13541","score":25.187788,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-8584-10307","score":25.128393,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_03749-1776-3774","score":24.689135,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_08069-7-2230","score":23.79986,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_12544-1669-3632","score":23.499142,"text":"\nUsage access is managed separately and can be targeted to the enterprise, an account group, or an account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/includes\/billing-usage\/includes\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_01029-0-4062","score":23.479218,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"},{"document_id":"ibmcld_16727-1079289-1081125","score":22.819687,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":22.819687,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01183-7-2154","score":22.605787,"text":"\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https:\/\/cloud.ibm.com\/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03749-8477-10695","score":24.295904,"text":"\nFor more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_03749-3299-5633","score":23.930378,"text":"\nHowever, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing. As a result, subscription credit can't be added to individual child accounts. Subscription credit must be added to the enterprise account, where it becomes part of the enterprise credit pool.\n\n\n\n Billing transition when importing accounts \n\nWhen you import an existing account to an enterprise, its billing and invoicing transitions to being managed by the enterprise account. This transition includes the following changes to the account.\n\n\n\n* For Subscription accounts that are added, the account type is changed to Pay-As-You-Go. This change reflects that the account does not have its own subscriptions, but it still has full access to production-ready, billable services.\n* Subscriptions and promotions from each account are moved to the enterprise account, where they become part of the credit pool. After the move, each subscription has the same remaining credit and term period, but the subscription is given a new unique ID.\n* Access to billing and payment information for future billing periods is restricted to users in the enterprise account. Users in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_12544-8261-10509","score":22.92564,"text":"\n* Better discounts on usage costs because subscriptions are larger\n* Fewer expiration dates to track and manage after existing subscriptions expire\n\n\n\nIn an enterprise, subscriptions are managed from the enterprise account the same way as for a stand-alone account. For more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_12544-3190-5442","score":20.875217,"text":"\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing. As a result, subscription credit can't be added to individual child accounts. Subscription credit must be added to the enterprise account, where it becomes part of the enterprise credit pool.\n\n\n\n Billing transition when importing accounts \n\nWhen you import an existing account to an enterprise, its billing and invoicing transitions to being managed by the enterprise account. This transition includes the following changes to the account.\n\n\n\n* For Subscription accounts that are added, the account type is changed to Pay-As-You-Go. This change reflects that the account does not have its own subscriptions, but it still has full access to production-ready, billable services.\n* Subscriptions and promotions from each account are moved to the enterprise account, where they become part of the credit pool. After the move, each subscription has the same remaining credit and term period, but the subscription is given a new unique ID.\n* Access to billing and payment information for future billing periods is restricted to users in the enterprise account. Users in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_12559-4953-7138","score":19.967224,"text":"\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"},{"document_id":"ibmcld_12623-8173-10535","score":19.329603,"text":"\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically create or manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nFor more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Isolated user and access management \n\nEnterprises keep user and access management isolated between the enterprise and its child accounts to provide greater security for your accounts' data. The users and their assigned access in the enterprise account are entirely separate from those in the child accounts, and no access is automatically inherited between the two types of accounts.\n\nThe user lists for each account are only visible to the users who are invited to that account. Just because a user is invited and given access to manage the entire enterprise, it doesn't mean that they can view the users who are invited to each child account. User management in each enterprise and each account is entirely separate and must be managed by the account owner or a user given the Administrator role on the User management account management service in the specific account.\n\nSimilar to how user management is entirely separate in each account and the enterprise itself, so is access management. This separation means that users who manage your enterprise can't access account resources within the child accounts unless you specifically enable them to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"},{"document_id":"ibmcld_02114-9608-11655","score":19.077011,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-9608-11655","score":19.077011,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-9608-11655","score":19.077011,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12561-5237-7143","score":18.793056,"text":"\nIf you want to view usage for a specific account group or account, find the name or ID by running the ibmcloud enterprise command.\n\nFor example, the following command displays all account groups in an enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. View usage by running the ibmcloud billing command as shown in the following examples.\n\n\n\n* View usage for the entire enterprise for the current month.\n\nibmcloud billing enterprise-usage\n* View usage for the Development account group for July 2019.\n\nibmcloud billing enterprise-usage --account-group Development --month 2019-07\n* View the usage for the account groups and accounts that are directly under the enterprise.\n\nibmcloud billing enterprise-usage --children\n\n\n\n\n\nBy default, the commands output the usage report for the current month in the following format. Most costs are listed as billable costs. Non-billable costs are listed only in rare cases, such as for the month when you add a trial account to the enterprise.\n\nName Type Billable Cost Non-billable Cost Currency Month\nExample Corp account 123.45 0 USD 2019-07\nDevelopment account_group 234.56 0 USD 2019-07\nMarketing account_group 345.67 0 USD 2019-07\nSales account_group 456.78 0 USD 2019-07\n\nYou can output the report in JSON format by specifying the --output JSON option.\n\n\n\n\n\n Viewing enterprise usage by using the API \n\nYou can get usage reports from an enterprise and its accounts by calling the [Enterprise Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports). You can base the query in your API call on an enterprise, an account group, or an account and specify whether to view the entity or its children.\n\nThe following examples show queries that you can use to get different usage reports. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-7-2136","score":15.752526,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":15.752526,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_02361-24500-26305","score":14.6994095,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_05032-6428-8442","score":13.756793,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05168-15740-17188","score":13.719862,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04960-7-1834","score":13.695312,"text":"\nUsing Aspera high-speed transfer \n\nAspera high-speed transfer overcomes the limitations of traditional FTP and HTTP transfers to improve data transfer performance under most conditions, especially in networks with high latency and packet loss.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nInstead of the standard HTTP PUT operation, Aspera high-speed transfer uploads the object by using the [FASP protocol](https:\/\/www.ibm.com\/products\/aspera\/technology). Using Aspera high-speed transfer for uploads and downloads offers the following benefits:\n\n\n\n* Faster transfer speeds\n* Transfer large object uploads over 200 MB in the console and 1 GB by using an SDK or library\n* Upload entire folders of any type of data, such as multi-media files, disk images, and any other structured or unstructured data\n* Customize transfer speeds and default preferences\n* Transfers can be viewed, paused, resumed, or cancelled independently\n\n\n\nAspera high-speed transfer is available in the IBM Cloud [console](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-asperaaspera-console) and can also be used programmatically by using an [SDK](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-asperaaspera-sdk).\n\nAspera high-speed transfer is available in certain regions only. See [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-aspera"},{"document_id":"ibmcld_04866-4961-6763","score":13.657971,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":13.657971,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05138-7979-9034","score":13.506598,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"},{"document_id":"ibmcld_06808-1384-2991","score":13.256074,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.804809975,"ndcg_cut_10":0.9279611694}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":12.7528105,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":12.728548,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14708-3638-5837","score":9.349101,"text":"\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_04866-4961-6763","score":6.58547,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":6.58547,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14708-2831-4126","score":5.6540747,"text":"\nThis action allows data to be received from the proxy servers during backup and restore processes.\n\nufw status\nStatus: active\nTo Action From\n-- ------ ----\n6162\/tcp ALLOW 10.38.207.157 Allow Veeam Mgmt from Veeam BUR server\n2500\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n6162\/tcp ALLOW OUT Anywhere Veeam transport rule\n2500\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501\/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n\nZoom\n\n![Veeam backup](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/veeam-cr-sa-lhbr-proxy.svg)\n\nFigure 2. Veeam backup\n\n\n\n Best practices for a Linux hardened repository \n\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_16447-1597-3270","score":4.2131805,"text":"\nIn large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Export models \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"},{"document_id":"ibmcld_16518-1687-3559","score":3.6915555,"text":"\nTable 1. Role descriptions\n\n Role Description \n\n Admin Responsible for administrative tasks, which include managing users, resource consumption, and monthly charges. In large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Deploy and undeploy models to runtime services \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles"},{"document_id":"ibmcld_07118-11077-12656","score":3.5211701,"text":"\nFigure 21. Starting URL field\n\nYou will add only one starting URL. In a real scenario, you might add multiple URLs that go to other pages with information about the same topic. By adding more URLs, you can expand the breadth of the expertise of your assistant.\n4. Click Add.\n5. Click the Edit icon for the URL that you just added.\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-3.png)\n\nFigure 22. Edit starting URL\n6. In the Maximum number of links to follow field, change the value to 5.\n\nZoom\n\n![Shows the Starting URLs field](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-convo-web-crawl-4.png)\n\nFigure 23. Starting URL settings\n\nBy changing the value to 5, you indicate that you want the service to process the page that you specified plus you want it to follow up to 5 links from the starting page.\n7. Click Save, and then click Finish.\n\n\n\nThe Discovery service crawls the web page that you specified starting with the page that you specified as the starting URL.\n\nWhile the website is being crawled and the data indexed, let's go back to our Watson Assistant service instance. It's time to connect the action that we created to this Discovery project.\n\n\n\n\n\n Step 5: Add a search extension \n\nLet's connect your assistant to your Discovery data.\n\n\n\n1. From the navigation panel in Watson Assistant, click Environments.\n\nZoom\n\n![Shows the Environments menu item in the navigation panel.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-assistant-fred"},{"document_id":"ibmcld_03126-4-2343","score":3.4063802,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Plan your assistant \n\nBuild an assistant that meets the needs of your customers with speed and ease.\n\nTo start, consider these factors and make key decisions up front that will keep you on track as you build.\n\n\n\n Pick your assistant's areas of expertise \n\nDecide what you want your assistant to specialize in. What questions or tasks will it help customers with? To make an informed decision, review any support call logs that you have access to.\n\nStart small. Pick one or a handful of customer issues that will deliver the highest value to start.\n\nIt might be valuable for your assistant to answer a simple question that is asked all the time. Or maybe there's a task, such as scheduling appointments, that can be offloaded to the assistant to tackle 30% of all incoming customer requests.\n\nChoose a narrow set of user goals first. After your assistant is live, you can use built-in tools to gain insights from the incoming traffic that will tell you what areas to focus on next.\n\n\n\n\n\n Give the right type of answer to meet the need \n\nA conversational exchange is what your assistant does best, but your assistant can do other things too. The best response to a question might be a single answer with a link somewhere else. Think about the right way to answer customer questions; don't try to fit everything into one type of conversational exchange.\n\nThe following table lists some examples.\n\n\n\nExample of optimal response types\n\n Customer need Best type of response \n\n Get information about your store location Your assistant answers with text (the store address) and an image (an area map). \n Activate a credit card Your assistant can use a conversational flow to collect information for identity verification, and then call a webhook to submit the request to activate the card on the user's behalf. \n Complete a simple task that involves a complicated application Your assistant can link them to a 2-minute video that illustrates how to complete the task. \n Learn about insurance plan details after the death of a loved one Your assistant can connect the customer directly to a person who can show empathy and patience as the matter is addressed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":24.694174,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":24.694174,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-3142-5463","score":21.009943,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-3142-5463","score":21.009943,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7-2136","score":20.902996,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":20.902996,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05075-5285-7227","score":20.536457,"text":"\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased. If you are using default retention for validation testing please use a lower duration (such as 1 day) as the default retention, increasing it to your desired setting as needed.\n\n\n\n Creating and setting up your new bucket for use with Object Lock \n\n\n\n1. Navigate to your desired Object Storage instance and use Create Bucket with Customize your bucket option\n2. Enter the required bucket configuration details as per your use case requirements\n3. Navigate to the Object Versioning section and set it to Enabled\n4. Look for Immutability, and under Object Lock click Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n8. Proceed with rest of the configuration settings and click Create bucket\n\n\n\n\n\n\n\n Enabling Object Lock on an existing bucket: \n\nA bucket can be set for Object Lock use as follows:\n\n\n\n1. Navigate to your bucket Configuration section\n2. Click on Object Versioning\n3. At the Object Versioning section click on Edit, set the configuration option to Enabled and Save\n4. Navigate to Object Lock section, click on Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n\n\n\n\n\n\n\n Adding a Retain Until Date or Legal Hold to an object \n\n\n\n1. Navigate to the bucket with the target object\n2. Toggle Display Versions\n3. Go to the details of the target version\n4. Add a retention period and\/or toggle on a legal hold.\n\n\n\n\n\n\n\n\n\n Using Object Lock for business continuity and disaster recovery","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05032-6428-8442","score":20.226528,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04831-50613-52356","score":20.03448,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_04991-50585-52328","score":20.03448,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3010299957}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-7-2136","score":19.433828,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":19.433828,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05168-15740-17188","score":18.073656,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"},{"document_id":"ibmcld_04960-1454-3384","score":17.215609,"text":"\nSee [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console \n\nIf you add objects by using the console in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability), you are prompted with an option to install the Aspera Connect client. This browser plug-in provides Aspera high-speed transfer to upload files or folders.\n\n\n\n Install Aspera Connect \n\n\n\n1. Select Install Aspera Connect client.\n2. Follow the installation instructions for your operating system and browser.\n3. Resume file or folder upload.\n\n\n\nThe Aspera Connect plug-in can also be installed from the [Aspera website](https:\/\/downloads.asperasoft.com\/connect2\/) directly. For help troubleshooting issues with the Aspera Connect plug-in, [see the documentation](https:\/\/downloads.asperasoft.com\/en\/documentation\/8).\n\nAfter the plug-in is installed, you have the option to set Aspera high-speed transfer as the default for any uploads to the target bucket that use the same browser. Select Remember my browser preferences. Options are also available in the bucket configuration page under Transfer options. These options allow you to choose between Standard and High speed as the default transport for uploads and downloads.\n\nTypically, using the IBM Cloud Object Storage web-based console isn't the most common way to use Object Storage. The Standard transfer option limits objects size to 200 MB and the file name and key will be the same. Support for larger object sizes and improved performance (depending on network factors) is provided by Aspera high-speed transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-aspera"},{"document_id":"ibmcld_04862-1468-3398","score":17.215609,"text":"\nSee [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console \n\nIf you add objects by using the console in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability), you are prompted with an option to install the Aspera Connect client. This browser plug-in provides Aspera high-speed transfer to upload files or folders.\n\n\n\n Install Aspera Connect \n\n\n\n1. Select Install Aspera Connect client.\n2. Follow the installation instructions for your operating system and browser.\n3. Resume file or folder upload.\n\n\n\nThe Aspera Connect plug-in can also be installed from the [Aspera website](https:\/\/downloads.asperasoft.com\/connect2\/) directly. For help troubleshooting issues with the Aspera Connect plug-in, [see the documentation](https:\/\/downloads.asperasoft.com\/en\/documentation\/8).\n\nAfter the plug-in is installed, you have the option to set Aspera high-speed transfer as the default for any uploads to the target bucket that use the same browser. Select Remember my browser preferences. Options are also available in the bucket configuration page under Transfer options. These options allow you to choose between Standard and High speed as the default transport for uploads and downloads.\n\nTypically, using the IBM Cloud Object Storage web-based console isn't the most common way to use Object Storage. The Standard transfer option limits objects size to 200 MB and the file name and key will be the same. Support for larger object sizes and improved performance (depending on network factors) is provided by Aspera high-speed transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-aspera"},{"document_id":"ibmcld_04831-50613-52356","score":17.210634,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_04991-50585-52328","score":17.210634,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_05075-8514-10699","score":16.639599,"text":"\nDeleting a versioned object creates a delete marker. The object may appear to be deleted, but if the object is protected it is not possible to delete the protected version. Delete markers themselves are not protected.\n\n\n\n\n\n Replication \n\nObject Lock cannot be used on the source bucket for replication, only on the destination. Objects will be assigned the default retention period.\n\n\n\n\n\n Key Management Systems \n\nProtected objects will be encrypted using the root key of the bucket. When Object Lock is enabled on a bucket, the root key hosted by Key Protect or Hyper Protect Crypto Services is protected from deletion as long as an associated bucket has Object Lock enabled. This prevents crypto shredding of protected objects.\n\n\n\n\n\n Lifecycle configurations \n\nIt is possible to enable lifecycle policies that [archive locked objects](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive), but naturally not those that [expire objects](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) under retention or legal hold (unprotected objects in the bucket can still be expired).\n\n\n\n\n\n Immutable Object Storage \n\nObject Lock is an alternative to the retention policies available when using Immutable Object Storage. As Object Lock requires versioning to be enabled, and Immutable Object Storage is not compatible with versioning, it is not possible to have both WORM solutions enabled on the same bucket. It is possible to have a mix of buckets in a Service Instance, each using either Immutable Object Storage or Object Lock.\n\n\n\n\n\n Object Tagging \n\nThere are no restrictions on adding or modifying tags on a protected object.\n\n\n\n\n\n Other interactions \n\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05010-7-1832","score":15.876577,"text":"\nFAQ - General \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n How can I find out the total size of my bucket by using the API? \n\nYou can use the [Resource Configuration API](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) to get the bytes used for a given bucket.\n\n\n\n\n\n How can I view my buckets? \n\nYou can view and navigate your buckets using the console, CLI or the API.\n\nFor example, the CLI command ibmcloud cos buckets will list all buckets associated with the targeted service instance.\n\n\n\n\n\n Can I migrate data from AWS S3 into IBM Cloud Object Storage? \n\nYes, you can use your existing tools to read and write data into IBM Cloud Object Storage. You need to configure HMAC credentials allow your tools to authenticate. Not all S3-compatible tools are currently unsupported. For details, see [Using HMAC credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-uhc-hmac-credentials-main).\n\n\n\n\n\n Can I use AWS S3 SDKs with IBM Cloud Object Storage? \n\nYes, IBM COS SDKs are based on the official AWS S3 API SDKs, but are modified to use IBM Cloud features, such as IAM, Key Protect, Immutable Object Storage, and others. When using these SDKs, use HMAC authorization and an explicit endpoint. For details, see [About IBM COS SDKs](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-sdk-about).\n\n\n\n\n\n Is there a 100-bucket limit to an account? What happens if I need more? \n\nYes, 100 is the current bucket limit. Generally, prefixes are a better way to group objects in a bucket, unless the data needs to be in a different region or storage class. For example, to group patient records, you would use one prefix per patient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_04991-46928-48917","score":15.330267,"text":"\n--------------------\n\n\n\n\n\n Delete stale data with expiration rules \n\nObjects that are subject to a bucket's Immutable Object Storage retention policy will have any expiration actions deferred until the retention policy is no longer enforced.\n\nFor more about using lifecycle configuration to delete objects, check out the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry).\n\nThis implementation of the PUT operation uses the lifecycle query parameter to set lifecycle settings for the bucket. This operation allows for a single lifecycle policy definition for a bucket. The policy is defined as a set of rules consisting of the following parameters: ID, Status, Filter, and Expiration.\n\nNot all operations are supported in Satellite environments. For details, see [supported Satellite APIs](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-apis-cos-satellite)\n\n\n\n Header Type Description \n\n Content-MD5 String Required: The base64 encoded 128-bit MD5 hash of the payload, which is used as an integrity check to ensure that the payload wasn't altered in transit. \n\n\n\nThe following snippet shows one way to achieve the content for that particular header.\n\necho -n (XML block) | openssl dgst -md5 -binary | openssl enc -base64\n\nThe body of the request must contain an XML block with the following schema:\n\n\n\n Element Type Children Ancestor Constraint \n\n LifecycleConfiguration Container Rule None Limit 1. \n Rule Container ID, Status, Filter, Expiration LifecycleConfiguration Limit 1000. \n ID String None Rule Must consist of (a-z,A-Z0-9) and the following symbols:!_.*'()- \n Filter String Prefix Rule Must contain a Prefix element \n Prefix String None Filter The rule applies to any objects with keys that match this prefix. \n Expiration Container Days or Date Rule Limit 1. \n Days Non-negative integer None Expiration Must be a value greater than 0. \n Date Date None Expiration Must be in ISO 8601 Format. \n\n\n\nSyntax","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":22.453156,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":19.888796,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":14.373378,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-2946-5057","score":12.592393,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04105-5067-6335","score":12.006054,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":11.501283,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_16364-213826-215727","score":10.973666,"text":"\nFor details, see [Defining entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities) and search for Enabling system entities.\n* You can now view a history of conversations with users on the Improve page. You can use this to understand your bot's behavior. For details, see [Improving your skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs).\n* You can now import entities from a comma-separated value (CSV) file, which helps with when you have a large number of entities. For details, see [Defining entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities) and search for Importing entities.\n\n\n\n\n\n\n\n 20 September 2016 \n\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs).\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_04175-0-1274","score":10.0356045,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04111-35313-36062","score":9.826909,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_03070-6290-7633","score":9.457205,"text":"\nYour assistant responds by saying, We are always looking for talented people to add to our team. What type of job are you interested in?\n6. Instead of answering this question, ask the bot an unrelated question. Type What time do you open?\n\nYour assistant digresses away from the Job opportunities node to the Restaurant opening hours node to answer your question. Your assistant responds with The restaurant is open from 8:00 AM to 10:00 PM.\n\nUnlike in the previous test, this time the dialog does not pick up where it was in the Job opportunities node. Your assistant does not return to the dialog that was in progress because you changed the setting on the Restaurant opening hours node to not return.\n\n![Shows a conversation that does not return after a digression](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/tut-dig-noreturn.png)\n\n\n\nCongratulations! You have successfully digressed away from a dialog without returning.\n\n\n\n\n\n Summary \n\nIn this tutorial you experienced how digressions work, and saw how individual dialog node settings can impact the digressions behavior.\n\n\n\n\n\n Next steps \n\nFor help as you configure digressions for your own dialog, see [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-digressions"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":16.062292,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":15.168991,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-1672-3877","score":14.100814,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":13.093803,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04334-39121-41053","score":12.39673,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04146-2946-5057","score":12.036737,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04170-1738-2974","score":11.33941,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04113-1734-4014","score":11.216709,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04334-43529-45385","score":11.070423,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04105-7-2225","score":10.824433,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":22.400301,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":21.941723,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":21.69438,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04170-1738-2974","score":20.241522,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04175-0-1274","score":17.634619,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-7-2225","score":17.189045,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04118-5438-6061","score":16.570335,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04334-39121-41053","score":16.254765,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04107-6095-8145","score":16.10188,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04113-1734-4014","score":16.045742,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":24.875757,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_16464-20282-21209","score":22.27644,"text":"\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16495-7-2129","score":22.02584,"text":"\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_16437-7-2129","score":22.02584,"text":"\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_16563-20012-20766","score":21.979214,"text":"\nFor example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16524-7-2263","score":19.788568,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16451-7-2278","score":19.690325,"text":"\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16505-4167-5227","score":19.445816,"text":"\nSee [Adjudication](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruthwks_haperform). \n Train the model Create the machine learning model. See [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-mlwks_madocsets). \n Evaluate the model Evaluate the accuracy of the model. See [Evaluating annotations added by the model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-mlwks_matest). Depending on model accuracy, this step might result in the need to repeat earlier steps again and again until optimal accuracy is achieved. See [Analyzing machine learning model performance](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml) for ideas about what to update based on common performance issues. \n Publish the model Export the model. See [Using the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator"},{"document_id":"ibmcld_16451-1641-3812","score":19.093643,"text":"\nFor more information about which ratios to apply, see [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.\n\nThe document sets must contain at least 10 annotated documents.\n8. After the model is created, select one of the following actions:\n\nTable 1. Document options\n\n\n\n Option Description \n\n Log View the log file to see whether any problems occurred. \n Details View the annotation performance statistics, change the document sets that you want to use for training and testing the model, and create snapshot versions of the model artifacts. \n Export If you have a Standard plan or a Premium plan, you can export a ZIP file to your local system that contains the components that are required for the model to run in a machine learning runtime environment, such as Watson Explorer. \n\n\n\n\n\n\n\n\n\n\n\n Evaluating annotations added by the model \n\nYou can compare the ground truth view for annotations added by human annotators to the annotations added by the model.\n\n\n\n Procedures \n\nTo evaluate the annotations added by the model:\n\n\n\n1. Select Machine Learning Model > Performance > Train and evaluate. The Training\/Test\/Blind Sets page is displayed.\n2. Click View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16524-1630-3793","score":18.918522,"text":"\nSee [Document set management](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.\n\n> Note: The document sets must contain at least 10 annotated documents.\n8. After the model is created, select one of the following actions:\n\n\n\n\n\nDocument options\nEach row in this table describes one option for a choice.\n\n Option Description \n\n Log View the log file to see whether any problems occurred. \n Details View the annotation performance statistics, change the document sets that you want to use for training and testing the model, and create snapshot versions of the model artifacts. \n Export If you have a Standard plan or a Premium plan, you can export a ZIP file to your local system that contains the components that are required for the model to run in a machine learning runtime environment, such as Watson Explorer. \n\n\n\n\n\n\n\n\n\n Evaluating annotations added by the model \n\nYou can compare the ground truth view for annotations added by human annotators to the annotations added by the model.\n\n\n\n Procedure \n\nTo evaluate the annotations added by the model:\n\n\n\n1. Select Machine Learning Model > Performance > Train and evaluate. The Training\/Test\/Blind Sets page is displayed.\n2. Click View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":20.198254,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":18.746613,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":16.133476,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":15.501879,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":13.142355,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04107-6095-8145","score":13.06672,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_16358-7447-9162","score":12.859513,"text":"\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_04146-1603-3385","score":12.654087,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04334-39121-41053","score":12.115339,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04146-2946-5057","score":11.876056,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":19.903902,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":17.538687,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":17.431185,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_01391-16119-17644","score":14.496395,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04170-7-2189","score":14.3381605,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_06063-71860-73820","score":14.307942,"text":"\nFor proper protection and encryption, store personal information in [secrets](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) instead.\n: For centralized management of all your secrets across clusters and injection at application runtime, try [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets).\n\nUse a Kubernetes imagePullSecret to store image registry credentials\n: Do not store personal information in container images or registry namespaces. For proper protection and encryption, store registry credentials in [Kubernetes imagePullSecrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-registryother) and other personal information in [secrets](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) instead. Remember that if personal information is stored in a previous layer of an image, deleting an image might not be sufficient to delete this personal information.\n\nTo set up encryption for your secrets, see [Encrypting Kubernetes secrets by using a key management service (KMS) provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect).\n\n\n\n\n\n Kubernetes security bulletins \n\nIf vulnerabilities are found in Kubernetes, Kubernetes releases CVEs in security bulletins to inform users and to describe the actions that users must take to remediate the vulnerability. Kubernetes security bulletins that affect IBM Cloud Kubernetes Service users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https:\/\/cloud.ibm.com\/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a Kubernetes version that you can install as part of the regular [cluster update process](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) in IBM Cloud Kubernetes Service. Make sure to apply security patches in time to protect your cluster from malicious attacks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_02777-11403-13114","score":14.200225,"text":"\nBy default, custom attributes are modifiable and can be updated by using an App ID access token from a client application. Without taking proper precautions, either the user or the application can update custom attributes immediately following the first user sign-in, if they have an access token. Doing so can potentially lead to unintended consequences. For example, a user might change their role from user to admin, which might expose administrative privileges to malicious users.\n\n\n\n1. Go to the User profiles > Settings tab of the App ID dashboard.\n2. Toggle custom attributes to Enabled.\n3. Obtain access and identity tokens with the API.\n\n\n\n1. Obtain your tenant ID, client ID, secret, and OAuth Server URL from your credentials.\n2. Encode your client ID and secret by using a base64 encoder.\n3. Use the following code examples to retrieve your tokens. The grant type that you use to obtain your token can differ depending on the type of authorization that you're working with. For a detailed list of options, check out the [swagger documentation](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Authorization%20Server%20-%20Authorization%20Server%20V4\/oauth-server.token).\n\n\n\n* Curl\n* Java\n* Node\n* Swift\n* Swift\n\n\n\ncurl -X POST 'https:\/\/<region>.appid.cloud.ibm.com\/oauth\/v4\/<tenantID>\/token' -H 'Authorization: Basic base64Encoded{<clientID>:<clientSecret>}' -H 'Accept: application\/json' -F 'grant_type=password' -F 'username=testuser@test.com' -F 'password=testuser'\n\nAppID.getInstance().signinWithResourceOwnerPassword(getApplicationContext(), username, password, new TokenResponseListener() {\n@Override\npublic void onAuthorizationFailure (AuthorizationException exception) {\n\/\/Exception occurred","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles"},{"document_id":"ibmcld_04186-16084-17604","score":14.04936,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_10510-72440-73853","score":13.4824095,"text":"\nFor proper protection and encryption, store registry credentials in [Kubernetes imagePullSecrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryother) and other personal information in [secrets](https:\/\/kubernetes.io\/docs\/concepts\/configuration\/secret\/) instead. Remember that if personal information is stored in a previous layer of an image, deleting an image might not be sufficient to delete this personal information.\n\n\n\n\n\n Kubernetes security bulletins \n\nIf vulnerabilities are found in Kubernetes, Kubernetes releases CVEs in security bulletins to inform users and to describe the actions that users must take to remediate the vulnerability. Kubernetes security bulletins that affect Red Hat OpenShift on IBM Cloud users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https:\/\/cloud.ibm.com\/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a Red Hat OpenShift version that you can install as part of the regular [cluster update process](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) in Red Hat OpenShift on IBM Cloud. Make sure to apply security patches in time to protect your cluster from malicious attacks. For more information about what is included in a security patch, refer to the [version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_07902-1732-3843","score":13.462816,"text":"\nInformation system entry and exit points include, for example, firewalls, electronic mail servers, web servers, proxy servers, remote-access servers, workstations, notebook computers, and mobile devices. Malicious code includes, for example, viruses, worms, Trojan horses, and spyware. Malicious code can also be encoded in various formats (e.g., UUENCODE, Unicode), contained within compressed or hidden files, or hidden in files using steganography. Malicious code can be transported by different means including, for example, web accesses, electronic mail, electronic mail attachments, and portable storage devices. Malicious code insertions occur through the exploitation of information system vulnerabilities. Malicious code protection mechanisms include, for example, anti-virus signature definitions and reputation-based technologies. A variety of technologies and methods exist to limit or eliminate the effects of malicious code. Pervasive configuration management and comprehensive software integrity controls may be effective in preventing execution of unauthorized code. In addition to commercial off-the-shelf software, malicious code may also be present in custom-built software. This could include, for example, logic bombs, back doors, and other types of cyber attacks that could affect organizational missions\/business functions. Traditional malicious code protection mechanisms cannot always detect such code. In these situations, organizations rely instead on other safeguards including, for example, secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to help ensure that software does not perform functions other than the functions intended. Organizations may determine that in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, actions in response to detection of malicious downloads, and\/or actions in response to detection of maliciousness when attempting to open or execute files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-3"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09513-12728-14481","score":12.111803,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_09109-6121-7923","score":11.42207,"text":"\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_08515-6389-8309","score":11.207913,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keys"},{"document_id":"ibmcld_02776-3988-5695","score":11.074557,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_08433-6344-8271","score":11.072902,"text":"\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nA successful POST \/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-standard-keys"},{"document_id":"ibmcld_13616-13587-15670","score":10.390233,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_09167-10518-12373","score":10.347687,"text":"\nA unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n encrypted_key Required. The encrypted key material that you want to store and manage in the service. The value must be base64 encoded. Ensure that the key material meets the following requirements: <br> <br>The key must be 128, 192, or 256 bits.The bytes of data, for example 32 bytes for 256 bits, must be encoded by using base64 encoding. \n key_type OptionalA boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n encrypted_nonce Required. The AES-GCM encrypted nonce that ensures that the bits you send as part of a request are exactly the same as what we receive. The nonce validates the key that you are restoring. <br> <br>To learn more, see [Tutorial: Creating and importing encryption keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-tutorial-import-keystutorial-import-encrypt-nonce). \n iv Required. The initialization vector (IV) that is generated by the AES-GCM algorithm when you encrypt a nonce. This value is used to decode the key for storage in the Key Protect system. <br> <br>To learn more, see [Tutorial: Creating and importing encryption keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-tutorial-import-keystutorial-import-encrypt-nonce). \n\n\n\nA successful rotation request returns an HTTP 204 No Content response, which indicates that your root key was replaced by new key material.\n\n\n\n\n\n Optional: Verify import token key rotation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-rotate-keys"},{"document_id":"ibmcld_10889-1448-3175","score":10.304245,"text":"\nThe GDPR imposes strict rules on those hosting and processing personal data, anywhere in the world.\n\nIBM is committed to providing our clients and IBM Business Partners with innovative data privacy, security, and governance solutions to assist them in their journey to GDPR readiness. Data and data protection are becoming increasingly important to individuals and society. Enterprises must earn the client\u2019s trust in their ability to steward information.\n\nIBM Cloud is agile and scalable with built-in data security, and privacy services and solutions that can be consumed on premises or through public cloud. Our comprehensive data security platform helps safeguard sensitive data wherever it resides and provides a full range of data protection capabilities.\n\n\n\n\n\n Environmental information \n\nIBM Cloud, as a user and as a provider, is environmentally conscious and strives to provide power efficiency and recycling in our data centers. As such, the servers that are put in service within the IBM Cloud comply with Commission Regulation (EU) 2019\/424 of 15 March 2019 laying down ecodesign requirements for servers and data storage products (EU Lot 9).\n\nFor details, see the following data sheets on our physical hardware in the cloud:\n\n\n\n* [Rack Mount Server 618U-TR4T+](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X10DRU-i+.pdf)\n* [Rack Mount Server 6019U-TN4R4T](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11DPU.pdf)\n* [Rack Mount Server 5019C-WR-04](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11SCW.pdf)\n* [Rack Mount Server 5019S-W4TR](https:\/\/cloud.ibm.com\/media\/docs\/downloads\/environment-info-datasheets\/1U_X11SSW-4TF.pdf)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-compliance"},{"document_id":"ibmcld_09109-4709-6562","score":10.202069,"text":"\n<br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n IAM_token Required. Your IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the curl request. <br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br> <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n correlation_ID The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. <br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_08432-6308-8159","score":10.149493,"text":"\nA unique, human-readable name for easy identification of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nIf you set the expirationDate in your request, the key is moved to the deactivated state within 1 hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-root-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.4,"recall_5":0.4,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.3835663674,"ndcg_cut_10":0.3835663674}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":22.846573,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":22.509169,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_09410-1574-3779","score":18.507006,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01533-6329-8623","score":18.21994,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":18.21994,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":18.202818,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01535-4-2366","score":18.079916,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":18.079916,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-1902-3811","score":17.845213,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-1902-3785","score":17.76553,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":21.398106,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":21.050776,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":17.910822,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":17.910822,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":17.729445,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01535-4-2366","score":17.723558,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":17.723558,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_09410-1574-3779","score":17.26875,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01535-1902-3811","score":17.092007,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-1902-3785","score":17.039091,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2338647045}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01329-59746-61590","score":18.9387,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01535-4-2366","score":18.85325,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":18.85325,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-8109-9900","score":18.351137,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":18.351137,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-14955-16723","score":18.11771,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-1679-3832","score":17.96323,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":17.868181,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":17.868181,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_07578-370529-372403","score":17.712067,"text":"\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\nKubernetes service\n\n\n\n* What is Kubernetes?\n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n* How does IBM Cloud Kubernetes Service work?\n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2406672991}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-8109-9900","score":21.393457,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":21.393457,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_04340-57846-59619","score":19.807447,"text":"\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01329-59746-61590","score":19.730925,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_07578-368912-370964","score":19.243021,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-368886-370938","score":19.243021,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01410-2747-3497","score":18.75594,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01535-1902-3811","score":18.595762,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":18.518421,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01329-14955-16723","score":18.457264,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-8109-9900","score":18.198503,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":18.198503,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01410-2747-3497","score":17.152872,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01329-59746-61590","score":17.091204,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01329-14955-16723","score":17.044107,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_07578-368912-370964","score":16.866093,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-368886-370938","score":16.866093,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01442-1679-3832","score":16.693851,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":16.632105,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01329-58331-60199","score":16.401173,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":23.391325,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":23.018883,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":19.413004,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01535-1902-3811","score":19.360037,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-1902-3785","score":19.295666,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-6329-8623","score":19.201982,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":19.201982,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01535-4-2366","score":18.591026,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":18.591026,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01447-1492-3786","score":18.566069,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13149-5520-7284","score":16.666187,"text":"\nNote: If you want to build and push the application to your own container registry you can use the Docker CLI to do so. The Dockerfile is provided in the repository and images can be pushed to the Container Registry or any other container registry.\n\n\n\n1. Define an environment variable named MYAPP and set the name of the application by replacing the placeholder with your initials:\n\nexport MYAPP=<your-initials>kubenodeapp\n2. Identify your cluster:\n\nibmcloud ks cluster ls\n3. Initialize the variable with the cluster name:\n\nexport MYCLUSTER=<CLUSTER_NAME>\n4. Initialize the kubectl cli environment:\n\nibmcloud ks cluster config --cluster $MYCLUSTER\n\nMake sure the CLI is configured for the region and resource group where your created your cluster using ibmcloud target -r <region> -g <resource_group>. For more information on gaining access to your cluster and to configure the CLI to run kubectl commands, check the [CLI configure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_installcs_cli_configure) section\n5. You can either use the default Kubernetes namespace or create a new namespace for this application.\n\n\n\n1. If you want to use the default Kubernetes namespace, run the below command to set an environment variable:\n\nexport KUBERNETES_NAMESPACE=default\n2. If you want to create a new Kubernetes namespace, follow the steps mentioned under [Copying an existing image pull secret](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-registrycopy_imagePullSecret) and [Storing the image pull secret in the Kubernetes service account for the selected namespace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-registrystore_imagePullSecret) sections of the Kubernetes service documentation. Once completed, run the below command:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-kubernetes"},{"document_id":"ibmcld_16390-1728-3821","score":11.9902,"text":"\nAny action can be shown as a suggestion, unless its Ask clarifying question setting is set to Off. For more information about the Ask clarifying question setting, see [Asking clarifying questions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question).\n\nTo configure suggestions, complete the following steps:\n\n\n\n1. Open the Suggestions tab.\n\nSuggestions are enabled automatically for new web chat integrations. If you don't want to use suggestions, toggle the switch to Off.\n2. In the Include a connection to support section, specify when you want an option to connect with support to be included in the list of suggestions. You can specify Always, Never, or After one failed attempt.\n\nAfter one failed attempt: Adds the option to the list only if the customer reached a node with an anything_else condition in the previous conversation turn or reaches the same action for a second time in succession.\n3. In the Option label field, type the text of the message that requests help from support. This message is shown as the label for the support option, which is included in the Suggestions window under the circumstances you specified in the previous step. If the customer clicks this option, the same message is sent to the assistant.\n\nThe message you specify should trigger an action that gives customers a way to connect with support. By default, the message Connect with agent is used. If your web chat is integrated with a contact center platform, this message initiates a transfer to a human agent. (For more information about integrating with a contact center, see [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa).)\n\nIf your web chat is not integrated with a contact center, specify a message that helps your customers reach whatever form of support you do offer. If you offer a toll-free support line, you might add Get the support line phone number. Or if you offer an online support request form, you might add Open a support ticket.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions"},{"document_id":"ibmcld_16242-7-2224","score":11.596484,"text":"\nResponse modes \n\nIBM Cloud\n\nYou can choose a response mode for each action to set how it behaves. The modes are clarifying and confident.\n\nClarifying mode: Start here. In the clarifying mode, your assistant is eager to ask questions so you can ensure that your customer gets to the action they need. An assistant is more likely to ask questions to be sure an action matches what a customer is asking. A new or untested action gets the training that it needs.\n\nConfident mode: Take the next step. After you use analytics to improve your assistant, use the confident mode. Your assistant solves customer issues with authority and accuracy. An assistant is less likely to ask questions and is more likely to trigger actions that match. Use confident mode after you test and train actions.\n\nResponse modes are a beta feature that is available for evaluation and testing purposes on IBM Cloud only.\n\n\n\n Settings \n\nSettings for the two modes are in the global settings. For more information, see [Global settings for actions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings).\n\nYou can choose what mode to use when you create a new action. Clarifying mode is the default and is designed for use with new, untested actions that need training.\n\nThe settings are:\n\nClarify when one action matches: If an assistant prioritizes one action that it thinks matches the customer's request, it can clarify the match by asking the customer to confirm. This clarification helps you ensure that the action is the right one and allows the customer to give input before proceeding. For example, if the assistant thinks that a single action named Pay Bill is the right one, it can clarify the choice by asking the customer Did you mean: Pay Bill.\n\nClarify when more than one action matches: When your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to use, your assistant shows a list of the possible actions to the customer and asks the customer to pick the right one.\n\nOffer support option when asking a clarifying question: The assistant can include a choice to connect to other support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes"},{"document_id":"ibmcld_16312-7-1935","score":11.581729,"text":"\nGlossary \n\n\n\nGlossary\n\n Term Definition \n\n Action Actions represent the tasks or questions that your assistant can help customers with. Each action has a beginning and an end, making up a conversation between the assistant and a customer. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview). \n Ask clarifying question A feature that enables the assistant to ask customers to clarify (disambiguate) their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question). \n Assistant Container for your actions, channels, and integrations. You add actions and at least one channel to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview). \n Change conversation topic A feature that gives the user the power to direct the conversation. It allows digressions and prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-change-topic). \n Channel The location where your assistant interacts with your users, for example, over the phone, on a website, or in Slack. At least one channel is required for every assistant. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant). \n Completion Measures how often within a given time period users reach the end step of an action. [Learn more](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-action-completioncomplete-reasons). \n Content The conversation logic and words that are used to respond to your customer. Content is required for every assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-glossary"},{"document_id":"ibmcld_16268-7-2150","score":10.505757,"text":"\nUsing autolearning to improve assistant responses \n\nIBM Cloud\n\nUse autolearning to enable your assistant to learn from interactions with your customers and improve responses.\n\nWhen customers interact with your assistant, they often make choices. Your assistant can learn from these user decisions.\n\nFor example, a customer might ask a question that the assistant isn't sure it understands. The assistant asks a clarifying question so the customer can choose the right action from a list. If customers most often click the same action (option #2, for example), your assistant can learn that option #2 is the best answer.\n\nNext time, the assistant can list option #2 as the first choice, so customers can get to it more quickly. If the pattern persists over time, it can change its behavior even more. Your assistant can return option #2 immediately, rather than asking a clarifying question.\n\nAs your assistant learns over time, your customers get the best answer more often and in fewer clicks.\n\n\n\n How autolearning works \n\nBefore your assistant can learn from customer behavior, it must observe a significant amount of real conversation data. The conversations take place in a channel such as the web chat, or in a custom application.\n\nLogs of conversations and user decisions from your live environment are the data source for observation. Your assistant analyzes the logs to gain insights. (It doesn't watch real-time clicks during a conversation.)\n\nWhen the assistant observes enough real conversation data from the live environment, it gains insights to help improve your assistant, providing a better customer experience.\n\nWhen you publish your assistant to the live environment, autolearning starts training the assistant.\n\n\n\n\n\n Applying autolearning \n\nYou can apply autolearning when the following conditions are met:\n\n\n\n* Ask clarifying questions is enabled in global settings. For more information, see [Asking clarifying questions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question).\n* You publish a version of your assistant to the live environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-autolearn"},{"document_id":"ibmcld_01130-2647-4112","score":10.478817,"text":"\nAvro has support for a wide range of data types, including primitive types (null, Boolean, int, long, float, double, bytes, and string) and complex types (record, enum, array, map, union, and fixed).\n\nZoom\n\n![Avro format diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry3.svg)\n\nAvro message format\n\n\n\n\n\n Serialization and deserialization \n\nA producing application uses a serializer to produce messages that conform to a specific schema. As mentioned earlier, the message contains the data in Avro format, together with the schema identifier.\n\nA consuming application then uses a deserializer to consume messages that were serialized by using the same schema. When a consumer reads a message that is sent in Avro format, the deserializer finds the identifier of the schema in the message, and retrieves the schema from the Schema Registry to deserialize the data.\n\nThis process provides an efficient way of ensuring that data in messages conforms to the required structure.\n\nThe Event Streams Schema Registry supports the [Kafka AVRO serializer and deserializer](https:\/\/github.com\/confluentinc\/schema-registry\/tree\/master\/avro-serializer).\n\nZoom\n\n![Serialization and deserialization diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry3.svg)\n\nSerializer and deserializer\n\nZoom\n\n![Compatibility and versions diagram.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-ES_schema_registry"},{"document_id":"ibmcld_16390-7-2217","score":10.035015,"text":"\nConfiguring suggestions \n\nSuggestions give your customers a way to try something else when the current exchange with the assistant isn't delivering what they expect. A question mark icon ![Question mark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/question-mark.png) is displayed in the web chat that customers can click at any time to see other topics that might be of interest or, if configured, to request support. Customers can click a suggested topic to submit it as input or click the X icon to close the suggestions list.\n\nIf customers select a suggestion and the response is not helpful, they can open the suggestions list again to try a different suggestion. The input generated by the first choice is submitted and recorded as part of the conversation. However, any contextual information that is generated by the initial suggestion is reset when the subsequent suggestion is submitted.\n\nThe suggestions are shown automatically in situations where the customer might otherwise become frustrated. For example, if a customer uses different wording to ask the same question multiple times in succession, and the same action is triggered each time, then related topic suggestions are shown in addition to the triggered action's response. The suggestions that are offered give the customer a quick way to get the conversation back on track.\n\nThe suggestions list is populated with actions that are relevant in some way to the matched action. The actions are ones that the AI model considered to be possible alternatives, but that didn't meet the high confidence threshold that is required for an action to be listed as a disambiguation option. Any action can be shown as a suggestion, unless its Ask clarifying question setting is set to Off. For more information about the Ask clarifying question setting, see [Asking clarifying questions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-ask-clarifying-question).\n\nTo configure suggestions, complete the following steps:\n\n\n\n1. Open the Suggestions tab.\n\nSuggestions are enabled automatically for new web chat integrations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions"},{"document_id":"ibmcld_16359-8409-10354","score":10.020658,"text":"\nYou can change it to something else, such as I need something else or These aren't what I want. Or, you can remove the text to omit offering this choice. \n\n\n\n3. If you enable response modes, you can modify this text:\n\n\n\nResponse modes settings\n\n Field Default text Description \n\n One action matches Something else If an assistant prioritizes one action that it thinks matches the customer need, it can clarify the match by asking the customer to confirm. This choice accompanies the single action in case the customer needs something else. You can change it to something else, such as I need something else or This isn't what I want. \n Connection to support Connect to support The assistant can include a choice to connect to other support in the list of clarifying questions. If the customer picks this choice, the assistant uses your Fallback action. You can change it to something else, such as Talk to a live agent or Search for the answer. \n\n\n\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to apply the customizations. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Disabling clarifying questions \n\nYou can disable clarifying questions for all actions.\n\nTo disable clarification for all actions:\n\n\n\n1. From the Actions page of the assistant, click Global settings![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. On the Clarifying questions tab, ensure that the Response modes switch is set to Off.\n3. Set the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_16243-1218-3072","score":10.018068,"text":"\n* [Upload\/Download](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-upload-download)\n\n\n\n\n\n Clarifying questions \n\nOn the Clarifying questions tab, you can customize how an action asks clarifying questions.\n\nIn the Ask clarifying questions section, you can:\n\n\n\n* Enable or disable if your assistant disambiguates (asks a clarifying question).\n* Modify the text that your assistant uses to introduce the clarification list or when no action matches.\n* Enable or disable response modes, and modify the text that your assistant uses with a response mode. If you enable response modes, you can use the Customize modes section to choose a response mode for each action to set how it behaves.\n\n\n\nFor more information, see [Customizing clarifying questions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-disambiguation-config) and [Response modes](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-response-modes).\n\n\n\n\n\n Change conversation topic \n\nThe Change conversation topic feature enables your assistant to handle digressions, dynamically responding to the user by changing the conversation topic as needed. For more information, see [Allowing your customers to change the topic of the conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-change-topic).\n\nIf necessary, you can disable changing the topic for all actions:\n\n\n\n1. On the Change conversation topic tab, set the switch to Off.\n2. Click Save, and then click Close.\n\n\n\n\n\n Allow change of topic between actions and dialog \n\nIf you are using actions and dialog, you can ensure that customers can change topics between an action and a dialog node.\n\nThis setting is available if you activate dialog in Assistant settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settings"},{"document_id":"ibmcld_16359-9997-12076","score":9.90517,"text":"\nSet the Enable disambiguation switch to Off.\n4. Click Save, and then click Close.\n5. Publish a new version of your assistant to the live environment to disable clarification. For more information, see [Publishing your content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish).\n\n\n\n\n\n\n\n Excluding an action from clarifying questions \n\nYou can also prevent a single action from being used in a clarifying question. The effect of this choice depends on the confidence score for the action that you exclude.\n\nIf the action has the highest confidence score for a customer's question, no clarifying question is asked, and the action is triggered.\n\nIf the action doesn't have the highest confidence score, the action is excluded from the list of choices in the clarifying question.\n\nFor more information about confidence scores, see [Confidence scoring](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-confidence-scoring).\n\nTo exclude an action from clarification:\n\n\n\n1. From the action editor, click the Action settings icon ![Gear icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/settings.svg).\n2. In Action Settings, toggle the Ask clarifying question switch to Off.\n\n\n\n\n\n\n\n\n\n Coordinating how multiple actions start \n\nAs you work on your assistant, it's a good idea to coordinate customer phrase examples across multiple actions. It's important to distinguish how each action is triggered. When a user enters a question or request, the phrase is evaluated across all the Customer starts with examples in every action. If two actions have similar phrase examples, then the wrong action might get triggered by your user's question.\n\n\n\n Confidence scoring \n\nBehind the scenes, Watson Assistant determines a confidence score for each phrase. The score is absolute, meaning that a confidence score is assigned based on a predetermined scale, and not relative to other customer phrases. This approach adds flexibility in case multiple questions or requests are detected in a single user input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01388-7-1807","score":21.921871,"text":"\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https:\/\/cloud.ibm.com\/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01387-13496-15060","score":21.37797,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-13470-15034","score":21.37797,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":20.55866,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-8075-10005","score":20.55866,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_16729-71418-73421","score":20.438328,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01388-6772-8440","score":20.390053,"text":"\nCreate a second policy that grants the Reader and Writer roles on namespace_c to User B by running the following command.\n\nibmcloud iam user-policy-create <user.b@example.com> --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_c --roles Reader,Writer\n\nThis command adds two roles to the same resource in the same policy.\n\n\n\n4. Push images into namespace_a and namespace_b.\n\n\n\n1. Pull the hello-world image by running the following command.\n\ndocker pull hello-world\n2. Tag the image to namespace_a by running the following command, where <registry_region> is the name of your [IBM Cloud Container Registry region](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions), for example us-south.\n\ndocker tag hello-world <registry_region>.icr.io\/namespace_a\/hello-world\n3. Tag the image to namespace_b by running the following command.\n\ndocker tag hello-world <registry_region>.icr.io\/namespace_b\/hello-world\n4. Log in to IBM Cloud Container Registry by running the [ibmcloud cr login](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_login) command.\n\nibmcloud cr login\n\nIBM Cloud Container Registry supports other clients as well as Docker. To log in by using other clients, see [Accessing your namespaces interactively](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_interactive).\n\nIf you have a problem when you try to log in, see [Why can't I log in to Container Registry?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-login) for assistance.\n5. Push the image to namespace_a by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01471-37693-39572","score":20.363537,"text":"\nYou can use the new region by using the domain name jp.icr.io.\n\nFor more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n 21 February 2019 \n\nAutomating access to your namespaces\n: Using tokens to automate pushing and pulling Docker images to and from your namespaces is deprecated. You must now use API keys to automate access to your Container Registry namespaces so that you can push and pull images.\n\nFor more information, see [Creating a user API key manually](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_user_apikey_create).\n\n\n\n\n\n 8 January 2019 \n\nEnd of support for Vulnerability Advisor API version 2\n: Vulnerability Advisor\u2019s API version 2 is deprecated and is no longer usable. Use version 3 of the API, see [Vulnerability Advisor for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va).\n\n\n\n\n\n 4 October 2018 \n\nManaging user access\n: Use IBM Cloud Identity and Access Management (IAM) to control access by users in your account to Container Registry. When IAM access policies are enabled for your account in Container Registry, every user that accesses the service in your account must be assigned an IAM\n\naccess policywith an IAM user role defined. That policy determines the role that the user has within the context of the service, and what actions the user can perform.\n\nFor more information, see [Managing IAM access with Cloud Identity and Access Management](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam), [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser), and [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n\n\n 7 August 2018 \n\nExemption policies available in Vulnerability Advisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_05349-3936-5607","score":20.262075,"text":"\nDeploy an application that uses an image in a container registry with the CLI with the ibmcloud ce app create command.\n\nBefore you begin\n\n\n\n* Set up your [Code Engine CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-install-cli) environment.\n* [Create and work with a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project).\n\n\n\nBefore you can work with a Code Engine application that references an image in a private registry, you must first add access to the registry, pull the image, and then deploy it.\n\n\n\n1. To pull images from a private registry, you must first create a private registry. For example, to create a private Docker Hub registry, see [Docker Hub documentation](https:\/\/docs.docker.com\/docker-hub\/repos\/). After you create a private registry, [push an image to it](https:\/\/docs.docker.com\/docker-hub\/repos\/pushing-a-docker-container-image-to-docker-hub). You can also set up an access token. By using an access token, you can more easily grant and revoke access to your Docker Hub account without requiring a password change. For more information about access tokens and Docker Hub, see [Managing access tokens](https:\/\/docs.docker.com\/docker-hub\/access-tokens\/).\n2. Add access to your private registry to pull images. To add access to a private registry with the CLI, use the [ibmcloud ce secret create --format registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) command to create a registry secret. For example, the following command creates registry access to a Docker Hub registry called privatedocker that is at 'https:\/\/index.docker.io\/v1\/' and uses your username and password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-app-private"},{"document_id":"ibmcld_01377-4-1879","score":19.911663,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01484-4131-5923","score":16.484013,"text":"\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace&interface=ui"},{"document_id":"ibmcld_01477-4118-5910","score":16.484013,"text":"\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace"},{"document_id":"ibmcld_10805-8395-9992","score":15.519863,"text":"\nBefore you can create entities in the namespace, you must set your CLI context to the namespace by targeting it.\n\nibmcloud fn property set --namespace <namespace_name_or_id>\n\n\n\nAfter you set a property, such as the --namespace property, it is retained until you manually unset it. If you want to switch between IAM namespaces or between Cloud Foundry and IAM namespaces, you must unset the namespace property and then reset it. For more information, see [ibmcloud fn property set](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_prop_set).\n\n\n\n\n\n Creating a namespace with the API \n\nCreate your IAM-managed namespace with the API.\n\n\n\n1. Create an IAM-enabled namespace.\n\ncurl --request POST --url 'https:\/\/jp-tok.functions.cloud.ibm.com\/api\/v1\/namespaces' --header 'accept: application\/json' --header 'authorization: <IAM_token>' --data '{\"description\":\"string\",\"name\":\"string\",\"resource_group_id\":\"string\",\"resource_plan_id\":\"string\"}'\n\n| <IAM_token> | Your IBM Cloud Identity and Access Management (IAM) token. To retrieve your IAM token, run ibmcloud iam oauth-tokens. | | -n <name> | The name of the namespace. | | -n <resource_group_id> | The ID of the resource group that you want to create the namespace in. To see resource group IDs, run ibmcloud resource groups. | | -n <resource_plan_id> | The ID of the resource plan, such as functions-base-plan | | -n <description> | Optional: Add a description to the namespace, such as which kind of actions or packages it will contain. |\n\nThe following example shows sample output from the previous command.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_10805-7233-8822","score":14.998503,"text":"\nibmcloud fn namespace create <namespace_name> [--description <\"description of your namespace\">]\n\n| <namespace_name> | The display name for the IAM-based namespace. | | -n <description> | Optional: Add a description to the namespace, such as which kind of actions or packages you plan to create. If your description is longer than one word, it must be in quotations. | | --description <description> | Optional: Add a description to the namespace, such as which kind of actions or packages you plan to create. If your description is longer than one word, it must be in quotations. |\n\nThe following example shows sample output from the namespace create command.\n\nok: created namespace myNamespace\n3. Verify that your new namespace is created.\n\nibmcloud fn namespace get <namespace_name_or_id> --properties\n\nThe following example shows sample output from the namespace get command.\n\nDetails of namespace: myNamespace\nDescription: short description\nResource Plan Id: functions-base-plan\nLocation: jp-tok\nID: 05bae599-ead6-4ccb-9ca3-94ce8c8b3e43\n\nYou can also list all namespaces, including IAM-based and Cloud Foundry-based namespaces:\n\nibmcloud fn namespace list\n4. Before you can create entities in the namespace, you must set your CLI context to the namespace by targeting it.\n\nibmcloud fn property set --namespace <namespace_name_or_id>\n\n\n\nAfter you set a property, such as the --namespace property, it is retained until you manually unset it. If you want to switch between IAM namespaces or between Cloud Foundry and IAM namespaces, you must unset the namespace property and then reset it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_13880-1458-3206","score":13.171421,"text":"\n* Set up automated, serverless collection of GitHub traffic statistics\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Code Engine plugin,\n* IBM Cloud\u00ae Container Registry plugin,\n\n\n\n* a GitHub account.\n\n\n\nYou can run the sections requiring a shell in the [IBM\u00ae Cloud Shell](https:\/\/cloud.ibm.com\/docs\/cloud-shell?topic=cloud-shell-getting-started).\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\n\n\n\n\n Step 1: Service and Environment Setup (shell) \n\nIn this section, you set up the needed services and prepare the environment. All of this can be accomplished from the shell environment (terminal).\n\n\n\n1. If you are not logged in, use ibmcloud login or ibmcloud login --sso to log in interactively.\n2. St the resource group and region by running ibmcloud target command.\n\nRESOURCE_GROUP_NAME=Default\nREGION=us-south\nibmcloud target -r $REGION -g $RESOURCE_GROUP_NAME\n3. Create a Db2 on Cloud instance with the free (lite) plan and name it ghstatsDB.\n\nibmcloud resource service-instance-create ghstatsDB dashdb-for-transactions free $REGION\n4. Create an instance of the App ID service. Use ghstatsAppID as name and the Graduated tier plan.\n\nibmcloud resource service-instance-create ghstatsAppID appid graduated-tier $REGION\n5. Add a new namespace ghstats to the IBM Cloud\u00ae Container Registry. You are going to use it for referencing container images. There is one global registry as well as regional registries. Use the global registry.\n\nibmcloud cr region-set global\nNAMESPACE=ghstatsYourInitials\nibmcloud cr namespace-add $NAMESPACE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-serverless-github-traffic-analytics"},{"document_id":"ibmcld_01409-2859-4626","score":13.042911,"text":"\nGET \/api\/v1\/namespaces\/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH \/api\/v1\/namespaces\/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace. DELETE \/api\/v1\/namespaces\/{namespace} container-registry.namespace.delete container-registry.namespace.delete \n\n\n\n\n\n\n\n Plan API methods \n\n\n\nTable 5. Plans\n\n Action Method IAM ACTION AT ACTION \n\n Get plans for the targeted account. GET \/api\/v1\/plans container-registry.plan.get container-registry.plan.get \n Update plans for the targeted account. PATCH \/api\/v1\/plans container-registry.plan.set container-registry.plan.set \n\n\n\n\n\n\n\n Quota API methods \n\n\n\nTable 6. Quotas\n\n Action Method IAM ACTION AT ACTION \n\n Get quotas for the targeted account. GET \/api\/v1\/quotas container-registry.quota.get container-registry.quota.get \n Update quotas for the targeted account. PATCH \/api\/v1\/quotas container-registry.quota.set container-registry.quota.set \n\n\n\n\n\n\n\n Retention API methods \n\n\n\nTable 7. Retentions\n\n Action Method IAM ACTION AT ACTION \n\n List retention policies for all namespaces in the targeted IBM Cloud account. GET \/api\/v1\/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST \/api\/v1\/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST \/api\/v1\/retentions\/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_10773-5740-7643","score":12.775652,"text":"\nYou can set an access policy for a service ID by using the IAM console.\n\n\n\n1. Open the [IAM Service ID page](https:\/\/cloud.ibm.com\/iam\/serviceids).\n2. In the Service IDs list, select your Cloud Functions namespace.\n3. On the Manage page, click Access policies, then click Assign access.\n4. Next, select an Access Type. You can choose from the following options.\n\n\n\n* Assign access within a resource group: Use this option to grant your Cloud Functions service ID access to a resource group.\n* Assign access to resources: Use this option to grant your Cloud Functions service ID access to a specific resource, like an instance of IBM Cloud Object Storage.\n* Assign access to account management services: Use this option to grant your Cloud Functions service ID access to account management services such as billing, user management, and more.\n\n\n\n\n\n\n\n\n\n Setting an access policy for your Cloud Functions service ID through the CLI \n\nSet an access policy for a service ID by using the CLI.\n\nCopy the following command. Replace <namespace_service_ID> with the name of your Cloud Functions namespace. Replace <IAM_role1,IAM_role2> with the IAM roles you want to assign to your namespace. Replace <other_service_name> with the name of the IBM service you want Cloud Functions to work with. Replace <other_service_GUID> with the GUID of the IBM service instance.\n\nibmcloud iam service-policy-create <namespace_service_ID> --roles <IAM_role1,IAM_role2> --service-name <other_service_name> --service-instance <other_service_GUID>\n\n\n\nTable 1. Understanding the command components\n\n Option Description \n\n <namespace_service_ID> The service ID for the namespace. To see all service IDs, run ibmcloud iam service-ids. \n <IAM_role> The type of IAM service access role that the action must have to use the target service. To see the supported roles for the other service, run ibmcloud iam roles --service SERVICE_NAME.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-iam"},{"document_id":"ibmcld_10273-4400-6424","score":11.739719,"text":"\n--output OUTPUT\n: Optional: Prints the command output in JSON format.\n\n--domain-provider PROVIDER\n: Required. The external DNS provider type. Specify --cis-ext.\n\n--secret-namespace NAMESPACE\n: Optional. The namespace that the domain TLS secret is created in. If no namespace is specified, the secret is created in the default namespace.\n\n--domain-zone ZONE\n: Optional. The Domain ID for your IBM Cloud Internet Services instance. This is a GUID value.\n\n\n\n\n\n\n\n Setting up domains from other external providers \n\nTo add an Akamai or Cloudflare domain to your cluster, you must first apply credentials for the external provider to your cluster. Then, you can either add a domain that already exists in your external provider account, or you can create a new domain that registers with both your IBM Cloud and external provider accounts.\n\n\n\n Set up credentials for your provider \n\nTo use a domain that is registered with Akamai or Cloudflare, you must add the external provider credentials to your cluster. Red Hat OpenShift on IBM Cloud uses these credentials to provision or access a domain from the external provider on your behalf. You can only add one set of credentials to your cluster.\n\nDifferent providers might require different credentials, such as access tokens or secrets. Red Hat OpenShift on IBM Cloud does not provide the credentials; you must acquire them from the external provider.\n\n\n\n Add Akamai credentials \n\nAkamai\n\nRun the command to add Akamai provider credentials to your cluster.\n\nNote that registering credentials for Akamai requires the READ-WRITE permission for \/config-dns endpoint in your external Akamai account.\n\nibmcloud oc ingress domain credential set akamai --cluster CLUSTER --access-token TOKEN --client-secret SECRET --client-token TOKEN --host HOST --zone AKAMAI_ZONE [-q]\n\nThis command is only required when creating an external domain with the Akamai provider.\n\n-c, --cluster CLUSTER\n: Required. The name or ID of the cluster where you want to add the credentials.\n\n--access-token TOKEN","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ingress-domains"},{"document_id":"ibmcld_13149-1452-3205","score":11.616748,"text":"\nOptionally build the application to produce a container image.\n3. Optionally the image is pushed to a namespace in the IBM Cloud Container Registry.\n4. The application is deployed to a Kubernetes cluster.\n5. Users access the application.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* kubectl to interact with Kubernetes clusters,\n* Helm 3 to deploy charts.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.\n\nIn addition, make sure you:\n\n\n\n* [set up a registry namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_setup)\n* and [understand the basics of Kubernetes](https:\/\/kubernetes.io\/docs\/tutorials\/kubernetes-basics\/).\n\n\n\n\n\n\n\n Step 1: Create a Kubernetes cluster \n\nKubernetes Service delivers powerful tools by combining Docker and Kubernetes technologies, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts.\n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nOpen the [Kubernetes clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-kubernetes"},{"document_id":"ibmcld_05866-4400-6420","score":11.596885,"text":"\n--output OUTPUT\n: Optional: Prints the command output in JSON format.\n\n--domain-provider PROVIDER\n: Required. The external DNS provider type. Specify --cis-ext.\n\n--secret-namespace NAMESPACE\n: Optional. The namespace that the domain TLS secret is created in. If no namespace is specified, the secret is created in the default namespace.\n\n--domain-zone ZONE\n: Optional. The Domain ID for your IBM Cloud Internet Services instance. This is a GUID value.\n\n\n\n\n\n\n\n Setting up domains from other external providers \n\nTo add an Akamai or Cloudflare domain to your cluster, you must first apply credentials for the external provider to your cluster. Then, you can either add a domain that already exists in your external provider account, or you can create a new domain that registers with both your IBM Cloud and external provider accounts.\n\n\n\n Set up credentials for your provider \n\nTo use a domain that is registered with Akamai or Cloudflare, you must add the external provider credentials to your cluster. IBM Cloud Kubernetes Service uses these credentials to provision or access a domain from the external provider on your behalf. You can only add one set of credentials to your cluster.\n\nDifferent providers might require different credentials, such as access tokens or secrets. IBM Cloud Kubernetes Service does not provide the credentials; you must acquire them from the external provider.\n\n\n\n Add Akamai credentials \n\nAkamai\n\nRun the command to add Akamai provider credentials to your cluster.\n\nNote that registering credentials for Akamai requires the READ-WRITE permission for \/config-dns endpoint in your external Akamai account.\n\nibmcloud ks ingress domain credential set akamai --cluster CLUSTER --access-token TOKEN --client-secret SECRET --client-token TOKEN --host HOST --zone AKAMAI_ZONE [-q]\n\nThis command is only required when creating an external domain with the Akamai provider.\n\n-c, --cluster CLUSTER\n: Required. The name or ID of the cluster where you want to add the credentials.\n\n--access-token TOKEN","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ingress-domains"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10642-1365-3347","score":24.077642,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05754-3185-5238","score":23.649794,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10189-3187-5240","score":23.617498,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_06209-1393-3390","score":23.573595,"text":"\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master. Additionally, your worker nodes can be only up to two versions behind the master version (n-2). First, [update your master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate_master) to the latest Kubernetes version. Then, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10394-1469-2994","score":23.099926,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-7-1817","score":22.975328,"text":"\nUpdating clusters, worker nodes, and cluster components \n\nYou can install updates to keep your Kubernetes clusters up-to-date in IBM Cloud\u00ae Kubernetes Service.\n\n\n\n Updating the Kubernetes master \n\nPeriodically, the Kubernetes project releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). Updates can affect the Kubernetes API server version or other components in your Kubernetes master. IBM updates the patch version, but you must update the master major and minor versions.\n\n\n\n About updating the master \n\nHow do I know when to update the master?\n: You are notified in the IBM Cloud console and CLI when updates are available, and can also check the [supported versions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) page.\n\nHow many versions behind the latest can the master be?\n: IBM generally supports three versions of Kubernetes at a time. You can update the Kubernetes API server only to the next version ahead of its current version (n+1). Additionally, your worker nodes can be up to two versions behind the master version (n-2).\n\nFor example, if your current Kubernetes API server version is 1.18 (n) and you want to update to 1.20, you must first update to 1.19 (n+1) and then to 1.20 (n+2). Next, you can update the worker nodes up to two version ahead, such as 1.18 to 1.20 (n+2).\n\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10394-7-1848","score":22.959354,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-2829-4687","score":22.696695,"text":"\nIn any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/\/images\/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\nTo update the Kubernetes master major or minor version:\n\n\n\n1. Review the [Kubernetes changes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) and make any updates marked Update before master.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10246-15672-17685","score":22.55422,"text":"\nDuring the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Disabling remote health reporting \n\nOpenShift Container Platform collects anonymized health reports about your cluster through a [telemetry component that is enabled by default](https:\/\/docs.openshift.com\/container-platform\/4.11\/support\/remote_health_monitoring\/about-remote-health-monitoring.html) in your Red Hat OpenShift on IBM Cloud cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_10395-7-1827","score":22.401436,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05612-7-1934","score":25.539572,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_05618-7-2074","score":25.300388,"text":"\nKubernetes version 1.27 CIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.27. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark-use).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127"},{"document_id":"ibmcld_05617-7-2046","score":25.224327,"text":"\nVersion 1.26 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.26. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126"},{"document_id":"ibmcld_05614-7-1955","score":24.83829,"text":"\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_05611-7-1955","score":24.837843,"text":"\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-120"},{"document_id":"ibmcld_05613-7-1955","score":24.820518,"text":"\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"},{"document_id":"ibmcld_05616-7-1945","score":24.801146,"text":"\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05615-7-1945","score":24.786716,"text":"\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05610-7-1993","score":24.503548,"text":"\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119"},{"document_id":"ibmcld_05608-3099-5358","score":24.075449,"text":"\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure pod security policies for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05702-3089-5193","score":19.972628,"text":"\nkube-proxy uses Iptables rules, a Linux kernel feature, to direct requests to the pod behind a service equally, independent of pods' in-cluster IP addresses and the worker node that they are deployed to.\n\nFor example, apps inside the cluster can access a pod behind a cluster service by using the service's in-cluster IP or by sending a request to the name of the service. When you use the name of the service, kube-proxy looks up the name in the cluster DNS provider and routes the request to the in-cluster IP address of the service.\n\nIf you use a service that provides both an internal cluster IP address and an external IP address, clients outside of the cluster can send requests to the service's external public or private IP address. kube-proxy forwards the requests to the service's in-cluster IP address and load balances between the app pods behind the service.\n\n\n\n\n\n Understanding Kubernetes service types \n\nKubernetes supports four basic types of network services: ClusterIP, NodePort, LoadBalancer, and Ingress. ClusterIP services make your apps accessible internally to allow communication between pods in your cluster only. NodePort, LoadBalancer, and Ingress services make your apps externally accessible from the public internet or a private network.\n\nThe following table compares the features of each network service type.\n\n\n\nCharacteristics of Kubernetes network service types\n\n Characteristics ClusterIP NodePort LoadBalancer (Classic - NLB) LoadBalancer (VPC load balancer) Ingress \n\n Standard clusters Yes Yes Yes Yes Yes \n Externally accessible Yes Yes Yes Yes \n External hostname Yes Yes Yes \n Stable external IP Yes Yes \n HTTP(S) load balancing Yes* Yes* Yes \n TLS termination Yes \n Custom routing rules Yes \n Multiple apps per service Yes \n\n\n\n* An SSL certificate for HTTPS load balancing is provided by ibmcloud ks nlb-dns commands. In classic clusters, these commands are supported for public NLBs only.\n\n\n\n ClusterIP \n\nYou can expose apps only as [ClusterIP services](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/defining-a-service) on the private network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_network_planning"},{"document_id":"ibmcld_10673-13531-14829","score":18.553936,"text":"\nID Name Status Subnet CIDR Addresses ACL Public Gateway VPC Zone\n5f5787a4-f560-471b-b6ce-20067ac93439 vpc-prod-dal1 available 10.240.0.0\/24 183\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-1\ne3c19786-1c54-4248-86ca-e60aab74ed62 vpc-prod-dal2 available 10.240.64.0\/24 183\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-2\n2930a068-51cc-4eca-807b-3f296d0891b4 vpc-prod-dal3 available 10.240.128.0\/24 249\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-3\n\n\n\n* Individual worker node IP addresses: If you have a small number of worker nodes that run only one app and don't need to scale, or if you want to add only one worker node, list all the worker nodes in your cluster and note the Primary IP addresses. Only these worker nodes are added. If you delete the worker nodes or add worker nodes to the cluster, you must update your allowlist accordingly.\n\nibmcloud oc worker ls --cluster <cluster_name_or_ID>\n\n\n\n2. Add the subnet CIDRs or individual worker node IP addresses to your service's allowlist or your on-premises allowlist for outbound traffic.\n3. Repeat these steps for each cluster that you want to allow traffic to or from.\n\n\n\n\n\n\n\n\n\n Updating IAM allowlists for Kubernetes Service IP addresses","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-firewall"},{"document_id":"ibmcld_06260-12518-13816","score":18.471867,"text":"\nID Name Status Subnet CIDR Addresses ACL Public Gateway VPC Zone\n5f5787a4-f560-471b-b6ce-20067ac93439 vpc-prod-dal1 available 10.240.0.0\/24 183\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-1\ne3c19786-1c54-4248-86ca-e60aab74ed62 vpc-prod-dal2 available 10.240.64.0\/24 183\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-2\n2930a068-51cc-4eca-807b-3f296d0891b4 vpc-prod-dal3 available 10.240.128.0\/24 249\/256 allow-all-network-acl-ff537d43-a5a4-4b65-9627-17eddfa5237b - prod us-south-3\n\n\n\n* Individual worker node IP addresses: If you have a small number of worker nodes that run only one app and don't need to scale, or if you want to add only one worker node, list all the worker nodes in your cluster and note the Primary IP addresses. Only these worker nodes are added. If you delete the worker nodes or add worker nodes to the cluster, you must update your allowlist accordingly.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n\n\n\n2. Add the subnet CIDRs or individual worker node IP addresses to your service's allowlist or your on-premises allowlist for outbound traffic.\n3. Repeat these steps for each cluster that you want to allow traffic to or from.\n\n\n\n\n\n\n\n\n\n Updating IAM allowlists for Kubernetes Service IP addresses","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-firewall"},{"document_id":"ibmcld_05595-2977-4795","score":17.585436,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various kubectl commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cbr-tutorial"},{"document_id":"ibmcld_05739-8121-9783","score":17.554285,"text":"\nTo check your auto update settings, run the ibmcloud ks ingress alb autoupdate get command.<br> * ALB OAuth-Proxy add-on: networking.k8s.io\/v1beta1 is compatible with ALB OAuth-Proxy add-on version 2.0.0 only. If you use the ALB OAuth-Proxy add-on you must update the add-on to version 2.0.0 before updating your cluster to 1.22.<br><br><br> \n Unsupported: Service service.alpha.kubernetes.io\/tolerate-unready-endpoints annotation Services no longer support the service.alpha.kubernetes.io\/tolerate-unready-endpoints annotation. The annotation has been deprecated since Kubernetes version 1.11 and has been replaced by the spec.publishNotReadyAddresses field. If your services rely on this annotation, update them to use the spec.publishNotReadyAddresses field instead. For more information on this field, see [DNS for Services and Pods](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/dns-pod-service\/). \n\n\n\n\n\n\n\n Update after master \n\nThe following table shows the actions that you must take after you update the Kubernetes master.\n\n\n\nChanges to make after you update the master to Kubernetes 1.22\n\n Type Description \n\n Endpoint Security Mitigation Kubernetes cluster role system:aggregate-to-edit has removed endpoints permissions as a security mitigation for [CVE-2021-25740](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-25740). If your cluster does not require any customizations to the system:aggregate-to-edit cluster role, besides removing the endpoints permission, allow Kubernetes to reconcile the permissions by running the kubectl annotate --overwrite clusterrole\/system:aggregate-to-edit rbac.authorization.kubernetes.io\/autoupdate=true command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122"},{"document_id":"ibmcld_10067-2911-4724","score":17.182625,"text":"\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cbr-tutorial"},{"document_id":"ibmcld_06279-79845-81330","score":16.998222,"text":"\nList your Kubernetes services and find the name of the LoadBalancer service you want to change.\n\nkubectl get services\n\nExample output.\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nmy-load-balancer LoadBalancer 172.21.77.198 52.118.150.107 8080:32767\/TCP,443:30943\/TCP 5d\n3. Find the VPC load balancer that corresponds with the Kubernetes LoadBalancer service.\n\nVPC load balancer names are in the format kube-<cluster_ID>-<kubernetes_lb_service_UID>. To see your cluster ID, run ibmcloud ks cluster get --cluster <cluster_name>. To see the Kubernetes LoadBalancer service UID, run kubectl get svc <load-balancer-name> -o yaml and look for the metadata.uid field in the output. The dashes (-) are removed from the Kubernetes LoadBalancer service UID in the VPC load balancer name.\n\nibmcloud is load-balancers\n\nExample output.\n\nID Name Family Subnets Is public Provision status Operating status Resource group\nr000-5aaaa11f6-c111-111f-b2e0-1c11aaaaf0dc0 kube-c441c43d02mb8mg00r70-3e25d0b5bf11111111fe4ca3f11111cb Network subnet-1 true active online default Application\n4. Get the Kubernetes LoadBalancer service definition and save the output as a yaml file called my-lb.yaml.\n\nkubectl describe service my-load-balancer -o yaml\n5. Delete the Kubernetes LoadBalancer service. This also deletes the corresponding VPC load balancer.\n\nkubectl delete service my-load-balancer\n6. Update the Kubernetes LoadBalancer service definition file with the subnet or zone changes you want to implement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas"},{"document_id":"ibmcld_10686-79500-81017","score":16.965414,"text":"\nList your Kubernetes services and find the name of the LoadBalancer service you want to change.\n\noc get services\n\nExample output.\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nmy-load-balancer LoadBalancer 172.21.77.198 52.118.150.107 8080:32767\/TCP,443:30943\/TCP 5d\n3. Find the VPC load balancer that corresponds with the Kubernetes LoadBalancer service.\n\nVPC load balancer names are in the format kube-<cluster_ID>-<kubernetes_lb_service_UID>. To see your cluster ID, run ibmcloud ks cluster get --cluster <cluster_name>. To see the Kubernetes LoadBalancer service UID, run oc get svc <load-balancer-name> -o yaml and look for the metadata.uid field in the output. The dashes (-) are removed from the Kubernetes LoadBalancer service UID in the VPC load balancer name.\n\nibmcloud is load-balancers\n\nExample output.\n\nID Name Family Subnets Is public Provision status Operating status Resource group\nr000-5aaaa11f6-c111-111f-b2e0-1c11aaaaf0dc0 kube-c441c43d02mb8mg00r70-3e25d0b5bf11111111fe4ca3f11111cb Network subnet-1 true active online default Application\n4. Get the Kubernetes LoadBalancer service definition and save the output as a yaml file called my-lb.yaml.\n\noc describe service my-load-balancer -o yaml\n5. Delete the Kubernetes LoadBalancer service. This also deletes the corresponding VPC load balancer.\n\noc delete service my-load-balancer\n6. Update the Kubernetes LoadBalancer service definition file with the subnet or zone changes you want to implement. Do not change the name of the LoadBalancer service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"},{"document_id":"ibmcld_05624-7-1883","score":16.662512,"text":"\nAccessing private clusters by using the WireGuard VPN \n\nYou can use the WireGuard VPN to securely connect to Kubernetes clusters with only a private network connection.\n\nBefore you begin, make sure that you have a Kubernetes cluster with a private-only network connection and that the cluster is assigned a private service endpoint.\n\n\n\n1. Create a virtual server instance (VSI) that is connected to the same private network that your Kubernetes cluster runs in. This VSI serves as a jump box for your cluster. For example, if you have a private VPC cluster, make sure that you create the VSI in the same VPC. For more information about creating the VSI, consult your infrastructure provider's documentation. The VSI must meet the following specifications:\n\n\n\n* The VSI must have a minimum of 2 vCPUs, 8 GB memory, and 25 GB of disk space.\n* The VSI must run an operating system that is supported by WireGuard. For example, the steps in this topic were tested on an Ubuntu VSI.\n* You must create an SSH key that is stored on the VSI so that you can connect to your VSI via SSH.\n* You must assign a public IP address to your VSI so that your VSI is accessible over the public network.\n* Your VSI must allow at least the following network traffic. You can optionally open up more network traffic on your VSI if required for the apps that run on your cluster.\n\n\n\n* Inbound TCP traffic on port 22 for SSH connections\n* Inbound UDP traffic on port 51820 for the WireGuard server\n* All outbound traffic\n\n\n\n\n\n2. Log in to your VSI by using the public IP address of the VSI.\n\nssh -i <filepath_to_sshkey> root@<public_IP>\n3. Install the WireGuard server.\n\nThe following steps are specific to VSIs that run Ubuntu. If you run a different Linux distribution, refer to the [WireGuard documentation](https:\/\/www.wireguard.com\/install\/).\n\n\n\n1. Update the Ubuntu operating system.\n\napt update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-access-wireguard"},{"document_id":"ibmcld_12572-26318-27808","score":15.328972,"text":"\n: Resource type on which the tags should be attached (required for Classic Infrastructure resource of type SoftLayer_Hardware, SoftLayer_Network_Application_Delivery_Controller, SoftLayer_Network_Subnet_IpAddress or SoftLayer_Network_Vlan only).\n\n--tag-type value\n: Type of the tag. Only allowed values are: user, service or access (default value : user).\n\n--account-id value\n: The ID of the account that owns the resources to be detached (required if tag-type is set to service).\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n Examples \n\n\n\n* To detach the user tag MyTag from a Kubernetes cluster named MyCluster, first look for the CRN of the cluster you would like to detach the tag from:\n\nibmcloud resource search 'type:k8-cluster AND name:MyCluster'\n\nTake note of the CRN, which is a string similar to the following example:\n\ncrn:v1:bluemix:public:containers-kubernetes:us-south:a\/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::\n* To detach the tag, run the following command:\n\nibmcloud resource tag-detach --tag-names MyTag --resource-id rn:v1:bluemix:public:containers-kubernetes:us-south:a\/a27a4741a57dcf5c965939adb66fe1c7:a46242e638ca47b09f10e9a3cbe5687a::\n* To detach the user tag MyTag to a resource named MyResource:\n\nibmcloud resource tag-detach --tag-name MyTag --resource-name 'MyResource'\n* To detach the user tag MyTag to a classic infrastructure virtual guest named MyVM, first look for the ID of the virtual guest you would like to detach the tag from:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_resource"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04041-14573-16416","score":23.24927,"text":"\n* [Data privacy](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-privacy)\n* [GDPR](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-securityibp-security-kubernetes-gdpr)\n\n\n\n\n\n Kubernetes cluster security \n\nThe best place to start is to learn about the security features of the underlying Kubernetes infrastructure. The open source documentation provides a review of recommended practices for [securing a Kubernetes cluster](https:\/\/Kubernetes.io\/docs\/tasks\/administer-cluster\/securing-a-cluster\/).\n\nIf you are using IBM Cloud, you can review the topic on Security for the [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security) or [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security).\n\n\n\n\n\n Network security \n\nIBM Cloud provides the underlying network, including the networks and routers, over which customers\u2019 VLAN resides. The customer configures their servers and uses gateways and firewalls to route traffic between servers to protect workloads from network threats. Protecting your cloud network by using firewalls and intrusion prevention system devices is imperative for protecting your cloud-based workloads.\n\n\n\n Firewall configuration \n\nKubernetes clusters should be secured by a firewall to protect the network from unauthorized access from internet traffic. By default IBM Cloud Kubernetes service clusters are preconfigured with a Calico network plug-in that secures the public network interface of every worker node in the cluster. By configuring Kubernetes and Calico network policies you can easily control the inbound and outbound network traffic. For more information, see [Controlling traffic with network policies](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-network_policies).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-security"},{"document_id":"ibmcld_13167-13903-15855","score":22.637533,"text":"\nLeave the field for Service account as is to go with the default.\n* Finish by clicking Continue.\n\n\n\n5. Next, click on Access policy. In the list of services, select All Identity and Access enabled services and click Next. Go with All resources, click Next again, then select Viewer, and again click on Next. In the section Roles and actions, select Reader for Service access and Viewer for Platform access. When done, click Next and finally Add.\n6. Review the Summary on the right side, then Create the trusted profile with the shown trust relationship and the listed access privileges. Leave the browser tab open for later.\n\n\n\n[Utilizing an access group to assign access is best practices](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setuplimit-policies). For the sake of simplicity, we opted for assigning read-only access through a direct access policy. The recommendation is to create an access group with assigned privileges, then make the trusted profile a member of it.\n\n\n\n\n\n Step 4: Deploy the app \n\nWith the Kubernetes cluster and the trusted profile in place, it is time to deploy a simple test app. The source code for the app and the configuration is in the [GitHub repository trusted-profile-enterprise-security](https:\/\/github.com\/IBM-Cloud\/trusted-profile-enterprise-security) You don't need it for the deployment, but might be interested in how it works nonetheless.\n\n\n\n1. In the browser tab cluster overview, check that the cluster has been fully deployed. You might want to refresh the browser and check that all checkmarks are green. If this is the case, click on Kubernetes dashboard and a new browser tab opens (Kubernetes dashboard).\n2. In the top left, find the namespace selector and switch to All namespaces.\n3. On the upper right, click on + to create a new resource. Paste the following content into the text form Create from input.\n\napiVersion: v1\nkind: Namespace\nmetadata:\nname: tptest\nlabels:\nname: tptest\n---","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-trusted-profile-for-enterprise-security"},{"document_id":"ibmcld_07507-7174-9217","score":22.42996,"text":"\nFor more information about network isolation, see [FS Cloud Boundary Protection](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection).\n* Not all application models can share infrastructure\n\nShared application infrastructure makes sense only for sets of applications that have similar architectures. For example, sets of applications that use stateless microservices, containers, and managed database services can easily be deployed together. Other applications that are based on VM images with local storage will need separate application infrastructure. It is best practice to identify 2 or 3 common architectural patterns so that a small number of application hosting deployable architectures can be built and used for many applications.\n* Interactions with centralized networking and services\n\n\n\n* Transit gateway\n\n\n\nConnecting the shared infrastructure VPC to the central transit gateway requires a process where both the centralized operations team and the BU operations team coordinate to connect the VPC.\n\n\n\n* Hyper Protect Crypto Services and other centralized services\n\nAuthorizing the connection across accounts requires a process where both the centralized operations team and the BU operations team coordinate to create a service-to-service authorization for the consuming applications.\n\n\n\n* Hosting multiple applications on Kubernetes\n\nRed Hat OpenShift and Kubernetes are designed for efficient hosting of multiple applications. However, it is best practice to leverage Kubernetes names spaces for application isolation and istio for application network ingress and egress controls. The cluster configuration to support an application must be automated, and that automation owned by the shared infrastructure hosting project. However, application owners can provide information to tailor the automation to there needs. Note that application owners should not have permission to modify the configuration of the shared infrastructure directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-infra-account"},{"document_id":"ibmcld_16727-143758-145711","score":22.22759,"text":"\nIt is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n* What is the value of using IBM Blockchain Platform over native Hyperledger Fabric?\n\nHyperledger Fabric is a powerful, versatile, pluggable, open source, distributed ledger technology capable of addressing a wide variety of use cases across many industries. IBM Blockchain Platform is IBM's commercial distribution of Hyperledger Fabric. A key benefit of the platform is that IBM tests the open source code for security vulnerabilities daily and provides 24x7x365 support with SLAs appropriate for production environments. The platform is the commercial distribution of Hyperledger Fabric and includes integrated tools that provide end to end features for developers and network operators to develop, test, operate, monitor, and govern Fabric components by using an intuitive console UI.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-143784-145737","score":22.22759,"text":"\nIt is recommend that you take advantage of the IBM Log Analysis service that allows you to easily parse the logs in real time.\n* Is there a best practice for monitoring my blockchain resources?\n\nYou are responsible for the health monitoring and resource allocation of the blockchain nodes in your Kubernetes cluster. While requests against the nodes are being actively processed, you should be monitoring for spikes in resource consumption to avoid problems. IBM recommends that you configure IBM Cloud Monitoring and set up alerts to track when blockchain nodes are reaching their limits. See the tutorial on [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-getting-started) for more details.\n\nYou should be aware that JavaScript and TypeScript smart contracts require more resources than contracts written in Golang. Therefore, when you are allocating resources to your cluster, it is important to ensure adequate resources are available to your smart contract pods when they are deployed on a channel and during transaction processing. The pods containing the smart contracts will consume as much resources as they need to function.\n* What is the value of using IBM Blockchain Platform over native Hyperledger Fabric?\n\nHyperledger Fabric is a powerful, versatile, pluggable, open source, distributed ledger technology capable of addressing a wide variety of use cases across many industries. IBM Blockchain Platform is IBM's commercial distribution of Hyperledger Fabric. A key benefit of the platform is that IBM tests the open source code for security vulnerabilities daily and provides 24x7x365 support with SLAs appropriate for production environments. The platform is the commercial distribution of Hyperledger Fabric and includes integrated tools that provide end to end features for developers and network operators to develop, test, operate, monitor, and govern Fabric components by using an intuitive console UI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01533-1902-3785","score":21.669718,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-1902-3811","score":21.656202,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_03955-17975-20061","score":21.551292,"text":"\nTwo zones are better than one, but three are recommended for HA to increase the likelihood that the two additional zones can absorb the workload of any single zone failure. When redundant peers from the same organization and channel, and ordering nodes, are spread across multiple zones, a failure in any one zone should not affect the ability of the network to process transactions because the workload will shift to the blockchain nodes in the other zones.\n\nYou can use the IBM Blockchain Platform console to specify the zone where a CA, peer, or ordering node is created. When you deploy a CA, peer, or ordering service (or a single ordering node), check the Advanced deployment option that is labeled Deployment zone selection to see the list of zones that is currently configured for your Kubernetes cluster.\n\nIf you're deploying a CA, peer, or ordering service, you have the option to select the zone from the list of zones available to your cluster or to let your Kubernetes cluster decide for you by leaving the default selected. For a five node ordering service, these nodes will be distributed into multiple zones by default, depending on the relative space available in each zone. You also have the ability to distribute a five node ordering service yourself by unselecting the default option to have the zones chosen for you and distributing these nodes into the zones you have available. If you are deploying a redundant node (that is, another peer when you already have one), it is a best practice to deploy this node into a different zone. You can check which zone the other node was deployed to by opening the tile of the node and looking under the Node location. Alternatively, you can use the APIs to deploy a peer or orderer to a specific zone. For more information on how to do this with the APIs, see [Creating a node within a specific zone](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-apisibp-v2-apis-zone).\n\nThe CA zone selection is only available when the default database type SQLite is used and your cluster is configured with multiple zones.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-ha"},{"document_id":"ibmcld_05608-1309-3624","score":20.74738,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_04041-11998-13927","score":20.596159,"text":"\nFor example, if the default access to a particular resource is the Readers of all organizations, and that access is changed to the Admin of Org1, then only the Admin of Org1 will have access to the resource. Because access to certain resources is fundamental to the smooth operation of a channel, it is highly recommended to make access control decisions carefully. If you decide to limit access to a resource, make sure that the access to that resource is added, as needed, for each organization.\n\nYou can use the blockchain console to select which ACLs to apply to resources on a channel. See this information under [Creating a channel](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network-channels-create) for instructions on how to configure access control for a channel.\n\n\n\n\n\n API authentication \n\nIn order to use the blockchain [APIs](https:\/\/cloud.ibm.com\/apidocs\/blockchain) to create and manage network components, your application needs to be able to authenticate and connect to your network. See this topic on [API Authentication on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-apisibp-v2-apis-authentication)\n\n\n\n\n\n\n\n Best practices for security on the customer Kubernetes cluster \n\nAudience: Tasks in this section are typically performed by Kubernetes infrastructure managers.\n\nThe IBM Blockchain Platform console allows you to deploy and manage nodes on a Kubernetes cluster that you operate. The previous section addressed the security of the console. The following sections detail the best practices you can use to secure your Kubernetes cluster and the nodes of your network:\n\n\n\n* [Kubernetes cluster security](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-securityibp-security-Kubernetes-security)\n* [Network security](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-securityibp-security-Kubernetes-network)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03824-7-1809","score":20.16896,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_04085-7-1799","score":20.107246,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_06038-7-1830","score":14.520895,"text":"\nLocations \n\nYou can deploy IBM Cloud\u00ae Kubernetes Service clusters worldwide. When you create a cluster, its resources remain in the location that you deploy the cluster to. To work with your cluster, you can access the service via a global API endpoint.\n\nZoom\n\n![IBM Cloud Kubernetes Service locations](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/locations.svg)\n\nFigure 1. IBM Cloud Kubernetes Service locations\n\nThis image is an artistic representation and does not reflect actual political or geographic boundaries.\n\n\n\n IBM Cloud Kubernetes Service locations \n\nIBM Cloud resources are organized into a hierarchy of geographic locations. IBM Cloud Kubernetes Service is available in a subset of these locations, including worldwide multizone regions and single zone regions. Other IBM Cloud services might be available globally or within a specific location.\n\nibmcloud ks locations\n\n\n\n How locations are organized \n\nThe following image is used as an example to explain how IBM Cloud Kubernetes Service locations are organized. For more information, see [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n\nZoom\n\n![Organization of IBM Cloud Kubernetes Service locations](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_regions_hierarchy.png)\n\nFigure 1. Organization of IBM Cloud Kubernetes Service locations\n\n\n\nOrganization of IBM Cloud Kubernetes Service locations.\n\n Type Example Description \n\n Geography North America (na) An organizational grouping that is based on geographic continents. \n Country Canada (ca) The location's country within the geography. \n Metro For example, Dallas (dal). The name of a city where 1 or more data centers are located.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zones"},{"document_id":"ibmcld_05639-2621-4201","score":13.642004,"text":"\nlinear: '{\"coresPerReplica\":256,\"nodesPerReplica\":16,\"preventSinglePointFailure\":true}'\nkind: ConfigMap\nmetadata:\n...\n\n\n\n\n\n\n\n Customizing the cluster DNS provider \n\nYou can customize CoreDNS by editing the CoreDNS ConfigMap. For example, you might want to configure stub domains and upstream DNS servers to resolve services that point to external hosts. Additionally, you can configure multiple [Corefiles](https:\/\/coredns.io\/2017\/07\/23\/corefile-explained\/) within the CoreDNS ConfigMap. For more information, see [the Kubernetes documentation](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/dns-custom-nameservers\/).\n\nNodeLocal DNS caching relies on CoreDNS to maintain the cache of DNS resolutions. Keep applicable NodeLocal DNS cache and CoreDNS configurations such as stub domains the same to maintain DNS resolution consistency.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Verify that the CoreDNS deployment is available. In your CLI output, verify that one deployment is AVAILABLE.\n\nkubectl get deployment -n kube-system coredns\n\nExample output\n\nNAME READY UP-TO-DATE AVAILABLE AGE\ncoredns 3\/3 3 3 69d\n2. Edit the default settings for the CoreDNS ConfigMap. Use a Corefile in the data section of the ConfigMap to customize stub domains and upstream DNS servers. For more information, see [the Kubernetes documentation](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/dns-custom-nameservers\/coredns).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster_dns"},{"document_id":"ibmcld_05259-4110-5499","score":13.483467,"text":"\n* [Code Engine API](https:\/\/cloud.ibm.com\/apidocs\/codeengine)\n* [Kubernetes REST API](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-overview\/)\n* [Kubernetes API concepts](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-concepts\/)\n* [API client libraries](https:\/\/kubernetes.io\/docs\/reference\/api-client-libraries)\n* [kubectl command](https:\/\/kubernetes.io\/docs\/reference\/cli-reference)\n\n\n\n\n\n\n\n Custom resource definition (CRD) \n\nThe following sections list the custom resource definition methods to use with Code Engine.\n\n\n\n Batch CRD methods \n\n\n\nBatch CRDs for Code Engine\n\n Group Version Kind \n\n codeengine.cloud.ibm.com v1beta1 JobDefinition \n codeengine.cloud.ibm.com v1beta1 JobRun \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view Batch CRD details by using the following methods.\n\n\n\n1. Use kubectl explain --api-version='codeengine.cloud.ibm.com\/v1beta1' <Kind>.\n2. [Download Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).\n\n\n\nNote that you cannot delete a job run without also deleting any associated pods. Any attempt to delete with the propagationPolicy=Orphan option is rejected.\n\n\n\n\n\n Serving CRD methods \n\n\n\nServing CRDs for Code Engine\n\n Group Version Kind \n\n serving.knative.dev v1 Configuration \n serving.knative.dev v1 Revision \n serving.knative.dev v1 Route \n serving.knative.dev v1 Service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-api"},{"document_id":"ibmcld_05524-62917-64266","score":13.313392,"text":"\nUpdate resolves [CVE-2019-5736](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-5736). For more information, see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/871600). \n Kubernetes kubelet configuration N\/A N\/A Enabled the ExperimentalCriticalPodAnnotation feature gate to prevent critical static pod eviction. Set the event-qps option to 0 to prevent rate limiting event creation. \n\n\n\n\n\n\n\n Change log for 1.13.2_1507, released 5 February 2019 \n\nThe following table shows the changes that are in the patch 1.13.2_1507.\n\n\n\nTable 1. Changes since version 1.12.4_1535\n\n Component Previous Current Description \n\n Calico v3.3.1 v3.4.0 See the [Calico release notes](https:\/\/docs.tigera.io\/calico\/latest\/release-notes\/.). \n Cluster DNS provider N\/A N\/A CoreDNS is now the default cluster DNS provider for new clusters. If you update an existing cluster to 1.13 that uses KubeDNS as the cluster DNS provider, KubeDNS continues to be the cluster DNS provider. \n containerd 1.1.5 1.2.2 See the [containerd release notes](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.2.2). \n CoreDNS 1.2.2 1.2.6 See the [CoreDNS release notes](https:\/\/github.com\/coredns\/coredns\/releases\/tag\/v1.2.6). Additionally, the CoreDNS configuration is updated to [support multiple Corefiles](https:\/\/coredns.io\/2017\/07\/23\/corefile-explained\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-113_changelog"},{"document_id":"ibmcld_05259-5125-6683","score":13.19101,"text":"\nNote that you cannot delete a job run without also deleting any associated pods. Any attempt to delete with the propagationPolicy=Orphan option is rejected.\n\n\n\n\n\n Serving CRD methods \n\n\n\nServing CRDs for Code Engine\n\n Group Version Kind \n\n serving.knative.dev v1 Configuration \n serving.knative.dev v1 Revision \n serving.knative.dev v1 Route \n serving.knative.dev v1 Service \n\n\n\nFor more information about these CRDs, see [Knative Serving API Specification](https:\/\/github.com\/knative\/specs\/blob\/main\/specs\/serving\/knative-api-specification-1.0.md).\n\n\n\n\n\n Source-to-image CRD methods \n\n\n\nSource-to-image CRDs for Code Engine\n\n Group Version Kind \n\n shipwright.io v1alpha1 Build \n shipwright.io v1alpha1 BuildRun \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Source-to-image CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='shipwright.io\/v1alpha1' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).\n\n\n\n\n\n\n\n Subscription CRD methods \n\n\n\nSubscription CRDs for Code Engine\n\n Group Version Kind \n\n sources.codeengine.cloud.ibm.com v1alpha1 CosSource \n sources.knative.dev v1 PingSource \n\n\n\nAfter you retrieve the Kubernetes configuration, you can view the Subscription CRD details by using one of the following methods.\n\n\n\n* Use kubectl explain --api-version='sources.knative.dev\/<VERSION>' <KIND>.\n* [Download the Swagger or OpenAPI specification of CRDs](https:\/\/kubernetes.io\/docs\/concepts\/overview\/kubernetes-api\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-api"},{"document_id":"ibmcld_05653-262528-264130","score":12.795135,"text":"\n: Updated information for various service binding, logging, and nlb operations in the [user access](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) and [CLI reference](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli) pages.\n\n\n\n\n\n 7 May 2019 \n\nCluster DNS provider\n: [Explained the benefits of CoreDNS](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster_dns) now that clusters that run Kubernetes 1.14 and later support only CoreDNS.\n\nEdge nodes\n: Added private load balancer support for [edge nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-edge).\n\nFree clusters\n: Clarified where free clusters are supported.\n\nNew! Integrations\n: Added and restructure information about [IBM Cloud services and third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ibm-3rd-party-integrations), [popular integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations), and [partnerships](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-partners).\n\nNew! Kubernetes version 1.14\n: Create or update your clusters to [Kubernetes 1.14](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive).\n\nDeprecated Kubernetes version 1.11\n: [Update any clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update) that run [Kubernetes 1.11](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive) before they become unsupported.\n\nPermissions\n: Added an FAQ, [What access policies do I give my cluster users?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_05653-261467-263039","score":12.354118,"text":"\n: Removed all [virtual machine worker node flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) that are 48 or more cores. You can still provision [bare metal worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) with 48 or more cores.\n\n\n\n\n\n 8 May 2019 \n\nAPI\n: Added a link to the [global API swagger docs](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/).\n\nCloud Object Storage\n: [Added a troubleshooting guide for Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cos_pvc_pending) in your IBM Cloud Kubernetes Service clusters.\n\nKubernetes strategy\n: Added a topic about [What knowledge and technical skills are good to have before I move my apps to IBM Cloud Kubernetes Service?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategyknowledge).\n\nKubernetes version 1.14\n: Added that the [Kubernetes 1.14 release](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive) is certified.\n\nReference topics\n: Updated information for various service binding, logging, and nlb operations in the [user access](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) and [CLI reference](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli) pages.\n\n\n\n\n\n 7 May 2019 \n\nCluster DNS provider\n: [Explained the benefits of CoreDNS](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster_dns) now that clusters that run Kubernetes 1.14 and later support only CoreDNS.\n\nEdge nodes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_13877-22396-24231","score":12.349736,"text":"\n* [Let's Encrypt](https:\/\/letsencrypt.org\/) to generate the TLS certificates.\n* IBM Cloud Secrets Manager to integrate with Let's Encrypt to generate the TLS certificate for secure-file-storage.example.com and securely store.\n* Kubernetes [External Secrets Operator](https:\/\/external-secrets.io\/v0.7.0\/) to pull the secret TLS certificate directly from Secrets Manager\n\n\n\n\n\n Provision a CIS and Secrets Manager instance \n\n\n\n* A [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) instance is required. Use an existing instance or create one from this [catalog entry](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services). A number of pricing plans are available, including a free trial. The provisioning process of a new CIS will explain how to configure your existing DNS registrar (perhaps not in IBM Cloud) to use the CIS-provided domain name servers. This tutorial uses example.com for the DNS name. Substitute your domain for example.com in all steps. Also export it in the shell:\n\nexport MYDOMAIN=example.com\n* A Secrets Manager instance is required. Use an existing instance or create a new one described in [Creating a Secrets Manager service instance](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-create-instance&interface=ui). If creating a new instance, name it secure-file-storage-sm. You can enhance the security of your secrets at rest by integrating with the Key Protect instance created earlier.\n\n\n\nCreate a DNS entry in the CIS instance using YOUR-CLUSTER Ingress subdomain as the alias.\n\n\n\n1. Open the CIS service instance, you can find it in the [Resource List](https:\/\/cloud.ibm.com\/resources).\n2. Click the Reliability tab on the left.\n3. Click the DNS tab on the top.\n4. Scroll down to the DNS Records section and click Add to create a new record:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05998-3108-5122","score":23.161995,"text":"\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/namespaces\/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"},{"document_id":"ibmcld_10495-3085-5099","score":23.161995,"text":"\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/namespaces\/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_06294-9054-11040","score":21.977272,"text":"\nLearn more about [securing your personal information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi) when you work with Kubernetes resources.\n6. Make the app accessible by exposing the deployment as a NodePort service. Because your VPC worker nodes are connected to a private subnet only, the NodePort is assigned only a private IP address and is not exposed on the public network. Other services that run on the private network can access your app by using the private IP address of the NodePort service.\n\nkubectl expose deployment\/hello-world-deployment --type=NodePort --name=hello-world-service --port=8080 --target-port=8080\n\nExample output\n\nservice\/hello-world-service exposed\n\n\n\nTable 1. Information about the command options.\n\n Parameter Description \n\n expose Expose a Kubernetes resource, such as a deployment, as a Kubernetes service so that users can access the resource by using the IP address of the service. \n deployment\/<hello-world-deployment> The resource type and the name of the resource to expose with this service. \n --name=<hello-world-service> The name of the service. \n --type=NodePort The service type to create. In this lesson, you create a NodePort service. In the following lesson, you create a LoadBalancer service. \n --port=<8080> The port on which the service listens for external network traffic. \n --target-port=<8080> The port that your app listens on and to which the service directs incoming network traffic. In this example, the target-port is the same as the port, but other apps that you create might use a different port. \n\n\n\n7. Now that all the deployment work is done, you can test your app from within the cluster. Get the details to form the private IP address that you can use to access your app.\n\n\n\n1. Get information about the service to see which NodePort was assigned. The NodePorts are randomly assigned when they are generated with the expose command, but within 30000-32767. In this example, the NodePort is 30872.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"},{"document_id":"ibmcld_16098-9054-11040","score":21.977272,"text":"\nLearn more about [securing your personal information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi) when you work with Kubernetes resources.\n6. Make the app accessible by exposing the deployment as a NodePort service. Because your VPC worker nodes are connected to a private subnet only, the NodePort is assigned only a private IP address and is not exposed on the public network. Other services that run on the private network can access your app by using the private IP address of the NodePort service.\n\nkubectl expose deployment\/hello-world-deployment --type=NodePort --name=hello-world-service --port=8080 --target-port=8080\n\nExample output\n\nservice\/hello-world-service exposed\n\n\n\nTable 1. Information about the command options.\n\n Parameter Description \n\n expose Expose a Kubernetes resource, such as a deployment, as a Kubernetes service so that users can access the resource by using the IP address of the service. \n deployment\/<hello-world-deployment> The resource type and the name of the resource to expose with this service. \n --name=<hello-world-service> The name of the service. \n --type=NodePort The service type to create. In this lesson, you create a NodePort service. In the following lesson, you create a LoadBalancer service. \n --port=<8080> The port on which the service listens for external network traffic. \n --target-port=<8080> The port that your app listens on and to which the service directs incoming network traffic. In this example, the target-port is the same as the port, but other apps that you create might use a different port. \n\n\n\n7. Now that all the deployment work is done, you can test your app from within the cluster. Get the details to form the private IP address that you can use to access your app.\n\n\n\n1. Get information about the service to see which NodePort was assigned. The NodePorts are randomly assigned when they are generated with the expose command, but within 30000-32767. In this example, the NodePort is 30872.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc_ks_tutorial"},{"document_id":"ibmcld_06004-28242-30124","score":21.374855,"text":"\nkind: Service\nmetadata:\n...\n* You can use the kubectl apply -f command to apply to an entire directory, not just a single file.\n* Try out the [kustomize project](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-appkustomize) that you can use to help write, customize, and reuse your Kubernetes resource YAML configurations.\n\n\n\nWithin the YAML file, you can use labels or annotations as metadata to manage your deployments.\n\nLabels\n: [Labels](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/labels\/) are key:value pairs that can be attached to Kubernetes objects such as pods and deployments. They can be whatever you want, and are useful for selecting objects based on the label information. Labels provide the foundation for grouping objects. See the following examples for ideas for labels.\n\n\n\n* app: nginx\n* version: v1\n* env: dev\n\n\n\nAnnotations\n: [Annotations](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/annotations\/) are similar to labels in that they are also key:value pairs. They are better for non-identifying information that can be leveraged by tools or libraries, such as holding extra information about where an object came from, how to use the object, pointers to related tracking repos, or a policy about the object. You don't select objects based on annotations.\n\n\n\n\n\n What app update strategies can I use? \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_08848-0-1791","score":20.05635,"text":"\n\n\n\n\n\n\n  How can I resolve the network error when working with the Kubernetes Service provider? \n\n  What\u2019s happening \n\nDuring the cluster upgrade from Kubernetes Service older version to new version. The Terraform apply fails with the TCP connection error message.\n\nError: Get \"http:\/\/localhost\/api\/v1\/\": dial tcp [::1]:80: connect: connection refused\n\nOr\n\nError: {{site.data.keyword.containershort_notm}} cluster unreachable: invalid configuration: no configuration has been provided\n\n  Why it\u2019s happening \n\nYou are combining the cluster provisioning and working with the Kubernetes Service provider at the same time in your Terraform template in the IBM Cloud Schematics workspace or in your localhost. You make a change in the cluster configuration that leads to the cluster re-create. When you run terraform refresh command, you view strange errors such as, network or namespace issues.\n\n  How to fix it \n\nTo troubleshoot this error you need to ensure:\n\n\n\n*  You don't combine the Kubernetes Service provider with the cluster resource at the same time in the Terraform template.\n*  The resources should not be created in the same Terraform template or module where Kubernetes Service provider resources are in use.\n*  The Terraform provider evaluates the provider blocks versus actual resource, and the order in which the resources are defined. For more information, see [Provider configuration](https:\/\/developer.hashicorp.com\/terraform\/language\/providers\/configurationprovider-configuration).\n\n\n\nIf you cannot resolve this issue, contact support by opening a support case for the service that you want to work with. Make sure to include the incident ID. For more information, see [Using the Support Center](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-ks-network-error"},{"document_id":"ibmcld_05527-92264-93823","score":20.022606,"text":"\nKubernetes configuration N\/A N\/A [Kubernetes service account token volume projection](https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-service-account\/service-account-token-volume-projection) is enabled and issues tokens that use https:\/\/kubernetes.default.svc as the default API audience. \n Kubernetes admission controllers configuration N\/A N\/A The RuntimeClass admission controller is disabled to align with the RuntimeClass feature gate, which was disabled in IBM Cloud Kubernetes Service version 1.14. \n Kubernetes Dashboard v1.10.1 v2.0.0-beta5 See the [Kubernetes Dashboard release notes](https:\/\/github.com\/kubernetes\/dashboard\/releases\/tag\/v2.0.0-beta5). Unlike the previous version, the new Kubernetes dashboard version works with the metrics-server to display metrics. \n Kubernetes Dashboard metrics scraper N\/A v1.0.2 See the [Kubernetes Dashboard metrics scraper release notes](https:\/\/github.com\/kubernetes-sigs\/dashboard-metrics-scraper\/releases\/tag\/v1.0.2). \n Kubernetes DNS autoscaler 1.6.0 1.7.1 See the [Kubernetes DNS autoscaler release notes](https:\/\/github.com\/kubernetes-sigs\/cluster-proportional-autoscaler\/releases\/tag\/1.7.1). \n Operator Lifecycle Manager Catalog N\/A v1.4.0 See the [Operator Lifecycle Manager Catalog release notes](https:\/\/github.com\/operator-framework\/operator-registry\/releases\/tag\/v1.4.0). \n Operator Lifecycle Manager N\/A 0.12.0 See the [Operator Lifecycle Manager release notes](https:\/\/github.com\/operator-framework\/operator-lifecycle-manager\/releases\/tag\/0.12.0). \n\n\n\n\n\n\n\n Worker node patch","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog"},{"document_id":"ibmcld_13177-14661-16794","score":20.001633,"text":"\n* no matter the environment, all clusters will tend to look the same,\n* it is easier to control who has access to a specific cluster,\n* it gives flexibility in the update cycles for deployments and underlying resources: When there is a new Kubernetes version, it gives you the option to update the Development cluster first, validate your application then update the other environment,\n* it avoids mixing different workloads that may impact each other such as isolating the production deployment from the others.\n\n\n\nHowever, often not all of that properties are needed and the use of fewer resources is desired. Then, another approach is to use [Kubernetes namespaces](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/namespaces\/) in conjunction with [Kubernetes resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) to isolate environments and control resource consumption. The following diagram shows a non-production and a production resource group with a Kubernetes cluster in a VPC each. The non-production cluster has a development and testing namespace, the production cluster a production namespace.\n\nZoom\n\n![Diagram showing separate Kubernetes namespaces to isolate environments](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution20-users-teams-applications\/multiple-environments-with-namespaces.svg)\n\nUse separate Kubernetes namespaces to isolate environments\n\n\n\n\n\n Setup delivery pipeline \n\nWhen it comes to deploying to the different environments, your continuous integration \/ continuous delivery pipeline can be setup to drive the full process:\n\n\n\n* continuously update the Development environment with the latest and greatest code from the development branch, running unit tests and integration tests on the dedicated cluster;\n* promote development builds to the Testing environment, either automatically if all tests from the previous stages are OK or through a manual promotion process. Some teams will use different branches too here, merging the working development state to a stable branch as example;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications"},{"document_id":"ibmcld_10439-33029-35047","score":19.96808,"text":"\n: [Labels](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/labels\/) are key:value pairs that can be attached to Kubernetes objects such as pods and deployments. They can be whatever you want, and are useful for selecting objects based on the label information. Labels provide the foundation for grouping objects. See the following examples for ideas for labels.\n\n\n\n* app: nginx\n* version: v1\n* env: dev\n\n\n\nAnnotations\n: [Annotations](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/annotations\/) are similar to labels in that they are also key:value pairs. They are better for non-identifying information that can be leveraged by tools or libraries, such as holding extra information about where an object came from, how to use the object, pointers to related tracking repos, or a policy about the object. You don't select objects based on annotations.\n\n\n\n\n\n What app update strategies can I use? \n\nTo update your app, you can choose from various strategies such as the following. You might start with a rolling deployment or instantaneous switch before you progress to a more complicated canary deployment.\n\nRolling deployment\n: You can use Kubernetes-native functionality to create a v2 deployment and to gradually replace your previous v1 deployment. This approach requires that apps are compatible with earlier version so that users who are served the v2 app version don't experience any breaking changes. For more information, see [Managing rolling deployments to update your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_appapp_rolling).\n\nInstantaneous switch\n: Also referred to as a blue-green deployment, an instantaneous switch requires double the compute resources to have two versions of an app running at once. With this approach, you can switch your users to the newer version in near real time. Make sure that you use service label selectors (such as version: green and version: blue) to make sure that requests are sent to the correct app version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_06282-4283-5732","score":19.952284,"text":"\nKubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.\n\nTo check what VPC a cluster is in, run ibmcloud ks cluster get --cluster <cluster_name_or_id> and check the VPC ID in the output.\n\nibmcloud ks cluster ls --provider vpc-gen2\n2. List the security groups attached to the VPC that your cluster is in. The VPC security group is assigned a randomly generated name, such as trench-hexagon-matriarch-flower. The VPC cluster security group is named in the format of kube-<cluster-ID>. The Kubernetes Service security group is named in the format of kube-<vpc-ID>.\n\nibmcloud is sgs | grep <vpc_name>\n\nExample output.\n\nID Name Rules Network interfaces VPC Resource group\n\nr006-111aa1aa-1a1a-1a11-1111-a111aaa1a11a trench-hexagon-matriarch-flower 4 0 my-vpc default\nr006-222aa2aa-2a2a-2a22-2222-a222aaa2a22a kube-a111a11a11aa1aa11a11 4 0 my-vpc default\nr006-333aa3aa-3a3a-3a33-3333-a333aaa3a33a kube-r006-111a11aa-aaa1-1a1a-aa11-1a1a111aa11 4 0 my-vpc default\n3. Get the details of a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-380995-382843","score":25.572187,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-380969-382817","score":25.572187,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_06063-7869-9744","score":22.770594,"text":"\nThese certificates are never shared across clusters or across Kubernetes master components.\n\nNeed to revoke existing certificates and create new certificates for your cluster? Check out [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate).\n\nConnectivity to worker nodes\n: Although Kubernetes secures the communication between the master and worker nodes by using the https protocol, no authentication is provided on the worker node by default. To secure this communication, IBM Cloud Kubernetes Service automatically sets up an Konnectivity connection between the Kubernetes master and the worker node when the cluster is created.\n\nFine-grained access control\n: As the account administrator you can [grant access to other users for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersusers) by using IBM Cloud Identity and Access Management (IAM). IBM Cloud IAM provides secure authentication with the IBM Cloud platform, IBM Cloud Kubernetes Service, and all the resources in your account. Setting up proper user roles and permissions is key to limiting who can access your resources and to limiting the damage that a user can do when legitimate permissions are misused. You can select from the following pre-defined user roles that determine the set of actions that the user can perform:\n\n\n\n* Platform access roles: Determine the cluster and worker node management-related actions that a user can perform in IBM Cloud Kubernetes Service.\n* Service access roles: Determine the [Kubernetes RBAC role](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/rbac\/) that is assigned to the user and the actions that a user can run against the Kubernetes API server. With RBAC roles, users can create Kubernetes resources, such as app deployments, namespaces, or configmaps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05777-8738-10765","score":22.23305,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_06063-3142-5113","score":22.155247,"text":"\nBy default, Kubernetes requires every request to go through several stages before access to the API server is granted.\n\nAuthentication\n: Validates the identity of a registered user or service account.\n\nAuthorization\n: Limits the permissions of authenticated users and service accounts to ensure that they can access and operate only the cluster components that you want them to.\n\nAdmission control\n: Validates or mutates requests before they are processed by the Kubernetes API server. Many Kubernetes features require admission controllers to properly function.\n\n\n\n\n\n What does IBM Cloud Kubernetes Service do to secure my API server and etcd data store? \n\nThe following image shows the default cluster security settings that address authentication, authorization, admission control, and secure connectivity between the Kubernetes master and worker nodes.\n\nZoom\n\n![Describes the security stages when you access the Kubernetes API server.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_security_apiserver_access.png)\n\nFigure 1. Security stages when accessing the Kubernetes API server\n\nReview the following security features for Kubernetes API server and etcd.\n\nFully managed and dedicated Kubernetes master\n: Every cluster in IBM Cloud Kubernetes Service is controlled by a dedicated Kubernetes master that is managed by IBM in an IBM-owned IBM Cloud account. The Kubernetes master is set up with the following dedicated components that are not shared with other IBM customers.\n\n\n\n* etcd data store: Stores all Kubernetes resources of a cluster, such as Services, Deployments, and Pods. Kubernetes ConfigMaps and Secrets are app data that is stored as key value pairs so that they can be used by an app that runs in a pod. Data in etcd is stored on the local disk of the Kubernetes master and is backed up to IBM Cloud Object Storage. Data is encrypted during transit to IBM Cloud Object Storage and at rest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_10510-3027-5043","score":21.85366,"text":"\nBy default, Kubernetes requires every request to go through several stages before access to the API server is granted.\n\nAuthentication\n: Validates the identity of a registered user or service account.\n\nAuthorization\n: Limits the permissions of authenticated users and service accounts to ensure that they can access and operate only the cluster components that you want them to.\n\nAdmission control\n: Validates or mutates requests before they are processed by the Red Hat OpenShift API server. Many Kubernetes features require admission controllers to properly function.\n\n\n\n\n\n What does Red Hat OpenShift on IBM Cloud do to secure my API server and etcd data store? \n\nThe following image shows the default cluster security settings that address authentication, authorization, admission control, and secure connectivity between the Kubernetes master and worker nodes.\n\nZoom\n\n![Describes the security stages when you access the Kubernetes API server.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/oc_security_apiserver_access.png)\n\nFigure 1. Security stages when accessing the Kubernetes API server\n\nReview the following security features for Red Hat OpenShift API server and etcd.\n\nFully managed and dedicated Red Hat OpenShift master\n: Every cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud account. The Red Hat OpenShift master is set up with the following dedicated components that are not shared with other IBM customers.\n\n\n\n* etcd data store: Stores all Kubernetes resources of a cluster, such as Services, Deployments, and Pods. Kubernetes ConfigMaps and Secrets are app data that is stored as key value pairs so that they can be used by an app that runs in a pod. Data in etcd is stored on the local disk of the Red Hat OpenShift master and is backed up to IBM Cloud Object Storage. Data is encrypted during transit to IBM Cloud Object Storage and at rest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_05764-8558-10288","score":21.773928,"text":"\n* [Service](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/): Provides front-end access to pods by using a worker node or load balancer public IP address, or a public Ingress route.\n* [Ingress](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/ingress\/): Specifies a type of load balancer that provides routes to access your app publicly.\n\n\n\nLearn more about [securing your personal information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi) when you work with Kubernetes resources.\n2. Run the configuration file in a cluster's context.\n\nkubectl apply -f config.yaml\n3. If you made your app publicly available by using a NodePort service, a load balancer service, or Ingress, verify that you can access the app.\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Kubernetes namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-deploy_app"},{"document_id":"ibmcld_05777-10230-11885","score":21.48024,"text":"\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope \n\n App auditor [Viewer platform access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-platform-access-roles), [Reader service access role for a cluster, region, or resource group](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_09762-7-2229","score":21.429478,"text":"\nRBAC, teams, and IAM integration \n\nIBM Cloud\u00ae Identity and Access Management (IAM) enables you to securely authenticate users and consistently control access to all cloud resources in the IBM Cloud. Teams provide an isolated workspace in a Monitoring instance for a user or group of users to have access to metrics in a defined scope.\n\nIAM can map a combination of teams and roles so that a user only has access to a specific set of metrics and can take a defined set of actions within the product.\n\nTeams provide additional security by only allowing users to see metrics that are related to the infrastructure where their apps are deployed, as opposed to the entire infrastructure of the account. For example, in a Kubernetes cluster, you could grant a group of developers access to only see metrics from 1 kubernestes.namespace where their application is deployed.\n\nIn a Monitoring instance, you can define 1 or more teams. A team provides an isolated workspace for a user or group of users to have access to metrics with a defined scope.\n\nA Monitoring instance includes the following teams:\n\n\n\n* Monitor operations\n* Secure operations\n\n\n\nBy default, users are granted access to the monitor operations team or to the team that is configured as the default team by the instance administrator.\n\n\n\n* An admin of the service can configure multiple teams, and change the default team.\n* Each team has their own set of custom dashboards and alerts that they can use to monitor the data in scope for the team.\n* Users in a team have access to the data that is included in the scope defined by the team administrator.\n\n\n\n[Learn more about teams](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-teams).\n\nFor a user to monitor data within the context of a team, you must grant the user a policy for the IBM Cloud Monitoring service. The policy specifies the team and the service permissions for the user so the user can work with the data in scope for that team.\n\nYou can grant any of the following IAM service roles:\n\n\n\n* Writer: A writer role allows a user to monitor data through dashboards, alerts, and notifications, and to manage resources such as dashboards, alerts, and notifications that are in scope for the team.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-iam_grant_team"},{"document_id":"ibmcld_10016-6943-8953","score":21.159914,"text":"\nYou might do this if your organization currently uses custom RBAC policies to control Kubernetes access and plans to continue using custom RBAC instead of service access roles.\n\nAlthough platform access roles authorize you to perform infrastructure actions on the cluster, they don't grant access to the IBM Cloud infrastructure resources. Access to the IBM Cloud infrastructure resources is determined by the [API key that is set for the region](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overviewapi_key).\n\n\n\n\n\n Overview of IBM Cloud IAM service access roles \n\nUse service access roles in IBM Cloud Identity and Access Management (IAM) to grant users access to manage Kubernetes resources in Red Hat OpenShift on IBM Cloud clusters. When you configure permissions for Red Hat OpenShift on IBM Cloud in IAM, use the name containers-kubernetes for the API or CLI, and Kubernetes Service for the console.\n\nService access roles are synchronized with corresponding Kubernetes RBAC policies in a cluster. As such, service access roles grant access to the Kubernetes API, dashboard, and CLI (oc). Example actions that are permitted by service access roles include creating app deployments, adding namespaces, or setting up configmaps.\n\nYou can scope the policy for service access roles by resource group, region, or cluster instance. Further, you can also scope service access roles to Kubernetes namespaces that are in all, individual, or region-wide clusters. When you scope a service access role to a namespace, you can't apply the policy to a resource group or assign a platform access role at the same time.\n\nIf you assigned only service access roles to users, the users must be given the cluster master URL to open the Red Hat OpenShift web console from their browser at https:\/\/<master_URL>\/console instead of the IBM Cloud console. Otherwise, [give the users the platform Viewer role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersadd_users_cli_platform).\n\n\n\n\n\n Overview of RBAC","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access-overview"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02604-7-2037","score":17.713896,"text":"\nUsing the Support Center \n\nNeed help with your API Connect service instance? Visit the IBM Cloud [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to file a case.\n\n\n\n1. On the Support Center page, look in the \"Contact support\" section and click Create a case.\n2. On the Create a Case page, look in the \"Services\" list and click API Connect.\n\nIt's important to create your case with the correct service so that IBM Support can track the case and assign the appropriate people to help you. The list of services depends on your IBM Cloud account. If you don't see API Connect in the \"Services\" list, you can locate it as follows:\n\n\n\n* Locate the \"What do you need help with?\" section.\n* Review the text in that section and click the view all services link.\n* In the complete list of services, locate API Connect and click it (services are listed in alphabetic order).\n\n\n\n3. Describe your problem.\n\nUse the fields on the \"Create a Case\" page to explain your problem. The following list describes important information that assists us with resolving issues that you are having in API Connect.\n\nImportant: Do not include your private key in the support request.\n\n\n\n* For all issues, include the following information:\n\n\n\n* Region and customer service instance impacted\n* Component impacted: API Manager, API calls, Portal\n* URL where error is being seen\n* For Dedicated, identify the customer environment\n* For Reserved plan, use a prefix in the Subject field to indicate the version (such as v5, v2018 or v10) and provider-org. For example: [v10 - providerOrg].\n\n\n\n* For API Manager UI-based issues, additionally include:\n\n\n\n* All error codes returned\n* Time (including time zone) that the problem occurred\n\n\n\n* For Portal-based issues, additionally include the user name of person who encountered the problem\n* For issues with invoking APIs, additionally include:\n\n\n\n* Full API URL impacted - the host name should contain apiconnect.ibmcloud.com\n* HTTP method used\n* Frequency and time (with time zone) of the issue","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-get_help"},{"document_id":"ibmcld_05818-2659-4377","score":17.216814,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help"},{"document_id":"ibmcld_08091-5945-8032","score":16.966408,"text":"\nFor more information, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases. These services are in a trial stage of development and they aren't production-ready. A beta release helps IBM development and marketing teams to assess the value of the service in the market. This assessment enables teams to make updates before the service is released as a GA service or container image.\n\nIf the root cause analysis determines the issue is a defect in the beta service or container image, IBM isn't required to provide a fix. Additionally, the case is assigned the appropriate 3 or 4 severity level.\n\n\n\n\n\n Third-party services \n\nThird-party services are provided by vendors outside of IBM. These services are provided by individual software entities, IBM Business Partners, or independent software vendors (ISV).\n\nSupport for third-party services is provided by the service provider. This includes third-party products that are deployed by using the IBM Cloud Provider Plug-in for Terraform. If the root cause analysis determines that the issue is a defect in a third-party service, IBM isn't required to provide a fix. However, IBM shares analysis with the third-party service provider, if needed, and can work through Marketplace with the third-party service to help solve the issue.\n\n\n\n\n\n Open source or community service \n\nOpen source or community services are provided by open source communities outside of IBM.\n\nIf the root cause analysis determines that the issue is a defect in an open source or community service, IBM isn't required to provide a fix. IBM closes the case and refers you to the community or forum for assistance. You can get community assistance for technical issues through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar&interface=ui"},{"document_id":"ibmcld_12814-2351-4052","score":16.684061,"text":"\nIf you're experiencing issues with Partner Center, you can create a support case by using the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nTo create a support case, you must have a Pay-As-You-Go or Subscription account. Also, ensure that you're assigned at least the editor role on the Support Center account management service to create, edit, or view support cases. For more information about actions and roles for account management services, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles) or to assign other users access, see [Assigning user access for working with support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-access).\n\nTo create a support case for Partner Center related issues, complete the following steps:\n\n\n\n1. Click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/help.svg) > Support center from the console menu bar.\n2. From the Contact support section, click Create a case.\n3. Select All products.\n4. Select Partner Center - Sell as the topic and click Next.\n5. Complete the required fields.\n\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. The following steps are optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-support"},{"document_id":"ibmcld_08068-0-2916","score":16.348259,"text":"\n\n\n\n\n\n\n  Case severity and initial response times \n\nHow quickly your support cases are addressed depends on the assigned severity. You assign the severity of the issue when you open the case. With your agreement, the support team adjusts the assigned severity if an incorrect severity level is selected. For more information about Support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nThe following table lists some common examples of support issues, suggested severity levels, and the initial response time objectives. The initial response time objectives are used to describe IBM goals only, and don't represent a performance guarantee.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales-related inquiry or cases.\n\nSeverity Level Definition\n\nInitial Response Time Objectives\n\n\n\nTable 1. Case severity definitions\n\n Severity  Business impact  Details                                                                                                                                                                                                                                                                                                                       \n\n 4         Minimal          An inquiry or non-technical request.                                                                                                                                                                                                                                                                                          \n 3         Some             The product, service, or functions are usable, and the issue doesn't represent a significant impact on operations.                                                                                                                                                                                                            \n 2         Significant      A product, service, business feature, or function of the product or service is severely restricted in its use, or you are in jeopardy of missing business deadlines.                                                                                                                                                          \n 1         Critical         System or Service Down  <br>Business-critical functions are inoperable or a critical interface has failed. This usually applies to a production environment and indicates an inability to access products or services that results in a critical impact on operations. This condition requires an immediate solution.         \n\n\n\nWe work with you 24 hours a day and seven days a week to resolve Severity 1 problems if you have a technical resource available to work during those hours. You must reasonably assist with any problem diagnosis and resolution.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity"},{"document_id":"ibmcld_08091-4222-6344","score":15.911163,"text":"\nEU Support is provided 24 hours a day and 7 days a week by engineers that are located in Europe. Global teams provide support at the discretion of the EU support team. Global teams might be contacted, for example, when issues are not resolved by the Advanced Customer Support (ACS) team in the EU, and more expertise is needed.\n\nYou can specify that you want EU support for your account if the following criteria are true:\n\n\n\n* The EU Supported setting is enabled for your account by the master user or account owner. For more information, see [Enabling the EU Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* Your resources are in the appropriate European data center. For more information, see [Data centers](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locationsdata-centers).\n* You select the EU supported case level when you open the case.\n\n\n\nIBM Cloud platform services that are hosted in the Frankfurt location must be supported by a team that is physically located in Europe.\n\nEnabling the EU Support setting for your account applies to all future cases that you open for issues on any service or data center that is hosted in the EU region. However, if you add resources outside of an EU data center or Frankfurt location, issues for those resources are not necessarily handled by a support team in Europe. Any cases that are opened before you enable the EU Supported setting aren't affected.\n\n\n\n\n\n IBM generally available service \n\nSupport is provided for problems that are determined to be a defect for services or container images that are generally available (GA) and provided by IBM. The case is addressed based on the severity that you assign. For more information, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar&interface=ui"},{"document_id":"ibmcld_10227-2655-4315","score":15.412025,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help"},{"document_id":"ibmcld_08063-2713-4328","score":15.095125,"text":"\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessadd-user-access-group).\n* Select Email me updates about this case to receive support case notifications.\n\n\n\n7. Click Next, review your case summary, and click Submit case. After you receive email verification for the case, follow the instructions for further communication on the issue.\n\n\n\nAfter your support case is created, you can follow its progress on the [Manage cases page](https:\/\/cloud.ibm.com\/unifiedsupport\/cases).\n\n\n\n\n\n Creating a support case by using the API \n\nYou can programmatically open a support case by calling the Case Management API as shown in the following sample requests. For more information about the API, see [Case Management](https:\/\/cloud.ibm.com\/apidocs\/case-managementcasemanagement-createcase).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl --location --request POST 'support-center.cloud.ibm.com\/case-management\/v1\/cases' --header 'Content-Type: application\/json' --header 'Content-Type: text\/plain' --data-raw '{ \"type\": \"technical\",\n\"subject\": \"Case subject\",\n\"description\": \"Case description\",\n\"severity\":4,\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_03839-5438-7096","score":15.075791,"text":"\nEnsure that the ticket severity is assigned based on the published criteria that is defined in [Case severity and response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity). For more information, see [IBM Cloud support plan offerings](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).\n* If you do not purchase support, your IBM Cloud Pay-As-You-Go or Subscription account comes with a free Basic Support plan. In this case, your support case is automatically registered as Sev-4.\n\n\n\nBefore you open a support ticket, you need to [gather your logs](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-manage-consoleibp-console-manage-logs).\n\nFollow these steps to submit a support case.\n\n\n\n1. Log in to [IBM Cloud Service Portal](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) with your IBM ID.\n2. Under Need more help? on the right of the page, click Create a Case.\n3. Fill the Create Case form with your information at least for the following fields.\n\n\n\n* Choose Technical as your case type.\n* In the Category drop-down list, select Blockchain.\n* In the Subject field enter a summary of your issue.\n* In the Description field, describe your issue.\n* Attach any relevant logs or files to demonstrate your issue.\n* Click Email me updates to receive updates on the status of the ticket.\n\n\n\n4. Click the Submit button. You will receive an email notification in a few minutes for this case.\n\n\n\nYou can find your previously submitted cases by clicking My Cases in the IBM Cloud Service Portal. Click and open a case to check its status or provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-blockchain-support"},{"document_id":"ibmcld_08052-7-2152","score":15.005023,"text":"\nCustomer Incident Report \n\nIBM Cloud\u00ae works hard to maintain high availability of infrastructure and cloud services. If you're impacted by any event that disrupts your service delivery, a Customer Incident Report (CIR) can be provided. A CIR provides information about how services are impacted and how an issue is getting resolved.\n\nAfter you create a support case, you can view updates about your impacting event from the Manage cases page. For more information, see [Managing your support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases). If the scope of an impacting event is of a larger enterprise-wide scope, a CIR is provided upon request.\n\n\n\n Details about the Customer Incident Report (CIR) \n\nA CIR is provided for larger, enterprise-level issues. They are updates that provide a Root Cause Analysis (RCA) which is the process for determining the underlying cause of a Customer Impacting Event (CIE). Smaller issues that don't affect IBM Cloud at an enterprise level don't provide an RCA or CIR. The Advanced Customer Support (ACS) team that mitigates the issue still provides updates, but they're not a formal RCA.\n\nLarger enterprise-wide issues are events that typically impact multiple user environments or regions. Due to the scope and impact of enterprise issues, IBM Cloud requires a thorough RCA and the CIR is a summary report for the findings of the investigation.\n\nRCA investigations are complex and involve program review, feedback from product specialists, multiple inter-related cloud services, and vendor discussions. If the CIR can't be delivered within the Service Level Objective (SLO), an interim CIR is provided within the five business day SLO. For more information about SLO, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nThe CIR is a point-in-time document that is intended to convey a specific set of information about an impacting incident. The interim CIR document provides the current findings of the ongoing RCA, the next investigative steps, and a timeline for the next expected update.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-cir"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07191-1691-3739","score":15.754233,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07098-7-2215","score":15.268535,"text":"\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery). For an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_13446-19419-21379","score":15.013319,"text":"\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_07191-7-2252","score":14.705749,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13446-24100-26099","score":14.347286,"text":"\nAsynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n timestamps \n\nAn optional boolean that indicates whether the service produces timestamps for the words of the transcript. By default (false), timestamps are not returned. For more information, see [Word timestamps](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadataword-timestamps).\n\n\n\nTable 27. The timestamps parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n Transfer-Encoding \n\nAn optional value of chunked that causes the audio to be streamed to the service. By default, audio is sent all at once as a one-shot delivery. For more information, see [Audio transmission](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtransmission).\n\n\n\nTable 28. The Transfer-Encoding parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Not applicable; always streamed \n Synchronous HTTP Request header of POST \/v1\/recognize method \n Asynchronous HTTP Request header of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n word_alternatives_threshold \n\nAn optional double between 0.0 and 1.0 that specifies the threshold at which the service reports acoustically similar alternatives for words of the input audio. By default, word alternatives are not returned. For more information, see [Word alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingword-alternatives).\n\n\n\nTable 29. The word_alternatives_threshold parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_02590-7911-9371","score":14.193073,"text":"\nTo prevent [dangerous client bugs and backward-compatibility hazards](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-uris"},{"document_id":"ibmcld_15559-2851-5046","score":14.080693,"text":"\nExample message: The value provided for the expires_in field must be between 5 and 3600.\n\n\n\n\n\n missing_field \n\nUsed in any situation where a required header, query parameter, or property is not provided.\n\nmissing_field error code can accompany a 400 HTTP status code.\n\nExample message: A trusted profile ID was not passed in the request body.\n\n\n\n\n\n missing_value \n\nUsed for missing required headers, query parameters, or body properties (identified by the target).\n\nmissing_value error code can accompany a 400 HTTP status code.\n\nExample message: A value such as ibm must be provided in the Metadata-Flavor header.\n\n\n\n\n\n not_found \n\nUsed for headers, query parameters, path parameters, or body properties (identified by the target) that are syntactically valid but refer to a resource that does not exist.\n\nnot_found error code can accompany the following HTTP status codes:\n\n\n\n* 404 for path parameters\n* 400 for all other cases\n\n\n\nExample message: Placement group not found.\n\n\n\n\n\n profile_not_linked \n\nUsed when a trusted profile is not linked to a virtual server instance. This error code is returned only for the POST \/instance_identity\/v1\/iam_token method.\n\nprofile_not_linked error code can accompany a 400 HTTP status code.\n\nExample message: The virtual server instance is not linked to the specified trusted profile.\n\n\n\n\n\n service_error \n\nUsed when the client encounters a service-side issue.\n\nservice_error error code can accompany a 500 HTTP status code.\n\nExample message: An internal error occurred.\n\n\n\n\n\n unauthenticated \n\nUsed when a Bearer token is provided in the Authorization header, but the token is expired, malformed, or otherwise syntactically correct but not valid.\n\nunauthenticated error code can accompany a 401 HTTP status code.\n\nExample message: The provided token is invalid or expired.\n\n\n\n\n\n unauthorized \n\nUsed for headers, parameters, paths, or properties (identified by the target) that are syntactically valid but refer to a resource that you are not authorized to operate on in the requested manner.\n\nunauthorized error code can accompany a 403 HTTP status code.\n\nExample message: The metadata service is not enabled on the provided instance.\n\n\n\n\n\n unknown_field","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-metadata-error-codes"},{"document_id":"ibmcld_13446-4441-6470","score":13.961142,"text":"\nTable 5. The base_model_version parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n character_insertion_bias \n\nAn optional float between -1.0 and 1.0 that indicates whether the service is biased to recognize shorter (negative values) or longer (positive values) strings of characters when developing transcription hypotheses. By default, the service uses a default bias of 0.0. The value that you specify represents a change from a model's default. For more information, see [Character insertion bias](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsinginsertion-bias).\n\n\n\nTable 6. The character_insertion_bias parameter\n\n Availability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Beta for all models. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n Content-Type \n\nAn optional audio format (MIME type) that specifies the format of the audio data that you pass to the service. The service can automatically detect the format of most audio, so the parameter is optional for most formats. It is required for the audio\/alaw, audio\/basic, audio\/l16, and audio\/mulaw formats. For more information, see [Specifying an audio format](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-specifying).\n\n\n\nTable 7. The Content-Type parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket content-type parameter of JSON start message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_15845-18362-19949","score":13.862993,"text":"\ninvalid_generation_parameter \n\nMessage: The generation query parameter is invalid.\n\nFor versions on and after 5\/31\/2019, the 'generation' query parameter must be set to 1 to allow VPC API requests for use with generation 1 compute resources and set to 2 to allow VPC API requests for use with generation 2 compute resources.\n\nHow to set the generation parameter\n\nIn the CLI: ibmcloud is target --gen 1\n\nIn the API:\n\ncurl -X GET \"$rias_endpoint\/v1\/regions?version=$version&generation=1\"\n-H \"Authorization: $iam_token\"\n\n\n\n\n\n invalid_id_format \n\nMessage: Bad ID format. Ensure format is correct.\n\nMake sure that the ID you provided does not contain any malformed data.\n\nYou may get this error message if you provide a malformed start query when making a pagination request. For example, GET \/v1\/network_acls?start=23fbba08-ceb3-4cbe-a951-84ff20a06069?version=$version&generation=1 contains two ?s. Fix the query and try again.\n\n\n\n\n\n invalid_route \n\nMessage: The requested route does not exist.\n\nThe requested route on the API URL you provided does not exist. Verify that the URL you specified to call the API endpoint is correct.\n\n\n\n\n\n invalid_request_field \n\nMessage: A field provided in the request is not valid.\n\nFor example, to update the network ACL used by a subnet use the PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"network_acl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019 API.\n\nThe following request would be invalid because \u201cnetworkacl\u201d is not a valid field, PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"networkacl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_16340-16148-18298","score":13.59304,"text":"\nFor more information about session variables, see [Defining session variables](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-addactions-variables-global).\n3. Set the value of the variable by using an expression that looks like this: <? input.text ?>.\n\n\n\nThis expression captures the complete message that was submitted by the customer. As a result, your variable captures the customer message that triggered this action.\n\n\n\n1. Add the session variable to the Custom query field (for example, ${original_message}).\n\n\n\n* Custom results filter: Add a text string that defines information that must be present in any of the search results that are returned.\n\nYou are effectively defining the value that is used by the Discovery API as the filter parameter. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersfilter).\n\nThe syntax to use for the filter value is not intuitive. Here are a few examples of common use cases:\n\n\n\n* To indicate that you want to return only documents with positive sentiment, for example, specify enriched_text.sentiment.document.label:positive.\n* To filter results to include only documents that mention Boston, MA, specify enriched_text.entities.text:\"Boston, MA\".\n* To filter results to include only documents that mention a city name that you saved in a context variable named $destination, you can specify enriched_text.entities.text:$destination.\n\n\n\n\n\nIf you add both a query and a filter value, the filter parameter is applied first to filter the data collection documents and cache the results. The query parameter then ranks the cached results.\n3. If you want the search for an answer to be the last step in the action, select End the action after returning results.\n4. Click Apply.\n\n\n\n\n\n\n\n Test the search integration \n\nAfter you configure search, you can send test queries to see the search results that get returned from Discovery by using the Preview page.\n\nTo test the full experience that customers have when they ask questions that are either answered by the action or trigger a search, use the Preview for your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13455-7-1568","score":20.950136,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13455-26115-26611","score":19.98354,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13790-1284-2889","score":19.961554,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-7-1700","score":19.859848,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13429-163247-165127","score":19.117243,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13361-1589-2935","score":18.844093,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13297-4312-5935","score":18.550606,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_13455-1311-2796","score":18.532305,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-13886-15581","score":18.467573,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13455-2454-4219","score":18.017094,"text":"\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. All WebSocket examples call the method as {ws_url}\/v1\/recognize.\n\nA WebSocket client calls the \/v1\/recognize method with the following query parameters to establish an authenticated connection with the service. You can specify these aspects of the request only as query parameters of the WebSocket URL.\n\naccess_token (required string)\n: Pass a valid access token to establish an authenticated connection with the service. You must establish the connection before the access token expires. You pass an access token only to establish an authenticated connection. Once you establish a connection, you can keep it alive indefinitely. You remain authenticated for as long as you keep the connection open. You do not need to refresh the access token for an active connection that lasts beyond the token's expiration time. Once a connection is established, it can remain active even after the token or its credentials are deleted.\n\n\n\nIBM Cloud\n\nPass an Identity and Access Management (IAM) access token to authenticate with the service. You pass an IAM access token instead of passing an API key with the call. For more information, see [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud).\nIBM Cloud Pak for Data\n\nPass an access token as you would with the Authorization header of an HTTP request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8503449055,"ndcg_cut_10":0.8503449055}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-1284-2889","score":20.94784,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-7-1700","score":20.895021,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13297-4312-5935","score":20.637962,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_13455-7-1568","score":20.576357,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13455-26115-26611","score":20.494904,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13361-1589-2935","score":20.280254,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13455-1311-2796","score":19.705078,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13645-1132-2052","score":19.048407,"text":"\n* The HTTP POST \/v1\/synthesize method:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}\/v1\/synthesize?customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}\/v1\/synthesize?customization_id={customization_id}\"\n\n\n\nThe third example establishes a WebSocket connection with the \/v1\/synthesize method. The request uses the indicated custom model to synthesize text that is passed over the connection.\n\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}\/v1\/synthesize'\n+ '?access_token=' + access_token\n+ '&voice=en-US_AllisonV3Voice'\n+ '&customization_id=={customization_id}';\nvar websocket = new WebSocket(wsURI);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-custom-using"},{"document_id":"ibmcld_03285-13886-15581","score":18.875217,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13429-163247-165127","score":18.816849,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.60961995,"ndcg_cut_10":0.7486761295}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07390-58970-60390","score":12.004987,"text":"\nCommand options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nRULE_ID\n: The ID of custom resolver forwarding rule.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nGet a forwarding rule 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rule f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rules \n\nList custom resolver forwarding rules for a service instance.\n\nibmcloud dns custom-resolver-forwarding-rules RESOLVER_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nList forwarding rules in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rules f1aba936b94213e5b8dca0c0dbf1f9cc -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rule-delete \n\nDelete a custom resolver forwarding rule for a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_04345-58950-60370","score":12.004987,"text":"\nCommand options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nRULE_ID\n: The ID of custom resolver forwarding rule.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nGet a forwarding rule 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rule f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rules \n\nList custom resolver forwarding rules for a service instance.\n\nibmcloud dns custom-resolver-forwarding-rules RESOLVER_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nList forwarding rules in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rules f1aba936b94213e5b8dca0c0dbf1f9cc -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rule-delete \n\nDelete a custom resolver forwarding rule for a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_04334-228481-229509","score":10.990722,"text":"\nHigher numbers are tried first.\n\n<-- <\/ul> -->\n\n<-- <\/ul> -->\n\n<-- <\/ul> -->\n\nSample JSON data: {\n\"certificates\":\n{\n\"id\":\"5a7805061c76ada191ed06f989cc3dac\",\n\"priority\":2\n},\n{\n\"id\":\"da534493b38266b17fea74f3312be21c\",\n\"priority\":1\n}\n] ! !\n}\n-s, --json-str: Deprecated. The JSON data used to change the custom certificates' priority.-j, --json-file: Deprecated. A file contains input JSON data.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-change-priority-custom-options\" \"> --><-- <section \"id=\"section-change-priority-custom-examples\" \"> --> Examples Change custom certificates' priority for domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis certificate-priority-change 31984fea73a15b45779fa0df4ef62f9b --json '{\"certificates\": {\"id\":\"5a7805061c76ada191ed06f989cc3dac\", \"priority\":2},{\"id\":\"9a7806061c88ada191ed06f989cc3dac\",\"priority\":1}] ! ! ! }' -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16322-7-2220","score":10.790307,"text":"\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-context"},{"document_id":"ibmcld_07388-4-1865","score":10.679999,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Viewing custom resolver details \n\nYou view details of a single custom resolver and view a list of all custom resolvers in IBM Cloud\u00ae DNS Services by using the UI, CLI, or API.\n\n\n\n Viewing custom resolver details using the UI \n\nTo view the details of a custom resolver using the UI, navigate to the custom resolver tab in the DNS Services instance. From the custom resolver view, you can view a list of all custom resolvers. There, you can view information about a specific custom resolver by clicking the custom resolver name.\n\n\n\n\n\n Get details of a custom resolver using the CLI \n\nTo get the details of a custom resolver using the CLI, run the following command:\n\nibmcloud dns custom-resolver RESOLVER_ID [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* RESOLVER_ID is the ID of custom resolver.\n* -i, --instance is the instance name or ID. If this is not set, the context instance specified by dns instance-target INSTANCE is used instead.\n* --output specifies output format. Currently, JSON is the only supported format.\n\n\n\n\n\n List all custom resolvers \n\nTo list all custom resolvers using the CLI, run the following command:\n\nibmcloud dns custom-resolvers [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* -i, --instance is the instance name or ID. If this is not set, the context instance specified by dns instance-target INSTANCE is used instead.\n* --output specifies output format. Currently, JSON is the only supported format.\n\n\n\n\n\n\n\n\n\n Get details of a custom resolver using the API \n\n\n\n Get details of a single custom resolver \n\nTo get the details of a custom resolver using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store the following values in variables to be used in the API command:\n\n\n\n* instance_id, which is the unique identifier of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-details-cr"},{"document_id":"ibmcld_03037-2895-4808","score":10.670146,"text":"\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the \/message API, include the user_id property in your global [context](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_07390-58031-59301","score":10.666632,"text":"\n: The matching zone or hostname.\n\n--dns-svcs\n: The upstream DNS servers will be forwarded to, for example: ip1,ip2\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate a forwarding rule 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rule-update f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb --type zone --match \"example.com\" --dns-svcs 192.168.0.1,192.168.0.2 --description \"demo\" -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rule \n\nGet a custom resolver forwarding rule details for a service instance.\n\nibmcloud dns custom-resolver-forwarding-rule RESOLVER_ID RULE_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nRULE_ID\n: The ID of custom resolver forwarding rule.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"},{"document_id":"ibmcld_04345-58011-59281","score":10.666632,"text":"\n: The matching zone or hostname.\n\n--dns-svcs\n: The upstream DNS servers will be forwarded to, for example: ip1,ip2\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nUpdate a forwarding rule 9a234ede-c2b6-4c39-bc27-d39ec139ecdb in custom resolver f1aba936b94213e5b8dca0c0dbf1f9cc for instance dns-demo.\n\nibmcloud dns custom-resolver-forwarding-rule-update f1aba936b94213e5b8dca0c0dbf1f9cc 9a234ede-c2b6-4c39-bc27-d39ec139ecdb --type zone --match \"example.com\" --dns-svcs 192.168.0.1,192.168.0.2 --description \"demo\" -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns custom-resolver-forwarding-rule \n\nGet a custom resolver forwarding rule details for a service instance.\n\nibmcloud dns custom-resolver-forwarding-rule RESOLVER_ID RULE_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nRESOLVER_ID\n: The ID of custom resolver.\n\nRULE_ID\n: The ID of custom resolver forwarding rule.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_04345-48666-50242","score":10.664895,"text":"\n: The ID of global load balancer monitor. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n-f, --force\n: Delete load balancer monitor without prompting for confirmation.\n\n\n\n\n\n Examples \n\nDelete GLB monitor f1aba936b94213e5b8dca0c0dbf1f9cc.\n\nibmcloud dns glb-monitor-delete f1aba936b94213e5b8dca0c0dbf1f9cc -f -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns glb-monitors \n\nList GLB monitors for a service instance.\n\nibmcloud dns glb-monitors [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nList all GLB monitors for instance dns-demo.\n\nibmcloud dns glb-monitors -i \"dns-demo\"\n\n\n\n\n\n\n\n\n\n Custom resolver \n\nManage custom resolvers by using the following custom resolver commands.\n\n\n\n ibmcloud dns custom-resolver-create \n\nCreate a custom resolver for a service instance.\n\nibmcloud dns custom-resolver-create --name NAME [--location LOCATION1] [--location LOCATION2] [-description DESCRIPTION] [-f, --force] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-n, --name\n: The name of the custom resolver.\n\n-d, --description\n: The descriptive text of the custom resolver.\n\n-f, --force\n: Allow creating custom resolver with fewer than 2 locations.\n\n--location\n: The Locations on which the custom resolver will be running. The location subnet CRN is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-dns-services-cli-commands"},{"document_id":"ibmcld_07390-48686-50262","score":10.664895,"text":"\n: The ID of global load balancer monitor. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n-f, --force\n: Delete load balancer monitor without prompting for confirmation.\n\n\n\n\n\n Examples \n\nDelete GLB monitor f1aba936b94213e5b8dca0c0dbf1f9cc.\n\nibmcloud dns glb-monitor-delete f1aba936b94213e5b8dca0c0dbf1f9cc -f -i \"dns-demo\"\n\n\n\n\n\n\n\n ibmcloud dns glb-monitors \n\nList GLB monitors for a service instance.\n\nibmcloud dns glb-monitors [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by dns instance-target INSTANCE is used.\n\n--output\n: Specify output format. Currently, json is the only supported format.\n\n\n\n\n\n Examples \n\nList all GLB monitors for instance dns-demo.\n\nibmcloud dns glb-monitors -i \"dns-demo\"\n\n\n\n\n\n\n\n\n\n Custom resolver \n\nManage custom resolvers by using the following custom resolver commands.\n\n\n\n ibmcloud dns custom-resolver-create \n\nCreate a custom resolver for a service instance.\n\nibmcloud dns custom-resolver-create --name NAME [--location LOCATION1] [--location LOCATION2] [-description DESCRIPTION] [-f, --force] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-n, --name\n: The name of the custom resolver.\n\n-d, --description\n: The descriptive text of the custom resolver.\n\n-f, --force\n: Allow creating custom resolver with fewer than 2 locations.\n\n--location\n: The Locations on which the custom resolver will be running. The location subnet CRN is required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-dns-services-cli-commands"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":22.089533,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-6287-8401","score":17.599129,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16287-1442-3506","score":17.509151,"text":"\nThe trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.\n\nDepending on the architecture of your existing telephony infrastructure, there are multiple ways you might integrate it with Watson Assistant. For more information about common integration patterns, read the blog post [Hey Watson, can I have your number?](https:\/\/medium.com\/ibm-watson\/hey-watson-can-i-have-your-number-7de8fc7621ed) on Medium.\n\n\n\n Set up the integration \n\nYou must have Manager role access to the instance and Viewer role access to the resource group to complete setup. For more information about access levels, see [Managing access](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n\nTo set up the integration:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Choose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16288-7-2218","score":17.285292,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16287-7-2037","score":17.182695,"text":"\nIntegrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nAdding the phone integration to your assistant makes your assistant available to customers over the phone.\n\nIf an end user asks to speak to a person, the phone integration can transfer the call to an agent. Supported live agent and contact center integrations:\n\n\n\n* Genesys\n* Twilio Flex\n* NICE CXone\n* Bring your own\n\n\n\nThere are several ways to add the phone integration to your assistant:\n\n\n\n* You can generate a free phone number that is automatically provisioned from IntelePeer. This is available only with new phone integrations. If you have an existing phone integration, you must delete it and create a new one to switch to a free phone number.\n* You can connect to a contact center with live agents. For more information about setting up the integration, see [Integrating with phone and NICE CXone contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone).\n* You can use and connect an existing number by configuring a Session Initiation Protocol (SIP) trunk from a provider such as Genesys, IntelePeer, or Twilio.\n\n\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03158-23545-25765","score":16.660519,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16291-7-1781","score":16.607113,"text":"\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https:\/\/www.nice.com\/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https:\/\/help.nice-incontact.com\/content\/resources\/images\/icons\/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_16291-1353-3298","score":16.595144,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03158-21896-24017","score":16.586628,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16291-4496-6271","score":16.543907,"text":"\n* If the credentials are correct, the Save and exit button becomes clickable.\n\n\n\nClick Save and exit.\n\n\n\nThe connection between your assistant and NICE CXone is complete.\n\n\n\n Configuring the NICE CXone script \n\nNICE CXone provides a scripting tool that allows workflow developers to define routing flows for their contact centers in CXone.\n\nThe following actions and settings in the workflow are necessary for integration to work properly.\n\n\n\n Connecting a caller to your assistant \n\nUse the [Sipputheader](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/sipputheader\/sipputheader.htm) action. In the headerName property, enter the name of the SIP header field that will contain the Contact ID. This header field is included in outgoing SIP INVITE messages to Watson Assistant.\n\n\n\n* headerName X-Contact-ID\n* headerValue {ContactId}\n\n\n\nSipputheader must be executed before Placecall.\n\nUse a [Placecall](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/placecall\/placecall.htm) action to initiate an outbound call to Watson Assistant. In the PhoneNumber property, enter the phone number you allocated for this integration.\n\nThe phone number must match the number you configured in Use an existing phone number with an external provider in the Watson Assistant user interface.\n\n![Image of the outbound call flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/cxone-placecall.png)\n\n\n\n\n\n Transferring a caller to a live agent \n\nYou can configure your assistant to transfer a customer to a NICE CXone live agent.\n\nThe phone integration uses the [signal](https:\/\/developer.niceincontact.com\/API\/AdminAPI\/Contacts\/Signal%20a%20Contact) REST API. The p1 attribute is preserved for the session history key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-7-1807","score":15.769431,"text":"\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16288-1733-3996","score":15.349797,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-6287-8401","score":14.275341,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03369-22311-24192","score":14.205883,"text":"\nFor more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds. For more information, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 27 November 2021 \n\nNew API version\n: The current API version is now 2021-11-27. This version introduces the following changes:\n\n\n\n* The output.text object is no longer returned in message responses. All responses, including text responses, are returned only in the output.generic array.\n\n\n\n\n\n\n\n 9 November 2021 \n\nNew phone response types\n: New response types are available for controlling the configuration and behavior of the phone integration. These response types replace most of the older vgw actions, which are now deprecated. (The vgw actions will continue to work, so existing skills do not need to be changed.) For more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\nRich response types\n: Your assistant can now send responses that include elements such as audio, video, or embedded iframe content. For more information, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n 4 November 2021 \n\nActions enhancement: Add variables to links\n: In an actions skill, when including a link in an assistant response, you can now access and use variables. In the URL field for a link, type a dollar sign ($) character to see a list of variables to choose from.\n\n\n\n\n\n 14 October 2021 \n\nvgwHangUp message no longer sent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03165-4477-6547","score":13.849952,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03158-13826-15767","score":13.509087,"text":"\nFor more information, see [Transfer a call to a human agent](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n\n\n\n\n\n Optimize your dialog for voice \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your dialog text responses. To add formatting, use Markdown. For more information, see [Simple text response](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text).\n* Use the Connect to human agent response type to initiate a transfer to a human agent. For more information, see [Transferring a call to a human agent](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer).\n* Use the Channel transfer response type to initiate a transfer to the web chat integration. For more information, see [Transferring the caller to the web chat integration](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n* The pause response type is not supported. If you want to add a pause, use the turn_settings.timeout_count context variable (for more information, see [Context variables that are set by your dialog or actions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-contextphone-context-variables-set-by-dialog)).\n* You can include search skill response types in dialog nodes that the phone integration will read. The introductory message (I searched my knowledge base and so on), and then the body of only the first search result is read.\n\nThe search skill response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16294-8240-10414","score":13.461312,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_03158-8929-11062","score":13.058951,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-23545-25765","score":13.011421,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03369-30320-32392","score":12.7339115,"text":"\n* Change conversation topic: In general, an action is designed to lead a customer through a particular process without any interruptions. In real life, however, conversations almost never follow such a simple flow. In the middle of a conversation, customers might get distracted, ask questions about related issues, misunderstand something, or just change their minds about what they want to do. The Change conversation topic feature enables your assistant to handle these digressions, dynamically responding to the user by changing the conversation topic as needed.\n* Fallback action: The built-in action, Fallback, provides a way to automatically connect customers to a human agent if they need more help. This action helps you to handle errors in the conversation, and is triggered by these conditions:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a human agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n\n\n\n\n\nDialog skill \"Try it out\" improvements\n: For dialog skills, the Try it out pane now uses the [React](https:\/\/reactjs.org\/) UI framework similar to the rest of the Watson Assistant user interface. You shouldn't see any change in behavior or functionality. As a part of the update, dialog skill error handling has been improved within the \"Try it out\" pane. This update will be implemented incrementally, starting with service instances in the Tokyo and Seoul data centers.\n\n\n\n\n\n 2 September 2021 \n\nDeploy your assistant on the phone in minutes\n: We have partnered with [IntelePeer](https:\/\/intelepeer.com\/) to enable you to generate a phone number for free within the phone integration. Simply choose to generate a free number when following the prompts to create a phone integration, finish the setup, and a number is assigned to your assistant. These numbers are robust and ready for production.\n\nConnect to your existing service desks","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16287-7751-9832","score":14.774777,"text":"\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images\/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16290-6035-7786","score":14.668592,"text":"\nSelect Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent \n\nNow that your Genesys Cloud environment can connect to Watson Assistant, you can set up the ability for your assistant to transfer calls back to your live agents. To do so, follow these steps:\n\n\n\n1. In the Genesys Cloud console, go to DID Numbers -> DID Ranges and create a new range. Specify the following information:\n\n\n\n* In the DID Start and DID End fields, specify a phone number. (Once again, you do not need to use a real phone number; you can just make up an identifier for your Genesys environment, such as 1-888-888-1234.)\n\n\n\n![Genesys create range](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/phone-genesys-create-range.png)\n\n\n\n* In the Service Provider field, type a descriptive name (for example, Watson).\n\n\n\n2. If you have not already set up a queue to enable callers to wait for available agents, follow these steps to create a simple one now:\n\n\n\n1. Click Admin.\n2. Under Contact Center, click Queues.\n3. Create a new queue and give it a descriptive name.\n4. Add yourself as a member.\n5. Click Save.\n\n\n\n3. Create a simple call flow. Your business might already have something more complex for routing.\n\n\n\n1. Click Admin.\n2. Click Architect.\n3. In the Flows: Inbound Call section, click + to create a new flow.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys"},{"document_id":"ibmcld_16294-8240-10414","score":14.0229435,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_03165-4477-6547","score":13.754705,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16471-91132-93270","score":12.660838,"text":"\n* [group by<group by list>]\n\nGroups the tuples that are produced from the same document by common values of a specified field. This clause is optional.\n* [order by<order by list>]\n\nOrders the output tuples that are produced by the select statement from each document. The order is based on the values of the order-by list, a comma-delimited list of expressions. This clause is optional.\n* [limit <maximum number of output tuples for each document>]\n\nLimits the number of output tuples for each document to the specified maximum. This clause is optional.\n\n\n\n\n\n\n\n Usage Notes \n\nThe semantics of the select statement are as follows:\n\n\n\n* Determine the input data (in tuples) by taking the Cartesian product of relations in the from list.\n* For each input tuple that is generated, filter it by applying the predicates in the (optional) where clause.\n* If the optional group by clause is present, group tuples that are produced from the same document by the values that are specified in the group-by list and compute the result of the aggregate functions within the select list.\n* Consolidate any overlapping tuples, according to the policy defined in the (optional) consolidation clause. If the optional order by clause is present, order these tuples by the values of the order-by list.\n* Compute all expressions within the select list on each tuple, and rename the columns as specified by the as clauses.\n* If the optional limit clause is present, limit the number of output tuples to the specified number of tuples for each document.\n\n\n\n\n\n\n\n Examples \n\nAn example of how to use the select statement is to extract phone numbers that match a pattern. Assume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_03158-23545-25765","score":12.514514,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16294-7-1981","score":12.238546,"text":"\nIntegrating with SMS \n\nIBM Cloud\n\nAdd a text messaging integration so your assistant can exchange messages with your customers.\n\nThe Short Messaging Service (SMS) supports text-only messages. Typically, SMS restricts the text message length to 160 characters. The Multimedia Messaging Service (MMS) supports sending images and text messages that are over 160 characters in length. When you create a phone number with Twilio, MMS message support is included automatically. IntelePeer MMS message support is not yet available.\n\nCustomers send text messages to your hosted phone number. Twilio and IntelePeer use a messaging webhook that you set up to send a POST request with the text message body to your assistant. Each response from the assistant is sent back to Twilio or IntelePeer to be converted to an outbound SMS message that is sent to the customer. The responses are sent to the SMS provider's API for processing. You provide your SMS provider's authentication token information, which serve as your API access credentials.\n\nRefer to the following sections to set up the integration for your SMS provider:\n\n\n\n* [Integrating SMS with Twilio](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-smsdeploy-sms-twilio)\n* [Integrating SMS with IntelePeer](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-smsdeploy-sms-intelepeer)\n\n\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone).\n\n\n\n Integrating SMS with Twilio \n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up an SMS with Twilio account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_16471-92779-94574","score":12.20562,"text":"\nAssume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber\nfrom PhoneNumbers D\nwhere MatchesRegex(\/444-888-d{4}\/,D.phoneNumber)\nlimit 1;\n\nAnother example of how you can use the select statement is to find approximate mappings of people and their corresponding phone numbers. Assume that the view Person is already defined, and that it has the columns person and the view PhoneNumbers. This select statement evaluates the where clause to find text spans that contain a person mention followed by a phone number within 1 to 3 words or tokens. The input to this statement is represented by a join of the Person and PhoneNumbers views in the from list.\n\ncreate view PersonPhone as\nselect P1.documentText, P1.person, P2.phoneNumber, CombineSpans(P1.person,P2.phoneNumber) as personPhoneSpan\nfrom Person P1, PhoneNumbers P2\nwhere FollowsTok(P1.person,P2.phoneNumber,1,3);\n\nThe personPhoneSpan column will contain the matching spans that give the approximate person-phone mapping.\n\npersonPhoneSpan\nJohn : 433-999-1000\nMartha Mob 433-999-1001\n\n\n\n* The select list The select list in an AQL select or extract statement consists of a comma-delimited list of output expressions.\n* The from list The second part of a select or an extract statement in AQL is the from list. The from list is a comma-separated list that is the source of the tuples to be selected or extracted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16289-2888-4673","score":11.862122,"text":"\nYou will need this value in a subsequent step.\n\n\n\n\n\n\n\n Configuring the phone number \n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Phone Numbers.\n3. Under Manage Numbers, configure the phone number you want your assistant to use. Select Buy a Number to buy a new number, or Port & Host to port an existing phone number.\n4. In the Active Numbers list, click the new phone number.\n5. Under Voice and Fax, configure the following settings:\n\n\n\n* For CONFIGURE WITH field, select Webhook, TwiML Bins, Functions, Studio, or Proxy.\n* For A CALL COMES IN, select Studio Flow. Select your flow from the drop-down list.\n* For PRIMARY HANDLER FAILS, select Studio Flow. Select your flow from the drop-down list.\n\n\n\n6. Go to the Watson Assistant user interface, open the phone integration settings for your assistant.\n7. In the Phone number field, type the phone number you configured in Flex Studio.\n8. Click Save and exit.\n\n\n\n\n\n\n\n Test your phone number \n\nYou can now test that your phone number is connected to your flow by triggering a Say\/Play widget in the Twilio Flex Flow editor.\n\n\n\n1. Drag a Say\/Play widget onto your flow canvas.\n2. Configure the Say\/Play widget with a simple phrase like I'm alive..\n3. Connect the Incoming call node on your Trigger widget to your Say\/Play widget.\n4. Call your phone number. You should hear your Twilio flow respond with your test phrase.\n5. Delete the Say\/Play widget and continue to the next step.\n6. If this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-flex"},{"document_id":"ibmcld_03179-1292-3261","score":11.850267,"text":"\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account and follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:\n\n\n\n* Phone Number: Specify the Twilio phone number that you created earlier.\n\nConsider provisioning more than one phone number and going through the process of getting permission for the numbers in parallel. If your number was used by a different business previously (because Twilio assigned you a number that was used before, for example), WhatsApp will reject it.\n* Are you working with an ISV: No\n* Twilio Account SID: From the Twilio site, click the home icon to go to your project dashboard to find the SID.\n* Facebook Business Manager ID: Add the ID for the account that you created in the previous step.\n\n\n\n4. Click Request Now.\n\n\n\nGive WhatsApp time to evaluate and approve your request. It can take up to 7 days for your request to be approved.\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03312-7276-9469","score":18.431595,"text":"\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16250-5445-7809","score":17.725168,"text":"\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03312-5487-7760","score":17.07429,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_03158-8929-11062","score":16.638548,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-7-2218","score":16.60754,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-10521-12298","score":14.925136,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-9295-10984","score":14.843839,"text":"\n* [Use other third-party providers](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup)\n* [Bring your own SIP trunk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-byost)\n* [Migrate from Voice Agent with Watson](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https:\/\/www.twilio.com\/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard. If you do not see it on the sidebar, go to the Search Bar at the top and search for 'Elastic SIP Trunking', then select Elastic SIP Trunks.\n3. On the Elastic SIP Trunks page, click the Create new SIP Trunk button to create a SIP trunk. Enter a name for your SIP trunk and click Create. If you already have a SIP trunk, go to the next step.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-17978-19852","score":14.80777,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_14636-9913-12364","score":14.695927,"text":"\n* The client is responsible for providing in\u2013depth documentation at the time of a failure and responding timely to IBM Support when further clarification is needed.\n* Clients are also responsible for following the guidelines set forth in this document to grant consent to proactive support.\n* By declining consent or failing to abide by the guidelines provided, the client assumes the responsibility of possible lag in problem resolution, which might be caused by communication delays between the client and support team.\n* The client should be prepared to perform more technical troubleshooting that would otherwise be done by IBM Support. IBM will provide appropriate documentation and assistance where necessary.\n\n\n\n\n\n\n\n Security measures \n\n\n\n* Management of Cloud Service - Client is responsible for managing administration, operation, maintenance, and security of the applications, including underlying middleware.\n* Service Integrity and Availability - IBM will forward to the Client all network intrusion notifications detected for this Cloud Service. It is the Client\u2019s responsibility to ascertain the impact of each notification that is reported. Client will be notified of hardware failures. Monitoring and responding to OS or software failures is the responsibility of the Client, engaging IBM support as required.\n* Activity Logging - Client is responsible for activity logging of OS\/System and Database\/Applications, as needed.\n* Encryption - Client is responsible for configuring and managing all encryption (for both data at rest and in transit), as needed.\n* Business Continuity and Disaster Recovery - Client is responsible for configuring and managing all business continuity and disaster recovery processes, as needed.\n\n\n\n\n\n\n\n Third-party services \n\n\n\n* Third-Party software or code is included or bundled with some of our IBM offerings. This code is included for your convenience but is not considered part of the IBM program.\n* These non\u2013IBM programs are licensed directly by their providers. Client agrees to use the non\u2013IBM programs under the provider\u2019s terms and conditions. These terms are provided in the IBM licensing agreement that accompanies the IBM offering at time of purchase.\n* IBM does testing to ensure that the third-party products work with IBM programs and that they function correctly.\n* IBM Support will diagnose client's problems by using the knowledge of how IBM offerings work with the Third-Party software.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_hybrid_compl_info"},{"document_id":"ibmcld_16321-20604-22275","score":14.683495,"text":"\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure\n\n\n\nFor more information, see [Handling call and transfer failures](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-failure).\n\n\n\n\n\n Passing Watson Assistant Metadata in SIP Signaling \n\nTo support loading the conversational history between the caller and Watson Assistant, the phone integration specifies a value for the User-to-User header as a key that can be used with the web chat integration. If User-to-User is specified in the transfer_headers list, the session history key is sent in the X-Watson-Assistant-Session-History-Key header.\n\nThe value of the SIP header is limited to 1024 bytes.\n\nHow this data is presented in the SIP REFER message also depends on the value of transfer_headers_send_method(as defined in [Generic Service Desk SIP Parameters](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsgeneric-service-desk-sip-parameters)).\n\nThe following example shows the data included as headers:\n\nREFER sip:b@atlanta.example.com SIP\/2.0\nVia: SIP\/2.0\/UDP agenta.atlanta.example.com;branch=z9hG4bK2293940223\nTo: <sip:b@atlanta.example.com>\nFrom: <sip:a@atlanta.example.com>;tag=193402342\nCall-ID: 898234234@agenta.atlanta.example.com\nCSeq: 23 REFER\nMax-Forwards: 7\nRefer-To: sip:user@domain.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4556051496}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14105-0-1469","score":12.294832,"text":"\n\n\n\n\n\n\n  Differences between versions of XenServer \n\nLicensing is the only difference between versions of XenServer that are installed on the system. If you want to upgrade your license to a higher class license after installation, you experience no downtime to reinstall your server. Contact IBM Cloud\u00ae sales for pricing information.\n\nNote: Not all available features are supported.\n\nThe following lists of features are included for each of the different licenses that are offered (as of XenServer 6.0):\n\nXenServer free, advanced, enterprise license features\n\n\n\n*  XenServer Hypervisor\n*  Conversion Tools\n*  Management integration with Microsoft System Center VMM\n*  Resilient distributed management architecture\n*  VM disk snapshot and revert\n*  XenCenter Management Console\n*  XenMotion Live Migration\n\n\n\nXenServer advanced and enterprise license features\n\n\n\n*  Automated VM protection and recovery (Automated VM protection and recovery is only available for the Advanced and Enterprise editions in the 6.0 release and later.)\n*  Distributed virtual switching\n*  Heterogeneous Pools\n*  High Availability\n*  Memory Optimization\n*  Performance alerting and reporting\n\n\n\nXenServer Enterprise license features\n\n\n\n*  Dynamic workload balancing\n*  GPU pass-thru\n*  Host power management\n*  IntelliCache\n*  Live memory snapshot and revert\n*  Provisioning Services (virtual)\n*  Role-based administration\n*  StorageLink\n*  Web management console with delegated admin\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-differences-between-versions-of-xenserver"},{"document_id":"ibmcld_07068-7-1672","score":11.114704,"text":"\nAPI version comparison \n\nFor most API methods, the request parameters and response bodies differ between v1 and v2. Learn about the equivalent or alternative v2 methods that you can use to do actions that are supported by the v1 API.\n\nThe comparison information assumes you are using the latest version of the v1 API (version 2019-04-30) and compares it to the latest version of the v2 API (version 2020-08-30).\n\n\n\n Environments \n\nThere is no concept of an environment in v2. The deployment details such as size and index capacity are managed based on the service plan type. In v2, collections are organized in projects. You can create different types of projects to apply default configuration settings to the collections that you add to the projects.\n\nThere are no equivalent methods in v2 for the v1 environment methods. However, the following table shows v2 methods that serve similar functions to the corresponding v1 methods. The supported parameters and response bodies that are returned for each method differ also.\n\n\n\nEnvironment API action support details\n\n Action v1 API Related v2 API \n\n Create an environment [POST \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverycreateenvironment) [POST \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datacreateproject) \n List environments [GET \/v1\/environments](https:\/\/cloud.ibm.com\/apidocs\/discoverylistenvironments) [GET \/v2\/projects](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistprojects) \n Get environment info [GET \/v1\/environments\/{environment_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygetenvironment) [GET \/v2\/projects\/{project_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagetproject)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_03369-1415-3586","score":10.922613,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_12897-4335-5761","score":10.73431,"text":"\n\"_rev\": \"2-61ae00e029d4f5edd2981841243ded13\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"Latest smartphone from Samsung\",\n\"price\": 650\n}\n\nAt the same time, someone else - working with a replicated database - reduces the price.\n\nSee a different revision, conflicting with the previous one because of different price value:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"2-f796915a291b37254f6df8f6f3389121\",\n\"name\": \"Samsung Galaxy S4\",\n\"description\": \"\",\n\"price\": 600\n}\n\nThe two databases are then replicated. The difference in document versions results in a conflict.\n\n\n\n Get conflicting revisions \n\nYou identify documents with conflicts by using the conflicts=true option.\n\nSee the following example of finding documents with conflicts:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?conflicts=true\n\nSee the following example response that shows conflicting revisions that affect documents:\n\n{\n\"_id\":\"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\":\"2-f796915a291b37254f6df8f6f3389121\",\n\"name\":\"Samsung Galaxy S4\",\n\"description\":\"\",\n\"price\":600,\n\"_conflicts\":[\"2-61ae00e029d4f5edd2981841243ded13\"]\n}\n\nThe version with the changed price was chosen arbitrarily as the latest version of the document. The conflict with another version is noted by providing the ID of that other version in the _conflicts array. In most cases, this array has only one element, but many conflicting revisions might exist.\n\n\n\n\n\n Merge the changes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_06941-0-1401","score":9.518193,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nFind answers to questions that are commonly asked about migrating from Discovery v1 to v2.\n\nDo the two versions have all the same features?\n:   There are many feature differences between the two versions. For a full feature comparison, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nHow do I know which version I'm using now?\n:   When you open the product user interface in v2, the following page is displayed:\n\nZoom\n\n![Shows the main My Projects page with a single Sample Project tile.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/gs-home-page.png)\n\nFigure 1. Home page from the Sample Project\n\nHow long will the migration take?\n:   The time you need to set aside for the migration differs based on the amount of data you want to retain in your existing v1 service instance.\n\nDo I need to update my existing applications for them to work with v2?\n:   Yes. You will need to edit any existing applications to account for changes that are introduced with Discovery v2. For more information, see the [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\nTo get started, see [Migrating to Discovery v2](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data--migration-faq"},{"document_id":"ibmcld_07067-1816-3544","score":9.460423,"text":"\n* For more information about feature differences, see [the feature comparison table](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-chooseversion-choose-comparison).\n* For more information about detailed API differences, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\nDiscovery v2 is available for all users of Plus or Enterprise plan instances, or Premium plan instances that were created after 15 July 2020. v2 is also available for IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data users.\n\n\n\n Migration overview \n\nMigrating from Discovery v1 to v2 is a multistep process that you can do independently.\n\nThe two versions of the Discovery service have many differences, but you can adopt techniques and utilities that were applied to a v1 instance for use with your new v2 instance.\n\nTo migrate from v1 to v2, you must complete the following high-level steps:\n\n\n\n1. [Plan the migration](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-plans).\n2. [Transfer your documents](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-docs).\n3. [Update your application to use the v2 API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-difs).\n4. Regression test and deploy the updated application.\n5. [Delete your v1 plan service instance](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-delete).\n\n\n\nSome steps require you to make programmatic changes by using the API and others involve changes that you can make from the product user interface.\n\n\n\n\n\n Plan the migration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_05873-81662-83420","score":9.446041,"text":"\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n egressGateways[name: istio-egressgateway].enabled: true In the managed Istio add-on, the egress gateway is enabled by default. \n istiod, istio-ingressgateway, and istio-egressgateway In the managed Istio add-on, istiod and all Istio ingress and egress gateways are set up for basic high availability support. High availability support on these components includes the following settings by default: node anti-affinity, HorizontalPodAutoscaler, PodDisruptionBudget, and automatic scaling of replicas. \n prometheus.enabled: false In the managed Istio add-on, the Prometheus, Grafana, Jaeger, and Kiali monitoring components are disabled by default due to current security concerns in the community release of Istio that can't be adequately addressed for a production environment. \n values.global.pilot.enableProtocolSniffingForInbound and values.global.pilot.enableProtocolSniffingForOutbound In the managed Istio add-on, protocol sniffing is disabled by default until the feature becomes more stable in the community Istio. \n\n\n\n\n\n\n\n Change log for 1.5.10, released 1 September 2020 \n\nReview the changes that are in version 1.5.10 of the managed Istio add-on.\n\nPrevious version\n: 1.5.9\n\nCurrent version\n: 1.5.10\n\nUpdates in this version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_01130-3870-5707","score":8.863471,"text":"\n![Serialization and deserialization diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry3.svg)\n\nSerializer and deserializer\n\nZoom\n\n![Compatibility and versions diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/e0c3acba1296ff980e76d5db456d53adefaabba4\/EventStreams\/schema_registry4.svg)\n\nCompatibility and versions\n\n\n\n\n\n Versions and compatibility \n\nWhenever you add a schema, and any subsequent versions of the same schema, Event Streams can validate the format automatically and reject the schema if any issues exist. You can evolve your schemas over time to accommodate changing requirements. Create a new version of an existing schema, and the Schema Registry ensures that the new version is compatible with the existing version, meaning that producers and consumers that use the existing version are not broken by the new version.\n\nSchemas are compared to avoid creating duplicate schemas where the schemas differ only in a way that does not affect the semantics of the schema. In some cases, the ordering of the JSON properties within a schema can be crucial to how the schema is used for encoding and decoding data, but in other cases it might not be relevant.\n\nFor example, the name property of a record schema is not used as part of the encoding and decoding process so you can position it anywhere inside the record JSON object. All these variations are considered the same schema.\n\nThe fields property in the JSON of a record schema is a case where its ordering is important. The Avro specification requires that a record\u2019s fields are encoded and decoded in the order they appear in the schema that is used for the encode and decode operation.\n\nAs an example, consider the following three schemas.\n\n\n\n Schema 1 \n\n{\n\"type\": \"record\",\n\"name\": \"book\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-ES_schema_registry"},{"document_id":"ibmcld_05873-80552-82182","score":8.830547,"text":"\n* [CVE-2020-1752](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https:\/\/istio.io\/latest\/news\/security\/istio-security-2020-008\/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https:\/\/istio.io\/latest\/news\/releases\/1.6.x\/announcing-1.6\/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-changelog"},{"document_id":"ibmcld_04621-100453-102201","score":8.75396,"text":"\n* The buildpack was updated to download the latest 1.x [MariaDB Connector\/J JDBC driver](https:\/\/mariadb.com\/kb\/en\/about-mariadb-connector-j\/) when performing [auto-configuration for MySQL type of services](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-auto_config).\n\n\n\nUpdated Node.js buildpack v3.0-20160125-1224\n: This release is fully synchronized with the [Cloud Foundry community Node.js](https:\/\/github.com\/cloudfoundry\/nodejs-buildpack) buildpack. In addition to community changes, modifications were made to certain defaults, along with optimizations to reduce staging time and updates to the App Management feature.\n\n\n\n* Buildpack updates:\n\n\n\n* Node.js v4.2.4 (IBM SDK for Node.js Version 4) is now the default runtime on IBM Cloud, replacing v0.12.9. This change might cause your app to behave differently if a particular version is not specified for your app. To learn how to specify a version of Node.js for your IBM Cloud app, see [Node.js runtime](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-nodejs_runtime) documentation.\n* NODE_ENV is now set to production by default. This change will cause some node dependencies to behave differently. For example, the Express framework will no longer return stack traces in the web browser for faulty endpoints, but instead displays Internal Server Error. When NPM_CONFIG_PRODUCTION is set to true, NPM will set NODE_ENV to production for subshell scripts in the NPM install phase only. This function allows users to set NODE_ENV to another value like development for app runtime. For clarity, NPM scripts will see the message NODE_ENV=production.\n* A Bug-fix to the Monitoring and Analytics service is included.\n\n\n\n* Caching updates:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-7-1778","score":17.01743,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_05684-2632-4362","score":14.388588,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud ks flavor get and ibmcloud ks flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud ks cluster create satellite command.\n: Adds new ibmcloud ks flavor get and ibmcloud ks flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439 \n\nVersion 1.0.439 of the CLI was released on 26 Aug 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelog"},{"document_id":"ibmcld_10140-2632-4302","score":13.969953,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud oc cluster create satellite command.\n: Adds new ibmcloud oc flavor get and ibmcloud oc flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_03369-177225-178461","score":13.929784,"text":"\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs)\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_05337-28650-29915","score":12.743327,"text":"\n1.0.0 30 March 2021 This version is the generally available release of Code Engine CLI.- Important Introduced a breaking change to Code Engine service binding functions. Service bindings that were created with releases of the CLI earlier than release 1.0.0 will no longer work after you update to the CLI 1.0.0 release. Unbind pre-existing service bindings before you update to CLI 1.0.0.<br><br><br><br> * Updated service bindings to use a new naming convention. Binding names are now autogenerated to ensure uniqueness.<br> * Updated the app unbind and job unbind commands to accept the --binding option. The --binding option replaces the --service-instance option.<br> * Renamed the service binding VCAP_SERVICES environment variable, which is injected into running containers, to CE_SERVICES.<br> * Updated application and job service bindings to support multiple service bindings to the same service instance.<br> * Updated support for service bindings such that service bindings that are created without existing service credentials always generate a new, unique service credential.<br> * Added more information to output for bad request errors encountered by the CLI.<br><br><br> \n 0.6.3 26 March 2021 <br><br> * Updated translations for the CLI.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli_versions"},{"document_id":"ibmcld_00861-1418-3367","score":12.7154255,"text":"\nFor more information about this new version of the IBM Cloud CLI plug-in, see [Big changes are coming to the IBM Cloud Kubernetes Service CLI plugin to change your experience for the better](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/boost-your-productivity-with-a-new-cli-experience-for-the-ibm-cloud-kubernetes-service). To maintain compatibility with the current IBM Cloud Kubernetes Service runtimes after the new version 1.0 is available, Continuous Delivery will update the current base image for the Delivery Pipeline to include this version. For production workloads, set any of your pipelines that are using the current base image to instead use version 2.6 until you can update your scripts to work with the new version.\n\nYou can also use [custom Docker images](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-custom_docker_images) to control both the tools and which versions of those tools are used to build and deploy applications. However, this method requires that you are familiar with Docker and you must maintain and update the image that you create.\n\nOn 20 November 2020, Dockerhub introduced rate-limiting on anonymous image pulls. This change might impact users that are running jobs by using Dockerhub-hosted custom images.\n\nPipeline base images are hosted in a global IBM Cloud Container Registry namespace. To list these images, run the ibmcloud cr images --restrict continuous-delivery command when you target the global IBM Cloud Container Registry.\n\n\n\n Specifying the image version \n\n\n\n1. On the Pipeline page, click Actions... to access the list of options.\n2. Click Configure Pipeline.\n3. In the Image version tab, select either the Experimental: RedHat UBI or the Ubuntu image type. Then, based on the selected image type, select the default image version to use for all jobs in your pipeline. You can also customize this setting for each job in each stage of your pipeline.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_14851-9765-11592","score":12.292105,"text":"\n* If introducing new hosts, ensure that they are of the same initial version and upgrade them along with the rest of the cluster.\n* If you are adding or replacing disks during an upgrade, ensure that they are formatted with the appropriate legacy on-disk format version, if applicable.\n* Therefore, certain vSAN behavior changes are controlled by the on-disk format it is important that newer on-disk format versions are not introduced into a mixed-version cluster.\n\n\n\n\n\n\n\n\n\n Upgrade the vCenter Server Appliance \n\nFor more information, see [VCSA update and SSO-linked vCenters](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vum-updating-vcsa).\n\n\n\n\n\n Upgrade the vSphere ESXi hosts \n\nFor more information, see [Creating baselines and attaching to inventory objects](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vum-baselines).\n\n\n\n\n\n Upgrade the vSAN disk format \n\nRuby vSphere Console (RVC) is a Ruby-based command-line interface for vSphere and can be used to manage VMware vSphere ESXi and vCenter. The vSphere inventory is presented in a tree structure, that allows you to navigate and run commands against vCenter objects.\n\nMany basic administrative tasks can be done much more efficiently than clicking through the vSphere Client. RVC is fully implemented in the VCSA and is accused by an SSH connection to the appliance.\n\n\n\n1. SSH to the VCSA and login by using root and the password that is provided on the ICVS Console.\n2. At the prompt, type: rvc Administrator@vsphere.local@localhost and press Enter.\n3. Enter the Administrator\u2019s password provided on the ICVS Console. You are now at the root of the virtual file system, type ls and then press Enter. The output is: 0 \/ 1 localhost\/\n4. Type cd 1, enter and then ls and press Enter. The output is: 0 \/ datacenter1 (datacenter)\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vum-updating-vsan"},{"document_id":"ibmcld_02114-36409-38347","score":12.179076,"text":"\nFor more information, see [ibmcloud catalog offering version cra](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-pluginversion-cra) and [ibmcloud catalog offering version scc](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-pluginversion-scc).\n\nibmcloud catalog offering get-scan-results [--version-locator LOCATOR]\n\n\n\n Command options \n\n--version-locator LOCATOR\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering version create-draft \n\nRun the following command to create a draft of an existing version. This command is useful for changing an existing version that you want to publish without introducing a new version. Some changes, like changing the source file, require you to revalidate the product.\n\nibmcloud catalog offering version create-draft --version-locator VERSION_NUMBER [--output FORMAT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering version delete-version \n\nRun the following command to delete a version of a product.\n\nibmcloud catalog offering version delete-version --version-locator VERSION_NUMBER [--output FORMAT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_09919-7-1859","score":12.115249,"text":"\nRelease notes for Natural Language Understanding \n\nThe following new features and changes to the service are available.\n\n\n\n Service API versioning \n\nCurrent API version: 2022-08-10\n\nAPI requests require a version parameter that takes the date in the format version=YYYY-MM-DD. Send the version parameter with every API request.\n\nWhen we change the API in a backwards-incompatible way, we release a new minor version. To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to that version, don't change your version date.\n\n\n\n Active version dates \n\nThe following table shows the service behavior changes for each version date. Switching to a later version date will activate all changes introduced in earlier versions.\n\n\n\n Version date Changes summary \n\n [2022-08-10](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notesnatural-language-understanding-aug1022) Language expansion of entities with a new model for improved accuracy and confidence scores.<br><br>Version 2 Russian entity type system.<br><br>Version 2 Swedish entity type system. \n [2022-04-07](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notesnatural-language-understanding-apr0722) Bug fix for Version 2 Categories type system. \n [2021-08-15](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notesnatural-language-understanding-aug1521) Classifications GA and Categories type system Version 2 features. \n [2021-03-25](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notesnatural-language-understanding-mar2521) Custom categories (beta) and custom classifications (beta) features.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_16516-6223-8371","score":11.984124,"text":"\n: Admins and Project Managers can annotate document sets directly from the Ground Truth tab on the Annotations page.\n: Annotation tasks are still available. You can manage them from the Annotation Tasks tab on the Annotations page.\n: Annotations applied directly to ground truth are not applied to related active annotation tasks. It is recommended that you annotate document sets directly only when they are not associated with any active annotation tasks.\n: The Annotation Sets tab has been removed from the Documents page. You can manage annotation sets from the Annotation Tasks tab of the Annotations page.\n\n- To create new annotation sets, click Add task. Then, click Create Annotation Sets.\n- To manage existing annotation sets, click an existing annotation task, then click Edit.\n\n\n\n\n\n\n\n March 2019 \n\n\n\n New features and changes \n\nCustom categories workspace (Experimental)\n: Introduced an experimental custom categories workspace for Knowledge Studio service instances on Lite and Standard plans that are hosted in the Dallas location. With the new workspace, you can deploy your own custom text categorization model to Natural Language Understanding or Discovery.\n\n\n\n\n\n\n\n January 2019 \n\nMigrating Cloud Foundry service instances\n: You can now migrate Knowledge Studio Cloud Foundry service instances to a resource group.\n\n\n\n\n\n December 2018 \n\n\n\n New features and changes \n\nSupport to deploy same model to multiple instances\n: Introduced support to deploy the same machine learning model version to multiple service instances and general improvements to the Version History and Deployment page. For more information about deploying multiple instances of the same model version see [Deploying the same model version to multiple services](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_secdep)\n\nAdded models method\n: Added the models method to the Natural Language Understanding service allowing users to list deployed Knowledge Studio models.\n\n\n\n\n\n\n\n September 2018 \n\n\n\n New features and changes \n\nSupport for additional document types\n: Introduced support for HTML, DOC, DOCX, and PDF files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-6657-8493","score":22.978956,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15545-195860-197138","score":22.898176,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":22.898176,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-195756-197034","score":22.898176,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-195812-197090","score":22.898176,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15646-25256-26940","score":22.647043,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":22.442137,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-5434-7003","score":22.263891,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15544-7685-9445","score":21.640545,"text":"\nUsing the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instance.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by using calendar date and time or number of days. The obsolescence date must always be after the deprecation date. \n\n\n\n\n\n\n\n Importing a custom image by using the CLI \n\nMake sure that your compatible custom image is available in IBM Cloud Object Storage. For more information, see [Creating a Linux custom image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-linux-custom-image), [Creating a Windows custom image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-windows-custom-image), [Bring your own license](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-byol-vpc-about) and [Uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) to IBM Cloud Object Storage.\n\nWhen you have an image available in IBM Cloud Object Storage, you can import it to IBM Cloud VPC infrastructure by using the command-line interface (CLI).\n\nTo import a custom image by using the CLI, use the ibmcloud is image-create command. Specify the name of the custom image to be created by using the IMAGE_NAME variable. You must also specify the source; for example, specify the --file option with the image file location. Specify the --os-name option with the name of the operating system for the image.\n\nibmcloud is image-create IMAGE_NAME [--file IMAGE_FILE_LOCATION] [--os-name OPERATING_SYSTEM_NAME]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-importing-custom-images-vpc&interface=ui"},{"document_id":"ibmcld_15558-196868-198205","score":21.581942,"text":"\nDate and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-obsolete-at: Specify this flag to remove an existing obsolescence date and time. If the image status is \"obsolete\", it becomes \"deprecated\" if \"deprecate_at\" is in the past. Otherwise, it becomes \"available\".\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-delete \n\nDelete one or more images.\n\nibmcloud is image-delete (IMAGE1 IMAGE2 ...) [--output JSON] [-f, --force] [-q, --quiet]\n\n\n\n Command options \n\n\n\n* IMAGE1: ID or name of the image.\n* IMAGE2: ID or name of the image.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* --force, -f: Force the operation without confirmation.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-export-job","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.4716276525}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-8094-9618","score":21.939234,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-29196-30599","score":21.734129,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-29235-30638","score":21.734129,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-5434-7003","score":21.163715,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":21.10803,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-27849-29558","score":21.102932,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-1716-3433","score":21.00257,"text":"\nFailed Image creation failed. \n Deleting The image is being deleted. \n Deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before the status changes to obsolete. \n Obsolete You can't use the image to a create an instance. If you try to use an obsolete image to create an instance, you receive a message that the image can't be used to create an instance. This status allows a reversible disabiling of an image before you delete the image. \n\n\n\n\n\n\n\n Scheduling an image from volume lifecycle status by using the UI \n\nYou can schedule either a single image lifecycle status change or schedule the status changes for the entire lifecycle of the image.\n\nUse the following steps to schedule a single status change:\n\nYou can schedule a single status change for an image.\n\n\n\n1. In [IBM Cloud console](https:\/\/cloud.ibm.com\/login), go to Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2. On the Custom images tab, click the Actions icon ![More Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/action-menu-icon.svg) for a specific image and select from the available options.\n3. Select Schedule lifecycle.\n4. In Image status, select the status change for the image.\n5. In Deprecation details, select whether to change status Immediately or to Schedule future date.\n6. If you selected Schedule future date, you need to fill out the following:\n\n\n\n* Select either By calendar date or By number of days.\n\n\n\n* If you selected By calendar date, enter the date and time information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15647-25269-26966","score":20.812939,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-27823-29559","score":20.779215,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15507-9295-10840","score":20.404808,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.1428571429,"recall_10":0.2857142857,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1312050775,"ndcg_cut_10":0.1930505095}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":22.185143,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_07578-1213887-1215935","score":17.340887,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":17.340887,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16729-294066-295916","score":16.55405,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_12498-9696-11699","score":16.06589,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":16.04966,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12717-7818-8740","score":15.116917,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_06843-4238-6198","score":15.019766,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_06881-2811-4554","score":14.968099,"text":"\nIt runs the static scans and dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan. After scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence, so the Security and Compliance Center Center can update the compliance status of the found artifacts.\n\nThe CC pipeline uses the [async sub pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-async-stagesasync-stages-setup-triggers) that runs in parallel to the main pipeline run to optimize pipeline run time and improve pipeline resiliency.\n\nThis tutorial uses a staging environment as an example to configure and showcase the continuous compliance (CC) toolchain.\n\nThe CC toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner at pre-defined intervals on the application repositories that are provided to detect secrets in the application source code and vulnerable packages that are used as application dependencies.\n* Scan the container image for security vulnerabilities.\n* Any incident issue that is found during the scan or updated is marked with a due date.\n* Generate a summary.json file and store in IBM Cloud Object Storage at the end of every run that summarizes the details of the scan.\n\n\n\nLet's get started with the creation and exploration of the CC toolchain.\n\n\n\n\n\n Step 1: Start the CC toolchain setup \n\nStart the CC toolchain configuration by using one of the following options:\n\n\n\n* Click Create toolchain.\n\n[!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_12479-7-1826","score":14.319601,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14389-3006-4736","score":17.192585,"text":"\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS\n* Open Web Application Security Project (OWASP) top 10 threats\n* Common application vulnerabilities\n\n\n\n\n\nBIG-IP Access Policy Manager\u2122 (APM) offers users secure, simplified access to applications located anywhere within a multicloud environment, incorporating features such as SSO (Single Sign-On) and MFA (Multifactor Authentication).\n\nYou cannot change the license model after service installation. To change the license model, you must delete the existing service and reinstall the service by choosing a different license model.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [F5 BIG-IP overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_considerations)\n* [Managing F5 BIG-IP](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing_f5)\n* [Ordering services for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservices)\n* [Contacting IBM\u00ae Support](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-trbl_support)\n* [FAQ](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)\n* [F5 Deployment Guides](https:\/\/www.f5.com\/services\/resources\/deployment-guides)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_ordering"},{"document_id":"ibmcld_07949-17036-19108","score":14.301064,"text":"\nBy monitoring for risks, you can identify security vulnerabilities and quickly work to mitigate the impact and fix the issue. By using Security and Compliance Center along with [external integrations](https:\/\/cloud.ibm.com\/security-compliance\/integrations) (such as, OpenShift Compliance Operator (OSCO), Tanium, NeuVector, and so on), you can build a robust approach for monitoring for security and compliance issues.\n\n\n\n\n\n\n\n Integration \n\n\n\n IBM Event Streams for IBM Cloud (optional) \n\n[Event Streams](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-about) is a high-throughput message bus built with Apache Kafka. It is optimized for event ingestion into IBM Cloud and event stream distribution between your services and applications.\n\nYou can use Event Streams to complete the following tasks:\n\n\n\n* Offload work to back-end worker applications.\n* Connect event streams to streaming analytics to realize powerful insights.\n* Publish event data to multiple applications to react in real time.\n\n\n\nEvent Streams offers a fully managed Apache Kafka service, ensuring durability and high availability for our clients. By using Event Streams, you have support around the clock from our team of Kafka experts.\n\n\n\n\n\n\n\n Databases \n\n\n\n IBM Cloud Hyper Protect DBaaS for MongoDB (optional) \n\nMoving confidential and mission-critical data to the cloud presents data confidentiality, security, and reliability concerns. [IBM Cloud\u00ae Hyper Protect DBaaS for MongoDB](https:\/\/cloud.ibm.com\/docs\/hyper-protect-dbaas-for-mongodb?topic=hyper-protect-dbaas-for-mongodb-overview) offers highly secure database environments that have technology-enforced protection and high availability.\n\nBuilt on IBM LinuxONE technology, Hyper Protect DBaaS for MongoDB helps you to alleviate data security and compliance concerns with built-in encryption and tamper protection for data at rest and in flight. You can deploy your workloads with sensitive data and build compliant applications without having to be a security expert.\n\n\n\n\n\n IBM Cloud Hyper Protect DBaaS for PostgreSQL (optional)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-about"},{"document_id":"ibmcld_16696-7-2390","score":14.137725,"text":"\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-key-features"},{"document_id":"ibmcld_16674-3-1592","score":13.899015,"text":"\nIBM Cloud Security and Compliance Center Workload Protection \n\nUse IBM Cloud Security and Compliance Center Workload Protection to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/workload-protection)[CLI reference](https:\/\/cloud.ibm.com\/docs\/workload-protection-cli-plugin)\n\n Recommended content \n\n[Getting started with IBM Cloud Security and Compliance Center Workload Protection Use the IBM Cloud Security and Compliance Center Workload Protection CLI to configure your account to detect and respond to software vulnerabilities.](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-getting-started)[See what's new Read about the latest changes to IBM Cloud Security and Compliance Center Workload Protection. ](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-release-notes)\n\n Learn more \n\n[IBM Developer<br><br>Visit IBM Developer for technical articles, code patterns, tutorials, and more.<br><br>![112-Developer-tools.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/112-Developer-tools.svg)](https:\/\/developer.ibm.com\/depmodels\/cloud\/)[Architecture Center<br><br>Discover the architecture references available for this product.<br><br>![190-Application-Platform.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/190-Application-Platform.svg)](https:\/\/www.ibm.com\/cloud\/architecture)[IBM Training<br><br>Build your skills with IBM Cloud training.<br><br>!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection"},{"document_id":"ibmcld_11605-7-2426","score":13.689444,"text":"\nIBM Security Services for SAP \n\nIBM Cloud\u00ae Security Services for SAP offer a cybersecurity solution that automates the monitoring and protection of SAP applications on IBM Cloud, and keeps workloads compliant and secure from inside and outside threats.\n\nIBM Services for SAP, developed in partnership with IBM Security Software and other business partners, implement and configure the SAP landscape to meet IT environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, IBM Security Services are able to deliver near real-time preventive, detective, and corrective solutions for securing SAP systems and applications with unmatched coverage and protection. This protection includes context-aware insight across SAP NetWeaver ABAP or Javas and SAP HANA platforms, with network security, security management, and associated workflows.\n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors\n* Methods to implement and avoid defects in ABAP code or SAP Transports\n* Identifying configuration vulnerabilities for ABAP, JAVA, and HANA environments\n* Identifying missing or outdated SAP notes and patches\n* Identifying, monitoring and review of highly privileged SAP accounts\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution\n\n\n\nKey benefits of requesting IBM Security Services for SAP to assist with your IBM Cloud\u00ae for SAP deployments:\n\n\n\n* Consultative engagement methods centered on your business objectives\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features\n* Rapid learning and risk mitigation through access to IBM Cloud experts\n\n\n\nFor more information, see [IBM.com - IBM Security - SAP Security and GRC Strategy Services](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy)\n\n\n\n Procedure to request IBM Security Services for SAP \n\nTo begin with IBM Security Services for SAP, use either:\n\n\n\n* Live Chat with IBM Security Sales, by using [IBM.com - IBM Security](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy) and click Let's talk in the botttom-left","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-security-services"},{"document_id":"ibmcld_09835-0-777","score":13.589293,"text":"\n\n\n\n\n--------------------\n\n\n\n  Identifying software vulnerabilities \n\nYou can also use the IBM Cloud Monitoring Workload Protection service to find and prioritize software vulnerabilities, detect and respond to threats, and manage configurations, permissions and compliance from source to run.\n\nThe ability to monitor software vulnerabilities is included when you use the [Graduated Tier - Sysdig Secure + Monitor service plan](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-service_plans). This plan integrates IBM Cloud Security and Compliance Center Workload Protection as part of IBM Cloud Monitoring.\n\nFor more information, see the [IBM Cloud Security and Compliance Center Workload Protection documentation.](https:\/\/cloud.ibm.com\/docs\/workload-protection)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-workoad-protection"},{"document_id":"ibmcld_11573-21506-21994","score":13.147262,"text":"\n* [SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities](https:\/\/launchpad.support.sap.com\/\/notes\/2588225)\n* [SAP Note 1380654 - SAP support in IaaS environments](https:\/\/launchpad.support.sap.com\/\/notes\/1380654)\n* [SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment](https:\/\/launchpad.support.sap.com\/\/notes\/2414097)\n\n\n\nThis automation is offered free of charge however, the provisioned infrastructure comes at cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-create-terraform-3tier-nw-hana-vpc-ansible"},{"document_id":"ibmcld_10510-7-2044","score":13.13991,"text":"\nSecurity for Red Hat OpenShift on IBM Cloud \n\nYou can use built-in security features in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae for risk analysis and security protection. These features help you to protect your cluster infrastructure and network communication, isolate your compute resources, and ensure security compliance across your infrastructure components and container deployments.\n\n\n\n Overview of security threats for your cluster \n\nTo protect your cluster from being compromised, you must understand potential security threats for your cluster and what you can do to reduce the exposure to vulnerabilities.\n\nExternal attacks\n: Attackers that gain access to your cluster, deployed resources, apps, or personal information.\n\nVulnerable deployments\n: Known vulnerabilities are exploited to gain access to the cloud environment and run malicious software.\n\nCompromised or lost data\n: Incorrect storage of sensitive data and missing encryption.\n\nInsiders and third party vendors\n: Missing network isolation and segmentation can lead to the misuse of legitimate permissions.\n\nCloud security and the protection of your systems, infrastructure, and data against attacks became very important over the last couple of years as companies continue to move their workloads into the public cloud. A cluster consists of several components that each can put your environment at risk for malicious attacks. To protect your cluster against these security threats, you must make sure that you apply the latest Red Hat OpenShift on IBM Cloud, Red Hat OpenShift, and Kubernetes security features and updates in all cluster components.\n\nThese components include:\n\n\n\n* [Red Hat OpenShift API server and etcd data store](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityapiserver)\n* [Worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityworkernodes)\n* [Network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork)\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitystorage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06063-7-2179","score":12.736933,"text":"\nSecurity for IBM Cloud Kubernetes Service \n\nYou can use built-in security features in IBM Cloud\u00ae Kubernetes Service for risk analysis and security protection. These features help you to protect your cluster infrastructure and network communication, isolate your compute resources, and ensure security compliance across your infrastructure components and container deployments.\n\nFor an analysis of security guidelines by product version, see [CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n Overview of security threats for your cluster \n\nTo protect your cluster from being compromised, you must understand potential security threats for your cluster and what you can do to reduce the exposure to vulnerabilities.\n\nExternal attacks\n: Attackers that gain access to your cluster, deployed resources, apps, or personal information.\n\nVulnerable deployments\n: Known vulnerabilities are exploited to gain access to the cloud environment and run malicious software.\n\nCompromised or lost data\n: Incorrect storage of sensitive data and missing encryption.\n\nInsiders and third party vendors\n: Missing network isolation and segmentation can lead to the misuse of legitimate permissions.\n\nCloud security and the protection of your systems, infrastructure, and data against attacks became very important over the last couple of years as companies continue to move their workloads into the public cloud. A cluster consists of several components that each can put your environment at risk for malicious attacks. To protect your cluster against these security threats, you must make sure that you apply the latest IBM Cloud Kubernetes Service and Kubernetes security features and updates in all cluster components.\n\nThese components include:\n\n\n\n* [Kubernetes API server and etcd data store](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityapiserver)\n* [Worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworkernodes)\n* [Network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork)\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitystorage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_14459-7-2518","score":12.303304,"text":"\nIBM Security Services for SAP on IBM Cloud overview \n\nIBM Security Services for SAP\u00ae on IBM Cloud offer a cybersecurity solution to automate the monitoring and protection of SAP applications on IBM Cloud, and to keep workloads compliant and secure from inside and outside threats. IBM Security Services for SAP on IBM Cloud is a non-IBM product that is offered under terms and conditions from Entrust and Intel, not IBM.\n\nThese services, developed between IBM Security and Onapsis (an IBM Business Partner), are designed to implement and configure Onapsis specifically to your environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, the Onapsis Security Platform delivers a near real-time, preventive, detective, and corrective solution for securing SAP systems and applications. The Onapsis Security Platform provides unmatched coverage and protection with context-aware insight across SAP NetWeaver ABAP, Java\u00ae Platform, Enterprise Edition, and HANA platforms. The platform integrates with network security, security management, and associated workflows.\n\n\n\n Technical specifications for IBM Security Services for SAP \n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors.\n* Methods to implement and avoid defects in ABAP code or SAP Transports.\n* Identifying configuration vulnerabilities for ABAP, Java\u00ae, and HANA environments.\n* Identifying missing or outdated SAP notes and patches.\n* Identifying, monitoring and review of highly privileged SAP accounts.\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution.\n\n\n\n\n\n\n\n Key benefits of IBM Security Services for SAP \n\nYou can expect the following benefits when you request IBM Security Services for SAP:\n\n\n\n* Consultative engagement methods centered on your business objectives.\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team.\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud.\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features.\n* Rapid learning and risk mitigation through access to IBM Cloud experts.\n\n\n\n\n\n\n\n Procedure to request IBM Security Services for SAP \n\n\n\n1. In the IBM Cloud for VMware Solutions console, scroll down to the services section and click IBM Security Services for SAP in the Featured workload solutions category.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing-ss-sap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":17.176542,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-9696-11699","score":15.338671,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":15.140772,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12467-1716-3849","score":14.171062,"text":"\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL\/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_12493-27359-28981","score":14.072236,"text":"\nPrerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager. For more information, see [Examples](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-static-secret-examples).\n\npassword\n: The new password to assign to a username_password secret.\n\ncertificate\n: The new certificate data to store for an imported_cert secret. Supported file type is .pem.\n\nprivate_key\n: The new private key data to store for an imported_cert secret. Supported file type is .pem.\n\nintermediate\n: The new intermediate certificate data to store for an imported_cert secret. Supported file type is .pem.\n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n-force\n: Replaces the password that is stored for a username_password secret with a randomly generated, 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\n\n\n\n\n Examples \n\nManually rotate the secret data that is stored for an arbitrary secret.\n\nvault write -format=json ibmcloud\/arbitrary\/secrets\/fe874c2b-e8fd-bbb6-9f19-e91bbe744735\/rotate payload=\"Updated secret data.\"\n\nManually rotate the password that is stored for a username_password secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_12428-14731-16279","score":14.069904,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-14705-16253","score":14.069904,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_16727-1218119-1220168","score":14.067518,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":14.067518,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12717-7818-8740","score":14.061296,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":21.087656,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":20.580236,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12498-9696-11699","score":19.179663,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_16727-1218119-1220168","score":19.121593,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":19.121593,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12428-4-1817","score":18.784506,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-4-1817","score":18.784506,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12479-7-1826","score":18.748579,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"},{"document_id":"ibmcld_07578-1213887-1215935","score":18.55468,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":18.55468,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12518-7-1970","score":18.630882,"text":"\nAuditing events for account, IAM, catalog management \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud\u00ae Activity Tracker service to track how users and applications interact with an IBM Cloud\u00ae account, the IBM Cloud catalog, private catalogs, and with IBM Cloud Identity and Access Management (IAM).\n\nTo get started with monitoring your user's actions, see [Activity Tracker](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-getting-startedgetting-started).\n\n\n\n Account management events \n\nYou can track the following events:\n\n\n\n* Managing an account by creating an account, updating information, activating an account, or creating a Subscription account\n* Adding or removing users\n* Creating organizations\n\n\n\n\n\n\n\n IAM events \n\nYou must create an instance of the Activity Tracker service in the Frankfurt (eu-de) region to start tracking IAM events. When you create the instance, you can track the following events:\n\n\n\n* Managing access groups by creating and deleting groups or adding and removing users\n* Creating, updating, or deleting service IDs\n* Creating, updating, or deleting API keys\n* Creating, updating, or deleting access policies\n* Creating, updating, or deleting trusted profiles\n* Logging in to IBM Cloud by using an API key, authorization code, passcode, password, or an API key associated with a service ID\n* Logging in to IBM Cloud by using a trusted profile. For more information, see [Monitoring login sessions for trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-trusted-profile-monitor).\n\n\n\nFor more information, see [IAM events](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_iam).\n\n\n\n\n\n Catalog management events \n\nYou can track the following events:\n\n\n\n* Viewing or updating account settings\n* Viewing or updating a catalog\n* Listing all products in a catalog\n* Listing all products in an account\n* Creating, updating, viewing, or deleting a product","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-acct_iam_tracking"},{"document_id":"ibmcld_01623-10743-12723","score":16.53693,"text":"\nFor example, if you know multiple users in your account need to be able to apply subscription codes, track usage, or perform other billed-related tasks, you might name your group Billing-Editor-Access.\n\n\n\n2. Assign access to the group.\n\n\n\n1. Click Access > Assign access.\n2. Select individual services or a group of services:\n\n\n\n* All Identity and Access enabled services: Assigns access to all catalog services that use IAM for access management.\n* All Account Management services: Assigns access to manage platform services, such as billing, license and entitlements, and enterprises. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services&interface=uiaccount-management-actions-roles).\n* All IAM Account Management services: Assigns access to a subset of account management services that includes the IAM platform services IAM Identity, IAM Access Management, IAM User Management, IAM Groups, and future IAM services.\n\n\n\n3. Click Next.\n4. Select all roles that apply, then click Next.\n5. Click Add and repeat as needed.\n6. Click Assign.\n\n\n\n\n\nSee [What makes a good access group strategy?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setupresource-group-strategy) for details about how to best set-up your access groups.\n\n\n\n\n\n Step 8: Invite users to your account \n\nYou're ready to invite users to your account and grant them access based on the resources they work with and the tasks they perform. If you want users to create resources from the catalog and assign the resources to a resource group, the following access is required:\n\n\n\n* Viewer role or higher on the resource group.\n* Editor or administrator role on the service.\n\n\n\nComplete the following steps:\n\n\n\n1. Go to Manage > Access (IAM) > Users in the IBM Cloud console.\n2. Click Invite users.\n3. Specify the email address of the user. If you are inviting more than one user, they are all assigned the same access.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_11163-82702-85033","score":15.947934,"text":"\nFor more information and a comprehensive list of data centers and regions, see [Service availability](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-services_region).\n\n\n\nTable 1. New location names\n\n Previous Location Display Name New Location Display Name Code \n\n US South Dallas us-south \n US East Washington DC us-east \n United Kingdom London eu-gb \n Germany Frankfurt eu-de \n Sydney Sydney au-syd \n AP North Tokyo jp-tok \n\n\n\n\n\n\n\n\n\n October 2018 \n\n\n\n 30 October 2018 \n\nAssign account management access to others\n: With IBM Cloud Identity and Access Management (IAM), you can delegate common tasks that you complete as an account administrator to another user in your account. By creating an access policy on one or all of the available account management services, you can easily delegate responsibilities such as inviting and removing users, managing access groups, managing service IDs, maintaining private catalog services, and even monitoring billing and tracking usage. There are four individual account management services and an all services option that you can use to set up access policies:\n\n\n\n* User Management for inviting and removing users\n* IAM Access Groups for creating, editing, deleting, updating, and assigning access\n* IAM Identity Service for viewing, creating, deleting, and assigning access to service IDs and associated API keys across the account\n* Global resource catalog for viewing private catalog offerings and updating the metadata and visibility for the offerings\n* All account management services for access to each of the individual account management service options based on the assigned role as well as access to billing and usage tracking.\n\n\n\nFor more information on the tasks that a user can do based on which account management service they have a policy on and which role they are assigned, see [Example platform management roles and actions for account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles). For more information about this new feature, see the [Introducing More Flexibility and Control for IBM Cloud Account Management Services Access](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/introducing-more-flexibility-and-control-for-ibm-cloud-account-management-services-access) blog post.\n\n\n\n\n\n\n\n July 2018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_12613-7-2387","score":15.824972,"text":"\nIBM Cloud IAM roles \n\nAll services that are organized in a resource group in your account are managed by using IBM Cloud Identity and Access Management (IAM). Account owners are automatically assigned the account administrator role. As the account administrator, you can assign and manage access for users, create resource groups, create access groups, create trusted profiles, view billing details and track usage, and create service instances. You provide access for users, service IDs, access groups, and trusted profiles by creating policies that set a target for the subject of the policy to access and a role that defines what type of access that is allowed.\n\n\n\n IAM roles \n\nYou can manage and define access based on specific roles for users and resources in your account.\n\n\n\n* Platform management roles cover a range of actions, including the ability to create and delete instances, manage aliases, bindings, and credentials, and manage access. The platform roles are administrator, editor, operator, viewer. Platform management roles also apply to [account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles) that enable users to invite users, manage service IDs, access policies, catalog entries, and track billing and usage depending on their assigned role on an account management service.\n* Service access roles define a user or service\u2019s ability to perform actions on a service instance, such as accessing the console or performing API calls. The most common service access roles are manager, writer, and reader. Each service maps particular actions for working with the service to each of these roles.\n\nYou might not see all of the roles that are listed here as options when you assign policies in the UI because only the roles available for the service that you chose are displayed. For more information on what roles are enabled and what actions each access role allows for each service, see the documentation for that service.\n* Custom roles for a service can be created on the IAM Roles page by the account owner or a user assigned the administrator role on the role management service.\n\nYou can review the available roles and associated actions for a particular service by going to the [Roles](https:\/\/cloud.ibm.com\/iam\/roles) page, and selecting the service that you want to learn more about.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-userroles"},{"document_id":"ibmcld_01623-9218-11190","score":15.344071,"text":"\nOr, you can access it directly from the [Notification preferences](https:\/\/cloud.ibm.com\/user\/notifications) page by clicking Manage in the Billing and Usage section.\n\nYou receive notifications when you reach 80%, 90%, and 100% of the spending thresholds that you specify. Enter the dollar amount to set a spending threshold when set up your spending notification. For more information, see [Setting spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending).\n\n\n\n\n\n\n\n Step 6: Create your resource groups \n\nResource groups provide a way for you to easily manage access to multiple resources and to view billing usage for a set of resources. With your Pay-As-You-Go account, you can create more resource groups in addition to the default resource group that's created for you.\n\n\n\n1. Go to Manage > Account > Account resources > Resource groups in the IBM Cloud console.\n2. Click Create.\n3. Enter a name for your resource group, and click Add.\n\n\n\nSee [What makes a good resource group strategy?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setupresource-group-strategy) for details about how to optimally organize resources in your resource groups.\n\n\n\n\n\n Step 7: Set up access \n\nIAM access groups provide a way for you to quickly and easily assign access to multiple resources in your account at one time.\n\n\n\n1. Create an access group.\n\n\n\n1. Go to Manage > Access (IAM) > Access Groups in the IBM Cloud console.\n2. Click Create.\n3. Enter a name for your group, and click Create. For example, if you know multiple users in your account need to be able to apply subscription codes, track usage, or perform other billed-related tasks, you might name your group Billing-Editor-Access.\n\n\n\n2. Assign access to the group.\n\n\n\n1. Click Access > Assign access.\n2. Select individual services or a group of services:\n\n\n\n* All Identity and Access enabled services: Assigns access to all catalog services that use IAM for access management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_12385-3409-5426","score":15.327146,"text":"\nIf you accidentally assign a secret to the wrong secret group, or if you don't want a secret to belong to the default secret group, delete the secret and create a new one.\n2. Optionally, use secret groups to allow privileged access to specific resources in your account.\n\nSecret groups can be used to grant direct access to resources that otherwise wouldn't be possible through IAM. For example, assume that User A has no access to Service A in IAM. If you create an IAM access policy that assigns User A to Secret Group A, and Secret Group A contains an [IAM credential](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) with a service ID that gives access to Service A, then you grant User A access to Service A. In this scenario, Secret Group A becomes a gateway to Service A, even if a restriction exists in IAM. Keep in mind that with this scenario it is possible to grant access to a resource unintentionally. Review your configuration carefully to ensure that your secret group assignments do not override your IAM access policies accidentally.\n3. Audit your secret groups regularly and remove them when they're no longer needed.\n\nGrant only the minimum access that is required, and delete a secret group when it is no longer needed.\n\nTo delete a secret group, it must be empty. If you need to remove a secret group that contains secrets, you must first [delete the secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-delete-secrets) that are part of the group.\n\n\n\n\n\n\n\n Track your related secrets by adding labels \n\nAdd labels so that you can further search by and categorize the secrets in your instance. When you use a consistent labeling schema, you can easily group similar secrets together.\n\n\n\n1. Label your secrets by using a consistent schema, such as creating labels to differentiate which secrets are used for a specific purpose. To add labels by using the Secrets Manager UI, go to the Secrets page, and then select a secret to edits its details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets"},{"document_id":"ibmcld_12791-78084-80482","score":15.320897,"text":"\n* User Management\n* Billing\n* Catalog management\n* Context-based restrictions\n* Enterprise\n* Global catalog\n* IBM Cloud shell settings\n* License and entitlement\n* Partner Center\n* Partner Center - Sell\n* Projects\n* Security and Compliance Center\n* Software instance\n* Support center\n\n\n\n\n\nTable 1. Roles and example actions for a policy on account management services\n\n Roles Actions \n\n Viewer All viewer role actions for the account management services \n Operator All operator role actions for the account management services \n Editor All editor role actions for the account management services and the ability to create resource groups \n Administrator All administrator role actions for the account management services and the ability to create resource groups \n\n\n\n\n\n\n\n All IAM Account Management services \n\nIdentity and Access Management (IAM) services make up a subset of all account management services. Give users access to all IAM account management services so that they can work with the following services:\n\n\n\n* IAM Access Groups\n* IAM Identity service\n* IAM Access Management\n\n\n\n* Role Management\n\n\n\n* User Management\n\n\n\n\n\nTable 2. Roles and example actions for a policy on all IAM account management services\n\n Roles Actions \n\n Viewer All viewer role actions for IAM services \n Operator All operator role actions for IAM services \n Editor All editor role actions for IAM services and the ability to create resource groups \n Administrator All administrator role actions for IAM services and the ability to create resource groups \n User API key creator Create API keys when the account setting to restrict API key creation is enabled \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"},{"document_id":"ibmcld_16727-112889-114655","score":15.1545105,"text":"\nFor details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https:\/\/cloud.ibm.com\/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-112910-114676","score":15.1545105,"text":"\nFor details, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https:\/\/cloud.ibm.com\/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https:\/\/cloud.ibm.com\/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12791-3746-5818","score":15.0328455,"text":"\nTable 2. Roles and example actions for a policy on all IAM account management services\n\n Roles Actions \n\n Viewer All viewer role actions for IAM services \n Operator All operator role actions for IAM services \n Editor All editor role actions for IAM services and the ability to create resource groups \n Administrator All administrator role actions for IAM services and the ability to create resource groups \n User API key creator Create API keys when the account setting to restrict API key creation is enabled \n Service ID creator Create service IDs when the account setting to restrict service ID creation is enabled \n\n\n\nSome roles that you might assign on a policy for All IAM Account Management services affect only certain resources. For example, the role Service ID Creator is relevant to only the IAM Identity service.\n\n\n\n\n\n Billing \n\nYou can give users access to update account settings, view subscriptions, view offers, apply subscription and feature codes, update spending limits, and track usage by using the Billing service.\n\n\n\nTable 3. Roles and example actions for the Billing service\n\n Roles Actions \n\n Viewer View account feature settings<br><br>View subscriptions in account<br><br>View account name<br><br>View subscription balances and track usage \n Operator View account feature settings<br><br>View subscriptions in account<br><br>View and change account name \n Editor View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage \n Administrator View and update account feature settings<br><br>View subscriptions in account<br><br>View offers in account<br><br>View and apply subscription and feature codes<br><br>View and change account name<br><br>View and update spending limits<br><br>Set spending notifications<br><br>View subscription balances and track usage<br><br>Create an enterprise","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-account-services"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00052-7-2119","score":23.194155,"text":"\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"},{"document_id":"ibmcld_00064-7-2200","score":23.129223,"text":"\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00060-7-1693","score":22.999216,"text":"\nRetrieving details of a serverless instance \n\nYou can retrieve information, like the instance ID (or GUID) and the provisioning state of an IBM Analytics Engine serverless instance from the instance details. You need the instance ID to use the Spark application REST API and the Livy batch APIs.\n\nYou can retrieve the details by:\n\n\n\n* [Using the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-cli)\n* [Using the IBM Cloud REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-api)\n\n\n\n\n\n Accessing instance details by using the IBM Cloud CLI \n\nTo get the details of an instance:\n\n\n\n1. List all of the created serverless instances:\n\n$ ibmcloud resource service-instances --service-name ibmanalyticsengine\n\nThis call retrieves the instances of type service_instance in all resource groups in all locations for your account.\n\nExample response:\n\nName Location State Type Resource Group ID\nserverless-instance us-south active service_instance 65xxxxxxxxxxxxxxxa3fd\n2. Enter the following command with the server instance name of your instance to view the instance details:\n\n$ ibmcloud resource service-instance \"Analytics Engine-xyz\"\n\nThis retrieves your instance from the resource groups under your account.\n\nExample response:\n\nName: Analytics Engine-xyz\nID:\ncrn:v1:staging:public:ibmanalyticsengine:us-south:a\/XXXXX:XXXXX::\nGUID: XXXXX\nLocation: us-south\nService Name: ibmanalyticsengine\nService Plan Name: standard-serverless-spark\nResource Group Name: Default\nState: active\nType: service_instance\nSub Type:\nCreated at: 2021-01-06T07:49:12Z\nCreated by: XXXXX","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details"},{"document_id":"ibmcld_00007-1713-3490","score":22.961,"text":"\nSee [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https:\/\/cloud.ibm.com\/docs\/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00020-7-2287","score":22.950176,"text":"\nBest practices \n\nUse the following set of recommended guidelines when provisioning and managing your serverless instances and when running Spark applications.\n\n\n\nTable 1. Best practices when using serverless instances including detailed descriptions and reference links\n\n Best Practice Description Reference Link \n\n Use separate IBM Analytics Engine service instances for your development and production environments. This is a general best practice. By creating separate IBM Analytics Engine instances for different environments, you can test any configuration and code changes before applying them on the production instance. NA \n Upgrade to the latest Spark version As open source Spark versions are released, they are made available in IBM Analytics Engine after a time interval required for internal testing. Watch out for the announcement of a new Spark versions in the Release Notes section and upgrade the runtime of your instance to move your applications to latest Spark runtime. Older runtimes are be deprecated and eventually removed as newer versions are released. Make sure you test your applications on the new runtime before making changes on the production instances. <br><br> * [Release notes for IBM Analytics Engine serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes)<br><br><br> \n Grant role-based access You should grant role-based access to all users on the IBM Analytics Engine instances based on their requirements. For example, only your automation team should have permissions to submit applications because it has access to secrets and your DevOps team should only be able to see the list of all applications and their states. <br><br> * [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless)<br><br><br> \n Choose the right IBM Cloud Object Storage configuration <br><br> * Disaster Recovery (DR) Resiliency: You should use the IBM Cloud Object Storage Cross Regional resiliency option that backs up your data across several different cities in a region. In contrast, the Regional resiliency option back ups data in a single data center.<br> * Encryption: IBM Cloud Object Storage comes with default built-in encryption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"},{"document_id":"ibmcld_00055-7-1864","score":22.689651,"text":"\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_00096-7-2347","score":22.411306,"text":"\nExplore creating serverless instances and submitting applications using the CLI \n\nLearn how to use the IBM Analytics Engine CLI to create the services that you need to create and manage a serverless instance, and submit and monitor your Spark applications.\n\nYou create a serverless instance by selecting the IBM Analytics Engine Standard serverless plan. When a serverless instance is provisioned, an Apache Spark cluster is created, which you can customize with library packages of your choice, and is where you run your Spark applications.\n\n\n\n Objectives \n\nYou will learn how to install and set up the following services and components that you will need to use the CLI:\n\n\n\n* An IBM Cloud Object Storage instance in which your IBM Analytics Engine instance stores custom application libraries and Spark history events.\n* A Object Storage bucket for application files and data files.\n* An IBM Analytics Engine serverless instance. This instance is allocated compute and memory resources on demand whenever Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the instance. The price is based on the actual usage of resources consumed by the instance, billed on a per second basis.\n* Logging service to help you to troubleshoot issues that might occur in the IBM Analytics Engine instance and submitted application, as well as to view any output generated by your application. When you run applications with logging enabled, logs are forwarded to an IBM Log Analysis service where they are indexed, enabling full-text search through all generated messages and convenient querying based on specific fields.\n\n\n\n\n\n\n\n Before you begin \n\nTo start using the the Analytics Engine V3 CLI you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* To install the IBM Cloud CLI. See [Getting started with the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) for the instructions to download and install the CLI.\n\n\n\nNow you can start using the Analytics Engine V3 CLI. You must follow the instructions in steps 1 and 2 to install the required services before you start with step 3 to upload and submit Spark applications. Step 4 shows you how to create a logging instance and enable logging. Step 5 shows you how to delete an Analytics Engine instance, although this step is optional.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli"},{"document_id":"ibmcld_00007-7-2159","score":22.28426,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00062-7-2216","score":22.283367,"text":"\nSecurity model \n\nIBM Analytics Engine serverless instances provide a security architecture that is designed to enable administrators and developers to create secure Spark clusters.\n\nThe following sections describe how the security model of IBM Analytics Engine serverlesss instances manages the access to and control of the secure instances.\n\n\n\n Controlling access to IBM Analytics Engine activities \n\nAccess to IBM Analytics Engine serverless instances is controlled by IAM authentication and authorization. IAM is the Identity and Access Management service of IBM Cloud\u00ae. User authentication and access control happens through IAM when you log in with your IBMId. See how to [retrieve the IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n\nAs an administrator or creator of the service instance, you can grant or deny access to other users with whom you may want to share the service instance. All activities on the service instance life cycle management, like modifying the instance configuration, submitting and tracking Spark applications or customizing the instance with custom library sets are controlled through IAM authentication and authorization. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless) to understand which operations are supported and what is the level of access required for each of those operations.\n\n\n\n\n\n Encrypting at Rest \n\nIBM Cloud Object Storage is the recommended data store to store the data required for executing Spark jobs on the cluster. IBM Cloud Object Storage comes with default built-in encryption. See [Encrypting your data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-encryptionencryption).\n\nIn addition, or as an alternative to using IBM Cloud Object Storage storage encryption in analytic scenarios for large-scale data, you can use Parquet modular encryption, especially when fine-grained access control is important. See [Working with Parquet modular encryption](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption-serverless).\n\n\n\n\n\n Encrypting endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverless"},{"document_id":"ibmcld_16642-7777-9007","score":22.001736,"text":"\n8afde05e-5fd8-4359-a597-946d8432dd45\n3. Get the IAM token. For instructions, see [steps](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n4. Create an instance by using the Resource controller REST API:\n\ncurl -X POST https:\/\/resource-controller.cloud.ibm.com\/v2\/resource_instances\/\n--header \"Authorization: Bearer $token\" -H 'Content-Type: application\/json' -d @provision.json\n\nThe provision.json file contains the provisioning parameters for the instance that you want to create. See [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nFollowing is a sample of the provision.json file.\n\n{\n\"name\": \"your-service-instance-name\",\n\"resource_plan_id\": \"8afde05e-5fd8-4359-a597-946d8432dd45\",\n\"resource_group\": \"resource-group-id\",\n\"target\": \"us-south\",\n\"parameters\": {\n\"default_runtime\": {\n\"spark_version\": \"3.3\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",\n\"endpoint\": \"s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"hmac_access_key\": \"your-access-key\",\n\"hmac_secret_key\": \"your-secret-key\"\n}\n}\n}\nShow more\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-provisioning-serverless"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.195190025,"ndcg_cut_10":0.4484679027}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00083-7-1689","score":14.994101,"text":"\nStandard Spark examples \n\nYou can use the following code samples to learn how to use Spark in different situations.\n\nTo understand how to access Object Storage, see [Understanding the Object Storage credentials](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-credentials-in-iae-serverless).\n\n\n\n Reading a CSV file from Object Storage using already stated credentials \n\nThe following code samples show you how to create a Python script that reads data from a CSV file to a Python DataFrame. Both the Python script and the CSV file are located in Object Storage.\n\nYou can use the same IBM Cloud Object Storage credentials that you specified at the time you submitted the Spark application or that were set as a default configuration when you created the IBM Analytics Engine service instance to read from Object Storage within the application.\n\nExample of the application called read-employees.py. Insert the Object Storage bucket name and service name. The service name is any name given to your Object Storage instance:\n\nfrom pyspark.sql import SparkSession\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"read-write-cos-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef read_employees(spark,sc):\nprint(\"Hello 1\" , spark )\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos:\/\/cosbucketname.cosservicename\/employees.csv\")\nprint(\"Hello 2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\nseniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND >= 6\")\nprint(\"Hello 3\", seniors)\nseniors.show()\n\ndef main():\nspark,sc = init_spark()\nread_employees(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"},{"document_id":"ibmcld_00086-7-1903","score":12.955635,"text":"\nSpark user interface \n\nThe Spark user interface (Spark UI) helps you to keep track of various aspects of a running Spark application.\n\nThe list below includes a few examples:\n\n\n\n* current running stage\n* number of tasks in a stage\n* reason for a longer running stage\n* strangler task in a stage\n* whether the executors in the application are used optimally\n* inspect into memory and disk consumption of the driver and executors\n\n\n\nFor details, see the [Spark-UI documentation](https:\/\/spark.apache.org\/docs\/latest\/monitoring.htmlweb-interfaces).\n\nIBM Analytics Engine displays the Spark UI only for the Spark applications that are currently running. You cannot access Spark UI for a completed application.\n\nUse the Spark history server to inspect the run of a completed Spark application. To access the Spark history server, see the [Access Spark history server](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless).\n\n\n\n Accessing the Spark UI \n\nThe Spark UI endpoint of a running Spark application is accessible from the service details page of the IBM Analytics Engine instance.\n\nThe following image shows you an example of the Application tab with the link to the Spark UI of a running application.\n\nZoom\n\n![Shows the ink to Spark-ui of a running application](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/spark_ui.png)\n\nFigure 1. Application tab of IBM Analytics Engine service details page\n\nThe Spark UI endpoint of the running Spark application can also be obtained by invoking the following IBM Analytics Engine REST API endpoints or corresponding SDK methods:\n\n\n\n* [Retrieve the details of a given Spark application](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3get-application)\n* [List Spark applications](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3list-applications)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-user-interface"},{"document_id":"ibmcld_16661-2743-3994","score":12.948101,"text":"\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog\nspark.sql(\"show databases from lakehouse\").show()\n\n demonstration: Create a basic Iceberg table, insert some data and then query table\nspark.sql(\"create table if not exists lakehouse.demodb.testTable(id INTEGER, name VARCHAR(10), age INTEGER, salary DECIMAL(10, 2)) using iceberg\").show()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"},{"document_id":"ibmcld_00029-6261-7679","score":12.899602,"text":"\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0},\n\u00a0 \"application\": \"cos:\/\/mybucket.ALIAS NAME\/create_table_data_engine.py\",\n\u00a0 \"arguments\": [\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\"<APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE>\"]\n\u00a0\u00a0\u00a0\u00a0}\n}\n\nParameter values:\n\nALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n\nMake sure that you select the standard aliases.\n{: important}\nShow more\n\n\n\n\n\n\n\n Reading data from table by passing full list of Data Engine parameters \n\nYou can read the data from the metastore table using the SQL querry.\n\nRead the data from the table by using the Spark SQL in the following application called select_query_data_engine.py:\n\nfrom pyspark.sql import SparkSession\nimport time\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"dataengine-table-select-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef select_query_data_engine(spark,sc):\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00054-3422-4901","score":12.561925,"text":"\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql:\/\/<CHANGEME>.databases.appdomain.CHANGEME\/ibmclouddb?sslmode=verify-ca&sslrootcert=\/home\/spark\/shared\/user-libs\/certificate_library_set\/custom\/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them. After running the following Spark application called postgres-create-schema.py, you will see the Hive metadata tables created against the \"public\" schema of the instance.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-schema\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef create_schema(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 time.sleep(30)\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 create_schema(spark,sc)\nif __name__ == '__main__':\n\u00a0 main()\n6. Now run the following script called postgres-parquet-table-create.py to create a Parquet table with metadata from IBM Cloud Object Storage in the Databases for PostgreSQL database.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-parquet-table-test\").getOrCreate()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_00071-13290-14873","score":12.462068,"text":"\n[EnvironmentVariableName]\" configuration (application_details > env) also. They will, however, be accessible only to the tasks running on the executor and not the driver.\n\nExample of pyspark application that accesses the environment variables that are passed using the \"os.getenv\" call.\n\nfrom pyspark.sql.types import IntegerType\nimport os\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"spark-env-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef returnExecutorEnv(x):\n Attempt to access environment variable from a task running on executor\nreturn os.getenv(\"TESTENV1\")\n\ndef main():\nspark,sc = init_spark()\n\n dummy dataframe\ndf=spark.createDataFrame([(\"1\",\"one\")])\ndf.show()\ndf.rdd.map(lambda x: (x[0],returnExecutorEnv(x[0]))).toDF().show()\n Attempt to access environment variable on driver\nprint (os.getenv(\"TESTENV1\"))\nspark.stop()\n\nif __name__ == '__main__':\nmain()\nShow more\n\n\n\n\n\n Run a Spark application with non-default language version \n\nThe Spark runtime support Spark application written in the following languages:\n\n\n\n* Scala\n* Python\n* R\n\n\n\nA Spark runtime version comes with default runtime language version. IBM extend support for new language versions and remove the existing language version to keep the runtime free from any security vulnerabilities. The system also provides settling time to transition your workloads when ever there is a new language versions. You can test your workload with a language version by passing an environment variable that points to the language version of the application.\n\nExample:\n\n\"application_details\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-api"},{"document_id":"ibmcld_00085-7-1802","score":11.936646,"text":"\nSpark history server \n\nThe Spark applications that are submitted on an IBM Analytics Engine instance forward their Spark events to the Object Storage bucket that was defined as the instance home. The Spark history server provides a Web UI to view these Spark events. The Web UI helps you to analyze how your Spark applications ran by displaying useful information like:\n\n\n\n* A list of the stages that the application goes through when it is run\n* The number of tasks in each stage\n* The configuration details such as the running executors and memory usage\n\n\n\nSee the [Spark History server documentation](https:\/\/spark.apache.org\/docs\/latest\/monitoring.htmlviewing-after-the-fact) for more details.\n\nYou can disable forwarding Spark events from a Spark application by setting the property spark.eventLog.enabled to false in the Spark application configuration.\n\n\n\n Starting and stopping the Spark history server \n\nBefore accessing the Spark history server, you need to start the server. When you no longer need it, you should stop the server. You will be charged for the CPU cores and memory consumed by the Spark history server while it is running.\n\nThe Spark history server can be started and stopped by using:\n\n\n\n* The [Analytics Engine REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessrest-api)\n* The [Analytics Engine instance UI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessiae-ui)\n\n\n\n\n\n Analytics Engine REST API \n\nYou can use the Analytics Engine REST API:\n\n\n\n1. To view the status of the Spark history server\n\ncurl \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n2. To start the Spark history server","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless"},{"document_id":"ibmcld_00054-5565-6372","score":11.715685,"text":"\ndf2=spark.sql(\"SELECT * from MYPARQUETBBSPEED\")\n\u00a0 df2.show()\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 generate_and_store_data(spark,sc)\n\u00a0 create_table_from_data(spark,sc)\n\u00a0 time.sleep(30)\nif __name__ == '__main__':\n\u00a0 main()\nShow more\n7. Run the following PySpark script called postgres-parquet-table-select.py to access this Parquet table with metadata from another Spark workload:\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-select-parquet-table-test\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef select_data_from_table(spark,sc):\n\u00a0 df=spark.sql(\"SELECT * from MYPARQUETBBSPEED\")\n\u00a0 df.show()\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 select_data_from_table(spark,sc)\n\u00a0 time.sleep(60)\nif __name__ == '__main__':\n\u00a0main()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_16661-2308-3705","score":11.533912,"text":"\nThe sample below demonstrates how to do some table maintenance operations by using Spark. For more information about the Iceberg Spark table maintenance operations, see [Table Operations](https:\/\/iceberg.apache.org\/docs\/1.2.1\/spark-procedures\/).\n\n\n\n\n\n\n\n Running the sample use case \n\nFollow the steps to run the Spark sample python file.\n\n\n\n Spark sample python file \n\nfrom pyspark.sql import SparkSession\nimport os\n\ndef init_spark():\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"},{"document_id":"ibmcld_13481-7434-8879","score":11.346515,"text":"\nThe SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)\n* [spark-dataengine-python](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine_spark-1.4.51-py3-none-any.whl)\n\n\n\nAn example of how to use the Python helper can be found in the [Watson Studio Notebooks section](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreusage_watson_notebooks).\n\nUse the following example to get started with IBM\u00ae Analytics Engine (IAE) or Spark runtimes in Watson Studio when using Scala. Submit the following application using a notebook or the spark-submit command:\n\npackage com.ibm.cloud.dataengine\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession.{Builder => SessionBuilder}\nimport SparkSessionBuilderAddOn._\nobject SparkSessionBuilderHMSConfigTest {\ndef main(args: Array[String]) = {\nval spark = SparkSession\n.builder()\n.appName(\"Spark DataEngine integration\")\n.enableDataengine(args(0), args(1), \"public\")\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\n.config(\"fs.stocator.scheme.list\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-6212-7871","score":21.92376,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16635-0-1693","score":20.557343,"text":"\n\n\n\n\n\n\n  HMS Overview \n\n\n\n  Hive Metastore \n\nHive Metastore (HMS) is a service that stores metadata related to Presto and other services in a backend Relational Database Management System (RDBMS) or Hadoop Distributed File System (HDFS).\n\nWhen you create a new table, information related to the schema such as column names, data types etc is stored in the metastore relational database. A metastore enables the user to see the data files in the HDFS object storage as if they are stored in tables with HMS.\n\nMetastore acts as a bridge between the schema of the table and the data files stored in object storages. HMS holds the definitions, schema, and other metadata for each table and maps the data files and directories to the table representation which is viewed by the user. Therefore, HMS is used as a storage location for the schema and tables. HMS is a metastore server that connects to the object storage to store data and keeps its related metadata on PostgreSQL.\n\nAny database with a JDBC driver can be used as a metastore. Presto makes requests through thrift protocol to HMS. The Presto instance reads and writes data to HMS. HMS supports 5 backend databases as follows. In IBM\u00ae watsonx.data, PostgreSQL database is used.\n\n\n\n*  Derby\n*  MySQL\n*  MS SQL Server\n*  Oracle\n*  PostgreSQL\n\n\n\nCurrently HMS in watsonx.data supports Iceberg table format.\n\nFollowing three modes of deployment are supported for HMS. In watsonx.data the remote mode is used.\n\n\n\n*  Embedded Metastore - Derby with singe session.\n*  Local Metastore - MySQl with multiple session accessible locally.\n*  Remote Metastore - metastore runs on its own separate JVM and accessible via thrift network APIs.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms_overview"},{"document_id":"ibmcld_13481-5443-6857","score":19.652403,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00029-8568-9861","score":19.051973,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00029-7-2023","score":18.753855,"text":"\nUsing IBM Cloud Data Engine as external metastore \n\nIBM Cloud Data Engine is IBM Cloud's central service for data lakes. It provides stream ingestion, data preparation, ETL, and data query from IBM Cloud Object Storage and Kafka. It also manages tables and views in a catalog that is compatible with Hive metastore and other big data engines and services can connect to it. See [Overview of IBM Cloud Data Engine](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nEach instance of IBM Cloud Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud Object Storage. Catalog syntax is compatible with Hive metastore syntax. You can use IBM Cloud Data Engine to externalize metadata outside the IBM Analytics Engine Spark cluster.\n\n\n\n Pre-requisites \n\nThe following are the pre-requisites:\n\n\n\n* Creating IBM Cloud Data Engine instance\n* Storing data in Cloud Object Storage\n* Creating schema\n\n\n\n\n\n Creating IBM Cloud Data Engine instance \n\n{: metastore-prerequisite_line1}\n\nCreate an IBM Cloud Data Engine instance by using the Standard plan.\u00a0See [Data Engine](http:\/\/cloud.ibm.com\/catalog\/services\/data-engine-previously-sql-query).\n\nAfter you have provisioned the Data Engine instance:\n1. Make a note of the CRN of the instance.\n1. Create an account-level API key or service ID level API key with access to the instance.\n1. This service ID should be granted access to both the Data Engine instance as well as the IBM Cloud Object Storage bucket.\n\nYou can then configure your IBM Analytics Engine instance to use the default metastore configuration either at instance level or at application level as needed.\n\nIBM Cloud Data Engine supports creating instances for different endpoints(location). Within an instance, different IBM Cloud Object Storage buckets are created to store data. The data buckets can be created for different end points(region). The endpoints for the data engine instance(thrift) and the data bucket are different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-4684-5710","score":18.154303,"text":"\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https:\/\/s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https:\/\/iam.cloud.ibm.com\/identity\/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"\/tmp\/dataengine\/\") \n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16636-0-1664","score":18.09036,"text":"\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside \/opt\/presto\/etc\/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift:\/\/<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hudi-conn"},{"document_id":"ibmcld_00032-0-1390","score":18.0505,"text":"\n\n\n\n\n\n\n  Working with Spark SQL and an external metastore \n\nSpark SQL uses Hive metastore to manage the metadata of a user's applications tables, columns, partition information.\n\nBy default, the database that powers this metastore is an embedded Derby instance that comes with the Spark cluster. You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n\nPlacing your metadata outside of the Spark cluster will enable you to reference the tables in different applications across your IBM Analytics Engine instances. This, in combination with storing your data in IBM Cloud Object Storage, helps persisting data and metadata and allows you to work with this data seamlessly across different Spark workloads.\n\n\n\n  Enabling and testing an external metastore with IBM Analytics Engine \n\nTo enable and test an external metastore with IBM Analytics Engine, you need to perform the following steps:\n\n\n\n1.  Create a metastore to store the metadata. You can choose to provision either an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n2.  Configure IBM Analytics Engine to work with the database instance.\n3.  Create a table in one Spark application and then access this table from another Spark application.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore"},{"document_id":"ibmcld_13481-3545-4909","score":17.900791,"text":"\ncurl -X POST https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<GUID of Analytic Engine>\/spark_applications --header \"Authorization: Bearer $TOKEN\" -H \"content-type: application\/json\" -d @listTablesExample.json\n\n\n\n\n\n Apache Spark Data Engine integration \n\nFor self-hosted Apache Spark installations use the following instructions.\n\n\n\n1. Ensure that [Stocator](https:\/\/github.com\/CODAIT\/stocator) is installed according to the instructions provided.\n2. Download the Hive-compatible client with the provided [instructions](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n3. Either download the [provided convenience libraries](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreconvenience_libraries) or, in case you don't want to use them, set the following settings in SparkContext yourself:\n\nspark = SparkSession.builder.appName('Python-App') \n.config(\"spark.sql.pyspark.jvmStacktrace.enabled\", True) \n.config(\"spark.hive.metastore.truststore.path\", \"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\") \n to access IBM Cloud Object Storage ensure that stocator is available\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-6629-7897","score":17.727928,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":18.23969,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_02597-3131-5174","score":15.054559,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_03749-1776-3774","score":14.452947,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_01705-7074-9036","score":14.295795,"text":"\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_03107-9852-11228","score":14.118502,"text":"\nTo upgrade your plan, click Upgrade from the page header before your trial period ends.\n* For all other plan types, click Manage![user icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon.png), and then choose Upgrade from the menu.\n\n\n\n2. From here, you can see other available plan options. For most plan types, you can step through the upgrade process yourself.\n\n\n\n* If you upgrade to an Enterprise with Data Isolation plan, you cannot do an in-place upgrade of your service instance. An Enterprise with Data Isolation plan instance must be provisioned for you first.\n* When you upgrade from a legacy Standard plan, you change the metrics that are used for billing purposes. Instead of basing billing on API usage, the Plus plan bases billing on the number of monthly active users. If you built a custom app to deploy your assistant, you might need to update the app. Ensure that the API calls from the app include user ID information. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n* You cannot change from a Trial plan to a Lite plan.\n\n\n\n\n\nFor answers to common questions about subscriptions, see the [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03776-8303-10233","score":14.113345,"text":"\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nFor more information about invoices, see [Managing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices).\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers with a Subscription account can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\nPremium and advanced support options are available for Pay as you go with Committed Use. Support plan pricing falls into two tiers depending on the price level of your commitment. For more information, see [Support options for Pay as you go with Committed Use](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03704-1531-3564","score":13.859232,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16252-10129-10965","score":13.534995,"text":"\nAn Enterprise with Data Isolation plan instance must be provisioned for you first.\n* When you upgrade from a legacy Standard plan, you change the metrics that are used for billing purposes. Instead of basing billing on API usage, the Plus plan bases billing on the number of monthly active users. If you built a custom app to deploy your assistant, you might need to update the app. Ensure that the API calls from the app include user ID information. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n* You cannot change from a Trial plan to a Lite plan.\n\n\n\n\n\nFor answers to common questions about subscriptions, see the [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_01447-3317-5285","score":13.375045,"text":"\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics. For more information about how billing works and what happens when you exceed service plan limits, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing).\n\n\n\nTable 2. Container Registry plans\n\n Characteristics Free Standard \n\n Description. Try out Container Registry to store and share your Docker images. This plan is the default service plan when you set up your first namespace in Container Registry. Benefit from unlimited storage and pull traffic usage to manage the Docker images for all namespaces in your IBM Cloud account. \n Amount of storage for images. 500 MB Unlimited \n Pull traffic. 5 GB per month Unlimited \n Billing. If you exceed your storage or pull traffic limits, you cannot push or pull images to and from your namespace. For more information, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing). Storage. You are charged by Gigabyte-Months of usage. The first 0.5 GB-Months are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog).<br><br>Pull traffic. You are charged by Gigabyte usage per month. The first 5 GB are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog). If you exceed your storage or pull traffic limits, you can't push or pull images to and from your namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_05012-7-2083","score":13.326233,"text":"\nFAQ - One Rate plans \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n What is the difference between a Standard and One Rate plan? \n\n\n\n* Standard plan is our most popular public Cloud pricing plan, that meets the requirements of majority of the enterprise workloads. The Standard plan is best suited for workloads that have large amount of storage and relatively small Outbound bandwidth (Outbound bandwidth < 20% of Storage capacity). The plan offers flexible choices for storage class based on data access patterns (lower the cost, the less frequently data is accessed). The Standard plan bills for every stored capacity ($\/GB\/month), Outbound bandwidth ($\/GB), class A ($\/1,000), class B ($\/10,000) and retrieval ($\/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions\/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($\/GB\/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n\n\n\n\n How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan? \n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05\/GBfor North America and Europe, $0.08\/GB for South America and Asia Pacific).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-onerate"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01623-6277-8255","score":17.452719,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_03735-7-1918","score":17.00866,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07578-278658-280528","score":16.53023,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-278632-280502","score":16.53023,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03735-1425-3233","score":16.157606,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_10116-17431-19145","score":15.878032,"text":"\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs \n\nThe following steps present a general process to manage costs for your Red Hat OpenShift on IBM Cloud clusters.\n\n\n\n1. Decide on a cloud platform strategy to manage your resources.\n\n\n\n* See [Best practices for billing and usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-best-practices).\n* Organize your billing with [resource groups](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs).\n* [Add tags to your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workerscluster_tags) according to your organizational strategy.\n\n\n\n2. Plan the type of cluster that you need.\n\n\n\n* [Size your cluster to support your workloads](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing), including the network bandwidth that your workloads need.\n* [Decide the cluster environment that you want](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategykube_env).\n* [Consider the availability that you want for your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clusters). For example, a basic high availability setup is one multizone cluster with two worker nodes in each of three zones, for a minimum total of 6 worker nodes.\n\n\n\n3. Check out other IBM Cloud services, add-ons, operators, and other third-party software that you might use that can increase your cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_07578-806120-808288","score":15.773499,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":15.773499,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11149-17131-19651","score":15.155958,"text":"\nStorage Products that support data to be created, read, updated, and deleted \n\n\n\nYou can also scope your view of the catalog by using the Provider filter to browse by individual providers and the Industry filter to view products catered for certain industries.\n\n\n\n\n\n\n\n Pricing and billing \n\nYou can view the pricing details for each service when you're browsing the catalog. If you choose a service plan with a paid plan, you can estimate your costs by using the cost estimator tool. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nIBM Cloud billing provides multiple services that ensure the IBM Cloud platform can securely manage pricing, accounts, usage, and more.\n\n\n\n Account management \n\nAccount management maintains the billing relationship with the customer. Each account is a billing entity that represents a customer. This service controls account lifecycle, subscription, user relationship, and organization.\n\n\n\n\n\n Usage metering \n\nWith usage metering, service providers can submit metrics that are collected for resource instances that are created by IBM Cloud users. Third-party service providers that deliver an integrated billing service are required to submit usage for all active service instances every hour.\n\n\n\n\n\n Usage reports \n\nUsage reports return the summary for the account for the specified month. Account billing managers are authorized to access the reports.\n\n\n\n\n\n\n\n Managing security and compliance \n\nThe IBM Cloud\u00ae Security and Compliance Center offers a single location where you can validate that your resources are meeting continuous security and compliance.\n\nYou can create profiles and config rules to ensure that specific areas of your business adhere to your defined requirements or industry regulations. From the Security and Compliance Center dashboard, you can download detailed reports that you can use to provide evidence to stakeholders or external auditors. The Security and Compliance Center also offers security insights that you can use to detect potential threats when observing your account activity. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n Creating resources \n\nThe resource controller is the next-generation IBM Cloud platform provisioning layer that manages the lifecycle of IBM Cloud resources in your account. Resources are created globally in an account scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_07578-506456-508701","score":15.044854,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.62405052,"ndcg_cut_10":0.62405052}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03798-0-2240","score":15.218192,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03797-4528-6268","score":15.001201,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_16315-6754-8418","score":14.858417,"text":"\n\"card_title\": \"Let\u2019s dispute a charge\",\n\"card_description\": \"Follow along with this guided journey to learn how to find and dispute charges.\",\n\"user_defined_type\": \"IBM_BETA_JOURNEYS_TOUR\",\n\"steps\":\n{\n\"response_type\": \"text\",\n\"text\": \"Charges are listed on the Transactions page. Click your profile photo in the top right corner of your screen, and then click Transactions from the menu.\"\n},\n{\n\"response_type\": \"text\",\n\"text\": \"Here you can view your charges.n Scroll through the Transactions page and review your charges. Each charge contains a merchant name, transaction date, and amount charged.\"\n},\n{\n\"response_type\": \"image\",\n\"source\": \"https:\/\/example.com\/image.png\",\n\"alt_text\": \"Image showing location of Dispute option\",\n\"description\": \"The option to Dispute is marked in red on the right hand side of each row in the Transactions table. Just click here to file a dispute.\"\n},\n{\n\"response_type\": \"video\",\n\"source\": \"https:\/\/vimeo.com\/769580398\",\n\"description\": \"Watch this short video to learn what to expect now that you\u2019ve filed a dispute.\"\n}\n]\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Starting a journey without opening the web chat \n\nAlthough journeys are part of the web chat integration, you can make it possible for your customers to start a journey directly from your website without opening the web chat window at all. For example, you might want to include a Show me button on your website that customers can click to launch an interactive tour of the page.\n\nTo start a journey without opening the web chat:\n\n\n\n1. In the action that sends the journey response, edit the JSON that defines the journey. Include \"skip_card\": true to bypass the introductory card.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-journeys"},{"document_id":"ibmcld_03797-3428-4809","score":14.283207,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03729-7-2197","score":13.933338,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03797-5893-7322","score":12.977686,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage),","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_11408-13151-14243","score":12.919231,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_02775-4830-5961","score":11.009822,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_03794-0-812","score":10.77447,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_12746-0-1760","score":9.555587,"text":"\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https:\/\/cloud.ibm.com\/security-compliance\/catalog) or [plan page](https:\/\/cloud.ibm.com\/security-compliance\/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scc-pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":23.404581,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-1672-3956","score":21.615978,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":21.564005,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_05666-7-2151","score":13.907802,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":13.575661,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_14546-1313-3289","score":13.442816,"text":"\nVMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.\n\nFor example, a single-zone on-demand virtual data center is created with a resource limit of 100 vCPU and 800 GB RAM. The data center has no VMs running on it, so you do not receive a charge for the vCPU and RAM. If an 8 vCPU with 8 GB virtual machine (VM) is started, metering is calculated for the size of that VM. If the VM uses fewer resources than the ones assigned to it, metering is applicable to the full size of the VM.\n\n\n\n\n\n Allocation \n\nMetering is applicable to the full potential size of the resource for the life of the resource.\n\nFor example, a single zone reserved virtual data center is created with a resource allocation of 100 vCPU and 800 GB RAM and no VMs are created or running on it. Metering is applicable to 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Monthly peak metric usage \n\nThe maximum value of the metric used over a full month.\n\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_05666-1575-3588","score":12.593056,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-1581-3594","score":12.593056,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_14546-7-1993","score":11.936311,"text":"\nVMware Shared pricing \n\nIBM Cloud\u00ae for VMware Solutions Shared offers two pricing plans for creating VMware\u00ae virtual data centers. Virtual data centers incur charges for the following virtual data center resource usages:\n\n\n\n* Storage allocations with tiered pricing based on storage performance\n* Virtual CPU (vCPU) usage\n* Virtual memory usage\n* Egress on public networking\n* Commercial operating system licenses used\n* Third-party VMware services\n\n\n\n\n\nTable 1. Pricing plans\n\n Plans Description \n\n VMware Shared On-demand <br><br> * The vCPU and RAM virtual data center are allocated based on the demand. Resources are not preallocated. If you have a large regional demand, delays in availability can occur.<br> <br> <br> <br> <br> * The limits that are established for the amount of vCPU and RAM are maximums.<br> * vCPU and RAM resource limits can be increased and decreased later as required.<br> * The price is calculated hourly and it is based on the resource usage in the virtual data center.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n VMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_14007-0-1917","score":10.039907,"text":"\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https:\/\/www.ibm.com\/cloud\/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12407-4383-5026","score":18.702103,"text":"\nTo update your service plan after you create an instance, see [Updating your service plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing).\n\n\n\n\n\n Upgrading a Secrets Manager instance to the Standard plan \n\nWhen your Trial instance expires, you lose access to your secrets, and integrations. To preserve your data, and prevent any disruptions in your workflow, you must upgrade to the Standard plan before your Trial plan expires. Follow the steps to [update your pricing plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing&interface=ui). You can use the UI, API, and CLI to complete this process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-create-instance&interface=ui"},{"document_id":"ibmcld_12858-3912-5854","score":17.827662,"text":"\n8. Select the broker that you want to link to this plan. If you haven't added a broker to your account, you can't link a broker to your plan. After you add a broker, you can link it by editing the pricing plan.\n9. Click Save.\n10. Click Add metrics.\n11. In the Usage metrics section, click Add metrics.\n12. Enter 1 as the smallest unit that customers pay.\n13. Select Instance as the unit.\n14. Enter Instance as the display name for the unit.\n15. Select Per unit as the charge method.\n16. Enter 1 as the USD price.\n17. Click Done.\n18. When you are ready to submit your pricing plan and metering for review, click Request update.\n\n\n\n\n\n\n\n Step 5: Add features for your service \n\nIf you completed the steps to define your pricing plan, you can add a list of features for your service. These features uniquely identify your product's attributes and differentiate your pricing plan from others. By providing a list of features for your product, you can help customers choose the most suitable pricing plan for their use case.\n\nYou can add up to five features for your product, but you must add at least one. The first feature that you add appears more prominently. Include the most important and differentiating details as the first feature.\n\nTo add features for your service, complete the following steps:\n\n\n\n1. Click Pricing.\n2. Select a pricing plan from the table that you previously added. After you select a plan, you are redirected to the Pricing plan details page.\n3. Click Add features.\n4. Enter a description for each feature.\n\n\n\n* You can remove any feature that you add by clicking Remove feature.\n\n\n\n5. Click Save.\n\n\n\n\n\n\n\n Step 6: Review and submit the digital platform reseller agreement \n\nIf you plan to offer usage-based pricing plans, it is required to review and submit the IBM Digital Platform Reseller Agreement. This legal agreement sets the terms and conditions under which providers can onboard and sell products in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-svc-pricing"},{"document_id":"ibmcld_03776-5228-7163","score":17.617807,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_02665-3418-5653","score":17.32844,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_11149-17131-19651","score":17.210318,"text":"\nStorage Products that support data to be created, read, updated, and deleted \n\n\n\nYou can also scope your view of the catalog by using the Provider filter to browse by individual providers and the Industry filter to view products catered for certain industries.\n\n\n\n\n\n\n\n Pricing and billing \n\nYou can view the pricing details for each service when you're browsing the catalog. If you choose a service plan with a paid plan, you can estimate your costs by using the cost estimator tool. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nIBM Cloud billing provides multiple services that ensure the IBM Cloud platform can securely manage pricing, accounts, usage, and more.\n\n\n\n Account management \n\nAccount management maintains the billing relationship with the customer. Each account is a billing entity that represents a customer. This service controls account lifecycle, subscription, user relationship, and organization.\n\n\n\n\n\n Usage metering \n\nWith usage metering, service providers can submit metrics that are collected for resource instances that are created by IBM Cloud users. Third-party service providers that deliver an integrated billing service are required to submit usage for all active service instances every hour.\n\n\n\n\n\n Usage reports \n\nUsage reports return the summary for the account for the specified month. Account billing managers are authorized to access the reports.\n\n\n\n\n\n\n\n Managing security and compliance \n\nThe IBM Cloud\u00ae Security and Compliance Center offers a single location where you can validate that your resources are meeting continuous security and compliance.\n\nYou can create profiles and config rules to ensure that specific areas of your business adhere to your defined requirements or industry regulations. From the Security and Compliance Center dashboard, you can download detailed reports that you can use to provide evidence to stakeholders or external auditors. The Security and Compliance Center also offers security insights that you can use to detect potential threats when observing your account activity. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n Creating resources \n\nThe resource controller is the next-generation IBM Cloud platform provisioning layer that manages the lifecycle of IBM Cloud resources in your account. Resources are created globally in an account scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_03776-8303-10233","score":17.210066,"text":"\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nFor more information about invoices, see [Managing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices).\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers with a Subscription account can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\nPremium and advanced support options are available for Pay as you go with Committed Use. Support plan pricing falls into two tiers depending on the price level of your commitment. For more information, see [Support options for Pay as you go with Committed Use](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12815-5234-7392","score":17.204681,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_12858-2498-4217","score":16.793388,"text":"\nIf you need help with selecting the UNSPSC for your service, see [How to select UNSPSC codes?](https:\/\/help.ungm.org\/hc\/en-us\/articles\/360013132940-How-to-select-UNSPSC-codes-) to find the one that applies to your product. For the purposes of this tutorial, select a common UNSPSC.\n\n\n\n1. Click Pricing > Add UNSPSC.\n2. Select Cloud-based software as a service.\n3. Click Add.\n\n\n\n\n\n\n\n Step 4: Define your pricing plan \n\nIBM Cloud supports two pricing models: free or usage-based. For the purposes of this tutorial, complete the following steps to add a usage-based plan.\n\nBy adding a usage-based pricing plan, you provide your suggested retail pricing information. However, IBM reserves the right to set the final pricing for any product that is offered to customers in the IBM Cloud catalog.\n\n\n\n1. Click Add plan.\n2. Select Usage-based as the type of plan.\n3. Enter a name for your plan. For the purposes of this tutorial, enter Usage-based. Plan names must be in English and can contain only alphanumeric characters, hyphens, spaces, and periods.\n4. Enter a description for your plan. Include any limitations that users must know. For example, The usage-based plan is for our upgraded services. This plan does not include our advanced features.\n5. Select Per-location for the deployment location.\n6. Select Specific locations to restrict deployment.\n7. Choose Dallas - Region, London - Region, and Osaka - Region.\n8. Select the broker that you want to link to this plan. If you haven't added a broker to your account, you can't link a broker to your plan. After you add a broker, you can link it by editing the pricing plan.\n9. Click Save.\n10. Click Add metrics.\n11. In the Usage metrics section, click Add metrics.\n12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-svc-pricing"},{"document_id":"ibmcld_12838-7607-9492","score":16.751127,"text":"\nAll plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Link a broker to the plan.\n\nIf you haven't finished adding a broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't complete your pricing plan until the broker is added and linked to your plan.\n9. Click Save.\n\n\n\n\n\n\n\n Adding a paid pricing plan \n\nBy adding a usage-based pricing plan, you are indicating that you offer your product as a paid integrated product, and customers need to pay to use it. All information that is entered on the Add plan panel is displayed to customers in the IBM Cloud catalog to help them purchase your service.\n\nWhen you add a usage-based pricing plan, you provide your suggested retail pricing information. However, IBM reserves the right to set the final pricing for any product that is offered to customers in the IBM Cloud catalog.\n\nTo add a paid pricing plan for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Click Add plan.\n4. Select Usage-based.\n5. Enter a name for your plan.\n6. Describe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-info"},{"document_id":"ibmcld_12815-6899-9236","score":16.594265,"text":"\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]\n\nThe next step is to add features that uniquely identify your product\u2019s attributes and differentiate this pricing plan from others. [Click Add feature to add more information about your pricing plan.]\n\nCheck your progress in the Onboarding checklist to make sure you\u2019ve completed all the required tasks. At this point, you\u2019re ready to submit your product for publishing approval. Submitting your request automatically notifies our onboarding team. The team will review the product details you provided to approve it for publishing, or they might request additional updates. [Click the name of your service in the breadcrumb menu, and click Checklist to open the Onboarding checklist. Click Request approval to request publishing approval for your product.]\n\nYou'll get an email with details about any changes that you might need to make.\n\nAfter your product is approved, return to Partner Center and publish it to the IBM Cloud catalog. Congratulations, your service is now ready and available to all users in the IBM Cloud catalog! [Click Publish to publish your service after you receive approval to do so.]\n\n\n\n\n\n\n\n Before you begin \n\nTo onboard your services to the IBM Cloud platform, you must be an approved IBM Cloud build partner. You can expand your network by receiving access to IBM\u2019s global ecosystem, receive insights to better engage customers, grow your business, and increase revenue. For more information on being an IBM Cloud build partner, see the [IBM Build Partner](https:\/\/www.ibm.com\/partnerworld\/public\/build) page.\n\nBesides being an IBM Cloud build partner, service onboarding is limited to providers who meet the following prerequisites due to current processing times:\n\n\n\n* Providers who leverage one or more services in the IBM Cloud catalog.\n* Providers who intend on selling their product in the IBM Cloud catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08067-0-1736","score":16.758837,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_03749-10273-12577","score":14.870852,"text":"\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice. If all of the credit in the credit pool is used, the invoice contains a line item for any overage charges.\n\nBecause all usage is invoiced through the enterprise account, child accounts within the enterprise don't receive separate invoices.\n\nYou can analyze usage costs for each account or account group on the Usage page in the enterprise account. For details, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Access management for enterprise billing and usage \n\nAs with other enterprise management roles, access to enterprise billing and usage is managed through the enterprise account. Users must be invited to the enterprise account and assigned an access policy with a role on the relevant service.\n\nIn an enterprise, billing access and usage access are assigned separately.\n\n\n\n* Billing access is provided by assigning enterprise users a role on the Billing account management service. For example, you can assign the Viewer role to an enterprise user so that they can view the amount of available subscription credit in the credit pool. If you would like an enterprise user to be able to add new subscriptions or manage payment methods, you can assign the Editor or Administrator role to them.\n* Usage access is provided by assigning enterprise users the Usage Reports Viewer, Editor, or Administrator role on the Enterprise account management service. You can assign this access for the entire enterprise or for specific account groups and accounts.\n\n\n\nIf you want your billing administrator to be able to view costs by account or account group, assign them the appropriate access on both the Enterprise service and Billing service.\n\nFor more information, see [Assigning access for enterprise management](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-assign-access-enterprise).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_03776-3313-5682","score":14.364498,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03749-8477-10695","score":14.053801,"text":"\nFor more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_07578-1033424-1035350","score":14.04268,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1033295-1035221","score":14.04268,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03729-7-2197","score":13.753557,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03787-5002-7004","score":12.86839,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03776-1678-3763","score":12.759061,"text":"\nIf you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page. You can download your latest invoice with all discounts and charges here or from the Invoices page.\n\nNow that you've walked through the common billing options and how to delegate billing administrator capabilities, track usage, and pay your bill, you're ready to start deciding what is best for your account. As always, if you need more information, check out the documentation for IBM Cloud billing and usage.\n\n\n\n\n\n How does billing work in IBM Cloud? \n\nIBM Cloud has two billable account types, Pay-As-You-Go and Subscription accounts. With a billable account, you can use IBM Cloud resources and services that incur costs. The account type that you choose impacts how you're billed for your resource usage.\n\nWhen you have a Pay-As-You-Go account, you're billed monthly for your resource usage. You pay only for what you use, with no long-term contracts. As your resource usage changes, so does your invoice, similar to a utility bill. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads.\n\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12561-5237-7143","score":12.692,"text":"\nIf you want to view usage for a specific account group or account, find the name or ID by running the ibmcloud enterprise command.\n\nFor example, the following command displays all account groups in an enterprise.\n\nibmcloud enterprise account-groups --recursive\n3. View usage by running the ibmcloud billing command as shown in the following examples.\n\n\n\n* View usage for the entire enterprise for the current month.\n\nibmcloud billing enterprise-usage\n* View usage for the Development account group for July 2019.\n\nibmcloud billing enterprise-usage --account-group Development --month 2019-07\n* View the usage for the account groups and accounts that are directly under the enterprise.\n\nibmcloud billing enterprise-usage --children\n\n\n\n\n\nBy default, the commands output the usage report for the current month in the following format. Most costs are listed as billable costs. Non-billable costs are listed only in rare cases, such as for the month when you add a trial account to the enterprise.\n\nName Type Billable Cost Non-billable Cost Currency Month\nExample Corp account 123.45 0 USD 2019-07\nDevelopment account_group 234.56 0 USD 2019-07\nMarketing account_group 345.67 0 USD 2019-07\nSales account_group 456.78 0 USD 2019-07\n\nYou can output the report in JSON format by specifying the --output JSON option.\n\n\n\n\n\n Viewing enterprise usage by using the API \n\nYou can get usage reports from an enterprise and its accounts by calling the [Enterprise Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports). You can base the query in your API call on an enterprise, an account group, or an account and specify whether to view the entity or its children.\n\nThe following examples show queries that you can use to get different usage reports. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03765-5710-7263","score":21.024395,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-7-1896","score":20.982649,"text":"\nManaging payments \n\nDepending on your account type, you can easily manage your payment methods by using the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud\u00ae console or by going to [IBM\u00ae Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nA valid credit card is required for all Pay-As-You-Go and Subscription accounts. Every month, the credit card is charged with the usage amount that is accumulated during that month. When updates to your payment details are approved, they are applied to your account within 24 hours. The contact that is specified in the billing address section receives an email confirming that the updates are applied.\n\nYou can contact IBM Cloud Support to get help with payment-related issues. From the console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/help.svg) > Support center, and then click Create a case to get in touch.\n\n\n\n Before you begin \n\nTo manage payments, you need to be assigned the operator role or higher on the billing account management service. See [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services) for more information.\n\n\n\n\n\n Managing payment methods for new US-based Pay-As-You-Go accounts with credit card billing \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-6753-8705","score":19.054766,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03704-4411-6289","score":19.006838,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1045891-1047755","score":18.884298,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":18.884298,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-3030-4892","score":17.786413,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03765-1346-3055","score":17.291416,"text":"\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.\n\n\n\nYou can\u2019t enter a PO Box as the billing address.\n\nWhen you add a new credit card, it becomes the default credit card. Recurring payments are charged to the default payment method.\n\nComplete the following steps to edit your active payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit menu.\n2. To edit the billing address, click Edit and update the billing address.\n3. To edit the card details, click Edit and update the card number or expiration date.\n\n\n\nYou can only have one address that's associated with your payment methods. All credit cards in the account will be updated to the same address.\n\nComplete the following steps to set a new default payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-4100-6125","score":16.891489,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_07578-1044428-1046278","score":16.85957,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.4441228664}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16727-1068047-1069909","score":24.081701,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03771-7-2029","score":22.762848,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03771-1594-3365","score":21.703108,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_07578-1065299-1067188","score":20.471207,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1066874-1068548","score":20.40178,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03771-2998-4769","score":19.462421,"text":"\nFor some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts \n\nIf you own one of the following accounts, you can view your invoice on the [Invoices@IBM](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the IBM console.\n\n\n\n* New and existing Pay-As-You-Go accounts that are based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nTo save a copy of your invoice, click the PDF icon in the Invoice Number column. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg).\n\n\n\n Getting access to Invoices@IBM \n\nIf you are attempting to access the [Invoices@IBM](http:\/\/ibm.com\/invoices) website for the first time, you can sign up with your IBMid, complete your profile, and provide your IBM customer number to access your account. Your IBM customer number is used for identification purposes during your registration process with the IBM Invoices page and during other interactions with [IBM Support](https:\/\/www.ibm.com\/support\/home\/).\n\nTo ensure that access is granted to the correct individuals, you must register using an email address that includes your company's domain, such as ibm.com. Requests using personal, non-company-specific email addresses might not be approved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_07578-1062822-1064465","score":19.252298,"text":"\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03764-7-1642","score":19.168064,"text":"\nFAQs for invoices \n\nReview the following FAQs to find helpful information about invoices. To find all FAQs for IBM Cloud\u00ae, see our [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n Where can I access my invoice? \n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n\n\n\n\n\n Why does my usage not match my invoice? \n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I manage my invoices? \n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_03795-7-1690","score":18.998959,"text":"\nWhy can't I view the invoices for my Pay-As-You-Go or Subscription account in the console? \n\nInvoices that are managed outside of the console can not be viewed by going to Manage > Billing and Usage > Invoices in the IBM Cloud console.\n\n What\u2019s happening \n\nAs a Pay-As-You-Go or Subscription account owner, you might not be able to view your invoices from the Invoices page in the IBM Cloud console.\n\nWhen you try to view your invoices, one of the following messages is displayed:\n\nYour invoices are managed through IBM.com.\n\nThis account is invoiced on a separate billing platform.\n\n Why it\u2019s happening \n\nIf you have a Pay-As-You-Go account that is billed in a currency other than US dollars or a Subscription account, you view your invoices on the [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/) website, which is linked from the Invoices page in the console.\n\n How to fix it \n\nIf you're visiting the Invoices website for the first time, sign up with your IBMid and complete your profile. Then, add access to your account with your IBM customer number.\n\n\n\n1. Go to [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/), and select your region.\n2. Log in with the same IBMid and password that you use to log in to IBM Cloud.\n3. Complete your profile on the Invoices website.\n4. From the Invoices website, go to the Accesses tab. Add access to your account and provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option or contact the [eCustomer Care team](https:\/\/www-112.ibm.com\/software\/howtobuy\/passportadvantage\/paocustomer\/docs\/en_US\/ecare.html) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice"},{"document_id":"ibmcld_03764-2220-3440","score":18.803074,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.592512032,"ndcg_cut_10":0.7315682115}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03710-0-838","score":25.904547,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_03786-7-2105","score":23.91668,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03786-1684-3421","score":22.669304,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_12597-0-804","score":22.387932,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03785-7-2010","score":22.144766,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_03787-5002-7004","score":20.860657,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03704-10459-12479","score":20.591562,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":20.474672,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1066746-1068772","score":20.441542,"text":"\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?\n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n* What happens if I spend my entire subscription amount before my term ends?\n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to sign up for a new subscription.\n* Is there a monthly minimum amount required for Subscription accounts?\n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n* Can I cancel my Subscription account before the end of my term commitment?\n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03732-0-1673","score":20.379625,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":23.116934,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03732-0-1673","score":21.424814,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03711-0-822","score":19.523304,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"},{"document_id":"ibmcld_03704-10459-12479","score":17.784359,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1051890-1053900","score":17.200558,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":17.200558,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1048947-1050776","score":16.863966,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1048818-1050647","score":16.863966,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-7496-9340","score":16.83691,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03704-8977-10890","score":16.377981,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-7-2194","score":19.34193,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_01660-2990-4730","score":19.292997,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n\n\n\n\n\n How do I upgrade my account? \n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1071351-1073249","score":18.47153,"text":"\nSome countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03713-1710-3705","score":18.410557,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_16727-1073973-1075745","score":18.309769,"text":"\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03782-0-720","score":17.753962,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03765-2725-4571","score":17.077742,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03713-7896-8949","score":16.991133,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_07578-1044428-1046278","score":16.920275,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":16.920275,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.6816587806}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":29.500626,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":29.07835,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":28.577415,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":23.29172,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":19.887627,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":19.775522,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_07578-1069800-1071727","score":17.064196,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1072450-1074392","score":16.45803,"text":"\nFor more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03782-0-720","score":15.938067,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_02273-0-665","score":14.736688,"text":"\n\n\n\n\n\n\n  Why can't I submit the form to add my credit card information? \n\nYou can't submit your credit card information to upgrade your Lite account to a billable account.\n\n  What\u2019s happening \n\nThe Upgrade account button is disabled.\n\n  Why it\u2019s happening \n\nThis problem happens when your information isn't entered correctly.\n\n  How to fix it \n\nComplete the following steps:\n\n\n\n1.  Complete all of the required fields to add your credit card and billing information in the IBM Cloud console.\n\nEnsure that you specified a business account and not a personal account type, if you are providing a VAT ID or tax identification number.\n2.  Click Upgrade account.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_addcc"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
